Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myvit', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.54379394335 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [6.02112e+05 0.00000e+00 0.00000e+00 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 3.07200e+03 3.07200e+03 3.07200e+03
 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119084652.15974277 119084652.15974277
All candidates indexes:  (array([15, 16, 17, 18]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.0029296875
17.314453125
Total layers size  104.46981048583984
Server, client, server+client, vanilla  899.79833984375 331.15380859375 1230.9521484375 4909.90380859375
Candidate split  16
Server, client, server+client, vanilla  899.79833984375 331.15380859375 1230.9521484375 4909.90380859375
Model size  327.36083984375
Fixed, scale_with_bsz  327.36083984375 17.888671875
Mem usage  1654.0 3.0
Using split index: 16
Freezing the lower layers of the model (myvit) till index 17
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.1483473777770996 seconds
Streaming plantleave data took 2.1490490436553955 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.328641414642334
Time for copying to cuda: 0.0004956722259521484
Memory occpied: (1654.0, 36.0)
Memory occpied: (1654.0, 534.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.056946039199829 seconds
Streaming plantleave data took 2.0577914714813232 seconds
Memory occpied: (1654.0, 1006.0)
Time for forward pass: 3.1486976146698
Time for backpropagation: 0.07449007034301758
GPU memory for training: 1.3174376487731934                          

One training iteration takes: 3.6069183349609375 seconds
Index: 0
Then, training+dataloading take 3.606982946395874 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.37240004539489746
Time for copying to cuda: 0.0005481243133544922
Time for forward pass: 0.033692359924316406
Time for backpropagation: 0.009310245513916016
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5228245258331299 seconds
Index: 1
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.1642038822174072 seconds
Streaming plantleave data took 2.1648762226104736 seconds
Then, training+dataloading take 2.165191888809204 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33736324310302734
Time for copying to cuda: 0.0004992485046386719
Time for forward pass: 0.03342938423156738
Time for backpropagation: 0.007889747619628906
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.46834659576416016 seconds
Index: 2
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 1.9991652965545654 seconds
Streaming plantleave data took 2.0000288486480713 seconds
Then, training+dataloading take 2.0006401538848877 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.3330979347229004
Time for copying to cuda: 0.0005052089691162109
Time for forward pass: 0.03336191177368164
Time for backpropagation: 0.007909536361694336
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.4435439109802246 seconds
Index: 3
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 1.9825496673583984 seconds
Streaming plantleave data took 1.9831047058105469 seconds
Then, training+dataloading take 1.9837067127227783 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.34068965911865234
Time for copying to cuda: 0.0005071163177490234
Time for forward pass: 0.05414581298828125
Time for backpropagation: 0.008728742599487305
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5186359882354736 seconds
Index: 4
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.1081154346466064 seconds
Streaming plantleave data took 2.108661413192749 seconds
Then, training+dataloading take 2.1091010570526123 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33411645889282227
Time for copying to cuda: 0.0004696846008300781
Time for forward pass: 0.03336143493652344
Time for backpropagation: 0.007900238037109375
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.45558595657348633 seconds
Index: 5
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 1.9465062618255615 seconds
Streaming plantleave data took 1.9473986625671387 seconds
Then, training+dataloading take 1.948164939880371 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.37819552421569824
Time for copying to cuda: 0.0005085468292236328
Time for forward pass: 0.03328204154968262
Time for backpropagation: 0.008039712905883789
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5043957233428955 seconds
Index: 6
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.0640869140625 seconds
Streaming plantleave data took 2.0646917819976807 seconds
Then, training+dataloading take 2.0653414726257324 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.35995936393737793
Time for copying to cuda: 0.0004992485046386719
Time for forward pass: 0.03327226638793945
Time for backpropagation: 0.007943391799926758
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.4824690818786621 seconds
Index: 7
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 1.8959977626800537 seconds
Streaming plantleave data took 1.8965613842010498 seconds
Then, training+dataloading take 1.897038221359253 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33724546432495117
Time for copying to cuda: 0.0005130767822265625
Time for forward pass: 0.033303260803222656
Time for backpropagation: 0.007842302322387695
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.45517516136169434 seconds
Index: 8
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.0726325511932373 seconds
Streaming plantleave data took 2.07318115234375 seconds
Then, training+dataloading take 2.073643684387207 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4211869239807129
Time for copying to cuda: 0.0005195140838623047
Memory occpied: (2422.0, 1660.0)
Time for forward pass: 0.033416748046875
Time for backpropagation: 0.007840633392333984
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5454871654510498 seconds
Index: 9
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.0293233394622803 seconds
Streaming plantleave data took 2.0298891067504883 seconds
Then, training+dataloading take 2.030339002609253 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33545875549316406
Time for copying to cuda: 0.00048732757568359375
Time for forward pass: 0.03327012062072754
Time for backpropagation: 0.00782465934753418
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.46534085273742676 seconds
Index: 10
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 1.937385082244873 seconds
Streaming plantleave data took 1.9379525184631348 seconds
Then, training+dataloading take 1.9384000301361084 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3751814365386963
Time for copying to cuda: 0.0005011558532714844
Time for forward pass: 0.03332042694091797
Time for backpropagation: 0.007919073104858398
GPU memory for training: 1.337742805480957                          

Memory occpied: (2422.0, 1660.0)
One training iteration takes: 0.5062358379364014 seconds
Index: 11
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.061431407928467 seconds
Streaming plantleave data took 2.0620248317718506 seconds
Then, training+dataloading take 2.062391996383667 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.34430384635925293
Time for copying to cuda: 0.0004904270172119141
Time for forward pass: 0.03325343132019043
Time for backpropagation: 0.007950782775878906
GPU memory for training: 1.337742805480957                          

Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.1013593673706055 seconds
Streaming plantleave data took 2.1022469997406006 seconds
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
One training iteration takes: 5.396403789520264 seconds
Index: 12
Then, training+dataloading take 5.396476984024048 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3788425922393799
Time for copying to cuda: 0.0005543231964111328
Time for forward pass: 0.0333552360534668
Time for backpropagation: 0.007980823516845703
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5452666282653809 seconds
Index: 13
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.0795185565948486 seconds
Streaming plantleave data took 2.080223798751831 seconds
Then, training+dataloading take 2.0805933475494385 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.34026622772216797
Time for copying to cuda: 0.00046181678771972656
Time for forward pass: 0.033271074295043945
Time for backpropagation: 0.007889986038208008
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.4671344757080078 seconds
Index: 14
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.1154277324676514 seconds
Streaming plantleave data took 2.116276264190674 seconds
Then, training+dataloading take 2.1168298721313477 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.3397054672241211
Time for copying to cuda: 0.0004894733428955078
Time for forward pass: 0.0667409896850586
Time for backpropagation: 0.008028268814086914
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.49579524993896484 seconds
Index: 15
Memory occpied: (2422.0, 1660.0)
Read 0.7588310241699219 MBs for this batch
Executing all posts took 2.0764241218566895 seconds
Streaming plantleave data took 2.076991558074951 seconds
Then, training+dataloading take 2.077605724334717 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3784191608428955
Time for copying to cuda: 0.0005125999450683594
Time for forward pass: 0.03367781639099121
Time for backpropagation: 0.008353471755981445
GPU memory for training: 1.337742805480957                          

One training iteration takes: 0.5381207466125488 seconds
Index: 16
Memory occpied: (2422.0, 1660.0)
Read 0.44469738006591797 MBs for this batch
Executing all posts took 1.5985565185546875 seconds
Streaming plantleave data took 1.5989396572113037 seconds
Then, training+dataloading take 1.5993092060089111 seconds

Epoch: 0
Time of next(dataloader) is: 0.37491369247436523
Time for copying to cuda: 0.0003952980041503906
Time for forward pass: 0.03349637985229492
Time for backpropagation: 0.007876873016357422
GPU memory for training: 1.337430477142334                          

Memory occpied: (2422.0, 1660.0)
The whole process took 50.055429220199585 seconds
