Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=20, model='mydensenet121', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4934034795798 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 3.211264e+06
 3.211264e+06 3.211264e+06 1.605632e+06 4.014080e+05 1.605632e+06
 1.605632e+06 1.605632e+06 8.028160e+05 2.007040e+05 8.028160e+05
 8.028160e+05 8.028160e+05 4.014080e+05 1.003520e+05 2.007040e+05
 2.007040e+05 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119078047.38087548 119078047.38087548
All candidates indexes:  (array([18, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 20
Intermediate:  0.095703125
6.125
Total layers size  29.763755798339844
Server, client, server+client, vanilla  355.76953125 1239.953125 1595.72265625 2930.453125
Candidate split  19
Server, client, server+client, vanilla  355.76953125 1239.953125 1595.72265625 2930.453125
Model size  27.03515625
Fixed, scale_with_bsz  27.03515625 10.27294921875
Mem usage  1318.0 3.0
Using split index: 19
Freezing the lower layers of the model (mydensenet121) till index 20
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1318.0, 3.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.1383717060089111 seconds
Streaming plantleave data took 1.1478221416473389 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Memory occpied: (1318.0, 3.0)
Time of next(dataloader) is: 0.407820463180542
Time for copying to cuda: 0.007599592208862305
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.958282470703125 seconds
Streaming plantleave data took 0.9682013988494873 seconds
Memory occpied: (1344.0, 456.0)
Memory occpied: (1344.0, 924.0)
Memory occpied: (2606.0, 2202.0)
Time for forward pass: 3.5808329582214355
Time for backpropagation: 0.06600451469421387
GPU memory for training: 1.3005084991455078                          

One training iteration takes: 4.123018741607666 seconds
Index: 0
Then, training+dataloading take 4.123078107833862 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3550899028778076
Time for copying to cuda: 0.006754159927368164
Time for forward pass: 0.04349255561828613
Time for backpropagation: 0.010242700576782227
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5131373405456543 seconds
Index: 1
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0729446411132812 seconds
Streaming plantleave data took 1.0828468799591064 seconds
Then, training+dataloading take 1.0835809707641602 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.369351863861084
Time for copying to cuda: 0.0064465999603271484
Time for forward pass: 0.04219365119934082
Time for backpropagation: 0.011983871459960938
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5040624141693115 seconds
Index: 2
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0202405452728271 seconds
Streaming plantleave data took 1.0304031372070312 seconds
Then, training+dataloading take 1.0314130783081055 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.42627978324890137
Time for copying to cuda: 0.006833076477050781
Time for forward pass: 0.05280303955078125
Time for backpropagation: 0.010415077209472656
GPU memory for training: 0.2554512023925781                          

Memory occpied: (2250.0, 1676.0)
One training iteration takes: 0.5822708606719971 seconds
Index: 3
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0463769435882568 seconds
Streaming plantleave data took 1.0525658130645752 seconds
Then, training+dataloading take 1.0534327030181885 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3900606632232666
Time for copying to cuda: 0.007285356521606445
Time for forward pass: 0.05014777183532715
Time for backpropagation: 0.019901275634765625
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5724353790283203 seconds
Index: 4
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.9349925518035889 seconds
Streaming plantleave data took 0.9409067630767822 seconds
Then, training+dataloading take 0.9414272308349609 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3729369640350342
Time for copying to cuda: 0.006703376770019531
Time for forward pass: 0.04867386817932129
Time for backpropagation: 0.012757062911987305
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5135788917541504 seconds
Index: 5
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0567357540130615 seconds
Streaming plantleave data took 1.062936782836914 seconds
Then, training+dataloading take 1.063389539718628 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.376110315322876
Time for copying to cuda: 0.0067138671875
Time for forward pass: 0.05111861228942871
Time for backpropagation: 0.02196669578552246
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5472009181976318 seconds
Index: 6
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0259432792663574 seconds
Streaming plantleave data took 1.03629732131958 seconds
Then, training+dataloading take 1.0374729633331299 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4367833137512207
Time for copying to cuda: 0.007079124450683594
Time for forward pass: 0.10562443733215332
Time for backpropagation: 0.010473251342773438
GPU memory for training: 0.2554512023925781                          

Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.036226749420166 seconds
Streaming plantleave data took 1.0479342937469482 seconds
Memory occpied: (2250.0, 1676.0)
Memory occpied: (2250.0, 1676.0)
Memory occpied: (2250.0, 1676.0)
Memory occpied: (2250.0, 1676.0)
One training iteration takes: 5.581128358840942 seconds
Index: 7
Then, training+dataloading take 5.581282615661621 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3657991886138916
Time for copying to cuda: 0.006854534149169922
Time for forward pass: 0.04822850227355957
Time for backpropagation: 0.010406017303466797
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5304946899414062 seconds
Index: 8
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.1230273246765137 seconds
Streaming plantleave data took 1.133051872253418 seconds
Then, training+dataloading take 1.1337945461273193 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Memory occpied: (2250.0, 1676.0)
Time of next(dataloader) is: 0.39075541496276855
Time for copying to cuda: 0.006561279296875
Time for forward pass: 0.05368661880493164
Time for backpropagation: 0.012406110763549805
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5423972606658936 seconds
Index: 9
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.9986052513122559 seconds
Streaming plantleave data took 1.0084774494171143 seconds
Then, training+dataloading take 1.009167194366455 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4103248119354248
Time for copying to cuda: 0.006667375564575195
Time for forward pass: 0.05074572563171387
Time for backpropagation: 0.011224985122680664
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5922048091888428 seconds
Index: 10
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.1264936923980713 seconds
Streaming plantleave data took 1.1326119899749756 seconds
Then, training+dataloading take 1.1332850456237793 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36664748191833496
Time for copying to cuda: 0.006723165512084961
Time for forward pass: 0.048828840255737305
Time for backpropagation: 0.012352943420410156
GPU memory for training: 0.2554512023925781                          

Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.047245740890503 seconds
Streaming plantleave data took 1.0570552349090576 seconds
Memory occpied: (2250.0, 1676.0)
Memory occpied: (2250.0, 1676.0)
Memory occpied: (2250.0, 1676.0)
One training iteration takes: 5.4494500160217285 seconds
Index: 11
Then, training+dataloading take 5.449531555175781 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Memory occpied: (2250.0, 1676.0)
Time of next(dataloader) is: 0.4511890411376953
Time for copying to cuda: 0.0075533390045166016
Time for forward pass: 0.050316810607910156
Time for backpropagation: 0.01797962188720703
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.6069786548614502 seconds
Index: 12
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.07155442237854 seconds
Streaming plantleave data took 1.081775426864624 seconds
Then, training+dataloading take 1.0823619365692139 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.39667773246765137
Time for copying to cuda: 0.00667572021484375
Time for forward pass: 0.05019426345825195
Time for backpropagation: 0.011397361755371094
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.6014785766601562 seconds
Index: 13
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0016796588897705 seconds
Streaming plantleave data took 1.0115728378295898 seconds
Then, training+dataloading take 1.011993646621704 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.37292027473449707
Time for copying to cuda: 0.00664520263671875
Time for forward pass: 0.05094718933105469
Time for backpropagation: 0.014997720718383789
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5435993671417236 seconds
Index: 14
Memory occpied: (2250.0, 1676.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.9852046966552734 seconds
Streaming plantleave data took 0.991389274597168 seconds
Then, training+dataloading take 0.9921431541442871 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.37702250480651855
Time for copying to cuda: 0.00674748420715332
Time for forward pass: 0.04956984519958496
Time for backpropagation: 0.012658119201660156
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.5497901439666748 seconds
Index: 15
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.0320804119110107 seconds
Streaming plantleave data took 1.042276382446289 seconds
Then, training+dataloading take 1.0434050559997559 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Memory occpied: (2250.0, 1676.0)
Time of next(dataloader) is: 0.38652729988098145
Time for copying to cuda: 0.0070002079010009766
Time for forward pass: 0.05142831802368164
Time for backpropagation: 0.011658430099487305
GPU memory for training: 0.2554512023925781                          

One training iteration takes: 0.533348560333252 seconds
Index: 16
Read 14.36253833770752 MBs for this batch
Executing all posts took 0.6025021076202393 seconds
Streaming plantleave data took 0.6082937717437744 seconds
Then, training+dataloading take 0.6091864109039307 seconds

Epoch: 0
Time of next(dataloader) is: 0.39810848236083984
Time for copying to cuda: 0.004031658172607422
Memory occpied: (2560.0, 1754.0)
Time for forward pass: 0.4249598979949951
Time for backpropagation: 0.024166345596313477
GPU memory for training: 1.017042636871338                          

The whole process took 38.39775013923645 seconds
