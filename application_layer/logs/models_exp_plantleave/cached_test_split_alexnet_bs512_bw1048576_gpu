Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=512, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5041572372814 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119079456.89740495 119079456.89740495
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  283.43798828125 582.75830078125 866.1962890625 1569.63330078125
Candidate split  6
Server, client, server+client, vanilla  283.43798828125 582.75830078125 866.1962890625 1569.63330078125
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 512, post_step 64

Memory occpied: (1500.0, 3.0)
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.2512831687927246 seconds
Streaming plantleave data took 1.2757585048675537 seconds
The mode is:  split
Start 512, end 1024, post_step 64


Epoch: 0
Memory occpied: (1500.0, 3.0)
Time of next(dataloader) is: 0.27952003479003906
Time for copying to cuda: 0.017279386520385742
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1464080810546875 seconds
Streaming plantleave data took 1.2029633522033691 seconds
Memory occpied: (1564.0, 460.0)
Memory occpied: (1564.0, 902.0)
Memory occpied: (2644.0, 2496.0)
Time for forward pass: 3.6447627544403076
Time for backpropagation: 0.05730438232421875
GPU memory for training: 2.8516130447387695                          

One training iteration takes: 4.070686340332031 seconds
Index: 0
Then, training+dataloading take 4.070950746536255 seconds
The mode is:  split
Start 1024, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.30970168113708496
Time for copying to cuda: 0.016979694366455078
Time for forward pass: 0.05202436447143555
Time for backpropagation: 0.002851247787475586
GPU memory for training: 1.703878402709961                          

Memory occpied: (2952.0, 2512.0)
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1755988597869873 seconds
Streaming plantleave data took 1.1998767852783203 seconds
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
One training iteration takes: 5.4043169021606445 seconds
Index: 1
Then, training+dataloading take 5.404438495635986 seconds
The mode is:  split
Start 1536, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.32450318336486816
Time for copying to cuda: 0.016860008239746094
Time for forward pass: 0.07698678970336914
Time for backpropagation: 0.0026252269744873047
GPU memory for training: 1.703878402709961                          

Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1596052646636963 seconds
Memory occpied: (2952.0, 2512.0)
Streaming plantleave data took 1.1838793754577637 seconds
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
One training iteration takes: 5.443166732788086 seconds
Index: 2
Then, training+dataloading take 5.4446351528167725 seconds
The mode is:  split
Start 2048, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3238863945007324
Time for copying to cuda: 0.01662302017211914
Time for forward pass: 0.07835888862609863
Time for backpropagation: 0.0031633377075195312
GPU memory for training: 1.703878402709961                          

Memory occpied: (2952.0, 2512.0)
One training iteration takes: 0.5067117214202881 seconds
Index: 3
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.0674827098846436 seconds
Streaming plantleave data took 1.0922753810882568 seconds
Then, training+dataloading take 1.094848871231079 seconds
The mode is:  split
Start 2560, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.32680583000183105
Time for copying to cuda: 0.016353845596313477
Time for forward pass: 0.0778050422668457
Time for backpropagation: 0.0031974315643310547
GPU memory for training: 1.703878402709961                          

Memory occpied: (2952.0, 2512.0)
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1088619232177734 seconds
Streaming plantleave data took 1.1327857971191406 seconds
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
One training iteration takes: 5.444432973861694 seconds
Index: 4
Then, training+dataloading take 5.444587469100952 seconds
The mode is:  split
Start 3072, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33289146423339844
Time for copying to cuda: 0.01711726188659668
Time for forward pass: 0.07728147506713867
Time for backpropagation: 0.002935647964477539
GPU memory for training: 1.703878402709961                          

Memory occpied: (2952.0, 2512.0)
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1394760608673096 seconds
Streaming plantleave data took 1.1634852886199951 seconds
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
One training iteration takes: 5.46391224861145 seconds
Index: 5
Then, training+dataloading take 5.464035272598267 seconds
The mode is:  split
Start 3584, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36395788192749023
Time for copying to cuda: 0.016823768615722656
Time for forward pass: 0.07700371742248535
Time for backpropagation: 0.0028486251831054688
GPU memory for training: 1.703878402709961                          

Memory occpied: (2952.0, 2512.0)
Read 63.39838409423828 MBs for this batch
Executing all posts took 1.1157152652740479 seconds
Streaming plantleave data took 1.1399004459381104 seconds
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
Memory occpied: (2952.0, 2512.0)
One training iteration takes: 5.480473041534424 seconds
Index: 6
Then, training+dataloading take 5.481809854507446 seconds
The mode is:  split
Start 4096, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3229672908782959
Time for copying to cuda: 0.016699790954589844
Time for forward pass: 0.07697582244873047
Time for backpropagation: 0.0025806427001953125
GPU memory for training: 1.703878402709961                          

One training iteration takes: 0.5068118572235107 seconds
Index: 7
Read 50.2730131149292 MBs for this batch
Executing all posts took 1.041649580001831 seconds
Memory occpied: (2952.0, 2512.0)
Streaming plantleave data took 1.0612828731536865 seconds
Then, training+dataloading take 1.0638413429260254 seconds

Epoch: 0
Time of next(dataloader) is: 0.31361842155456543
Time for copying to cuda: 0.013281822204589844
Time for forward pass: 0.4587717056274414
Time for backpropagation: 0.008814334869384766
GPU memory for training: 2.6404223442077637                          

The whole process took 41.99160957336426 seconds
