Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=11, model='myresnet18', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.458599973189 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 4.816896e+06
 4.816896e+06 2.408448e+06 2.408448e+06 1.204224e+06 1.204224e+06
 6.021120e+05 6.021120e+05 2.048000e+03 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119073485.61568584 119073485.61568584
All candidates indexes:  (array([12, 13]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 11
Intermediate:  0.095703125
6.125
Total layers size  27.181724548339844
Server, client, server+client, vanilla  257.10498046875 117.27294921875 374.3779296875 1807.77294921875
Fixed, scale_with_bsz  0 6.69921875
Mem usage  1336.0 3.0
Using split index: 11
Freezing the lower layers of the model (myresnet18) till index 11
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1336.0, 3.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.609344482421875 seconds
Streaming plantleave data took 0.619128942489624 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3244438171386719
Time for copying to cuda: 0.0078105926513671875
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5261061191558838 seconds
Streaming plantleave data took 0.5363287925720215 seconds
Memory occpied: (1362.0, 212.0)
Memory occpied: (1362.0, 664.0)
Memory occpied: (1362.0, 1100.0)
Time for forward pass: 3.419842481613159
Time for backpropagation: 0.2671794891357422
GPU memory for training: 3.379058361053467                          

One training iteration takes: 4.096994400024414 seconds
Index: 0
Then, training+dataloading take 4.097059965133667 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3910400867462158
Time for copying to cuda: 0.007346153259277344
Time for forward pass: 0.0173492431640625
Time for backpropagation: 0.00510096549987793
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5365264415740967 seconds
Index: 1
Memory occpied: (1474.0, 2968.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6241402626037598 seconds
Streaming plantleave data took 0.6340851783752441 seconds
Then, training+dataloading take 0.6345770359039307 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3716263771057129
Time for copying to cuda: 0.006988525390625
Time for forward pass: 0.012809038162231445
Time for backpropagation: 0.0055980682373046875
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.47663283348083496 seconds
Index: 2
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5491483211517334 seconds
Streaming plantleave data took 0.5592987537384033 seconds
Then, training+dataloading take 0.5596661567687988 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3927748203277588
Time for copying to cuda: 0.006885528564453125
Time for forward pass: 0.061904191970825195
Time for backpropagation: 0.0068395137786865234
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5896546840667725 seconds
Index: 3
Memory occpied: (1706.0, 2968.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.654987096786499 seconds
Streaming plantleave data took 0.6610748767852783 seconds
Then, training+dataloading take 0.6616442203521729 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36649465560913086
Time for copying to cuda: 0.006860971450805664
Time for forward pass: 0.018117666244506836
Time for backpropagation: 0.004889965057373047
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.47376132011413574 seconds
Index: 4
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5463161468505859 seconds
Streaming plantleave data took 0.556250810623169 seconds
Then, training+dataloading take 0.5566024780273438 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3689889907836914
Time for copying to cuda: 0.0071222782135009766
Time for forward pass: 0.022478103637695312
Time for backpropagation: 0.005925178527832031
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5036134719848633 seconds
Index: 5
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6393330097198486 seconds
Streaming plantleave data took 0.6508147716522217 seconds
Then, training+dataloading take 0.6515004634857178 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Memory occpied: (1706.0, 2968.0)
Time of next(dataloader) is: 0.37415599822998047
Time for copying to cuda: 0.007078886032104492
Time for forward pass: 0.01719522476196289
Time for backpropagation: 0.005343914031982422
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5004673004150391 seconds
Index: 6
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5516393184661865 seconds
Streaming plantleave data took 0.5615720748901367 seconds
Then, training+dataloading take 0.5619997978210449 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.37466859817504883
Time for copying to cuda: 0.0072634220123291016
Time for forward pass: 0.019435405731201172
Time for backpropagation: 0.005206584930419922
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5300724506378174 seconds
Index: 7
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5898759365081787 seconds
Streaming plantleave data took 0.5963687896728516 seconds
Then, training+dataloading take 0.5970358848571777 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4534568786621094
Time for copying to cuda: 0.0070688724517822266
Time for forward pass: 0.017246484756469727
Time for backpropagation: 0.004838466644287109
GPU memory for training: 0.45867156982421875                          

Memory occpied: (1706.0, 2968.0)
One training iteration takes: 0.5709013938903809 seconds
Index: 8
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6077802181243896 seconds
Streaming plantleave data took 0.6177487373352051 seconds
Then, training+dataloading take 0.6181137561798096 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4019949436187744
Time for copying to cuda: 0.007287263870239258
Time for forward pass: 0.0175931453704834
Time for backpropagation: 0.005067586898803711
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5129308700561523 seconds
Index: 9
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5628108978271484 seconds
Streaming plantleave data took 0.5689268112182617 seconds
Then, training+dataloading take 0.5695104598999023 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.37782979011535645
Time for copying to cuda: 0.05086946487426758
Time for forward pass: 0.0196688175201416
Time for backpropagation: 0.0061244964599609375
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5764238834381104 seconds
Index: 10
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6400277614593506 seconds
Memory occpied: (1706.0, 2968.0)
Streaming plantleave data took 0.650137186050415 seconds
Then, training+dataloading take 0.6504998207092285 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3905928134918213
Time for copying to cuda: 0.007149457931518555
Time for forward pass: 0.020762920379638672
Time for backpropagation: 0.005253791809082031
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.4974377155303955 seconds
Index: 11
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5385520458221436 seconds
Streaming plantleave data took 0.5446481704711914 seconds
Then, training+dataloading take 0.5452475547790527 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4004669189453125
Time for copying to cuda: 0.007196903228759766
Time for forward pass: 0.017160892486572266
Time for backpropagation: 0.00992131233215332
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.511296272277832 seconds
Index: 12
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6483063697814941 seconds
Streaming plantleave data took 0.6584861278533936 seconds
Then, training+dataloading take 0.6590750217437744 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Memory occpied: (1706.0, 2968.0)
Memory occpied: (1706.0, 2968.0)
Time of next(dataloader) is: 0.41478610038757324
Time for copying to cuda: 0.00704646110534668
Time for forward pass: 0.017510652542114258
Time for backpropagation: 0.0049495697021484375
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5317373275756836 seconds
Index: 13
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.5815629959106445 seconds
Streaming plantleave data took 0.5876481533050537 seconds
Then, training+dataloading take 0.588463306427002 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4220445156097412
Time for copying to cuda: 0.007208585739135742
Time for forward pass: 0.017500877380371094
Time for backpropagation: 0.005065202713012695
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5372419357299805 seconds
Index: 14
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.6694419384002686 seconds
Streaming plantleave data took 0.6797173023223877 seconds
Then, training+dataloading take 0.6806695461273193 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Memory occpied: (1706.0, 2968.0)
Time of next(dataloader) is: 0.4155435562133789
Time for copying to cuda: 0.0071790218353271484
Time for forward pass: 0.017394304275512695
Time for backpropagation: 0.008496999740600586
GPU memory for training: 0.45867156982421875                          

One training iteration takes: 0.5249509811401367 seconds
Index: 15
Read 24.51193618774414 MBs for this batch
Executing all posts took 0.560723066329956 seconds
Streaming plantleave data took 0.5668683052062988 seconds
Then, training+dataloading take 0.5677852630615234 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.40042924880981445
Time for copying to cuda: 0.007067680358886719
Time for forward pass: 0.017714977264404297
Time for backpropagation: 0.004900693893432617
GPU memory for training: 0.45867156982421875                          

Read 14.36253833770752 MBs for this batch
Executing all posts took 0.4680216312408447 seconds
Streaming plantleave data took 0.4742097854614258 seconds
One training iteration takes: 0.5346109867095947 seconds
Index: 16
Then, training+dataloading take 0.5347628593444824 seconds

Epoch: 0
Time of next(dataloader) is: 0.39145922660827637
Time for copying to cuda: 0.004057168960571289
Time for forward pass: 0.14004898071289062
Time for backpropagation: 0.17577242851257324
GPU memory for training: 2.923328399658203                          

Memory occpied: (1706.0, 2968.0)
The whole process took 22.260740756988525 seconds
