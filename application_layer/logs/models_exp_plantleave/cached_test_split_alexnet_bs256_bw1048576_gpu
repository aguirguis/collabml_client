Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5112411656721 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119080385.40206698 119080385.40206698
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  283.43798828125 400.27783203125 683.7158203125 893.71533203125
Candidate split  6
Server, client, server+client, vanilla  283.43798828125 400.27783203125 683.7158203125 893.71533203125
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1500.0, 3.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8473920822143555 seconds
Streaming plantleave data took 0.8598906993865967 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3850240707397461
Time for copying to cuda: 0.009435892105102539
Memory occpied: (1532.0, 22.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8321359157562256 seconds
Streaming plantleave data took 0.8446524143218994 seconds
Memory occpied: (1532.0, 590.0)
Memory occpied: (1532.0, 1002.0)
Time for forward pass: 3.5458133220672607
Time for backpropagation: 0.10970735549926758
GPU memory for training: 2.0372190475463867                          

One training iteration takes: 4.1352927684783936 seconds
Index: 0
Then, training+dataloading take 4.135452508926392 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Memory occpied: (2450.0, 1538.0)
Time of next(dataloader) is: 0.3571932315826416
Time for copying to cuda: 0.008830785751342773
Time for forward pass: 0.03618979454040527
Time for backpropagation: 0.0026998519897460938
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.47913241386413574 seconds
Index: 1
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8076441287994385 seconds
Streaming plantleave data took 0.8204522132873535 seconds
Then, training+dataloading take 0.8210358619689941 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3892035484313965
Time for copying to cuda: 0.008801460266113281
Time for forward pass: 0.0362238883972168
Time for backpropagation: 0.0027823448181152344
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5203237533569336 seconds
Index: 2
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7954626083374023 seconds
Streaming plantleave data took 0.807781457901001 seconds
Then, training+dataloading take 0.8081803321838379 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3946089744567871
Time for copying to cuda: 0.00870823860168457
Time for forward pass: 0.04612874984741211
Time for backpropagation: 0.002493143081665039
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5359721183776855 seconds
Index: 3
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.758528470993042 seconds
Streaming plantleave data took 0.7665486335754395 seconds
Then, training+dataloading take 0.7669186592102051 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4581599235534668
Time for copying to cuda: 0.008652687072753906
Time for forward pass: 0.04603004455566406
Time for backpropagation: 0.002550840377807617
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.6342563629150391 seconds
Index: 4
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8355977535247803 seconds
Streaming plantleave data took 0.8431155681610107 seconds
Then, training+dataloading take 0.8435091972351074 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36177587509155273
Time for copying to cuda: 0.008514404296875
Time for forward pass: 0.04615211486816406
Time for backpropagation: 0.0025207996368408203
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5207438468933105 seconds
Index: 5
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7615396976470947 seconds
Streaming plantleave data took 0.769385576248169 seconds
Then, training+dataloading take 0.7697746753692627 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.45193982124328613
Memory occpied: (2460.0, 1914.0)
Time for copying to cuda: 0.008765935897827148
Time for forward pass: 0.04605722427368164
Time for backpropagation: 0.0027718544006347656
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5991706848144531 seconds
Index: 6
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7901425361633301 seconds
Streaming plantleave data took 0.7977077960968018 seconds
Then, training+dataloading take 0.7980740070343018 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.38057851791381836
Time for copying to cuda: 0.008652448654174805
Time for forward pass: 0.04611635208129883
Time for backpropagation: 0.0024771690368652344
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5446372032165527 seconds
Index: 7
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.9125752449035645 seconds
Streaming plantleave data took 0.9205687046051025 seconds
Then, training+dataloading take 0.9209768772125244 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3712031841278076
Time for copying to cuda: 0.00868678092956543
Time for forward pass: 0.046088457107543945
Time for backpropagation: 0.002506256103515625
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5302872657775879 seconds
Index: 8
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7561848163604736 seconds
Streaming plantleave data took 0.7637248039245605 seconds
Then, training+dataloading take 0.7640862464904785 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.44984960556030273
Time for copying to cuda: 0.008760452270507812
Time for forward pass: 0.046161651611328125
Time for backpropagation: 0.007122516632080078
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.652324914932251 seconds
Index: 9
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7892165184020996 seconds
Streaming plantleave data took 0.7972073554992676 seconds
Then, training+dataloading take 0.7976634502410889 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3736910820007324
Time for copying to cuda: 0.008656024932861328
Time for forward pass: 0.046135663986206055
Time for backpropagation: 0.0025014877319335938
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5068302154541016 seconds
Index: 10
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7603859901428223 seconds
Streaming plantleave data took 0.7679131031036377 seconds
Then, training+dataloading take 0.7683067321777344 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4274461269378662
Time for copying to cuda: 0.008689641952514648
Time for forward pass: 0.046250104904174805
Time for backpropagation: 0.0026502609252929688
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.6117684841156006 seconds
Index: 11
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8905375003814697 seconds
Streaming plantleave data took 0.8986029624938965 seconds
Then, training+dataloading take 0.8990094661712646 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.364915132522583
Time for copying to cuda: 0.008500814437866211
Time for forward pass: 0.04614520072937012
Time for backpropagation: 0.0025131702423095703
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.49777841567993164 seconds
Index: 12
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.8477065563201904 seconds
Streaming plantleave data took 0.8629302978515625 seconds
Then, training+dataloading take 0.8635039329528809 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Memory occpied: (2460.0, 1914.0)
Time of next(dataloader) is: 0.40707993507385254
Time for copying to cuda: 0.008570671081542969
Time for forward pass: 0.046121835708618164
Time for backpropagation: 0.002521514892578125
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5448908805847168 seconds
Index: 13
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7852685451507568 seconds
Streaming plantleave data took 0.79319167137146 seconds
Then, training+dataloading take 0.7936418056488037 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3630561828613281
Time for copying to cuda: 0.008620262145996094
Time for forward pass: 0.046146392822265625
Time for backpropagation: 0.002579212188720703
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5218334197998047 seconds
Index: 14
Memory occpied: (2460.0, 1914.0)
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.844620943069458 seconds
Streaming plantleave data took 0.8521833419799805 seconds
Then, training+dataloading take 0.8526065349578857 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36762547492980957
Time for copying to cuda: 0.008532047271728516
Time for forward pass: 0.04613924026489258
Time for backpropagation: 0.002531766891479492
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.5179839134216309 seconds
Index: 15
Read 31.69919204711914 MBs for this batch
Executing all posts took 0.7554295063018799 seconds
Streaming plantleave data took 0.763420820236206 seconds
Then, training+dataloading take 0.7638015747070312 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.40875959396362305
Time for copying to cuda: 0.008597373962402344
Time for forward pass: 0.046289920806884766
Time for backpropagation: 0.002866983413696289
GPU memory for training: 1.2656989097595215                          

One training iteration takes: 0.6136667728424072 seconds
Index: 16
Read 18.57382106781006 MBs for this batch
Executing all posts took 0.6689023971557617 seconds
Streaming plantleave data took 0.6732313632965088 seconds
Then, training+dataloading take 0.6735894680023193 seconds

Epoch: 0
Memory occpied: (2460.0, 1914.0)
Memory occpied: (2460.0, 1914.0)
Time of next(dataloader) is: 0.3760044574737549
Time for copying to cuda: 0.005141735076904297
Time for forward pass: 0.25296759605407715
Time for backpropagation: 0.0032541751861572266
GPU memory for training: 1.8260283470153809                          

The whole process took 25.344131469726562 seconds
