Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=25, model='myvgg11', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.998073947958 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 3.2112640e+06 6.4225280e+06 6.4225280e+06
 1.6056320e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 8.0281600e+05 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119013123.54850675 119013123.54850675
All candidates indexes:  (array([20, 21, 22, 23, 24, 25, 26, 27, 28]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 25
Intermediate:  0.095703125
24.5
Total layers size  62.683677673339844
Server, client, server+client, vanilla  1293.92431640625 589.09228515625 1883.0166015625 6983.59228515625
Candidate split  21
Server, client, server+client, vanilla  1293.92431640625 589.09228515625 1883.0166015625 6983.59228515625
Model size  491.54931640625
Fixed, scale_with_bsz  491.54931640625 25.07421875
Mem usage  1824.0 3.0
Using split index: 21
Freezing the lower layers of the model (myvgg11) till index 25
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1824.0, 3.0)
Memory occpied: (1824.0, 3.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 2.0472640991210938 seconds
Streaming plantleave data took 2.05705189704895 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3357198238372803
Time for copying to cuda: 0.007397174835205078
Memory occpied: (1850.0, 116.0)
Memory occpied: (1850.0, 596.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.959592342376709 seconds
Streaming plantleave data took 1.9696190357208252 seconds
Memory occpied: (1850.0, 1058.0)
Time for forward pass: 3.1945855617523193
Time for backpropagation: 0.05392718315124512
GPU memory for training: 1.972815990447998                          

One training iteration takes: 3.668672800064087 seconds
Index: 0
Then, training+dataloading take 3.668745517730713 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4275398254394531
Time for copying to cuda: 0.006762266159057617
Time for forward pass: 0.060516357421875
Time for backpropagation: 0.0030341148376464844
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.6075057983398438 seconds
Index: 1
Memory occpied: (3036.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9319450855255127 seconds
Streaming plantleave data took 1.9417827129364014 seconds
Then, training+dataloading take 1.9423003196716309 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3611884117126465
Time for copying to cuda: 0.0067250728607177734
Time for forward pass: 0.06053972244262695
Time for backpropagation: 0.002991914749145508
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.52433180809021 seconds
Index: 2
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.952707052230835 seconds
Streaming plantleave data took 1.9626672267913818 seconds
Then, training+dataloading take 1.963087558746338 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4074535369873047
Time for copying to cuda: 0.006689786911010742
Time for forward pass: 0.06058812141418457
Time for backpropagation: 0.0030503273010253906
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.614220380783081 seconds
Index: 3
Memory occpied: (3438.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 2.010223388671875 seconds
Streaming plantleave data took 2.016362428665161 seconds
Then, training+dataloading take 2.0170531272888184 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3853487968444824
Time for copying to cuda: 0.006659507751464844
Time for forward pass: 0.060553550720214844
Time for backpropagation: 0.002923250198364258
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5425827503204346 seconds
Index: 4
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.887986183166504 seconds
Streaming plantleave data took 1.8942856788635254 seconds
Then, training+dataloading take 1.894721269607544 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4117593765258789
Time for copying to cuda: 0.006795644760131836
Time for forward pass: 0.06046104431152344
Time for backpropagation: 0.0029299259185791016
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.6199350357055664 seconds
Index: 5
Memory occpied: (3438.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9447247982025146 seconds
Streaming plantleave data took 1.950930118560791 seconds
Then, training+dataloading take 1.9515111446380615 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36879920959472656
Time for copying to cuda: 0.006896257400512695
Time for forward pass: 0.060672760009765625
Time for backpropagation: 0.0031561851501464844
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5341348648071289 seconds
Index: 6
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.992518424987793 seconds
Streaming plantleave data took 2.002483367919922 seconds
Then, training+dataloading take 2.0028936862945557 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4160268306732178
Time for copying to cuda: 0.006589651107788086
Time for forward pass: 0.06053280830383301
Time for backpropagation: 0.0030307769775390625
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5814874172210693 seconds
Index: 7
Memory occpied: (3438.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9404735565185547 seconds
Streaming plantleave data took 1.946627140045166 seconds
Then, training+dataloading take 1.9473235607147217 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3615233898162842
Time for copying to cuda: 0.0067043304443359375
Time for forward pass: 0.06064963340759277
Time for backpropagation: 0.0029151439666748047
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5186338424682617 seconds
Index: 8
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.8813188076019287 seconds
Streaming plantleave data took 1.8912513256072998 seconds
Then, training+dataloading take 1.891711950302124 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4327385425567627
Time for copying to cuda: 0.006804466247558594
Time for forward pass: 0.06078290939331055
Time for backpropagation: 0.0032546520233154297
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.6441223621368408 seconds
Index: 9
Memory occpied: (3438.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 2.0274128913879395 seconds
Streaming plantleave data took 2.0335288047790527 seconds
Then, training+dataloading take 2.0341622829437256 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3809659481048584
Time for copying to cuda: 0.006802082061767578
Time for forward pass: 0.060640811920166016
Time for backpropagation: 0.0032956600189208984
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5407097339630127 seconds
Index: 10
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.885507345199585 seconds
Streaming plantleave data took 1.8954083919525146 seconds
Then, training+dataloading take 1.8958611488342285 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.46367859840393066
Time for copying to cuda: 0.0069348812103271484
Memory occpied: (3438.0, 1814.0)
Time for forward pass: 0.060890913009643555
Time for backpropagation: 0.0032470226287841797
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.6326963901519775 seconds
Index: 11
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 2.047724962234497 seconds
Streaming plantleave data took 2.0538554191589355 seconds
Then, training+dataloading take 2.054565191268921 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.35857343673706055
Time for copying to cuda: 0.006710529327392578
Time for forward pass: 0.060632944107055664
Time for backpropagation: 0.003264904022216797
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5201172828674316 seconds
Index: 12
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9625575542449951 seconds
Streaming plantleave data took 1.9728434085845947 seconds
Then, training+dataloading take 1.9739322662353516 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.41512393951416016
Time for copying to cuda: 0.006663322448730469
Time for forward pass: 0.06053972244262695
Time for backpropagation: 0.0030231475830078125
GPU memory for training: 2.0985188484191895                          

Memory occpied: (3438.0, 1814.0)
One training iteration takes: 0.5704984664916992 seconds
Index: 13
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9924190044403076 seconds
Streaming plantleave data took 1.9984941482543945 seconds
Then, training+dataloading take 1.9992730617523193 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36425161361694336
Time for copying to cuda: 0.006779193878173828
Time for forward pass: 0.06054973602294922
Time for backpropagation: 0.0030853748321533203
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5300815105438232 seconds
Index: 14
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9067943096160889 seconds
Streaming plantleave data took 1.9168941974639893 seconds
Then, training+dataloading take 1.9173216819763184 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4013838768005371
Time for copying to cuda: 0.006755352020263672
Time for forward pass: 0.060408830642700195
Time for backpropagation: 0.003022909164428711
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.6079330444335938 seconds
Index: 15
Memory occpied: (3438.0, 1814.0)
Memory occpied: (3438.0, 1814.0)
Read 24.51193618774414 MBs for this batch
Executing all posts took 1.9369251728057861 seconds
Streaming plantleave data took 1.9431893825531006 seconds
Then, training+dataloading take 1.9439992904663086 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.35698866844177246
Time for copying to cuda: 0.00669097900390625
Time for forward pass: 0.06058478355407715
Time for backpropagation: 0.0030717849731445312
GPU memory for training: 2.0985188484191895                          

One training iteration takes: 0.5177960395812988 seconds
Index: 16
Memory occpied: (3438.0, 1814.0)
Read 14.36253833770752 MBs for this batch
Executing all posts took 1.3180577754974365 seconds
Streaming plantleave data took 1.324108600616455 seconds
Then, training+dataloading take 1.3245034217834473 seconds

Epoch: 0
Time of next(dataloader) is: 0.35044074058532715
Time for copying to cuda: 0.004051923751831055
Time for forward pass: 0.05936551094055176
Time for backpropagation: 0.0030341148376464844
GPU memory for training: 2.080348014831543                          

The whole process took 45.07256293296814 seconds
