Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5384889825096 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119083956.8279155 119083956.8279155
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5236506462097168 seconds
Streaming plantleave data took 0.5336899757385254 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3202629089355469
Time for copying to cuda: 0.008113861083984375
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7134878635406494 seconds
Streaming plantleave data took 0.7259795665740967 seconds
Memory occpied: (1526.0, 234.0)
Memory occpied: (1526.0, 698.0)
Memory occpied: (1526.0, 1128.0)
Time for forward pass: 3.662019968032837
Time for backpropagation: 0.05149221420288086
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.099188327789307 seconds
Index: 0
Then, training+dataloading take 4.099250316619873 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Memory occpied: (2370.0, 1504.0)
Time of next(dataloader) is: 0.45995235443115234
Time for copying to cuda: 0.007493495941162109
Time for forward pass: 0.03361201286315918
Time for backpropagation: 0.0031108856201171875
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6163430213928223 seconds
Index: 1
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6163606643676758 seconds
Streaming plantleave data took 0.6263389587402344 seconds
Then, training+dataloading take 0.6266500949859619 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3931117057800293
Time for copying to cuda: 0.007507801055908203
Time for forward pass: 0.03379631042480469
Time for backpropagation: 0.0037717819213867188
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5412986278533936 seconds
Index: 2
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5564370155334473 seconds
Streaming plantleave data took 0.5666077136993408 seconds
Then, training+dataloading take 0.5669221878051758 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.49094533920288086
Time for copying to cuda: 0.007641315460205078
Time for forward pass: 0.03947162628173828
Time for backpropagation: 0.007711887359619141
GPU memory for training: 1.2220048904418945                          

Memory occpied: (2380.0, 1862.0)
One training iteration takes: 0.6348257064819336 seconds
Index: 3
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6475634574890137 seconds
Streaming plantleave data took 0.6539080142974854 seconds
Then, training+dataloading take 0.6544778347015381 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3782782554626465
Time for copying to cuda: 0.007561683654785156
Time for forward pass: 0.04458737373352051
Time for backpropagation: 0.0037174224853515625
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5325808525085449 seconds
Index: 4
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5613243579864502 seconds
Streaming plantleave data took 0.5672223567962646 seconds
Then, training+dataloading take 0.56754469871521 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42109251022338867
Time for copying to cuda: 0.00789022445678711
Time for forward pass: 0.04411196708679199
Time for backpropagation: 0.004531145095825195
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5678267478942871 seconds
Index: 5
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6191749572753906 seconds
Memory occpied: (2380.0, 1862.0)
Streaming plantleave data took 0.6255383491516113 seconds
Then, training+dataloading take 0.6259033679962158 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.379533052444458
Time for copying to cuda: 0.007174491882324219
Time for forward pass: 0.04393577575683594
Time for backpropagation: 0.0035130977630615234
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5104031562805176 seconds
Index: 6
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5443642139434814 seconds
Streaming plantleave data took 0.554307222366333 seconds
Then, training+dataloading take 0.5546200275421143 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38367700576782227
Time for copying to cuda: 0.0071871280670166016
Time for forward pass: 0.04377293586730957
Time for backpropagation: 0.0030825138092041016
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5504860877990723 seconds
Index: 7
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6486639976501465 seconds
Streaming plantleave data took 0.6552300453186035 seconds
Then, training+dataloading take 0.6558904647827148 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.43112993240356445
Time for copying to cuda: 0.007497072219848633
Time for forward pass: 0.04374384880065918
Time for backpropagation: 0.003271818161010742
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5656816959381104 seconds
Index: 8
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5972683429718018 seconds
Streaming plantleave data took 0.6073141098022461 seconds
Then, training+dataloading take 0.6076743602752686 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3619256019592285
Time for copying to cuda: 0.00748896598815918
Time for forward pass: 0.049124717712402344
Time for backpropagation: 0.0062639713287353516
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5166077613830566 seconds
Index: 9
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6540706157684326 seconds
Streaming plantleave data took 0.6666326522827148 seconds
Then, training+dataloading take 0.6672523021697998 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.41115784645080566
Time for copying to cuda: 0.007602691650390625
Time for forward pass: 0.04395794868469238
Time for backpropagation: 0.0031538009643554688
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5607988834381104 seconds
Index: 10
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5671336650848389 seconds
Streaming plantleave data took 0.5772242546081543 seconds
Then, training+dataloading take 0.5776407718658447 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37033915519714355
Time for copying to cuda: 0.007430553436279297
Time for forward pass: 0.04383683204650879
Time for backpropagation: 0.0032286643981933594
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5166587829589844 seconds
Index: 11
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5739462375640869 seconds
Streaming plantleave data took 0.5863296985626221 seconds
Then, training+dataloading take 0.5873672962188721 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.443739652633667
Time for copying to cuda: 0.007355928421020508
Time for forward pass: 0.04395890235900879
Time for backpropagation: 0.003516674041748047
GPU memory for training: 1.2220048904418945                          

Memory occpied: (2380.0, 1862.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5941836833953857 seconds
One training iteration takes: 0.5978877544403076 seconds
Index: 12
Streaming plantleave data took 0.6075434684753418 seconds
Then, training+dataloading take 0.6079027652740479 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3826601505279541
Time for copying to cuda: 0.008459806442260742
Time for forward pass: 0.04390835762023926
Time for backpropagation: 0.003050565719604492
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5374691486358643 seconds
Index: 13
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.568629264831543 seconds
Streaming plantleave data took 0.5747816562652588 seconds
Then, training+dataloading take 0.5753524303436279 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36119771003723145
Time for copying to cuda: 0.0072019100189208984
Time for forward pass: 0.08197689056396484
Time for backpropagation: 0.004667520523071289
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5792796611785889 seconds
Index: 14
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6368534564971924 seconds
Memory occpied: (2380.0, 1862.0)
Streaming plantleave data took 0.6471827030181885 seconds
Then, training+dataloading take 0.6475279331207275 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.401386022567749
Time for copying to cuda: 0.007997274398803711
Time for forward pass: 0.04409217834472656
Time for backpropagation: 0.003388643264770508
GPU memory for training: 1.2220048904418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5651717185974121 seconds
One training iteration takes: 0.5683999061584473 seconds
Index: 15
Streaming plantleave data took 0.574437141418457 seconds
Then, training+dataloading take 0.5749940872192383 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3889584541320801
Time for copying to cuda: 0.007219076156616211
Time for forward pass: 0.07263374328613281
Time for backpropagation: 0.004156351089477539
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5971109867095947 seconds
Index: 16
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6353423595428467 seconds
Streaming plantleave data took 0.6456551551818848 seconds
Then, training+dataloading take 0.6460356712341309 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.37940406799316406
Time for copying to cuda: 0.007548093795776367
Time for forward pass: 0.04404115676879883
Time for backpropagation: 0.003315448760986328
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5107195377349854 seconds
Index: 17
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5708181858062744 seconds
Streaming plantleave data took 0.5771884918212891 seconds
Then, training+dataloading take 0.5778224468231201 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.385113000869751
Time for copying to cuda: 0.007254838943481445
Time for forward pass: 0.04379010200500488
Time for backpropagation: 0.003285646438598633
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5413181781768799 seconds
Index: 18
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5859224796295166 seconds
Streaming plantleave data took 0.5962328910827637 seconds
Then, training+dataloading take 0.5965888500213623 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40683555603027344
Time for copying to cuda: 0.008228778839111328
Time for forward pass: 0.0445253849029541
Time for backpropagation: 0.0033228397369384766
GPU memory for training: 1.2220048904418945                          

Memory occpied: (2380.0, 1862.0)
One training iteration takes: 0.5478558540344238 seconds
Index: 19
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5809991359710693 seconds
Streaming plantleave data took 0.5872690677642822 seconds
Then, training+dataloading take 0.5878372192382812 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39816737174987793
Time for copying to cuda: 0.007355690002441406
Time for forward pass: 0.0438995361328125
Time for backpropagation: 0.003340482711791992
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5447461605072021 seconds
Index: 20
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5663340091705322 seconds
Streaming plantleave data took 0.576331615447998 seconds
Then, training+dataloading take 0.5766358375549316 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42343878746032715
Time for copying to cuda: 0.0077228546142578125
Time for forward pass: 0.04629921913146973
Time for backpropagation: 0.0037567615509033203
GPU memory for training: 1.2220048904418945                          

Read 12.630309104919434 MBs for this batch
Executing all posts took 0.5475606918334961 seconds
Streaming plantleave data took 0.5566680431365967 seconds
One training iteration takes: 0.5847594738006592 seconds
Index: 21
Then, training+dataloading take 0.584869384765625 seconds

Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.3552086353302002
Time for copying to cuda: 0.003798246383666992
Time for forward pass: 0.19793009757995605
Time for backpropagation: 0.0032308101654052734
GPU memory for training: 1.673959732055664                          

The whole process took 24.80825114250183 seconds
