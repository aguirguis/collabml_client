Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=20, model='mydensenet121', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3073187884399 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 3.211264e+06
 3.211264e+06 3.211264e+06 1.605632e+06 4.014080e+05 1.605632e+06
 1.605632e+06 1.605632e+06 8.028160e+05 2.007040e+05 8.028160e+05
 8.028160e+05 8.028160e+05 4.014080e+05 1.003520e+05 2.007040e+05
 2.007040e+05 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119053656.8882384 119053656.8882384
All candidates indexes:  (array([18, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 20
Intermediate:  0.095703125
6.125
Total layers size  29.763755798339844
Server, client, server+client, vanilla  283.85888671875 974.6273193359375 1258.4862060546875 2295.3304443359375
Candidate split  19
Server, client, server+client, vanilla  283.85888671875 974.6273193359375 1258.4862060546875 2295.3304443359375
Model size  27.03515625
Fixed, scale_with_bsz  27.03515625 10.27294921875
Mem usage  1318.0 3.0
Using split index: 19
Freezing the lower layers of the model (mydensenet121) till index 20
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1318.0, 3.0)
Memory occpied: (1318.0, 3.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.6961185932159424 seconds
Streaming plantleave data took 1.7037444114685059 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3231167793273926
Time for copying to cuda: 0.00567936897277832
Memory occpied: (1338.0, 250.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.589860200881958 seconds
Streaming plantleave data took 1.5976769924163818 seconds
Memory occpied: (1338.0, 668.0)
Memory occpied: (1338.0, 1124.0)
Time for forward pass: 3.638436794281006
Time for backpropagation: 0.06984543800354004
GPU memory for training: 1.149247169494629                          

One training iteration takes: 4.095231056213379 seconds
Index: 0
Then, training+dataloading take 4.0952887535095215 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39102673530578613
Time for copying to cuda: 0.00551915168762207
Time for forward pass: 0.04049229621887207
Time for backpropagation: 0.010556936264038086
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.560697078704834 seconds
Index: 1
Memory occpied: (2134.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.4183025360107422 seconds
Streaming plantleave data took 1.425750732421875 seconds
Then, training+dataloading take 1.4263370037078857 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4160470962524414
Time for copying to cuda: 0.005259513854980469
Time for forward pass: 0.044542789459228516
Time for backpropagation: 0.010899782180786133
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.565143346786499 seconds
Index: 2
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.5418379306793213 seconds
Streaming plantleave data took 1.5501129627227783 seconds
Then, training+dataloading take 1.5509235858917236 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41246461868286133
Time for copying to cuda: 0.005247592926025391
Time for forward pass: 0.04384326934814453
Time for backpropagation: 0.010889530181884766
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.5438952445983887 seconds
Index: 3
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3281264305114746 seconds
Streaming plantleave data took 1.332728624343872 seconds
Then, training+dataloading take 1.3333947658538818 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39837002754211426
Time for copying to cuda: 0.005163908004760742
Time for forward pass: 0.04344749450683594
Time for backpropagation: 0.010778427124023438
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.583794116973877 seconds
Index: 4
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.4145784378051758 seconds
Streaming plantleave data took 1.4196298122406006 seconds
Then, training+dataloading take 1.4200198650360107 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40102148056030273
Time for copying to cuda: 0.005250453948974609
Time for forward pass: 0.043488264083862305
Time for backpropagation: 0.010949373245239258
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5837209224700928 seconds
Index: 5
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3712401390075684 seconds
Streaming plantleave data took 1.3760664463043213 seconds
Then, training+dataloading take 1.3764996528625488 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.43494462966918945
Time for copying to cuda: 0.005217313766479492
Time for forward pass: 0.043135643005371094
Time for backpropagation: 0.010766744613647461
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.6355385780334473 seconds
Index: 6
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3842551708221436 seconds
Streaming plantleave data took 1.3891146183013916 seconds
Then, training+dataloading take 1.389524221420288 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3975656032562256
Time for copying to cuda: 0.005368232727050781
Time for forward pass: 0.14688873291015625
Time for backpropagation: 0.011736392974853516
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.647475004196167 seconds
Index: 7
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.285759687423706 seconds
Streaming plantleave data took 1.2909016609191895 seconds
Then, training+dataloading take 1.291292667388916 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38786840438842773
Time for copying to cuda: 0.005488872528076172
Time for forward pass: 0.04533791542053223
Time for backpropagation: 0.010999917984008789
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5450263023376465 seconds
Index: 8
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3185336589813232 seconds
Streaming plantleave data took 1.3232696056365967 seconds
Then, training+dataloading take 1.3236615657806396 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40929651260375977
Time for copying to cuda: 0.005463361740112305
Time for forward pass: 0.044027090072631836
Time for backpropagation: 0.010758399963378906
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5959231853485107 seconds
Index: 9
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.4947702884674072 seconds
Streaming plantleave data took 1.499833345413208 seconds
Then, training+dataloading take 1.500232458114624 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39898681640625
Time for copying to cuda: 0.00532841682434082
Time for forward pass: 0.044203996658325195
Time for backpropagation: 0.010662078857421875
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5395324230194092 seconds
Index: 10
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3580927848815918 seconds
Streaming plantleave data took 1.3628134727478027 seconds
Then, training+dataloading take 1.3632357120513916 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39745616912841797
Time for copying to cuda: 0.005476713180541992
Time for forward pass: 0.04455065727233887
Time for backpropagation: 0.010743141174316406
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5698263645172119 seconds
Index: 11
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.4323272705078125 seconds
Streaming plantleave data took 1.4373364448547363 seconds
Then, training+dataloading take 1.4378371238708496 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4301581382751465
Time for copying to cuda: 0.005416154861450195
Time for forward pass: 0.04502129554748535
Time for backpropagation: 0.011544227600097656
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.5813939571380615 seconds
Index: 12
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.2807142734527588 seconds
Streaming plantleave data took 1.285334587097168 seconds
Then, training+dataloading take 1.2857112884521484 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39362263679504395
Time for copying to cuda: 0.005405426025390625
Time for forward pass: 0.043622732162475586
Time for backpropagation: 0.010928630828857422
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5692138671875 seconds
Index: 13
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3502750396728516 seconds
Streaming plantleave data took 1.3554530143737793 seconds
Then, training+dataloading take 1.35585355758667 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39157986640930176
Time for copying to cuda: 0.005339145660400391
Time for forward pass: 0.08694267272949219
Time for backpropagation: 0.011022090911865234
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.5686423778533936 seconds
Index: 14
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3575947284698486 seconds
Streaming plantleave data took 1.3622691631317139 seconds
Then, training+dataloading take 1.3626689910888672 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Memory occpied: (2150.0, 1620.0)
Time of next(dataloader) is: 0.46294164657592773
Time for copying to cuda: 0.005343437194824219
Time for forward pass: 0.04392552375793457
Time for backpropagation: 0.010726451873779297
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5959913730621338 seconds
Index: 15
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.389589786529541 seconds
Streaming plantleave data took 1.3947117328643799 seconds
Then, training+dataloading take 1.3950881958007812 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4594850540161133
Time for copying to cuda: 0.005398273468017578
Time for forward pass: 0.044682979583740234
Time for backpropagation: 0.01079106330871582
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.5939724445343018 seconds
Index: 16
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.4345996379852295 seconds
Streaming plantleave data took 1.4393279552459717 seconds
Then, training+dataloading take 1.439708948135376 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44505763053894043
Time for copying to cuda: 0.005440711975097656
Time for forward pass: 0.04418230056762695
Time for backpropagation: 0.011403322219848633
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.6181774139404297 seconds
Index: 17
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.2803754806518555 seconds
Streaming plantleave data took 1.285839557647705 seconds
Then, training+dataloading take 1.2862496376037598 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3549642562866211
Time for copying to cuda: 0.005383014678955078
Time for forward pass: 0.0993804931640625
Time for backpropagation: 0.011784076690673828
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5955104827880859 seconds
Index: 18
Memory occpied: (2150.0, 1620.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.483504056930542 seconds
Streaming plantleave data took 1.4882335662841797 seconds
Then, training+dataloading take 1.4886550903320312 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.438248872756958
Time for copying to cuda: 0.0053975582122802734
Time for forward pass: 0.045332908630371094
Time for backpropagation: 0.015845298767089844
GPU memory for training: 0.2141728401184082                          

Memory occpied: (2150.0, 1620.0)
One training iteration takes: 0.5936954021453857 seconds
Index: 19
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.271533727645874 seconds
Streaming plantleave data took 1.2766497135162354 seconds
Then, training+dataloading take 1.2770438194274902 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4230337142944336
Time for copying to cuda: 0.0055429935455322266
Memory occpied: (2150.0, 1620.0)
Time for forward pass: 0.14289474487304688
Time for backpropagation: 0.010872125625610352
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.6821315288543701 seconds
Index: 20
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.3333275318145752 seconds
Streaming plantleave data took 1.3379008769989014 seconds
Then, training+dataloading take 1.3382439613342285 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4012734889984131
Time for copying to cuda: 0.005480527877807617
Time for forward pass: 0.04471397399902344
Time for backpropagation: 0.01112222671508789
GPU memory for training: 0.2141728401184082                          

One training iteration takes: 0.5721771717071533 seconds
Index: 21
Memory occpied: (2150.0, 1620.0)
Read 9.766636848449707 MBs for this batch
Executing all posts took 0.8844830989837646 seconds
Streaming plantleave data took 0.8870265483856201 seconds
Then, training+dataloading take 0.8873746395111084 seconds

Epoch: 0
Time of next(dataloader) is: 0.36078739166259766
Time for copying to cuda: 0.0029535293579101562
Time for forward pass: 0.3263721466064453
Time for backpropagation: 0.023350238800048828
GPU memory for training: 0.8870882987976074                          

Memory occpied: (1632.0, 2108.0)
The whole process took 42.424644231796265 seconds
