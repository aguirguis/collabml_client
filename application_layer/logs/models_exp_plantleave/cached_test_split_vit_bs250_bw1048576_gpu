Namespace(batch_size=250, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myvit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5734385731433 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [6.02112e+05 0.00000e+00 0.00000e+00 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 3.07200e+03 3.07200e+03 3.07200e+03
 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119088537.74065904 119088537.74065904
All candidates indexes:  (array([15, 16, 17, 18]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.0029296875
17.314453125
Total layers size  104.46981048583984
Server, client, server+client, vanilla  774.57763671875 331.0649108886719 1105.6425476074219 4802.500457763672
Candidate split  16
Server, client, server+client, vanilla  774.57763671875 331.0649108886719 1105.6425476074219 4802.500457763672
Model size  327.36083984375
Fixed, scale_with_bsz  327.36083984375 17.888671875
Mem usage  1654.0 3.0
Using split index: 16
Freezing the lower layers of the model (myvit) till index 17
The mode is:  split
Start 0, end 250, post_step 50

Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.3921589851379395 seconds
Streaming plantleave data took 2.3930935859680176 seconds
The mode is:  split
Start 250, end 500, post_step 50


Epoch: 0
Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Time of next(dataloader) is: 0.32588744163513184
Time for copying to cuda: 0.0005381107330322266
Memory occpied: (1654.0, 474.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.299264430999756 seconds
Streaming plantleave data took 2.300048351287842 seconds
Memory occpied: (1654.0, 890.0)
Time for forward pass: 3.1727490425109863
Time for backpropagation: 0.07555866241455078
GPU memory for training: 1.3174200057983398                          

One training iteration takes: 3.6525440216064453 seconds
Index: 0
Then, training+dataloading take 3.6527326107025146 seconds
The mode is:  split
Start 500, end 750, post_step 50


Epoch: 0
Memory occpied: (2394.0, 1652.0)
Memory occpied: (2394.0, 1652.0)
Time of next(dataloader) is: 0.3864297866821289
Time for copying to cuda: 0.0005106925964355469
Time for forward pass: 0.03334188461303711
Time for backpropagation: 0.008777141571044922
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5174143314361572 seconds
Index: 1
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.1621475219726562 seconds
Streaming plantleave data took 2.162869453430176 seconds
Then, training+dataloading take 2.1633076667785645 seconds
The mode is:  split
Start 750, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3352010250091553
Time for copying to cuda: 0.00052642822265625
Time for forward pass: 0.05425095558166504
Time for backpropagation: 0.008520126342773438
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5016160011291504 seconds
Index: 2
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.3472132682800293 seconds
Streaming plantleave data took 2.3479182720184326 seconds
Then, training+dataloading take 2.34847354888916 seconds
The mode is:  split
Start 1000, end 1250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33547496795654297
Time for copying to cuda: 0.0004937648773193359
Time for forward pass: 0.03324413299560547
Time for backpropagation: 0.007869482040405273
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.4684569835662842 seconds
Index: 3
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.316663980484009 seconds
Streaming plantleave data took 2.317225456237793 seconds
Then, training+dataloading take 2.317791223526001 seconds
The mode is:  split
Start 1250, end 1500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3388073444366455
Time for copying to cuda: 0.0005145072937011719
Time for forward pass: 0.03348183631896973
Time for backpropagation: 0.007891178131103516
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.4603302478790283 seconds
Index: 4
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.2478573322296143 seconds
Streaming plantleave data took 2.2484169006347656 seconds
Then, training+dataloading take 2.24891996383667 seconds
The mode is:  split
Start 1500, end 1750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3385615348815918
Time for copying to cuda: 0.0005209445953369141
Time for forward pass: 0.03377890586853027
Time for backpropagation: 0.008114099502563477
GPU memory for training: 1.3377251625061035                          

Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.334197521209717 seconds
Streaming plantleave data took 2.335115909576416 seconds
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
One training iteration takes: 5.391520023345947 seconds
Index: 5
Then, training+dataloading take 5.391602516174316 seconds
The mode is:  split
Start 1750, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3979499340057373
Time for copying to cuda: 0.0005161762237548828
Time for forward pass: 0.033593177795410156
Time for backpropagation: 0.008031606674194336
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5598564147949219 seconds
Index: 6
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.203014850616455 seconds
Streaming plantleave data took 2.2037036418914795 seconds
Then, training+dataloading take 2.2041943073272705 seconds
The mode is:  split
Start 2000, end 2250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3356952667236328
Time for copying to cuda: 0.00047898292541503906
Time for forward pass: 0.03350543975830078
Time for backpropagation: 0.007969379425048828
GPU memory for training: 1.3377251625061035                          

Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.319746255874634 seconds
Streaming plantleave data took 2.3204588890075684 seconds
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
One training iteration takes: 5.394025087356567 seconds
Index: 7
Then, training+dataloading take 5.394094467163086 seconds
The mode is:  split
Start 2250, end 2500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3755817413330078
Time for copying to cuda: 0.0005056858062744141
Time for forward pass: 0.033391714096069336
Time for backpropagation: 0.007865667343139648
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5420870780944824 seconds
Index: 8
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.2697176933288574 seconds
Streaming plantleave data took 2.2704052925109863 seconds
Then, training+dataloading take 2.270904779434204 seconds
The mode is:  split
Start 2500, end 2750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33510375022888184
Time for copying to cuda: 0.0004906654357910156
Time for forward pass: 0.03334546089172363
Time for backpropagation: 0.007818460464477539
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.4699547290802002 seconds
Index: 9
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.136082172393799 seconds
Streaming plantleave data took 2.1367850303649902 seconds
Then, training+dataloading take 2.1373424530029297 seconds
The mode is:  split
Start 2750, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34215831756591797
Time for copying to cuda: 0.0005235671997070312
Time for forward pass: 0.03332161903381348
Time for backpropagation: 0.007900714874267578
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.47606992721557617 seconds
Index: 10
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.188771963119507 seconds
Streaming plantleave data took 2.189814567565918 seconds
Then, training+dataloading take 2.190781593322754 seconds
The mode is:  split
Start 3000, end 3250, post_step 50


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.3631134033203125
Time for copying to cuda: 0.0005347728729248047
Time for forward pass: 0.03328680992126465
Time for backpropagation: 0.007848024368286133
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.47935056686401367 seconds
Index: 11
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.253377914428711 seconds
Streaming plantleave data took 2.253937005996704 seconds
Then, training+dataloading take 2.254598617553711 seconds
The mode is:  split
Start 3250, end 3500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37666845321655273
Time for copying to cuda: 0.0005488395690917969
Time for forward pass: 0.03336191177368164
Time for backpropagation: 0.007934093475341797
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5506577491760254 seconds
Index: 12
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.309955358505249 seconds
Streaming plantleave data took 2.3105263710021973 seconds
Then, training+dataloading take 2.311056137084961 seconds
The mode is:  split
Start 3500, end 3750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34386110305786133
Time for copying to cuda: 0.0004971027374267578
Time for forward pass: 0.03340506553649902
Time for backpropagation: 0.007861614227294922
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.4756457805633545 seconds
Index: 13
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.4169366359710693 seconds
Streaming plantleave data took 2.4174914360046387 seconds
Then, training+dataloading take 2.4180610179901123 seconds
The mode is:  split
Start 3750, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34373974800109863
Time for copying to cuda: 0.0005321502685546875
Time for forward pass: 0.03360104560852051
Time for backpropagation: 0.008007287979125977
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.47907185554504395 seconds
Index: 14
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.1125800609588623 seconds
Streaming plantleave data took 2.113189935684204 seconds
Then, training+dataloading take 2.1137537956237793 seconds
The mode is:  split
Start 4000, end 4250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36249423027038574
Time for copying to cuda: 0.0004639625549316406
Time for forward pass: 0.0582125186920166
Time for backpropagation: 0.00782322883605957
GPU memory for training: 1.3377251625061035                          

Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 1.990354061126709 seconds
Streaming plantleave data took 1.9912612438201904 seconds
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
One training iteration takes: 5.447264671325684 seconds
Index: 15
Then, training+dataloading take 5.447346925735474 seconds
The mode is:  split
Start 4250, end 4500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41690492630004883
Time for copying to cuda: 0.0005488395690917969
Time for forward pass: 0.033960819244384766
Time for backpropagation: 0.008296728134155273
GPU memory for training: 1.3377251625061035                          

Memory occpied: (2422.0, 1660.0)
One training iteration takes: 0.5389068126678467 seconds
Index: 16
Memory occpied: (2422.0, 1660.0)
Read 0.7411909103393555 MBs for this batch
Executing all posts took 2.368088483810425 seconds
Streaming plantleave data took 2.368777275085449 seconds
Then, training+dataloading take 2.3691768646240234 seconds
The mode is:  split
Start 4500, end 4502, post_step 50


Epoch: 0
Read 0.006039619445800781 MBs for this batch
Executing all posts took 0.24742603302001953 seconds
Streaming plantleave data took 0.24774408340454102 seconds
Read 0.006039619445800781 MBs for this batch
Executing all posts took 0.24742603302001953 seconds
Streaming plantleave data took 0.24774408340454102 seconds
Time of next(dataloader) is: 0.3762500286102295
Time for copying to cuda: 0.00055694580078125
Time for forward pass: 0.03407907485961914
Time for backpropagation: 0.008258342742919922
GPU memory for training: 1.3377251625061035                          

One training iteration takes: 0.5212502479553223 seconds
Index: 17
Then, training+dataloading take 0.5213847160339355 seconds

Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.3391611576080322
Time for copying to cuda: 0.00021767616271972656
Time for forward pass: 0.03368043899536133
Time for backpropagation: 0.007941961288452148
GPU memory for training: 1.3369941711425781                          

The whole process took 60.4402174949646 seconds
