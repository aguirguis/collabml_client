Namespace(batch_size=250, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.1727828515452 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 118904950.99391773 118904950.99391773
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 396.0009460449219 665.0800476074219 877.8735046386719
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 396.0009460449219 665.0800476074219 877.8735046386719
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 250, post_step 50

Memory occpied: (1500.0, 3.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7249646186828613 seconds
Streaming plantleave data took 0.7370791435241699 seconds
The mode is:  split
Start 250, end 500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3519575595855713
Time for copying to cuda: 0.0100860595703125
Memory occpied: (1532.0, 134.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.6780698299407959 seconds
Streaming plantleave data took 0.6903512477874756 seconds
Memory occpied: (1532.0, 602.0)
Memory occpied: (1532.0, 1054.0)
Time for forward pass: 3.600416898727417
Time for backpropagation: 0.0994868278503418
GPU memory for training: 2.01790189743042                          

One training iteration takes: 4.138981103897095 seconds
Index: 0
Then, training+dataloading take 4.139172077178955 seconds
The mode is:  split
Start 500, end 750, post_step 50


Epoch: 0
Memory occpied: (1984.0, 2454.0)
Time of next(dataloader) is: 0.4533238410949707
Time for copying to cuda: 0.009171724319458008
Time for forward pass: 0.03641152381896973
Time for backpropagation: 0.0030107498168945312
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.6003868579864502 seconds
Index: 1
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7233226299285889 seconds
Streaming plantleave data took 0.735884428024292 seconds
Then, training+dataloading take 0.7364151477813721 seconds
The mode is:  split
Start 750, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39124107360839844
Time for copying to cuda: 0.00914144515991211
Time for forward pass: 0.035559892654418945
Time for backpropagation: 0.0031354427337646484
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5293495655059814 seconds
Index: 2
Memory occpied: (2516.0, 2462.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7212116718292236 seconds
Streaming plantleave data took 0.7336752414703369 seconds
Then, training+dataloading take 0.7341346740722656 seconds
The mode is:  split
Start 1000, end 1250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4129781723022461
Time for copying to cuda: 0.009070158004760742
Time for forward pass: 0.04687237739562988
Time for backpropagation: 0.004060029983520508
GPU memory for training: 1.2625885009765625                          

Read 30.956368446350098 MBs for this batch
Executing all posts took 0.688406229019165 seconds
Streaming plantleave data took 0.7034223079681396 seconds
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
One training iteration takes: 5.487433671951294 seconds
Index: 3
Then, training+dataloading take 5.487590074539185 seconds
The mode is:  split
Start 1250, end 1500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4009697437286377
Time for copying to cuda: 0.009273052215576172
Time for forward pass: 0.04655957221984863
Time for backpropagation: 0.0029523372650146484
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5587356090545654 seconds
Index: 4
Memory occpied: (2516.0, 2462.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7678093910217285 seconds
Streaming plantleave data took 0.77998948097229 seconds
Then, training+dataloading take 0.7803564071655273 seconds
The mode is:  split
Start 1500, end 1750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3838798999786377
Time for copying to cuda: 0.009020566940307617
Time for forward pass: 0.04645872116088867
Time for backpropagation: 0.0033397674560546875
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5332655906677246 seconds
Index: 5
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7081096172332764 seconds
Streaming plantleave data took 0.720806360244751 seconds
Then, training+dataloading take 0.7211980819702148 seconds
The mode is:  split
Start 1750, end 2000, post_step 50


Epoch: 0
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
Time of next(dataloader) is: 0.4999701976776123
Time for copying to cuda: 0.011265277862548828
Time for forward pass: 0.04648852348327637
Time for backpropagation: 0.0034208297729492188
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.6475787162780762 seconds
Index: 6
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7554683685302734 seconds
Streaming plantleave data took 0.7630953788757324 seconds
Then, training+dataloading take 0.7637152671813965 seconds
The mode is:  split
Start 2000, end 2250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39824795722961426
Time for copying to cuda: 0.010013580322265625
Time for forward pass: 0.046289920806884766
Time for backpropagation: 0.0031540393829345703
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5533933639526367 seconds
Index: 7
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.72348952293396 seconds
Streaming plantleave data took 0.7410554885864258 seconds
Then, training+dataloading take 0.7421131134033203 seconds
The mode is:  split
Start 2250, end 2500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4477975368499756
Time for copying to cuda: 0.008967161178588867
Time for forward pass: 0.046401023864746094
Time for backpropagation: 0.003287076950073242
GPU memory for training: 1.2625885009765625                          

Memory occpied: (2516.0, 2462.0)
One training iteration takes: 0.5872361660003662 seconds
Index: 8
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7511532306671143 seconds
Streaming plantleave data took 0.7588083744049072 seconds
Then, training+dataloading take 0.7592525482177734 seconds
The mode is:  split
Start 2500, end 2750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40970635414123535
Time for copying to cuda: 0.011133670806884766
Time for forward pass: 0.04648900032043457
Time for backpropagation: 0.003175973892211914
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5685863494873047 seconds
Index: 9
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7313785552978516 seconds
Streaming plantleave data took 0.742224931716919 seconds
Then, training+dataloading take 0.742577075958252 seconds
The mode is:  split
Start 2750, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4693920612335205
Time for copying to cuda: 0.009415388107299805
Time for forward pass: 0.04648995399475098
Time for backpropagation: 0.003309488296508789
GPU memory for training: 1.2625885009765625                          

Memory occpied: (2516.0, 2462.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.770404577255249 seconds
Streaming plantleave data took 0.7852990627288818 seconds
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
One training iteration takes: 5.554272413253784 seconds
Index: 10
Then, training+dataloading take 5.55443263053894 seconds
The mode is:  split
Start 3000, end 3250, post_step 50


Epoch: 0
Memory occpied: (2516.0, 2462.0)
Time of next(dataloader) is: 0.39038753509521484
Time for copying to cuda: 0.008782386779785156
Time for forward pass: 0.046396493911743164
Time for backpropagation: 0.003481626510620117
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5416691303253174 seconds
Index: 11
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.6539897918701172 seconds
Streaming plantleave data took 0.6663763523101807 seconds
Then, training+dataloading take 0.6667959690093994 seconds
The mode is:  split
Start 3250, end 3500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40995216369628906
Time for copying to cuda: 0.008995532989501953
Time for forward pass: 0.06029510498046875
Time for backpropagation: 0.0043141841888427734
GPU memory for training: 1.2625885009765625                          

Memory occpied: (2516.0, 2462.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.744304895401001 seconds
Streaming plantleave data took 0.7567429542541504 seconds
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
Memory occpied: (2516.0, 2462.0)
One training iteration takes: 5.515761137008667 seconds
Index: 12
Then, training+dataloading take 5.515917062759399 seconds
The mode is:  split
Start 3500, end 3750, post_step 50


Epoch: 0
Memory occpied: (2516.0, 2462.0)
Time of next(dataloader) is: 0.43742966651916504
Time for copying to cuda: 0.009164094924926758
Time for forward pass: 0.05005216598510742
Time for backpropagation: 0.003556966781616211
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.603701114654541 seconds
Index: 13
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.690148115158081 seconds
Streaming plantleave data took 0.7028584480285645 seconds
Then, training+dataloading take 0.7051823139190674 seconds
The mode is:  split
Start 3750, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4453856945037842
Time for copying to cuda: 0.009332656860351562
Time for forward pass: 0.046979665756225586
Time for backpropagation: 0.00961446762084961
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.6127007007598877 seconds
Index: 14
Memory occpied: (2516.0, 2462.0)
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.6964795589447021 seconds
Streaming plantleave data took 0.7090771198272705 seconds
Then, training+dataloading take 0.7095179557800293 seconds
The mode is:  split
Start 4000, end 4250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4088127613067627
Time for copying to cuda: 0.010250329971313477
Time for forward pass: 0.04632925987243652
Time for backpropagation: 0.0036885738372802734
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5748872756958008 seconds
Index: 15
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.7576344013214111 seconds
Streaming plantleave data took 0.765488862991333 seconds
Then, training+dataloading take 0.7661669254302979 seconds
The mode is:  split
Start 4250, end 4500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.45713043212890625
Time for copying to cuda: 0.009450435638427734
Time for forward pass: 0.04657101631164551
Time for backpropagation: 0.0033910274505615234
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.6685707569122314 seconds
Index: 16
Read 30.956368446350098 MBs for this batch
Executing all posts took 0.729581356048584 seconds
Streaming plantleave data took 0.7407321929931641 seconds
Then, training+dataloading take 0.7412879467010498 seconds
The mode is:  split
Start 4500, end 4502, post_step 50


Epoch: 0
Memory occpied: (2516.0, 2462.0)
Read 0.24776172637939453 MBs for this batch
Executing all posts took 0.18259572982788086 seconds
Streaming plantleave data took 0.22877717018127441 seconds
Memory occpied: (2516.0, 2462.0)
Time of next(dataloader) is: 0.391033411026001
Time for copying to cuda: 0.008579015731811523
Time for forward pass: 0.04608297348022461
Time for backpropagation: 0.002706289291381836
GPU memory for training: 1.2625885009765625                          

One training iteration takes: 0.5347228050231934 seconds
Index: 17
Then, training+dataloading take 0.5347926616668701 seconds

Epoch: 0
Time of next(dataloader) is: 0.35830211639404297
Time for copying to cuda: 0.0003249645233154297
Time for forward pass: 0.07109856605529785
Time for backpropagation: 0.007367372512817383
GPU memory for training: 1.3791890144348145                          

Memory occpied: (2106.0, 2240.0)
The whole process took 39.70663785934448 seconds
