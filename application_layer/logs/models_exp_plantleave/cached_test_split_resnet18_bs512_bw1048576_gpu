Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=512, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=11, model='myresnet18', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.7184872647094 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 4.816896e+06
 4.816896e+06 2.408448e+06 2.408448e+06 1.204224e+06 1.204224e+06
 6.021120e+05 6.021120e+05 2.048000e+03 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118976477.56276 118976477.56276
All candidates indexes:  (array([12, 13]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 11
Intermediate:  0.095703125
6.125
Total layers size  27.181724548339844
Server, client, server+client, vanilla  257.10498046875 191.81591796875 448.9208984375 3572.81591796875
Fixed, scale_with_bsz  0 6.69921875
Mem usage  1336.0 3.0
Using split index: 11
Freezing the lower layers of the model (myresnet18) till index 11
The mode is:  split
Start 0, end 512, post_step 64

Memory occpied: (1336.0, 3.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.9124364852905273 seconds
Streaming plantleave data took 0.9309632778167725 seconds
The mode is:  split
Start 512, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3161497116088867
Time for copying to cuda: 0.013750553131103516
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.7955172061920166 seconds
Streaming plantleave data took 0.8148095607757568 seconds
Time for forward pass: 3.2172889709472656
Time for backpropagation: 0.40694570541381836
GPU memory for training: 4.5741496086120605                          

One training iteration takes: 4.035241603851318 seconds
Index: 0
Then, training+dataloading take 4.035416841506958 seconds
The mode is:  split
Start 1024, end 1536, post_step 64


Epoch: 0
Memory occpied: (1386.0, 3520.0)
Time of next(dataloader) is: 0.3055405616760254
Time for copying to cuda: 0.013140678405761719
Time for forward pass: 0.021834135055541992
Time for backpropagation: 0.004219532012939453
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.4277935028076172 seconds
Index: 1
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.93113112449646 seconds
Streaming plantleave data took 0.949923038482666 seconds
Then, training+dataloading take 0.9506511688232422 seconds
The mode is:  split
Start 1536, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3708529472351074
Time for copying to cuda: 0.014125347137451172
Time for forward pass: 0.0259397029876709
Time for backpropagation: 0.006748676300048828
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.5086679458618164 seconds
Index: 2
Memory occpied: (3622.0, 3536.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.7674582004547119 seconds
Streaming plantleave data took 0.7870244979858398 seconds
Then, training+dataloading take 0.7877252101898193 seconds
The mode is:  split
Start 2048, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3193690776824951
Time for copying to cuda: 0.013407230377197266
Time for forward pass: 0.02648782730102539
Time for backpropagation: 0.007882833480834961
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.4391007423400879 seconds
Index: 3
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.7170665264129639 seconds
Streaming plantleave data took 0.7359230518341064 seconds
Then, training+dataloading take 0.7367575168609619 seconds
The mode is:  split
Start 2560, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.36063718795776367
Time for copying to cuda: 0.015416145324707031
Time for forward pass: 0.027225732803344727
Time for backpropagation: 0.005333423614501953
GPU memory for training: 0.7285466194152832                          

Memory occpied: (3622.0, 3536.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.7874565124511719 seconds
Streaming plantleave data took 0.8066561222076416 seconds
Memory occpied: (3622.0, 3536.0)
Memory occpied: (3622.0, 3536.0)
Memory occpied: (3622.0, 3536.0)
Memory occpied: (3622.0, 3536.0)
One training iteration takes: 5.4278881549835205 seconds
Index: 4
Then, training+dataloading take 5.42802095413208 seconds
The mode is:  split
Start 3072, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.308269739151001
Time for copying to cuda: 0.01303410530090332
Time for forward pass: 0.025895118713378906
Time for backpropagation: 0.004133462905883789
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.4312291145324707 seconds
Index: 5
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.9183559417724609 seconds
Streaming plantleave data took 0.9712586402893066 seconds
Then, training+dataloading take 0.9735314846038818 seconds
The mode is:  split
Start 3584, end 4096, post_step 64


Epoch: 0
Memory occpied: (3622.0, 3536.0)
Time of next(dataloader) is: 0.34181666374206543
Time for copying to cuda: 0.012624025344848633
Time for forward pass: 0.02587747573852539
Time for backpropagation: 0.004183769226074219
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.4595324993133545 seconds
Index: 6
Read 49.02387237548828 MBs for this batch
Executing all posts took 0.8070893287658691 seconds
Streaming plantleave data took 0.826225757598877 seconds
Then, training+dataloading take 0.8270182609558105 seconds
The mode is:  split
Start 4096, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3281710147857666
Time for copying to cuda: 0.013692855834960938
Time for forward pass: 0.028574705123901367
Time for backpropagation: 0.005403757095336914
GPU memory for training: 0.7285466194152832                          

One training iteration takes: 0.4884061813354492 seconds
Index: 7
Memory occpied: (3622.0, 3536.0)
Read 38.87447452545166 MBs for this batch
Executing all posts took 0.678992748260498 seconds
Streaming plantleave data took 0.6938595771789551 seconds
Then, training+dataloading take 0.6945512294769287 seconds

Epoch: 0
Time of next(dataloader) is: 0.31142520904541016
Time for copying to cuda: 0.010187149047851562
Time for forward pass: 0.2921626567840576
Time for backpropagation: 0.3197956085205078
GPU memory for training: 4.114550590515137                          

Memory occpied: (3618.0, 3510.0)
The whole process took 23.340391635894775 seconds
