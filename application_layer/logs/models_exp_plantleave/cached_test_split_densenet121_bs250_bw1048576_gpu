Namespace(batch_size=250, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=20, model='mydensenet121', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.0504220873211 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 3.211264e+06
 3.211264e+06 3.211264e+06 1.605632e+06 4.014080e+05 1.605632e+06
 1.605632e+06 1.605632e+06 8.028160e+05 2.007040e+05 8.028160e+05
 8.028160e+05 8.028160e+05 4.014080e+05 1.003520e+05 2.007040e+05
 2.007040e+05 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119019984.92382935 119019984.92382935
All candidates indexes:  (array([18, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 20
Intermediate:  0.095703125
6.125
Total layers size  29.763755798339844
Server, client, server+client, vanilla  283.85888671875 1211.5253601074219 1495.3842468261719 2862.404266357422
Candidate split  19
Server, client, server+client, vanilla  283.85888671875 1211.5253601074219 1495.3842468261719 2862.404266357422
Model size  27.03515625
Fixed, scale_with_bsz  27.03515625 10.27294921875
Mem usage  1318.0 3.0
Using split index: 19
Freezing the lower layers of the model (mydensenet121) till index 20
The mode is:  split
Start 0, end 250, post_step 50

Memory occpied: (1318.0, 3.0)
Memory occpied: (1318.0, 3.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 2.0040507316589355 seconds
Streaming plantleave data took 2.0135483741760254 seconds
The mode is:  split
Start 250, end 500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3123180866241455
Time for copying to cuda: 0.007119655609130859
Memory occpied: (1342.0, 122.0)
Memory occpied: (1342.0, 592.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.8145372867584229 seconds
Streaming plantleave data took 1.8245325088500977 seconds
Memory occpied: (1342.0, 990.0)
Time for forward pass: 3.702691078186035
Time for backpropagation: 0.12210249900817871
GPU memory for training: 1.285888671875                          

Memory occpied: (1666.0, 1962.0)
One training iteration takes: 4.213554859161377 seconds
Index: 0
Then, training+dataloading take 4.2136218547821045 seconds
The mode is:  split
Start 500, end 750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3463160991668701
Time for copying to cuda: 0.006769895553588867
Time for forward pass: 0.043306589126586914
Time for backpropagation: 0.01040029525756836
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.47641420364379883 seconds
Index: 1
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.910447597503662 seconds
Streaming plantleave data took 1.9198791980743408 seconds
Then, training+dataloading take 1.920318841934204 seconds
The mode is:  split
Start 750, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42865824699401855
Time for copying to cuda: 0.006565093994140625
Time for forward pass: 0.047974586486816406
Time for backpropagation: 0.010905981063842773
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.595477819442749 seconds
Streaming plantleave data took 1.6054632663726807 seconds
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
One training iteration takes: 5.512783050537109 seconds
Index: 2
Then, training+dataloading take 5.5129170417785645 seconds
The mode is:  split
Start 1000, end 1250, post_step 50


Epoch: 0
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Time of next(dataloader) is: 0.35443902015686035
Time for copying to cuda: 0.006719350814819336
Time for forward pass: 0.048041343688964844
Time for backpropagation: 0.010803699493408203
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5080721378326416 seconds
Index: 3
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.689917802810669 seconds
Streaming plantleave data took 1.6997838020324707 seconds
Then, training+dataloading take 1.700533390045166 seconds
The mode is:  split
Start 1250, end 1500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38289499282836914
Time for copying to cuda: 0.00638890266418457
Time for forward pass: 0.04785895347595215
Time for backpropagation: 0.010704755783081055
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5230169296264648 seconds
Index: 4
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7544052600860596 seconds
Streaming plantleave data took 1.7643952369689941 seconds
Then, training+dataloading take 1.7648289203643799 seconds
The mode is:  split
Start 1500, end 1750, post_step 50


Epoch: 0
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Time of next(dataloader) is: 0.47683238983154297
Time for copying to cuda: 0.006300926208496094
Time for forward pass: 0.04709434509277344
Time for backpropagation: 0.010875225067138672
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.6289725303649902 seconds
Index: 5
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7607131004333496 seconds
Streaming plantleave data took 1.767017126083374 seconds
Then, training+dataloading take 1.7680118083953857 seconds
The mode is:  split
Start 1750, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36283373832702637
Time for copying to cuda: 0.006392240524291992
Time for forward pass: 0.04716014862060547
Time for backpropagation: 0.01066136360168457
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5122730731964111 seconds
Index: 6
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7486965656280518 seconds
Streaming plantleave data took 1.758671522140503 seconds
Then, training+dataloading take 1.7592487335205078 seconds
The mode is:  split
Start 2000, end 2250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40024566650390625
Time for copying to cuda: 0.006486415863037109
Time for forward pass: 0.14148449897766113
Time for backpropagation: 0.011394262313842773
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
One training iteration takes: 0.6494331359863281 seconds
Index: 7
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.59397292137146 seconds
Streaming plantleave data took 1.6453580856323242 seconds
Then, training+dataloading take 1.6529066562652588 seconds
The mode is:  split
Start 2250, end 2500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.43172311782836914
Time for copying to cuda: 0.006597042083740234
Time for forward pass: 0.04816079139709473
Time for backpropagation: 0.010952234268188477
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
One training iteration takes: 0.5877094268798828 seconds
Index: 8
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7798326015472412 seconds
Streaming plantleave data took 1.7944231033325195 seconds
Then, training+dataloading take 1.7958171367645264 seconds
The mode is:  split
Start 2500, end 2750, post_step 50


Epoch: 0
Memory occpied: (1684.0, 1978.0)
Time of next(dataloader) is: 0.38643693923950195
Time for copying to cuda: 0.006528139114379883
Time for forward pass: 0.047777414321899414
Time for backpropagation: 0.01075291633605957
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5481791496276855 seconds
Index: 9
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7886099815368652 seconds
Streaming plantleave data took 1.7988061904907227 seconds
Then, training+dataloading take 1.799375295639038 seconds
The mode is:  split
Start 2750, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3948228359222412
Time for copying to cuda: 0.0065577030181884766
Time for forward pass: 0.04788494110107422
Time for backpropagation: 0.010712385177612305
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5416741371154785 seconds
Index: 10
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7035040855407715 seconds
Streaming plantleave data took 1.7098767757415771 seconds
Then, training+dataloading take 1.710756778717041 seconds
The mode is:  split
Start 3000, end 3250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47522997856140137
Time for copying to cuda: 0.006663322448730469
Time for forward pass: 0.04762697219848633
Time for backpropagation: 0.010823726654052734
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
One training iteration takes: 0.6299550533294678 seconds
Index: 11
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.6763341426849365 seconds
Streaming plantleave data took 1.686629295349121 seconds
Then, training+dataloading take 1.6879727840423584 seconds
The mode is:  split
Start 3250, end 3500, post_step 50


Epoch: 0
Memory occpied: (1684.0, 1978.0)
Time of next(dataloader) is: 0.41012096405029297
Time for copying to cuda: 0.006438016891479492
Time for forward pass: 0.04758143424987793
Time for backpropagation: 0.010887622833251953
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5497097969055176 seconds
Index: 12
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.7916932106018066 seconds
Streaming plantleave data took 1.798020362854004 seconds
Then, training+dataloading take 1.7992370128631592 seconds
The mode is:  split
Start 3500, end 3750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3637659549713135
Time for copying to cuda: 0.0067713260650634766
Time for forward pass: 0.04733538627624512
Time for backpropagation: 0.010686635971069336
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.6394321918487549 seconds
Streaming plantleave data took 1.649355173110962 seconds
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
One training iteration takes: 5.4555134773254395 seconds
Index: 13
Then, training+dataloading take 5.455599784851074 seconds
The mode is:  split
Start 3750, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40434861183166504
Time for copying to cuda: 0.006811857223510742
Time for forward pass: 0.04843902587890625
Time for backpropagation: 0.01078653335571289
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5858676433563232 seconds
Index: 14
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.889167308807373 seconds
Streaming plantleave data took 1.8990695476531982 seconds
Then, training+dataloading take 1.8999073505401611 seconds
The mode is:  split
Start 4000, end 4250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40114259719848633
Time for copying to cuda: 0.006770610809326172
Time for forward pass: 0.049906015396118164
Time for backpropagation: 0.011433839797973633
GPU memory for training: 0.25062131881713867                          

Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.703669786453247 seconds
Streaming plantleave data took 1.7136800289154053 seconds
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
One training iteration takes: 5.483959674835205 seconds
Index: 15
Then, training+dataloading take 5.484041690826416 seconds
The mode is:  split
Start 4250, end 4500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3753201961517334
Time for copying to cuda: 0.007040739059448242
Time for forward pass: 0.09557485580444336
Time for backpropagation: 0.01214742660522461
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5931499004364014 seconds
Index: 16
Memory occpied: (1684.0, 1978.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.8095643520355225 seconds
Streaming plantleave data took 1.8220634460449219 seconds
Then, training+dataloading take 1.823213815689087 seconds
The mode is:  split
Start 4500, end 4502, post_step 50


Epoch: 0
Memory occpied: (1684.0, 1978.0)
Memory occpied: (1684.0, 1978.0)
Read 0.19161128997802734 MBs for this batch
Executing all posts took 0.34776830673217773 seconds
Streaming plantleave data took 0.348186731338501 seconds
Time of next(dataloader) is: 0.36650991439819336
Time for copying to cuda: 0.006554365158081055
Time for forward pass: 0.04853463172912598
Time for backpropagation: 0.011083602905273438
GPU memory for training: 0.25062131881713867                          

One training iteration takes: 0.5215704441070557 seconds
Index: 17
Then, training+dataloading take 0.521618127822876 seconds

Epoch: 0
Time of next(dataloader) is: 0.3642275333404541
Time for copying to cuda: 0.0002849102020263672
Time for forward pass: 0.10487556457519531
Time for backpropagation: 0.022350311279296875
GPU memory for training: 0.3977351188659668                          

Memory occpied: (1660.0, 1898.0)
The whole process took 54.26142144203186 seconds
