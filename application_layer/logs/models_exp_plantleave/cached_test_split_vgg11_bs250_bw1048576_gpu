Namespace(batch_size=250, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=25, model='myvgg11', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5289712728068 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 3.2112640e+06 6.4225280e+06 6.4225280e+06
 1.6056320e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 8.0281600e+05 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119082709.32266933 119082709.32266933
All candidates indexes:  (array([20, 21, 22, 23, 24, 25, 26, 27, 28]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 25
Intermediate:  0.095703125
24.5
Total layers size  62.683677673339844
Server, client, server+client, vanilla  1118.40478515625 586.8061218261719 1705.2109069824219 6831.435028076172
Candidate split  21
Server, client, server+client, vanilla  1118.40478515625 586.8061218261719 1705.2109069824219 6831.435028076172
Model size  491.54931640625
Fixed, scale_with_bsz  491.54931640625 25.07421875
Mem usage  1824.0 3.0
Using split index: 21
Freezing the lower layers of the model (myvgg11) till index 25
The mode is:  split
Start 0, end 250, post_step 50

Memory occpied: (1824.0, 3.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.3279380798339844 seconds
Streaming plantleave data took 1.337587594985962 seconds
The mode is:  split
Start 250, end 500, post_step 50


Epoch: 0
Memory occpied: (1824.0, 3.0)
Time of next(dataloader) is: 0.32848358154296875
Time for copying to cuda: 0.007219791412353516
Memory occpied: (1848.0, 388.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2363746166229248 seconds
Streaming plantleave data took 1.2463347911834717 seconds
Memory occpied: (1848.0, 830.0)
Memory occpied: (1848.0, 1782.0)
Time for forward pass: 3.3229897022247314
Time for backpropagation: 0.056563615798950195
GPU memory for training: 1.9723119735717773                          

One training iteration takes: 3.785876989364624 seconds
Index: 0
Then, training+dataloading take 3.7859432697296143 seconds
The mode is:  split
Start 500, end 750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35317254066467285
Time for copying to cuda: 0.006672859191894531
Time for forward pass: 0.06044816970825195
Time for backpropagation: 0.0030748844146728516
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5053918361663818 seconds
Index: 1
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1632823944091797 seconds
Streaming plantleave data took 1.1730315685272217 seconds
Then, training+dataloading take 1.173607349395752 seconds
The mode is:  split
Start 750, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3506135940551758
Time for copying to cuda: 0.006450176239013672
Time for forward pass: 0.06039738655090332
Time for backpropagation: 0.003016948699951172
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5112769603729248 seconds
Index: 2
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2509653568267822 seconds
Streaming plantleave data took 1.2610194683074951 seconds
Then, training+dataloading take 1.2615892887115479 seconds
The mode is:  split
Start 1000, end 1250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35100507736206055
Time for copying to cuda: 0.0065000057220458984
Time for forward pass: 0.060463905334472656
Time for backpropagation: 0.003055572509765625
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5127813816070557 seconds
Index: 3
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.259129285812378 seconds
Streaming plantleave data took 1.26505708694458 seconds
Then, training+dataloading take 1.265845537185669 seconds
The mode is:  split
Start 1250, end 1500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3512294292449951
Time for copying to cuda: 0.006458282470703125
Time for forward pass: 0.06053423881530762
Time for backpropagation: 0.0030145645141601562
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.511479377746582 seconds
Index: 4
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2479972839355469 seconds
Streaming plantleave data took 1.2540628910064697 seconds
Then, training+dataloading take 1.2545344829559326 seconds
The mode is:  split
Start 1500, end 1750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3685424327850342
Time for copying to cuda: 0.006589651107788086
Time for forward pass: 0.060474395751953125
Time for backpropagation: 0.003086566925048828
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5248050689697266 seconds
Index: 5
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1179420948028564 seconds
Streaming plantleave data took 1.1238760948181152 seconds
Then, training+dataloading take 1.124464511871338 seconds
The mode is:  split
Start 1750, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34891366958618164
Time for copying to cuda: 0.006559610366821289
Time for forward pass: 0.06038832664489746
Time for backpropagation: 0.003081083297729492
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5063109397888184 seconds
Index: 6
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.264693021774292 seconds
Streaming plantleave data took 1.2706599235534668 seconds
Then, training+dataloading take 1.2712368965148926 seconds
The mode is:  split
Start 2000, end 2250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35586094856262207
Time for copying to cuda: 0.006478786468505859
Time for forward pass: 0.06044745445251465
Time for backpropagation: 0.00328826904296875
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.49794793128967285 seconds
Index: 7
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2290782928466797 seconds
Streaming plantleave data took 1.2351179122924805 seconds
Then, training+dataloading take 1.2357745170593262 seconds
The mode is:  split
Start 2250, end 2500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3522937297821045
Time for copying to cuda: 0.006532430648803711
Time for forward pass: 0.06051802635192871
Time for backpropagation: 0.003084421157836914
GPU memory for training: 2.0980148315429688                          

Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1333074569702148 seconds
Streaming plantleave data took 1.1432833671569824 seconds
Memory occpied: (3436.0, 1810.0)
Memory occpied: (3436.0, 1810.0)
Memory occpied: (3436.0, 1810.0)
One training iteration takes: 5.43335747718811 seconds
Index: 8
Then, training+dataloading take 5.433431386947632 seconds
The mode is:  split
Start 2500, end 2750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4054272174835205
Time for copying to cuda: 0.006813526153564453
Time for forward pass: 0.06080508232116699
Time for backpropagation: 0.003087759017944336
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5845534801483154 seconds
Index: 9
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1788265705108643 seconds
Streaming plantleave data took 1.1884994506835938 seconds
Then, training+dataloading take 1.1891331672668457 seconds
The mode is:  split
Start 2750, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36883544921875
Time for copying to cuda: 0.006563663482666016
Time for forward pass: 0.06070566177368164
Time for backpropagation: 0.003260374069213867
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5324206352233887 seconds
Index: 10
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1226725578308105 seconds
Streaming plantleave data took 1.1331415176391602 seconds
Then, training+dataloading take 1.1336133480072021 seconds
The mode is:  split
Start 3000, end 3250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39310765266418457
Time for copying to cuda: 0.00657343864440918
Time for forward pass: 0.06054973602294922
Time for backpropagation: 0.0032205581665039062
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5524520874023438 seconds
Index: 11
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2291896343231201 seconds
Streaming plantleave data took 1.2352087497711182 seconds
Then, training+dataloading take 1.2359881401062012 seconds
The mode is:  split
Start 3250, end 3500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3680078983306885
Time for copying to cuda: 0.0064983367919921875
Time for forward pass: 0.06034278869628906
Time for backpropagation: 0.003105640411376953
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5250663757324219 seconds
Index: 12
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2116308212280273 seconds
Streaming plantleave data took 1.2216486930847168 seconds
Then, training+dataloading take 1.2221143245697021 seconds
The mode is:  split
Start 3500, end 3750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36052441596984863
Time for copying to cuda: 0.00644230842590332
Time for forward pass: 0.06053900718688965
Time for backpropagation: 0.0031342506408691406
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5340440273284912 seconds
Index: 13
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.2736811637878418 seconds
Streaming plantleave data took 1.279599905014038 seconds
Then, training+dataloading take 1.2803947925567627 seconds
The mode is:  split
Start 3750, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38640522956848145
Time for copying to cuda: 0.006479024887084961
Time for forward pass: 0.06049394607543945
Time for backpropagation: 0.0031194686889648438
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5525586605072021 seconds
Index: 14
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1618270874023438 seconds
Streaming plantleave data took 1.171861171722412 seconds
Then, training+dataloading take 1.1723215579986572 seconds
The mode is:  split
Start 4000, end 4250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37365126609802246
Time for copying to cuda: 0.006640911102294922
Time for forward pass: 0.06052756309509277
Time for backpropagation: 0.003195524215698242
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5331778526306152 seconds
Index: 15
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.1352972984313965 seconds
Streaming plantleave data took 1.1412580013275146 seconds
Then, training+dataloading take 1.1420185565948486 seconds
The mode is:  split
Start 4250, end 4500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3664426803588867
Time for copying to cuda: 0.006566524505615234
Time for forward pass: 0.06055760383605957
Time for backpropagation: 0.0031633377075195312
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5367898941040039 seconds
Index: 16
Memory occpied: (3436.0, 1810.0)
Read 23.9375638961792 MBs for this batch
Executing all posts took 1.0900187492370605 seconds
Streaming plantleave data took 1.1005353927612305 seconds
Then, training+dataloading take 1.101128339767456 seconds
The mode is:  split
Start 4500, end 4502, post_step 50


Epoch: 0
Read 0.19161128997802734 MBs for this batch
Executing all posts took 0.26194119453430176 seconds
Streaming plantleave data took 0.30651021003723145 seconds
Read 0.19161128997802734 MBs for this batch
Executing all posts took 0.26194119453430176 seconds
Time of next(dataloader) is: 0.3719806671142578
Time for copying to cuda: 0.006554603576660156
Time for forward pass: 0.06053352355957031
Time for backpropagation: 0.0031375885009765625
GPU memory for training: 2.0980148315429688                          

One training iteration takes: 0.5180609226226807 seconds
Index: 17
Then, training+dataloading take 0.5183746814727783 seconds

Epoch: 0
Time of next(dataloader) is: 0.4264962673187256
Time for copying to cuda: 0.0002779960632324219
Time for forward pass: 0.04839277267456055
Time for backpropagation: 0.0028772354125976562
GPU memory for training: 2.0669913291931152                          

Memory occpied: (3436.0, 1810.0)
The whole process took 38.59429359436035 seconds
