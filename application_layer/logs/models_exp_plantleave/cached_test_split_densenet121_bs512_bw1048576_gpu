Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=512, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=20, model='mydensenet121', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.6085323252572 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 3.211264e+06
 3.211264e+06 3.211264e+06 1.605632e+06 4.014080e+05 1.605632e+06
 1.605632e+06 1.605632e+06 8.028160e+05 2.007040e+05 8.028160e+05
 8.028160e+05 8.028160e+05 4.014080e+05 1.003520e+05 2.007040e+05
 2.007040e+05 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119093137.54893611 119093137.54893611
All candidates indexes:  (array([18, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 20
Intermediate:  0.095703125
6.125
Total layers size  29.763755798339844
Server, client, server+client, vanilla  355.76953125 2452.87109375 2808.640625 5833.87109375
Candidate split  19
Server, client, server+client, vanilla  355.76953125 2452.87109375 2808.640625 5833.87109375
Model size  27.03515625
Fixed, scale_with_bsz  27.03515625 10.27294921875
Mem usage  1318.0 3.0
Using split index: 19
Freezing the lower layers of the model (mydensenet121) till index 20
The mode is:  split
Start 0, end 512, post_step 64

Memory occpied: (1318.0, 3.0)
Memory occpied: (1318.0, 3.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.6228032112121582 seconds
Streaming plantleave data took 1.641552448272705 seconds
The mode is:  split
Start 512, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.28226447105407715
Time for copying to cuda: 0.013407230377197266
Memory occpied: (1368.0, 274.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.5827534198760986 seconds
Streaming plantleave data took 1.6020503044128418 seconds
Memory occpied: (1368.0, 676.0)
Memory occpied: (1368.0, 1138.0)
Time for forward pass: 3.7753114700317383
Time for backpropagation: 0.06928682327270508
GPU memory for training: 2.0050697326660156                          

One training iteration takes: 4.206951856613159 seconds
Index: 0
Then, training+dataloading take 4.207125663757324 seconds
The mode is:  split
Start 1024, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.34941864013671875
Time for copying to cuda: 0.012883424758911133
Time for forward pass: 0.06502962112426758
Time for backpropagation: 0.010727882385253906
GPU memory for training: 0.4717826843261719                          

Memory occpied: (1842.0, 2636.0)
One training iteration takes: 0.5071377754211426 seconds
Index: 1
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.4641773700714111 seconds
Streaming plantleave data took 1.483077049255371 seconds
Then, training+dataloading take 1.483802080154419 seconds
The mode is:  split
Start 1536, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.34738612174987793
Time for copying to cuda: 0.012598514556884766
Time for forward pass: 0.07468962669372559
Time for backpropagation: 0.010682106018066406
GPU memory for training: 0.4717826843261719                          

One training iteration takes: 0.553579568862915 seconds
Index: 2
Memory occpied: (1858.0, 2652.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.327073097229004 seconds
Streaming plantleave data took 1.3460338115692139 seconds
Then, training+dataloading take 1.346766710281372 seconds
The mode is:  split
Start 2048, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.32114195823669434
Time for copying to cuda: 0.012743473052978516
Time for forward pass: 0.07897138595581055
Time for backpropagation: 0.011389732360839844
GPU memory for training: 0.4717826843261719                          

Memory occpied: (1858.0, 2652.0)
One training iteration takes: 0.5232148170471191 seconds
Index: 3
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.2806735038757324 seconds
Streaming plantleave data took 1.299647331237793 seconds
Then, training+dataloading take 1.300461769104004 seconds
The mode is:  split
Start 2560, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3537769317626953
Time for copying to cuda: 0.012812137603759766
Time for forward pass: 0.07501006126403809
Time for backpropagation: 0.011050224304199219
GPU memory for training: 0.4717826843261719                          

One training iteration takes: 0.5611748695373535 seconds
Index: 4
Memory occpied: (1858.0, 2652.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.2327485084533691 seconds
Streaming plantleave data took 1.2519609928131104 seconds
Then, training+dataloading take 1.2527945041656494 seconds
The mode is:  split
Start 3072, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3116321563720703
Time for copying to cuda: 0.012682914733886719
Time for forward pass: 0.07813692092895508
Time for backpropagation: 0.011348485946655273
GPU memory for training: 0.4717826843261719                          

One training iteration takes: 0.5020711421966553 seconds
Index: 5
Memory occpied: (1858.0, 2652.0)
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.2822811603546143 seconds
Streaming plantleave data took 1.3017539978027344 seconds
Then, training+dataloading take 1.3026182651519775 seconds
The mode is:  split
Start 3584, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.38567042350769043
Time for copying to cuda: 0.012745380401611328
Memory occpied: (1858.0, 2652.0)
Time for forward pass: 0.07560014724731445
Time for backpropagation: 0.01212930679321289
GPU memory for training: 0.4717826843261719                          

One training iteration takes: 0.5618822574615479 seconds
Index: 6
Read 49.02387237548828 MBs for this batch
Executing all posts took 1.371880054473877 seconds
Streaming plantleave data took 1.3907175064086914 seconds
Then, training+dataloading take 1.3916094303131104 seconds
The mode is:  split
Start 4096, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4343893527984619
Time for copying to cuda: 0.012603998184204102
Time for forward pass: 0.12555408477783203
Time for backpropagation: 0.010767221450805664
GPU memory for training: 0.4717826843261719                          

Memory occpied: (1858.0, 2652.0)
One training iteration takes: 0.6573472023010254 seconds
Index: 7
Read 38.87447452545166 MBs for this batch
Executing all posts took 1.2882542610168457 seconds
Streaming plantleave data took 1.3038387298583984 seconds
Then, training+dataloading take 1.3045244216918945 seconds

Epoch: 0
Time of next(dataloader) is: 0.3049941062927246
Time for copying to cuda: 0.01072072982788086
Memory occpied: (2228.0, 1752.0)
Time for forward pass: 0.6173291206359863
Time for backpropagation: 0.026189088821411133
GPU memory for training: 1.7211723327636719                          

The whole process took 22.767664670944214 seconds
