Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=21, model='myresnet50', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3203268906027 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.4450688e+07
 1.4450688e+07 1.4450688e+07 1.0838016e+07 7.2253440e+06 7.2253440e+06
 7.2253440e+06 5.4190080e+06 3.6126720e+06 3.6126720e+06 3.6126720e+06
 3.6126720e+06 3.6126720e+06 2.7095040e+06 1.8063360e+06 1.8063360e+06
 8.1920000e+03 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119055361.88620508 119055361.88620508
All candidates indexes:  (array([20, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 21
Intermediate:  0.0078125
6.125
Total layers size  110.73641204833984
Server, client, server+client, vanilla  257.564453125 91.6800537109375 349.2445068359375 1429.9613037109375
Candidate split  21
Server, client, server+client, vanilla  257.564453125 91.6800537109375 349.2445068359375 1429.9613037109375
Model size  90.083984375
Fixed, scale_with_bsz  90.083984375 6.69921875
Mem usage  1390.0 3.0
Using split index: 21
Freezing the lower layers of the model (myresnet50) till index 21
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1390.0, 3.0)
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.9539167881011963 seconds
Streaming plantleave data took 0.9550130367279053 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3195912837982178
Time for copying to cuda: 0.0007603168487548828
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8971185684204102 seconds
Streaming plantleave data took 0.8983376026153564 seconds
Time for forward pass: 2.93888783454895
Time for backpropagation: 0.06508851051330566
GPU memory for training: 0.3899855613708496                          

One training iteration takes: 3.425304651260376 seconds
Index: 0
Then, training+dataloading take 3.425645351409912 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Memory occpied: (1390.0, 1388.0)
Memory occpied: (1390.0, 1388.0)
Time of next(dataloader) is: 0.32349658012390137
Time for copying to cuda: 0.0007178783416748047
Time for forward pass: 0.014160633087158203
Time for backpropagation: 0.007317066192626953
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.41625475883483887 seconds
Index: 1
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.9327058792114258 seconds
Streaming plantleave data took 0.9338493347167969 seconds
Then, training+dataloading take 0.9343481063842773 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39987659454345703
Time for copying to cuda: 0.0007638931274414062
Time for forward pass: 0.012253999710083008
Time for backpropagation: 0.006601095199584961
GPU memory for training: 0.3928656578063965                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.5067112445831299 seconds
Index: 2
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7913212776184082 seconds
Streaming plantleave data took 0.7924580574035645 seconds
Then, training+dataloading take 0.7927365303039551 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32560038566589355
Time for copying to cuda: 0.0007188320159912109
Time for forward pass: 0.012052297592163086
Time for backpropagation: 0.006514072418212891
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42986488342285156 seconds
Index: 3
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7814786434173584 seconds
Streaming plantleave data took 0.7826004028320312 seconds
Then, training+dataloading take 0.7830369472503662 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.367779016494751
Time for copying to cuda: 0.0007126331329345703
Time for forward pass: 0.012059688568115234
Time for backpropagation: 0.0064389705657958984
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.45502686500549316 seconds
Index: 4
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8060016632080078 seconds
Streaming plantleave data took 0.8071064949035645 seconds
Then, training+dataloading take 0.8074488639831543 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32381153106689453
Time for copying to cuda: 0.0006897449493408203
Time for forward pass: 0.011854410171508789
Time for backpropagation: 0.006382465362548828
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42525506019592285 seconds
Index: 5
Memory occpied: (1620.0, 1396.0)
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7924985885620117 seconds
Streaming plantleave data took 0.7936699390411377 seconds
Then, training+dataloading take 0.794032096862793 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3445777893066406
Time for copying to cuda: 0.0007262229919433594
Time for forward pass: 0.012049198150634766
Time for backpropagation: 0.006481170654296875
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42813682556152344 seconds
Index: 6
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7726273536682129 seconds
Streaming plantleave data took 0.7735836505889893 seconds
Then, training+dataloading take 0.7739200592041016 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4137425422668457
Time for copying to cuda: 0.0007076263427734375
Time for forward pass: 0.011927366256713867
Time for backpropagation: 0.006420612335205078
GPU memory for training: 0.3928656578063965                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.5039112567901611 seconds
Index: 7
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8740217685699463 seconds
Streaming plantleave data took 0.8749721050262451 seconds
Then, training+dataloading take 0.875253438949585 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3290889263153076
Time for copying to cuda: 0.0007545948028564453
Time for forward pass: 0.012035846710205078
Time for backpropagation: 0.006361484527587891
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.4240729808807373 seconds
Index: 8
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8101687431335449 seconds
Streaming plantleave data took 0.8119184970855713 seconds
Then, training+dataloading take 0.8124105930328369 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.34165525436401367
Time for copying to cuda: 0.0006899833679199219
Time for forward pass: 0.011926412582397461
Time for backpropagation: 0.006359100341796875
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.436185359954834 seconds
Index: 9
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7978425025939941 seconds
Streaming plantleave data took 0.7987747192382812 seconds
Then, training+dataloading take 0.7991409301757812 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3632831573486328
Time for copying to cuda: 0.0007381439208984375
Time for forward pass: 0.01213693618774414
Time for backpropagation: 0.05849957466125488
GPU memory for training: 0.3928656578063965                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.5320961475372314 seconds
Index: 10
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8201334476470947 seconds
Streaming plantleave data took 0.8210780620574951 seconds
Then, training+dataloading take 0.8213467597961426 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32483839988708496
Time for copying to cuda: 0.0007150173187255859
Time for forward pass: 0.01206350326538086
Time for backpropagation: 0.0063860416412353516
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.4126882553100586 seconds
Index: 11
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8255836963653564 seconds
Streaming plantleave data took 0.8273117542266846 seconds
Then, training+dataloading take 0.8280670642852783 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.34501218795776367
Time for copying to cuda: 0.0006933212280273438
Time for forward pass: 0.011986732482910156
Time for backpropagation: 0.006364345550537109
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.4286775588989258 seconds
Index: 12
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7944941520690918 seconds
Streaming plantleave data took 0.7954456806182861 seconds
Then, training+dataloading take 0.7958719730377197 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32515501976013184
Time for copying to cuda: 0.0006999969482421875
Time for forward pass: 0.011910200119018555
Time for backpropagation: 0.04534173011779785
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.5049102306365967 seconds
Index: 13
Memory occpied: (1620.0, 1396.0)
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7855134010314941 seconds
Streaming plantleave data took 0.7864804267883301 seconds
Then, training+dataloading take 0.7867710590362549 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3254222869873047
Time for copying to cuda: 0.0007593631744384766
Time for forward pass: 0.012005329132080078
Time for backpropagation: 0.006511688232421875
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42096567153930664 seconds
Index: 14
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8543140888214111 seconds
Streaming plantleave data took 0.8560733795166016 seconds
Then, training+dataloading take 0.8565285205841064 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.3631312847137451
Time for copying to cuda: 0.0007243156433105469
Time for forward pass: 0.011958599090576172
Time for backpropagation: 0.006516695022583008
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.45118284225463867 seconds
Index: 15
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7885396480560303 seconds
Streaming plantleave data took 0.7894940376281738 seconds
Then, training+dataloading take 0.7898898124694824 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32589173316955566
Time for copying to cuda: 0.0007257461547851562
Time for forward pass: 0.012055397033691406
Time for backpropagation: 0.006510734558105469
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.40964412689208984 seconds
Index: 16
Memory occpied: (1620.0, 1396.0)
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7875337600708008 seconds
Streaming plantleave data took 0.7885289192199707 seconds
Then, training+dataloading take 0.7889108657836914 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3422048091888428
Time for copying to cuda: 0.0007326602935791016
Time for forward pass: 0.011891365051269531
Time for backpropagation: 0.0064694881439208984
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42566347122192383 seconds
Index: 17
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.767369270324707 seconds
Streaming plantleave data took 0.7683203220367432 seconds
Then, training+dataloading take 0.7686469554901123 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4167935848236084
Time for copying to cuda: 0.0007135868072509766
Time for forward pass: 0.012161016464233398
Memory occpied: (1620.0, 1396.0)
Time for backpropagation: 0.006715297698974609
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.5228736400604248 seconds
Index: 18
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.793705940246582 seconds
Streaming plantleave data took 0.794642448425293 seconds
Then, training+dataloading take 0.7949323654174805 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3410673141479492
Time for copying to cuda: 0.000713348388671875
Time for forward pass: 0.012059926986694336
Time for backpropagation: 0.0065195560455322266
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.42470479011535645 seconds
Index: 19
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.8043615818023682 seconds
Streaming plantleave data took 0.8060598373413086 seconds
Then, training+dataloading take 0.8065664768218994 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.33139824867248535
Time for copying to cuda: 0.00075531005859375
Time for forward pass: 0.011991739273071289
Time for backpropagation: 0.006563901901245117
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.43857717514038086 seconds
Index: 20
Read 1.5704154968261719 MBs for this batch
Executing all posts took 0.7746777534484863 seconds
Streaming plantleave data took 0.7756185531616211 seconds
Then, training+dataloading take 0.7761540412902832 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3609929084777832
Time for copying to cuda: 0.0007269382476806641
Time for forward pass: 0.012232780456542969
Time for backpropagation: 0.006674766540527344
GPU memory for training: 0.3928656578063965                          

One training iteration takes: 0.466158390045166 seconds
Index: 21
Memory occpied: (1620.0, 1396.0)
Read 0.801020622253418 MBs for this batch
Executing all posts took 0.624253511428833 seconds
Streaming plantleave data took 0.6248414516448975 seconds
Then, training+dataloading take 0.6251020431518555 seconds

Epoch: 0
Time of next(dataloader) is: 0.32843804359436035
Time for copying to cuda: 0.0005371570587158203
Time for forward pass: 0.05937647819519043
Time for backpropagation: 0.007511615753173828
GPU memory for training: 0.3910059928894043                          

The whole process took 28.52111792564392 seconds
