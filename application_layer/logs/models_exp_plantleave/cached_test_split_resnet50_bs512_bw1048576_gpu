Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=512, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=21, model='myresnet50', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5870636458283 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.4450688e+07
 1.4450688e+07 1.4450688e+07 1.0838016e+07 7.2253440e+06 7.2253440e+06
 7.2253440e+06 5.4190080e+06 3.6126720e+06 3.6126720e+06 3.6126720e+06
 3.6126720e+06 3.6126720e+06 2.7095040e+06 1.8063360e+06 1.8063360e+06
 8.1920000e+03 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119090323.606186 119090323.606186
All candidates indexes:  (array([20, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 21
Intermediate:  0.0078125
6.125
Total layers size  110.73641204833984
Server, client, server+client, vanilla  304.458984375 94.169921875 398.62890625 3520.169921875
Candidate split  21
Server, client, server+client, vanilla  304.458984375 94.169921875 398.62890625 3520.169921875
Model size  90.083984375
Fixed, scale_with_bsz  90.083984375 6.69921875
Mem usage  1390.0 3.0
Using split index: 21
Freezing the lower layers of the model (myresnet50) till index 21
The mode is:  split
Start 0, end 512, post_step 64

Memory occpied: (1390.0, 3.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.2431578636169434 seconds
Streaming plantleave data took 1.246372938156128 seconds
The mode is:  split
Start 512, end 1024, post_step 64


Epoch: 0
Memory occpied: (1390.0, 3.0)
Time of next(dataloader) is: 0.2508211135864258
Time for copying to cuda: 0.0013933181762695312
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.140289545059204 seconds
Streaming plantleave data took 1.143392562866211 seconds
Memory occpied: (1390.0, 476.0)
Memory occpied: (1390.0, 898.0)
Time for forward pass: 3.039780855178833
Time for backpropagation: 0.06362462043762207
GPU memory for training: 0.39104604721069336                          

One training iteration takes: 3.406298875808716 seconds
Index: 0
Then, training+dataloading take 3.406372547149658 seconds
The mode is:  split
Start 1024, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3141040802001953
Time for copying to cuda: 0.0014688968658447266
Time for forward pass: 0.013771533966064453
Time for backpropagation: 0.006315946578979492
GPU memory for training: 0.3958606719970703                          

Memory occpied: (1606.0, 1404.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.2851066589355469 seconds
Streaming plantleave data took 1.2875752449035645 seconds
Memory occpied: (1614.0, 1404.0)
Memory occpied: (1614.0, 1404.0)
Memory occpied: (1614.0, 1404.0)
Memory occpied: (1614.0, 1404.0)
One training iteration takes: 5.34648871421814 seconds
Index: 1
Then, training+dataloading take 5.346562623977661 seconds
The mode is:  split
Start 1536, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.2702913284301758
Time for copying to cuda: 0.0013585090637207031
Time for forward pass: 0.012037038803100586
Time for backpropagation: 0.006286144256591797
GPU memory for training: 0.3958606719970703                          

Memory occpied: (1614.0, 1404.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.2124252319335938 seconds
Streaming plantleave data took 1.2148075103759766 seconds
Memory occpied: (1614.0, 1404.0)
Memory occpied: (1614.0, 1404.0)
Memory occpied: (1614.0, 1404.0)
One training iteration takes: 5.304798126220703 seconds
Index: 2
Then, training+dataloading take 5.3048741817474365 seconds
The mode is:  split
Start 2048, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3084383010864258
Time for copying to cuda: 0.001447916030883789
Time for forward pass: 0.012027263641357422
Time for backpropagation: 0.0063016414642333984
GPU memory for training: 0.3958606719970703                          

One training iteration takes: 0.41501498222351074 seconds
Index: 3
Memory occpied: (1614.0, 1404.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.2571682929992676 seconds
Streaming plantleave data took 1.259507656097412 seconds
Then, training+dataloading take 1.2599053382873535 seconds
The mode is:  split
Start 2560, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.30934953689575195
Time for copying to cuda: 0.0014109611511230469
Time for forward pass: 0.04479479789733887
Time for backpropagation: 0.006999015808105469
GPU memory for training: 0.3958606719970703                          

Memory occpied: (1614.0, 1404.0)
One training iteration takes: 0.4306833744049072 seconds
Index: 4
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.1740803718566895 seconds
Streaming plantleave data took 1.1763923168182373 seconds
Then, training+dataloading take 1.176816463470459 seconds
The mode is:  split
Start 3072, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.30759692192077637
Time for copying to cuda: 0.00144195556640625
Time for forward pass: 0.012375116348266602
Time for backpropagation: 0.006472349166870117
GPU memory for training: 0.3958606719970703                          

One training iteration takes: 0.4020106792449951 seconds
Index: 5
Memory occpied: (1614.0, 1404.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.1320865154266357 seconds
Streaming plantleave data took 1.1338047981262207 seconds
Then, training+dataloading take 1.1342179775238037 seconds
The mode is:  split
Start 3584, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.2713620662689209
Time for copying to cuda: 0.0013713836669921875
Time for forward pass: 0.01208043098449707
Time for backpropagation: 0.0063304901123046875
GPU memory for training: 0.3958606719970703                          

One training iteration takes: 0.3622887134552002 seconds
Index: 6
Memory occpied: (1614.0, 1404.0)
Read 4.01995849609375 MBs for this batch
Executing all posts took 1.1869392395019531 seconds
Streaming plantleave data took 1.188713550567627 seconds
Then, training+dataloading take 1.1892237663269043 seconds
The mode is:  split
Start 4096, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.27565550804138184
Time for copying to cuda: 0.0014088153839111328
Time for forward pass: 0.012082815170288086
Time for backpropagation: 0.006381988525390625
GPU memory for training: 0.3958606719970703                          

One training iteration takes: 0.3824915885925293 seconds
Index: 7
Memory occpied: (1614.0, 1404.0)
Read 3.1877737045288086 MBs for this batch
Executing all posts took 1.0000677108764648 seconds
Streaming plantleave data took 1.001652717590332 seconds
Then, training+dataloading take 1.002164363861084 seconds

Epoch: 0
Time of next(dataloader) is: 0.2722508907318115
Time for copying to cuda: 0.0011069774627685547
Time for forward pass: 0.012021303176879883
Time for backpropagation: 0.006291627883911133
GPU memory for training: 0.3944978713989258                          

The whole process took 27.733696937561035 seconds
