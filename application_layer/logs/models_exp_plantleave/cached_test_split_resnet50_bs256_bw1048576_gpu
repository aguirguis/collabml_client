Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=256, cached=True, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=21, model='myresnet50', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2991462455025 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.4450688e+07
 1.4450688e+07 1.4450688e+07 1.0838016e+07 7.2253440e+06 7.2253440e+06
 7.2253440e+06 5.4190080e+06 3.6126720e+06 3.6126720e+06 3.6126720e+06
 3.6126720e+06 3.6126720e+06 2.7095040e+06 1.8063360e+06 1.8063360e+06
 8.1920000e+03 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119052585.6966905 119052585.6966905
All candidates indexes:  (array([20, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 21
Intermediate:  0.0078125
6.125
Total layers size  110.73641204833984
Server, client, server+client, vanilla  304.458984375 92.126953125 396.5859375 1805.126953125
Candidate split  21
Server, client, server+client, vanilla  304.458984375 92.126953125 396.5859375 1805.126953125
Model size  90.083984375
Fixed, scale_with_bsz  90.083984375 6.69921875
Mem usage  1390.0 3.0
Using split index: 21
Freezing the lower layers of the model (myresnet50) till index 21
The mode is:  split
Start 0, end 256, post_step 64

Memory occpied: (1390.0, 3.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7972941398620605 seconds
Streaming plantleave data took 0.7984733581542969 seconds
The mode is:  split
Start 256, end 512, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3231692314147949
Time for copying to cuda: 0.0009188652038574219
Memory occpied: (1390.0, 132.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7065010070800781 seconds
Streaming plantleave data took 0.7080097198486328 seconds
Memory occpied: (1390.0, 558.0)
Memory occpied: (1390.0, 1026.0)
Time for forward pass: 3.184875726699829
Time for backpropagation: 0.06339693069458008
GPU memory for training: 0.38998985290527344                          

One training iteration takes: 3.648301124572754 seconds
Index: 0
Then, training+dataloading take 3.648369312286377 seconds
The mode is:  split
Start 512, end 768, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.38648557662963867
Time for copying to cuda: 0.0009076595306396484
Time for forward pass: 0.014336109161376953
Time for backpropagation: 0.007508993148803711
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.5154459476470947 seconds
Index: 1
Memory occpied: (1620.0, 1396.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7407357692718506 seconds
Streaming plantleave data took 0.742222785949707 seconds
Then, training+dataloading take 0.742537260055542 seconds
The mode is:  split
Start 768, end 1024, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3407607078552246
Time for copying to cuda: 0.0008630752563476562
Time for forward pass: 0.012125492095947266
Time for backpropagation: 0.006338834762573242
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.42885327339172363 seconds
Index: 2
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.74403977394104 seconds
Streaming plantleave data took 0.7453713417053223 seconds
Then, training+dataloading take 0.7456710338592529 seconds
The mode is:  split
Start 1024, end 1280, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.42586302757263184
Time for copying to cuda: 0.0008716583251953125
Time for forward pass: 0.012027263641357422
Time for backpropagation: 0.006348133087158203
GPU memory for training: 0.3928699493408203                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.513392448425293 seconds
Index: 3
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.6593081951141357 seconds
Streaming plantleave data took 0.6604232788085938 seconds
Then, training+dataloading take 0.6607184410095215 seconds
The mode is:  split
Start 1280, end 1536, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3340272903442383
Time for copying to cuda: 0.0008647441864013672
Time for forward pass: 0.012051105499267578
Time for backpropagation: 0.006338357925415039
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.4246649742126465 seconds
Index: 4
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7495725154876709 seconds
Streaming plantleave data took 0.7507219314575195 seconds
Then, training+dataloading take 0.7510080337524414 seconds
The mode is:  split
Start 1536, end 1792, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4112403392791748
Time for copying to cuda: 0.0008759498596191406
Time for forward pass: 0.012038469314575195
Time for backpropagation: 0.006391763687133789
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.5472671985626221 seconds
Index: 5
Memory occpied: (1620.0, 1396.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.6898198127746582 seconds
Streaming plantleave data took 0.6910004615783691 seconds
Then, training+dataloading take 0.6913192272186279 seconds
The mode is:  split
Start 1792, end 2048, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.33590197563171387
Time for copying to cuda: 0.0008313655853271484
Time for forward pass: 0.012063264846801758
Time for backpropagation: 0.006204128265380859
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.43364500999450684 seconds
Index: 6
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7438452243804932 seconds
Streaming plantleave data took 0.7449963092803955 seconds
Then, training+dataloading take 0.745307207107544 seconds
The mode is:  split
Start 2048, end 2304, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4189727306365967
Time for copying to cuda: 0.0008916854858398438
Time for forward pass: 0.012540578842163086
Time for backpropagation: 0.006361722946166992
GPU memory for training: 0.3928699493408203                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.5329468250274658 seconds
Index: 7
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7162380218505859 seconds
Streaming plantleave data took 0.7176697254180908 seconds
Then, training+dataloading take 0.7179601192474365 seconds
The mode is:  split
Start 2304, end 2560, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.343825101852417
Time for copying to cuda: 0.0008597373962402344
Time for forward pass: 0.012166500091552734
Time for backpropagation: 0.006357669830322266
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.44983935356140137 seconds
Index: 8
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7325217723846436 seconds
Streaming plantleave data took 0.7336645126342773 seconds
Then, training+dataloading take 0.733973503112793 seconds
The mode is:  split
Start 2560, end 2816, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.38265538215637207
Time for copying to cuda: 0.0008602142333984375
Time for forward pass: 0.011953115463256836
Time for backpropagation: 0.006279468536376953
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.5097818374633789 seconds
Index: 9
Memory occpied: (1620.0, 1396.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.6884608268737793 seconds
Streaming plantleave data took 0.6896262168884277 seconds
Then, training+dataloading take 0.6899266242980957 seconds
The mode is:  split
Start 2816, end 3072, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3369264602661133
Time for copying to cuda: 0.0008234977722167969
Time for forward pass: 0.012034416198730469
Time for backpropagation: 0.006281852722167969
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.42747068405151367 seconds
Index: 10
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.6892497539520264 seconds
Streaming plantleave data took 0.69038987159729 seconds
Then, training+dataloading take 0.6906976699829102 seconds
The mode is:  split
Start 3072, end 3328, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.4144432544708252
Time for copying to cuda: 0.0008544921875
Time for forward pass: 0.01228475570678711
Time for backpropagation: 0.00650477409362793
GPU memory for training: 0.3928699493408203                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.5187537670135498 seconds
Index: 11
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.700932502746582 seconds
Streaming plantleave data took 0.7020823955535889 seconds
Then, training+dataloading take 0.7023739814758301 seconds
The mode is:  split
Start 3328, end 3584, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3411247730255127
Time for copying to cuda: 0.0008990764617919922
Time for forward pass: 0.012114286422729492
Time for backpropagation: 0.006293058395385742
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.447629451751709 seconds
Index: 12
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7050812244415283 seconds
Streaming plantleave data took 0.7062211036682129 seconds
Then, training+dataloading take 0.7065021991729736 seconds
The mode is:  split
Start 3584, end 3840, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.433030366897583
Time for copying to cuda: 0.0008668899536132812
Time for forward pass: 0.012069463729858398
Time for backpropagation: 0.006346225738525391
GPU memory for training: 0.3928699493408203                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.521073579788208 seconds
Index: 13
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.6879262924194336 seconds
Streaming plantleave data took 0.6890411376953125 seconds
Then, training+dataloading take 0.689333438873291 seconds
The mode is:  split
Start 3840, end 4096, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.358612060546875
Time for copying to cuda: 0.0008478164672851562
Time for forward pass: 0.011971712112426758
Time for backpropagation: 0.006250858306884766
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.4456136226654053 seconds
Index: 14
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7407312393188477 seconds
Streaming plantleave data took 0.7419178485870361 seconds
Then, training+dataloading take 0.7422103881835938 seconds
The mode is:  split
Start 4096, end 4352, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.39680027961730957
Time for copying to cuda: 0.0008711814880371094
Time for forward pass: 0.01205754280090332
Time for backpropagation: 0.006294727325439453
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.5328598022460938 seconds
Index: 15
Memory occpied: (1620.0, 1396.0)
Read 2.009979248046875 MBs for this batch
Executing all posts took 0.7074406147003174 seconds
Streaming plantleave data took 0.7086572647094727 seconds
Then, training+dataloading take 0.7090141773223877 seconds
The mode is:  split
Start 4352, end 4502, post_step 64


Epoch: 0
Time of next(dataloader) is: 0.3374800682067871
Time for copying to cuda: 0.0008835792541503906
Time for forward pass: 0.012086153030395508
Time for backpropagation: 0.006272792816162109
GPU memory for training: 0.3928699493408203                          

One training iteration takes: 0.4359159469604492 seconds
Index: 16
Read 1.1777944564819336 MBs for this batch
Executing all posts took 0.5538454055786133 seconds
Streaming plantleave data took 0.5545756816864014 seconds
Then, training+dataloading take 0.5548486709594727 seconds

Epoch: 0
Time of next(dataloader) is: 0.3778843879699707
Time for copying to cuda: 0.0006580352783203125
Time for forward pass: 0.012237310409545898
Time for backpropagation: 0.006460428237915039
GPU memory for training: 0.39156389236450195                          

Memory occpied: (1620.0, 1396.0)
The whole process took 23.621480464935303 seconds
