Namespace(batch_size=250, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=21, model='myresnet50', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.0773512307703 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.4450688e+07
 1.4450688e+07 1.4450688e+07 1.0838016e+07 7.2253440e+06 7.2253440e+06
 7.2253440e+06 5.4190080e+06 3.6126720e+06 3.6126720e+06 3.6126720e+06
 3.6126720e+06 3.6126720e+06 2.7095040e+06 1.8063360e+06 1.8063360e+06
 8.1920000e+03 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119023514.58051953 119023514.58051953
All candidates indexes:  (array([20, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 21
Intermediate:  0.0078125
6.125
Total layers size  110.73641204833984
Server, client, server+client, vanilla  257.564453125 92.07907104492188 349.6435241699219 1764.9306335449219
Candidate split  21
Server, client, server+client, vanilla  257.564453125 92.07907104492188 349.6435241699219 1764.9306335449219
Model size  90.083984375
Fixed, scale_with_bsz  90.083984375 6.69921875
Mem usage  1390.0 3.0
Using split index: 21
Freezing the lower layers of the model (myresnet50) till index 21
The mode is:  split
Start 0, end 250, post_step 50

Memory occpied: (1390.0, 3.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.2382311820983887 seconds
Streaming plantleave data took 1.2401864528656006 seconds
The mode is:  split
Start 250, end 500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32282304763793945
Time for copying to cuda: 0.0008950233459472656
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.0989181995391846 seconds
Streaming plantleave data took 1.1004109382629395 seconds
Time for forward pass: 2.909905433654785
Time for backpropagation: 0.06249523162841797
GPU memory for training: 0.38998937606811523                          

Memory occpied: (1390.0, 3.0)
One training iteration takes: 3.3603925704956055 seconds
Index: 0
Then, training+dataloading take 3.360445976257324 seconds
The mode is:  split
Start 500, end 750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33049440383911133
Time for copying to cuda: 0.0008747577667236328
Time for forward pass: 0.013902902603149414
Time for backpropagation: 0.0074193477630615234
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.43460917472839355 seconds
Index: 1
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.2887849807739258 seconds
Streaming plantleave data took 1.2902541160583496 seconds
Then, training+dataloading take 1.2907440662384033 seconds
The mode is:  split
Start 750, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35251736640930176
Time for copying to cuda: 0.0008521080017089844
Time for forward pass: 0.011994123458862305
Time for backpropagation: 0.006435871124267578
GPU memory for training: 0.3928694725036621                          

Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1214141845703125 seconds
Streaming plantleave data took 1.1234064102172852 seconds
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
One training iteration takes: 5.38277268409729 seconds
Index: 2
Then, training+dataloading take 5.382836818695068 seconds
The mode is:  split
Start 1000, end 1250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33559203147888184
Time for copying to cuda: 0.0008711814880371094
Time for forward pass: 0.01196908950805664
Time for backpropagation: 0.00633549690246582
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4364755153656006 seconds
Index: 3
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.0089662075042725 seconds
Streaming plantleave data took 1.0104241371154785 seconds
Then, training+dataloading take 1.0114221572875977 seconds
The mode is:  split
Start 1250, end 1500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3294103145599365
Time for copying to cuda: 0.0008568763732910156
Time for forward pass: 0.012005329132080078
Time for backpropagation: 0.006367921829223633
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4177887439727783 seconds
Index: 4
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1526150703430176 seconds
Streaming plantleave data took 1.154109001159668 seconds
Then, training+dataloading take 1.1544981002807617 seconds
The mode is:  split
Start 1500, end 1750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33262157440185547
Time for copying to cuda: 0.0008516311645507812
Time for forward pass: 0.011958122253417969
Time for backpropagation: 0.006412982940673828
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.41736555099487305 seconds
Index: 5
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.0875270366668701 seconds
Streaming plantleave data took 1.0889835357666016 seconds
Then, training+dataloading take 1.0894098281860352 seconds
The mode is:  split
Start 1750, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35374903678894043
Time for copying to cuda: 0.0008537769317626953
Time for forward pass: 0.012056350708007812
Time for backpropagation: 0.0063703060150146484
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.45828866958618164 seconds
Index: 6
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1881117820739746 seconds
Streaming plantleave data took 1.1893744468688965 seconds
Then, training+dataloading take 1.1898982524871826 seconds
The mode is:  split
Start 2000, end 2250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34031057357788086
Time for copying to cuda: 0.0008325576782226562
Time for forward pass: 0.011989355087280273
Time for backpropagation: 0.006377220153808594
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.44208192825317383 seconds
Index: 7
Read 1.9630193710327148 MBs for this batch
Executing all posts took 0.9692592620849609 seconds
Streaming plantleave data took 0.9704480171203613 seconds
Then, training+dataloading take 0.9710249900817871 seconds
The mode is:  split
Start 2250, end 2500, post_step 50


Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.35312700271606445
Time for copying to cuda: 0.0008440017700195312
Time for forward pass: 0.012105464935302734
Time for backpropagation: 0.006440162658691406
GPU memory for training: 0.3928694725036621                          

Read 1.9630193710327148 MBs for this batch
Executing all posts took 0.9447078704833984 seconds
Streaming plantleave data took 0.9466738700866699 seconds
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
One training iteration takes: 5.38884425163269 seconds
Index: 8
Then, training+dataloading take 5.388920068740845 seconds
The mode is:  split
Start 2500, end 2750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35123372077941895
Time for copying to cuda: 0.0008337497711181641
Time for forward pass: 0.011968851089477539
Time for backpropagation: 0.0065038204193115234
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4412825107574463 seconds
Index: 9
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.0028467178344727 seconds
Streaming plantleave data took 1.0043566226959229 seconds
Then, training+dataloading take 1.0047597885131836 seconds
The mode is:  split
Start 2750, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33463597297668457
Time for copying to cuda: 0.0008614063262939453
Time for forward pass: 0.011981487274169922
Time for backpropagation: 0.006319999694824219
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.43775486946105957 seconds
Index: 10
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1029064655303955 seconds
Streaming plantleave data took 1.1043798923492432 seconds
Then, training+dataloading take 1.1049304008483887 seconds
The mode is:  split
Start 3000, end 3250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3335912227630615
Time for copying to cuda: 0.0008263587951660156
Time for forward pass: 0.011887550354003906
Time for backpropagation: 0.0063953399658203125
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4181556701660156 seconds
Index: 11
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1377954483032227 seconds
Streaming plantleave data took 1.1390125751495361 seconds
Then, training+dataloading take 1.1395981311798096 seconds
The mode is:  split
Start 3250, end 3500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3460569381713867
Time for copying to cuda: 0.0009038448333740234
Time for forward pass: 0.012188196182250977
Time for backpropagation: 0.0066378116607666016
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4354262351989746 seconds
Index: 12
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1207373142242432 seconds
Streaming plantleave data took 1.1219508647918701 seconds
Then, training+dataloading take 1.1225216388702393 seconds
The mode is:  split
Start 3500, end 3750, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3359248638153076
Time for copying to cuda: 0.0008716583251953125
Time for forward pass: 0.012010812759399414
Time for backpropagation: 0.006502389907836914
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4376819133758545 seconds
Index: 13
Read 1.9630193710327148 MBs for this batch
Executing all posts took 0.9602446556091309 seconds
Streaming plantleave data took 0.9614439010620117 seconds
Then, training+dataloading take 0.9617705345153809 seconds
The mode is:  split
Start 3750, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4186689853668213
Time for copying to cuda: 0.0008785724639892578
Time for forward pass: 0.012100458145141602
Time for backpropagation: 0.006529808044433594
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.5597727298736572 seconds
Index: 14
Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.0959138870239258 seconds
Streaming plantleave data took 1.0971155166625977 seconds
Then, training+dataloading take 1.097437858581543 seconds
The mode is:  split
Start 4000, end 4250, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34903931617736816
Time for copying to cuda: 0.0008363723754882812
Time for forward pass: 0.011926651000976562
Time for backpropagation: 0.006440877914428711
GPU memory for training: 0.3928694725036621                          

Memory occpied: (1620.0, 1396.0)
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1030268669128418 seconds
Streaming plantleave data took 1.1050686836242676 seconds
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
Memory occpied: (1620.0, 1396.0)
One training iteration takes: 5.403832912445068 seconds
Index: 15
Then, training+dataloading take 5.403961896896362 seconds
The mode is:  split
Start 4250, end 4500, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3668088912963867
Time for copying to cuda: 0.0008296966552734375
Time for forward pass: 0.012048482894897461
Time for backpropagation: 0.00644993782043457
GPU memory for training: 0.3928694725036621                          

Memory occpied: (1620.0, 1396.0)
One training iteration takes: 0.451279878616333 seconds
Index: 16
Read 1.9630193710327148 MBs for this batch
Executing all posts took 1.1229255199432373 seconds
Streaming plantleave data took 1.1243906021118164 seconds
Then, training+dataloading take 1.1247804164886475 seconds
The mode is:  split
Start 4500, end 4502, post_step 50


Epoch: 0
Read 0.01581287384033203 MBs for this batch
Executing all posts took 0.20042991638183594 seconds
Streaming plantleave data took 0.25194692611694336 seconds
Read 0.01581287384033203 MBs for this batch
Executing all posts took 0.20042991638183594 seconds
Time of next(dataloader) is: 0.3761892318725586
Time for copying to cuda: 0.0008842945098876953
Time for forward pass: 0.012157678604125977
Time for backpropagation: 0.006715297698974609
GPU memory for training: 0.3928694725036621                          

One training iteration takes: 0.4804854393005371 seconds
Index: 17
Then, training+dataloading take 0.48061490058898926 seconds

Epoch: 0
Memory occpied: (1620.0, 1396.0)
Time of next(dataloader) is: 0.3541555404663086
Time for copying to cuda: 0.00021958351135253906
Time for forward pass: 0.012002706527709961
Time for backpropagation: 0.006245136260986328
GPU memory for training: 0.39023447036743164                          

The whole process took 43.021639347076416 seconds
