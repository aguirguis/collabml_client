Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=25, model='myvgg11', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=6, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 9981.180461414311 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 3.2112640e+06 6.4225280e+06 6.4225280e+06
 1.6056320e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 8.0281600e+05 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 4.0000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 1308253285.4384966 1308253285.4384966
All candidates indexes:  (array([20, 21, 22, 23, 24, 25, 26, 27, 28]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 6 25
Intermediate:  1.53125
24.5
Total layers size  62.687408447265625
Server, client, server+client, vanilla  908.396484375 8264.83837890625 9173.23486328125 31807.80712890625
Fixed, scale_with_bsz  0 25.07421875
Mem usage  1840.0 3.0
Using split index: 6
Freezing the lower layers of the model (myvgg11) till index 25
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.114934921264648 seconds
Memory occpied: (1840.0, 3.0)
Streaming imagenet data took 7.737514972686768 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Memory occpied: (1840.0, 3.0)
Time of next(dataloader) is: 1.1365487575531006
Time for copying to cuda: 0.3912012577056885
Memory occpied: (3372.0, 940.0)
Memory occpied: (3372.0, 1412.0)
Memory occpied: (3372.0, 1824.0)
Memory occpied: (12198.0, 10966.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.292346477508545 seconds
Memory occpied: (13452.0, 10966.0)
Streaming imagenet data took 7.990140438079834 seconds
Memory occpied: (13452.0, 10966.0)
Memory occpied: (13452.0, 10966.0)
Memory occpied: (11920.0, 10966.0)
Memory occpied: (11920.0, 10966.0)
Memory occpied: (11920.0, 10966.0)
Time for forward pass: 13.333514928817749
Time for backpropagation: 0.10651326179504395
GPU memory for training: 21.35338592529297                          

Memory occpied: (11930.0, 4082.0)
One training iteration takes: 15.203637599945068 seconds
Index: 0
Then, training+dataloading take 15.207046747207642 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Memory occpied: (11930.0, 4082.0)
Time of next(dataloader) is: 1.2656514644622803
Time for copying to cuda: 0.38901329040527344
Memory occpied: (11928.0, 9388.0)
Memory occpied: (11928.0, 9388.0)
Time for forward pass: 2.7448737621307373
Time for backpropagation: 0.004381895065307617
GPU memory for training: 16.727325439453125                          

One training iteration takes: 4.670241117477417 seconds
Index: 1
Memory occpied: (11936.0, 4090.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.374417304992676 seconds
Memory occpied: (11936.0, 4090.0)
Streaming imagenet data took 8.011707544326782 seconds
Then, training+dataloading take 8.094083309173584 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 4090.0)
Time of next(dataloader) is: 1.296147108078003
Time for copying to cuda: 0.388946533203125
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8826813697814941
Time for backpropagation: 0.0032334327697753906
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.828077793121338 seconds
Index: 2
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 6.904444217681885 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.547095060348511 seconds
Then, training+dataloading take 7.636522054672241 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2211499214172363
Time for copying to cuda: 0.38609743118286133
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8545727729797363
Time for backpropagation: 0.0032546520233154297
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.721264123916626 seconds
Index: 3
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 6.8524909019470215 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.5399909019470215 seconds
Then, training+dataloading take 7.594528913497925 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2783758640289307
Time for copying to cuda: 0.3858654499053955
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8649420738220215
Time for backpropagation: 0.0032460689544677734
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.7978737354278564 seconds
Index: 4
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Memory occpied: (11936.0, 9388.0)
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.168311357498169 seconds
Streaming imagenet data took 7.7320263385772705 seconds
Then, training+dataloading take 7.782958507537842 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2838108539581299
Time for copying to cuda: 0.43326544761657715
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8668370246887207
Time for backpropagation: 0.0032553672790527344
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.855708122253418 seconds
Index: 5
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 6.949468374252319 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.566887617111206 seconds
Then, training+dataloading take 7.61389684677124 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2880666255950928
Time for copying to cuda: 0.388352632522583
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8504443168640137
Time for backpropagation: 0.0032889842987060547
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.7726075649261475 seconds
Index: 6
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.772603511810303 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 8.453092813491821 seconds
Then, training+dataloading take 8.539103507995605 seconds

Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2319374084472656
Time for copying to cuda: 0.39092016220092773
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.864081859588623
Time for backpropagation: 0.0032587051391601562
GPU memory for training: 16.727325439453125                          

The whole process took 81.09723162651062 seconds
