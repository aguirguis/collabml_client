Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=36, model='myvgg19', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=6, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 9969.28135636148 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 1.2845056e+07 1.2845056e+07 3.2112640e+06
 6.4225280e+06 6.4225280e+06 6.4225280e+06 6.4225280e+06 1.6056320e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.6056320e+06
 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 1.6056320e+06 1.6056320e+06 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 1.6384000e+04 4.0000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 1306693645.941012 1306693645.941012
All candidates indexes:  (array([36, 37, 38, 39, 40, 41, 42, 43, 44]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 6 36
Intermediate:  6.125
24.5
Total layers size  119.34365844726562
Server, client, server+client, vanilla  949.6103515625 19501.36474609375 20450.97509765625 38450.58349609375
Fixed, scale_with_bsz  0 25.07421875
Mem usage  1894.0 3.0
Using split index: 6
Freezing the lower layers of the model (myvgg19) till index 36
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 23.934688806533813 seconds
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Streaming imagenet data took 26.50693130493164 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 4.121419191360474
Time for copying to cuda: 1.544480800628662
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 25.428345918655396 seconds
Streaming imagenet data took 27.71776032447815 seconds
Time for forward pass: 25.21941614151001
Time for backpropagation: 0.05034494400024414
GPU memory for training: 21.65230655670166                          

One training iteration takes: 31.74867081642151 seconds
Index: 0
Then, training+dataloading take 31.76178002357483 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Memory occpied: (1894.0, 10552.0)
Memory occpied: (1894.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Time of next(dataloader) is: 4.1169915199279785
Memory occpied: (9520.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Time for copying to cuda: 1.6916096210479736
Memory occpied: (13712.0, 10560.0)
Memory occpied: (13712.0, 10560.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/collabml_client/application_layer/models/myvgg.py", line 39, in forward
    x = m(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/pooling.py", line 162, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py", line 422, in fn
    return if_false(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 797, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 14.76 GiB total capacity; 11.18 GiB already allocated; 1.36 GiB free; 12.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 76.26175022125244 seconds
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 24.198720455169678 seconds
Streaming imagenet data took 26.453901529312134 seconds
