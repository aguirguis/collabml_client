Namespace(batch_size=4000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4882052578871 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119077366.03956178 119077366.03956178
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 1060.849609375 1345.58837890625 9125.302734375
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 1060.849609375 1345.58837890625 9125.302734375
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 4000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.8321316242218018 seconds
Streaming imagenet data took 3.886237859725952 seconds
The mode is:  split
Start 4000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39988112449645996
Time for copying to cuda: 0.037014007568359375
Memory occpied: (1656.0, 318.0)
Memory occpied: (1656.0, 746.0)
Memory occpied: (1656.0, 1170.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.91097354888916 seconds
Time for forward pass: 3.5203425884246826
Streaming imagenet data took 3.9670639038085938 seconds
Time for backpropagation: 0.05836033821105957
GPU memory for training: 1.2877898216247559                          

One training iteration takes: 4.0966551303863525 seconds
Index: 0
Then, training+dataloading take 4.09706711769104 seconds
The mode is:  split
Start 8000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.45691418647766113
Time for copying to cuda: 0.07659173011779785
Memory occpied: (2242.0, 1738.0)
Time for forward pass: 0.10176920890808105
Time for backpropagation: 0.003665447235107422
GPU memory for training: 1.4443821907043457                          

One training iteration takes: 0.7332723140716553 seconds
Index: 1
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.5989928245544434 seconds
Streaming imagenet data took 3.653259038925171 seconds
Then, training+dataloading take 3.6622071266174316 seconds
The mode is:  split
Start 12000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4572279453277588
Time for copying to cuda: 0.0784451961517334
Memory occpied: (2548.0, 1738.0)
Time for forward pass: 0.12896084785461426
Time for backpropagation: 0.0031332969665527344
GPU memory for training: 1.4443821907043457                          

One training iteration takes: 0.771045446395874 seconds
Index: 2
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.5465211868286133 seconds
Streaming imagenet data took 3.6009416580200195 seconds
Then, training+dataloading take 3.6103999614715576 seconds
The mode is:  split
Start 16000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.45687031745910645
Time for copying to cuda: 0.036452293395996094
Time for forward pass: 0.12914133071899414
Time for backpropagation: 0.0029439926147460938
GPU memory for training: 1.4443821907043457                          

One training iteration takes: 0.730243444442749 seconds
Index: 3
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.479229688644409 seconds
Streaming imagenet data took 3.5337095260620117 seconds
Then, training+dataloading take 3.543299913406372 seconds
The mode is:  split
Start 20000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4833836555480957
Time for copying to cuda: 0.03601384162902832
Time for forward pass: 0.12877106666564941
Time for backpropagation: 0.0027632713317871094
GPU memory for training: 1.4443821907043457                          

One training iteration takes: 0.761970043182373 seconds
Index: 4
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Memory occpied: (2548.0, 1738.0)
Read 140.7875518798828 MBs for this batch
Executing all posts took 3.691044569015503 seconds
Streaming imagenet data took 3.744802474975586 seconds
Then, training+dataloading take 3.754417896270752 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.48181939125061035
Read 11.263076782226562 MBs for this batch
Executing all posts took 0.5231266021728516 seconds
Time for copying to cuda: 0.04094529151916504
Streaming imagenet data took 0.5440900325775146 seconds
Time for forward pass: 0.12894129753112793
Time for backpropagation: 0.0027403831481933594
GPU memory for training: 1.4443821907043457                          

One training iteration takes: 0.7597012519836426 seconds
Index: 5
Then, training+dataloading take 0.7599301338195801 seconds

Epoch: 0
Time of next(dataloader) is: 0.4340991973876953
Time for copying to cuda: 0.0032248497009277344
Time for forward pass: 0.028248071670532227
Time for backpropagation: 0.0026061534881591797
GPU memory for training: 1.0992178916931152                          

Memory occpied: (2548.0, 1738.0)
The whole process took 31.310189962387085 seconds
