Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=14, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
Initialize time: 1.1618013381958008
Time to prepare transforms: 0.00025343894958496094
Time to download labels: 0.04911041259765625
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5434648516031 Mbps
Get bandwitdh took 1.2327332496643066
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 119084609.02502932 119084609.02502932
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 14 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  266.27734375 440.30517578125 706.58251953125 2456.41845703125
Fixed, scale_with_bsz  0 2.05126953125
Mem usage  1514.0 3.0
Time for splitting algorithm: 5.2229228019714355
Using split index: 14
Freezing the lower layers of the model (myalexnet) till index 17
Time to freeze model: 0.00020194053649902344
Time for model prep: 0.0007994174957275391
Time for model and splitting algorithm: 5.223942756652832
The mode is:  split
Start 0, end 1000, post_step 1000

GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [1514.0, 3.0] Time: 0.32720255851745605
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [1514.0, 3.0] Time: 1.6600804328918457
Length of received data: 36906612
Future took 1.8473875522613525 seconds
Pickle took 0.021167755126953125 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8687269687652588 seconds
Dataloader took 0.01374053955078125 seconds
Streaming imagenet data took 1.8825008869171143 seconds
First stream takes: 1.8843119144439697 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.02048349380493164
Time for copying to cuda: 0.008342742919921875
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 3, 0']
Memory occupied: [1550.0, 494.0] Time: 3.0394389629364014
Length of received data: 36906612
Future took 1.6430976390838623 seconds
Pickle took 0.016768455505371094 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6600162982940674 seconds
Dataloader took 0.013912200927734375 seconds
Streaming imagenet data took 1.6739699840545654 seconds
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 4, 0']
Memory occupied: [1550.0, 950.0] Time: 4.4542999267578125
Time for forward pass: 3.350205659866333
Time for backpropagation: 0.04919934272766113
GPU memory for training: 0.9945564270019531                          

One training iteration takes: 3.430828094482422 seconds
Index: 0
Then, training+dataloading take 3.4310317039489746 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.020172595977783203
Time for copying to cuda: 0.007917642593383789
Time for forward pass: 0.04526209831237793
Time for backpropagation: 0.0027005672454833984
GPU memory for training: 1.1492953300476074                          

One training iteration takes: 0.07867240905761719 seconds
Index: 1
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 61, 13']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 10, 1']
Memory occupied: [2290.0, 1560.0] Time: 5.8807923793792725
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Length of received data: 36906612
Future took 1.9721448421478271 seconds
Pickle took 0.02120065689086914 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.9935243129730225 seconds
Memory occupied: [2290.0, 1560.0] Time: 7.3198771476745605
Dataloader took 0.014091730117797852 seconds
Streaming imagenet data took 2.0076563358306885 seconds
Then, training+dataloading take 2.0084056854248047 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.019230365753173828
Time for copying to cuda: 0.007811069488525391
Time for forward pass: 0.045380353927612305
Time for backpropagation: 0.0022020339965820312
GPU memory for training: 1.1496615409851074                          

One training iteration takes: 0.07694101333618164 seconds
Index: 2
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [2290.0, 1560.0] Time: 8.759673833847046
Length of received data: 36906612
Future took 1.6732711791992188 seconds
Pickle took 0.01652240753173828 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6899378299713135 seconds
Dataloader took 0.01364588737487793 seconds
Streaming imagenet data took 1.7036216259002686 seconds
Then, training+dataloading take 1.7054593563079834 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.019437313079833984
Time for copying to cuda: 0.007875680923461914
Time for forward pass: 0.04533195495605469
Time for backpropagation: 0.0022339820861816406
GPU memory for training: 1.1496615409851074                          

One training iteration takes: 0.07716703414916992 seconds
Index: 3
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [2290.0, 1560.0] Time: 10.19059944152832
Length of received data: 36906612
Future took 1.643726110458374 seconds
Pickle took 0.016350746154785156 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6602134704589844 seconds
Dataloader took 0.014176130294799805 seconds
Streaming imagenet data took 1.6744275093078613 seconds
Then, training+dataloading take 1.6762926578521729 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.019393444061279297
Time for copying to cuda: 0.007873773574829102
Time for forward pass: 0.045406341552734375
Time for backpropagation: 0.0023856163024902344
GPU memory for training: 1.1496615409851074                          

One training iteration takes: 0.07738947868347168 seconds
Index: 4
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [2290.0, 1560.0] Time: 11.632030248641968
Length of received data: 36906612
Future took 1.646320104598999 seconds
Pickle took 0.016326904296875 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6627857685089111 seconds
Dataloader took 0.013998746871948242 seconds
Streaming imagenet data took 1.6768250465393066 seconds
Then, training+dataloading take 1.678788423538208 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.019574880599975586
Time for copying to cuda: 0.007915496826171875
Time for forward pass: 0.04528355598449707
Time for backpropagation: 0.0021886825561523438
GPU memory for training: 1.1496615409851074                          

One training iteration takes: 0.0772407054901123 seconds
Index: 5
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Memory occupied: [2290.0, 1560.0] Time: 13.072412490844727
Length of received data: 36906612
Future took 1.6646387577056885 seconds
Pickle took 0.016615867614746094 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6813914775848389 seconds
Dataloader took 0.05872368812561035 seconds
Streaming imagenet data took 1.7401809692382812 seconds
Then, training+dataloading take 1.7440574169158936 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.020511865615844727
Time for copying to cuda: 0.008022308349609375
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
Time for forward pass: 0.0753028392791748
Time for backpropagation: 0.003281831741333008
GPU memory for training: 1.1496615409851074                          

One training iteration takes: 0.10923552513122559 seconds
Index: 6
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 16, 5']
Memory occupied: [2290.0, 1560.0] Time: 14.520921468734741
GPU ID:  0  uuid,utilization.gpu,utilization.memory:  ['GPU-be601ad8-2c65-26d5-b2a8-47f20f99e389, 0, 0']
GPU ID:  1  uuid,utilization.gpu,utilization.memory:  ['GPU-938738c2-611e-c1d4-d629-2d6173de0c19, 0, 0']
Length of received data: 36906612
Future took 1.80277419090271 seconds
Pickle took 0.024046897888183594 seconds
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8270719051361084 seconds
Memory occupied: [2290.0, 1560.0] Time: 15.968727588653564
Dataloader took 0.014174461364746094 seconds
Streaming imagenet data took 1.8412995338439941 seconds
Then, training+dataloading take 1.8434422016143799 seconds

Epoch: 0
Time of next(dataloader) is: 0.019835472106933594
Time for copying to cuda: 0.007853984832763672
Time for forward pass: 0.04521298408508301
Time for backpropagation: 0.002153635025024414
GPU memory for training: 1.1496615409851074                          

Last train takes: 0.07715201377868652 seconds
Total time for streaming and training: 16.049108505249023
Finish gpu thread time: 0.9206981658935547
The whole process took 23.405274152755737 seconds
