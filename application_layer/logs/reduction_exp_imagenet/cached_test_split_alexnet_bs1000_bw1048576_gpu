Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 906.8913824124403 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118868067.27556337 118868067.27556337
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6673979759216309 seconds
Streaming imagenet data took 1.6811153888702393 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.324263334274292
Time for copying to cuda: 0.01004934310913086
Memory occpied: (1550.0, 246.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6809172630310059 seconds
Streaming imagenet data took 1.694998025894165 seconds
Memory occpied: (1550.0, 674.0)
Memory occpied: (1550.0, 1150.0)
Time for forward pass: 3.2442872524261475
Time for backpropagation: 0.051131486892700195
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.69215726852417 seconds
Index: 0
Then, training+dataloading take 3.6923470497131348 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3552255630493164
Time for copying to cuda: 0.009572505950927734
Time for forward pass: 0.049794912338256836
Time for backpropagation: 0.0033915042877197266
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.513768196105957 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.598912000656128 seconds
Streaming imagenet data took 1.6128199100494385 seconds
Then, training+dataloading take 1.615311861038208 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4852266311645508
Time for copying to cuda: 0.009479522705078125
Time for forward pass: 0.049147844314575195
Time for backpropagation: 0.0025787353515625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.6451406478881836 seconds
Index: 2
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6091992855072021 seconds
Streaming imagenet data took 1.6803741455078125 seconds
Then, training+dataloading take 1.6847898960113525 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3587183952331543
Time for copying to cuda: 0.009581565856933594
Time for forward pass: 0.049347639083862305
Time for backpropagation: 0.00272369384765625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5187685489654541 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.623077154159546 seconds
Streaming imagenet data took 1.637063980102539 seconds
Then, training+dataloading take 1.6397984027862549 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40232157707214355
Time for copying to cuda: 0.009623050689697266
Time for forward pass: 0.049332380294799805
Time for backpropagation: 0.002721071243286133
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5559089183807373 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6237974166870117 seconds
Streaming imagenet data took 1.637709617614746 seconds
Then, training+dataloading take 1.6403298377990723 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.46526479721069336
Time for copying to cuda: 0.00954747200012207
Time for forward pass: 0.049396514892578125
Time for backpropagation: 0.0027229785919189453
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.6195707321166992 seconds
Index: 5
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6557722091674805 seconds
Streaming imagenet data took 1.7113397121429443 seconds
Then, training+dataloading take 1.715794324874878 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.36527490615844727
Time for copying to cuda: 0.009576559066772461
Time for forward pass: 0.0493776798248291
Time for backpropagation: 0.002848386764526367
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.515711784362793 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.603797197341919 seconds
Streaming imagenet data took 1.617997407913208 seconds
Then, training+dataloading take 1.6207177639007568 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39453911781311035
Time for copying to cuda: 0.009487390518188477
Time for forward pass: 0.0492708683013916
Time for backpropagation: 0.00260162353515625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5480351448059082 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6049065589904785 seconds
Streaming imagenet data took 1.6186153888702393 seconds
Then, training+dataloading take 1.62117600440979 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4085531234741211
Time for copying to cuda: 0.009592533111572266
Time for forward pass: 0.04940319061279297
Time for backpropagation: 0.0027070045471191406
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.568610429763794 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6106626987457275 seconds
Streaming imagenet data took 1.6665163040161133 seconds
Then, training+dataloading take 1.6708779335021973 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4328162670135498
Time for copying to cuda: 0.009390115737915039
Time for forward pass: 0.049314022064208984
Time for backpropagation: 0.002710103988647461
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5889499187469482 seconds
Index: 9
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6495556831359863 seconds
Streaming imagenet data took 1.6637022495269775 seconds
Then, training+dataloading take 1.6663925647735596 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4179422855377197
Time for copying to cuda: 0.009810686111450195
Time for forward pass: 0.0495152473449707
Time for backpropagation: 0.0027425289154052734
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5702085494995117 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6248528957366943 seconds
Streaming imagenet data took 1.6387927532196045 seconds
Then, training+dataloading take 1.641493797302246 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3946502208709717
Time for copying to cuda: 0.009595870971679688
Time for forward pass: 0.049324989318847656
Time for backpropagation: 0.0026092529296875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5462274551391602 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5913829803466797 seconds
Streaming imagenet data took 1.6056873798370361 seconds
Then, training+dataloading take 1.6083967685699463 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3708522319793701
Time for copying to cuda: 0.00952005386352539
Time for forward pass: 0.08795738220214844
Time for backpropagation: 0.0035772323608398438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5574111938476562 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5963985919952393 seconds
Streaming imagenet data took 1.610177755355835 seconds
Then, training+dataloading take 1.6128053665161133 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42905712127685547
Time for copying to cuda: 0.009698152542114258
Time for forward pass: 0.0493924617767334
Time for backpropagation: 0.002978086471557617
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.6251280307769775 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6299097537994385 seconds
Streaming imagenet data took 1.643782138824463 seconds
Then, training+dataloading take 1.6463520526885986 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42998671531677246
Time for copying to cuda: 0.009639978408813477
Time for forward pass: 0.04921078681945801
Time for backpropagation: 0.0026738643646240234
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.6161973476409912 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6813368797302246 seconds
Streaming imagenet data took 1.7380311489105225 seconds
Then, training+dataloading take 1.7423608303070068 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.43144726753234863
Time for copying to cuda: 0.0096893310546875
Time for forward pass: 0.049284934997558594
Time for backpropagation: 0.0026259422302246094
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5931904315948486 seconds
Index: 15
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6693084239959717 seconds
Streaming imagenet data took 1.6835713386535645 seconds
Then, training+dataloading take 1.6854336261749268 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40943145751953125
Time for copying to cuda: 0.009575366973876953
Time for forward pass: 0.049234628677368164
Time for backpropagation: 0.0025703907012939453
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5676424503326416 seconds
Index: 16
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7482330799102783 seconds
Streaming imagenet data took 1.7625775337219238 seconds
Then, training+dataloading take 1.7642340660095215 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.39026522636413574
Time for copying to cuda: 0.009608745574951172
Time for forward pass: 0.04922008514404297
Time for backpropagation: 0.002624034881591797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5445239543914795 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5932896137237549 seconds
Streaming imagenet data took 1.607358694076538 seconds
Then, training+dataloading take 1.61006498336792 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3652637004852295
Time for copying to cuda: 0.009454011917114258
Time for forward pass: 0.04927206039428711
Time for backpropagation: 0.002598285675048828
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5005440711975098 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5701699256896973 seconds
Streaming imagenet data took 1.5840122699737549 seconds
Then, training+dataloading take 1.5866358280181885 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3985099792480469
Time for copying to cuda: 0.00969076156616211
Time for forward pass: 0.04963541030883789
Time for backpropagation: 0.0026693344116210938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5653805732727051 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5733399391174316 seconds
Streaming imagenet data took 1.629300832748413 seconds
Then, training+dataloading take 1.6337370872497559 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4055516719818115
Time for copying to cuda: 0.009546756744384766
Time for forward pass: 0.04924345016479492
Time for backpropagation: 0.002511739730834961
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5538551807403564 seconds
Index: 20
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6682038307189941 seconds
Streaming imagenet data took 1.7235214710235596 seconds
Then, training+dataloading take 1.7279961109161377 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.38466310501098633
Time for copying to cuda: 0.009452581405639648
Time for forward pass: 0.049199819564819336
Time for backpropagation: 0.002564668655395508
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5342161655426025 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5756633281707764 seconds
Streaming imagenet data took 1.5895912647247314 seconds
Then, training+dataloading take 1.5923354625701904 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39246082305908203
Time for copying to cuda: 0.00958251953125
Time for forward pass: 0.049309730529785156
Time for backpropagation: 0.0025756359100341797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5402939319610596 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.603679895401001 seconds
Streaming imagenet data took 1.617875099182129 seconds
Then, training+dataloading take 1.6204946041107178 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3781163692474365
Time for copying to cuda: 0.009662151336669922
Time for forward pass: 0.049596548080444336
Time for backpropagation: 0.002737760543823242
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5511105060577393 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6413817405700684 seconds
Streaming imagenet data took 1.6553914546966553 seconds
Then, training+dataloading take 1.6578943729400635 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.43288207054138184
Time for copying to cuda: 0.009462594985961914
Time for forward pass: 0.04923248291015625
Time for backpropagation: 0.0025911331176757812
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.591646671295166 seconds
Index: 24
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.672574520111084 seconds
Streaming imagenet data took 1.7344131469726562 seconds
Then, training+dataloading take 1.7387382984161377 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.36559224128723145
Time for copying to cuda: 0.009599924087524414
Time for forward pass: 0.04926347732543945
Time for backpropagation: 0.0028667449951171875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.527766227722168 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6089787483215332 seconds
Streaming imagenet data took 1.6229159832000732 seconds
Then, training+dataloading take 1.625713586807251 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3666419982910156
Time for copying to cuda: 0.009499311447143555
Time for forward pass: 0.04926180839538574
Time for backpropagation: 0.002609729766845703
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5225043296813965 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5865538120269775 seconds
Streaming imagenet data took 1.6002774238586426 seconds
Then, training+dataloading take 1.6029295921325684 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3795506954193115
Time for copying to cuda: 0.009655237197875977
Time for forward pass: 0.0494687557220459
Time for backpropagation: 0.0026962757110595703
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5537562370300293 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6607489585876465 seconds
Streaming imagenet data took 1.675011396408081 seconds
Then, training+dataloading take 1.6775031089782715 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4113352298736572
Time for copying to cuda: 0.009628772735595703
Time for forward pass: 0.0493311882019043
Time for backpropagation: 0.0026433467864990234
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5706448554992676 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6587131023406982 seconds
Streaming imagenet data took 1.6731908321380615 seconds
Then, training+dataloading take 1.6758019924163818 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37340378761291504
Time for copying to cuda: 0.00972437858581543
Time for forward pass: 0.049365997314453125
Time for backpropagation: 0.0026717185974121094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5280225276947021 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6291301250457764 seconds
Streaming imagenet data took 1.6432909965515137 seconds
Then, training+dataloading take 1.6459581851959229 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37262845039367676
Time for copying to cuda: 0.009694099426269531
Time for forward pass: 0.06921696662902832
Time for backpropagation: 0.0031414031982421875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.561769962310791 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.702946424484253 seconds
Streaming imagenet data took 1.7176220417022705 seconds
Then, training+dataloading take 1.7192916870117188 seconds

Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41205930709838867
Time for copying to cuda: 0.009701967239379883
Time for forward pass: 0.049353837966918945
Time for backpropagation: 0.0027403831481933594
GPU memory for training: 1.1639018058776855                          

The whole process took 62.84389042854309 seconds
