Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.7736275684252 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119114776.91264863 119114776.91264863
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.048799753189087 seconds
Streaming imagenet data took 2.076265811920166 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38201355934143066
Time for copying to cuda: 0.01890873908996582
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0045828819274902 seconds
Streaming imagenet data took 2.032454490661621 seconds
Time for forward pass: 3.0283145904541016
Time for backpropagation: 0.05026102066040039
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.5897815227508545 seconds
Index: 0
Then, training+dataloading take 3.5899932384490967 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3805980682373047
Time for copying to cuda: 0.019051551818847656
Time for forward pass: 0.07548332214355469
Time for backpropagation: 0.003793478012084961
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5695755481719971 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.6540307998657227 seconds
Streaming imagenet data took 2.681396007537842 seconds
Then, training+dataloading take 2.6881792545318604 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3928184509277344
Time for copying to cuda: 0.01852107048034668
Time for forward pass: 0.07551121711730957
Time for backpropagation: 0.0027587413787841797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5806655883789062 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.607236385345459 seconds
Streaming imagenet data took 2.634552001953125 seconds
Then, training+dataloading take 2.6399295330047607 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3926427364349365
Time for copying to cuda: 0.018704652786254883
Time for forward pass: 0.07559990882873535
Time for backpropagation: 0.0027828216552734375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5854225158691406 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3158793449401855 seconds
Streaming imagenet data took 2.343737840652466 seconds
Then, training+dataloading take 2.348252773284912 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3957986831665039
Time for copying to cuda: 0.018686294555664062
Time for forward pass: 0.0755610466003418
Time for backpropagation: 0.0027458667755126953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5949845314025879 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.8081893920898438 seconds
Streaming imagenet data took 2.836406946182251 seconds
Then, training+dataloading take 2.840796709060669 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42418479919433594
Time for copying to cuda: 0.018520832061767578
Time for forward pass: 0.0898752212524414
Time for backpropagation: 0.003131866455078125
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6236832141876221 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.9443185329437256 seconds
Streaming imagenet data took 3.0137271881103516 seconds
Then, training+dataloading take 3.0217416286468506 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.39557623863220215
Time for copying to cuda: 0.018645763397216797
Time for forward pass: 0.07559919357299805
Time for backpropagation: 0.002722024917602539
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5804307460784912 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.7829692363739014 seconds
Streaming imagenet data took 2.8113162517547607 seconds
Then, training+dataloading take 2.816575288772583 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39261579513549805
Time for copying to cuda: 0.01872992515563965
Time for forward pass: 0.07553720474243164
Time for backpropagation: 0.002737760543823242
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.573162317276001 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.9322938919067383 seconds
Streaming imagenet data took 3.9602725505828857 seconds
Then, training+dataloading take 3.9649128913879395 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39607810974121094
Time for copying to cuda: 0.018624544143676758
Time for forward pass: 0.0767824649810791
Time for backpropagation: 0.0032036304473876953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5991084575653076 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.508953332901001 seconds
Streaming imagenet data took 3.536827564239502 seconds
Then, training+dataloading take 3.5412094593048096 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3971107006072998
Time for copying to cuda: 0.01867365837097168
Time for forward pass: 0.07559919357299805
Time for backpropagation: 0.0027647018432617188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.612619161605835 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.352867364883423 seconds
Streaming imagenet data took 2.380779266357422 seconds
Then, training+dataloading take 2.386176824569702 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3939850330352783
Time for copying to cuda: 0.018776893615722656
Time for forward pass: 0.07554864883422852
Time for backpropagation: 0.0027599334716796875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5870373249053955 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.1431941986083984 seconds
Streaming imagenet data took 3.1713364124298096 seconds
Then, training+dataloading take 3.1791374683380127 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.44965696334838867
Time for copying to cuda: 0.01858043670654297
Time for forward pass: 0.07562947273254395
Time for backpropagation: 0.0027840137481689453
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6385002136230469 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 11.263076782226562 MBs for this batch
Executing all posts took 2.1416728496551514 seconds
Streaming imagenet data took 2.1468026638031006 seconds
Then, training+dataloading take 2.1479854583740234 seconds

Epoch: 0
Time of next(dataloader) is: 0.35173559188842773
Time for copying to cuda: 0.003319263458251953
Time for forward pass: 0.03261971473693848
Time for backpropagation: 0.002699613571166992
GPU memory for training: 1.0984325408935547                          

The whole process took 44.41416382789612 seconds
