Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.53365772887 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 119083323.58583845 119083323.58583845
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  266.27734375 440.30517578125 706.58251953125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  266.27734375 440.30517578125 706.58251953125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7531170845031738 seconds
Streaming imagenet data took 1.7669379711151123 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.29474925994873047
Time for copying to cuda: 0.010007143020629883
Memory occpied: (1550.0, 228.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6877663135528564 seconds
Streaming imagenet data took 1.7019016742706299 seconds
Memory occpied: (1550.0, 674.0)
Memory occpied: (1550.0, 1096.0)
Time for forward pass: 3.2388498783111572
Time for backpropagation: 0.04945635795593262
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.661188840866089 seconds
Index: 0
Then, training+dataloading take 3.661379337310791 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32483577728271484
Time for copying to cuda: 0.009516477584838867
Time for forward pass: 0.04986739158630371
Time for backpropagation: 0.003621339797973633
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.4713478088378906 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8009121417999268 seconds
Streaming imagenet data took 1.8155086040496826 seconds
Then, training+dataloading take 1.8162736892700195 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3342595100402832
Time for copying to cuda: 0.00937509536743164
Time for forward pass: 0.049332380294799805
Time for backpropagation: 0.002669811248779297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47449398040771484 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.650045394897461 seconds
Streaming imagenet data took 1.6639575958251953 seconds
Then, training+dataloading take 1.6663813591003418 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3286724090576172
Time for copying to cuda: 0.009374856948852539
Time for forward pass: 0.04927825927734375
Time for backpropagation: 0.0025305747985839844
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47989559173583984 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6534557342529297 seconds
Streaming imagenet data took 1.667616844177246 seconds
Then, training+dataloading take 1.6700117588043213 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3689460754394531
Time for copying to cuda: 0.009375572204589844
Time for forward pass: 0.04933595657348633
Time for backpropagation: 0.002561807632446289
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5397489070892334 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.694526195526123 seconds
Streaming imagenet data took 1.7460803985595703 seconds
Then, training+dataloading take 1.7504172325134277 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.32782602310180664
Time for copying to cuda: 0.009319067001342773
Time for forward pass: 0.04924273490905762
Time for backpropagation: 0.0027327537536621094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4725959300994873 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.639045000076294 seconds
Streaming imagenet data took 1.6529905796051025 seconds
Then, training+dataloading take 1.6557064056396484 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.330477237701416
Time for copying to cuda: 0.009434938430786133
Time for forward pass: 0.04930615425109863
Time for backpropagation: 0.0027413368225097656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47960591316223145 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6390774250030518 seconds
Streaming imagenet data took 1.6529545783996582 seconds
Then, training+dataloading take 1.6555368900299072 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3838343620300293
Time for copying to cuda: 0.009551286697387695
Time for forward pass: 0.049562692642211914
Memory occpied: (2290.0, 1578.0)
Time for backpropagation: 0.0027201175689697266
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.52541184425354 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7166664600372314 seconds
Streaming imagenet data took 1.7305629253387451 seconds
Then, training+dataloading take 1.7329699993133545 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3384280204772949
Time for copying to cuda: 0.009359598159790039
Time for forward pass: 0.04928135871887207
Time for backpropagation: 0.0025691986083984375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48897862434387207 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6470036506652832 seconds
Streaming imagenet data took 1.6607604026794434 seconds
Then, training+dataloading take 1.6632354259490967 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35178112983703613
Time for copying to cuda: 0.009447097778320312
Time for forward pass: 0.04932093620300293
Time for backpropagation: 0.0026094913482666016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4898824691772461 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6221542358398438 seconds
Streaming imagenet data took 1.6361291408538818 seconds
Then, training+dataloading take 1.6385712623596191 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3761317729949951
Time for copying to cuda: 0.009404420852661133
Time for forward pass: 0.04924273490905762
Time for backpropagation: 0.002584695816040039
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5368707180023193 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6755294799804688 seconds
Streaming imagenet data took 1.6896021366119385 seconds
Then, training+dataloading take 1.6920225620269775 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3734602928161621
Time for copying to cuda: 0.00949406623840332
Time for forward pass: 0.0493922233581543
Time for backpropagation: 0.002647876739501953
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5174729824066162 seconds
Index: 11
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7058026790618896 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7199950218200684 seconds
Then, training+dataloading take 1.7224202156066895 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3325233459472656
Time for copying to cuda: 0.009436607360839844
Time for forward pass: 0.04929518699645996
Time for backpropagation: 0.002616405487060547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4836733341217041 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6344070434570312 seconds
Streaming imagenet data took 1.6482949256896973 seconds
Then, training+dataloading take 1.6508100032806396 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3360331058502197
Time for copying to cuda: 0.009487628936767578
Time for forward pass: 0.049308061599731445
Time for backpropagation: 0.0027556419372558594
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4876418113708496 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6314806938171387 seconds
Streaming imagenet data took 1.6453354358673096 seconds
Then, training+dataloading take 1.6478548049926758 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4186532497406006
Time for copying to cuda: 0.009545087814331055
Time for forward pass: 0.049393653869628906
Time for backpropagation: 0.0027692317962646484
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5594487190246582 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.713151454925537 seconds
Streaming imagenet data took 1.7270593643188477 seconds
Then, training+dataloading take 1.7295820713043213 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3368971347808838
Time for copying to cuda: 0.009459972381591797
Time for forward pass: 0.04927659034729004
Time for backpropagation: 0.002599000930786133
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48458266258239746 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.634281873703003 seconds
Streaming imagenet data took 1.6482675075531006 seconds
Then, training+dataloading take 1.6507940292358398 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3375577926635742
Time for copying to cuda: 0.00959634780883789
Time for forward pass: 0.04942488670349121
Time for backpropagation: 0.0027031898498535156
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4877350330352783 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6392905712127686 seconds
Streaming imagenet data took 1.6914544105529785 seconds
Then, training+dataloading take 1.695908546447754 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37456321716308594
Time for copying to cuda: 0.009475231170654297
Time for forward pass: 0.04934358596801758
Time for backpropagation: 0.0025305747985839844
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5161755084991455 seconds
Index: 17
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7003896236419678 seconds
Streaming imagenet data took 1.7145419120788574 seconds
Then, training+dataloading take 1.7170541286468506 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000

Memory occpied: (2290.0, 1578.0)

Epoch: 0
Time of next(dataloader) is: 0.3336451053619385
Time for copying to cuda: 0.00956416130065918
Time for forward pass: 0.04942774772644043
Time for backpropagation: 0.0026955604553222656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4775521755218506 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6282241344451904 seconds
Streaming imagenet data took 1.6419918537139893 seconds
Then, training+dataloading take 1.644571304321289 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34650468826293945
Time for copying to cuda: 0.009527921676635742
Time for forward pass: 0.049367427825927734
Time for backpropagation: 0.0025789737701416016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4851090908050537 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6352813243865967 seconds
Streaming imagenet data took 1.6491625308990479 seconds
Then, training+dataloading take 1.6516950130462646 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37661004066467285
Time for copying to cuda: 0.009523153305053711
Time for forward pass: 0.049466848373413086
Time for backpropagation: 0.0026695728302001953
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5449492931365967 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6757032871246338 seconds
Streaming imagenet data took 1.6901228427886963 seconds
Then, training+dataloading take 1.6916534900665283 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.37241101264953613
Time for copying to cuda: 0.009411096572875977
Time for forward pass: 0.04933953285217285
Time for backpropagation: 0.0026483535766601562
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5404157638549805 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6600368022918701 seconds
Streaming imagenet data took 1.6738719940185547 seconds
Then, training+dataloading take 1.6747355461120605 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3326702117919922
Time for copying to cuda: 0.009499311447143555
Time for forward pass: 0.04949760437011719
Time for backpropagation: 0.0026798248291015625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47758960723876953 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6291735172271729 seconds
Streaming imagenet data took 1.6430227756500244 seconds
Then, training+dataloading take 1.6455292701721191 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36952853202819824
Time for copying to cuda: 0.009554147720336914
Time for forward pass: 0.049688100814819336
Time for backpropagation: 0.04071784019470215
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5540087223052979 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7475247383117676 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.761626958847046 seconds
Then, training+dataloading take 1.764092206954956 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3371119499206543
Time for copying to cuda: 0.009416341781616211
Time for forward pass: 0.04924345016479492
Time for backpropagation: 0.00263214111328125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47841930389404297 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6299571990966797 seconds
Streaming imagenet data took 1.643841028213501 seconds
Then, training+dataloading take 1.646336317062378 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3322300910949707
Time for copying to cuda: 0.0094757080078125
Time for forward pass: 0.04948711395263672
Time for backpropagation: 0.0026488304138183594
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4755222797393799 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.627483606338501 seconds
Streaming imagenet data took 1.6412129402160645 seconds
Then, training+dataloading take 1.6437535285949707 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37520313262939453
Time for copying to cuda: 0.009513616561889648
Time for forward pass: 0.04948019981384277
Time for backpropagation: 0.0028007030487060547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5388150215148926 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.702197551727295 seconds
Streaming imagenet data took 1.7650737762451172 seconds
Then, training+dataloading take 1.7695343494415283 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33675646781921387
Time for copying to cuda: 0.009404182434082031
Time for forward pass: 0.04930543899536133
Time for backpropagation: 0.0028052330017089844
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48142027854919434 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6241264343261719 seconds
Streaming imagenet data took 1.6378238201141357 seconds
Then, training+dataloading take 1.6387708187103271 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3291013240814209
Time for copying to cuda: 0.009392499923706055
Time for forward pass: 0.049359798431396484
Time for backpropagation: 0.0028395652770996094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47491979598999023 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6329455375671387 seconds
Streaming imagenet data took 1.6468391418457031 seconds
Then, training+dataloading take 1.6493732929229736 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37047743797302246
Time for copying to cuda: 0.009392976760864258
Time for forward pass: 0.049222469329833984
Time for backpropagation: 0.002540111541748047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5614793300628662 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6273884773254395 seconds
Streaming imagenet data took 1.6793124675750732 seconds
Then, training+dataloading take 1.683708667755127 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.369586706161499
Time for copying to cuda: 0.009383440017700195
Time for forward pass: 0.049262046813964844
Time for backpropagation: 0.0025899410247802734
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5098943710327148 seconds
Index: 30
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.727543592453003 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7414147853851318 seconds
Then, training+dataloading take 1.7441318035125732 seconds

Epoch: 0
Time of next(dataloader) is: 0.33170270919799805
Time for copying to cuda: 0.009357213973999023
Time for forward pass: 0.04927706718444824
Time for backpropagation: 0.0025124549865722656
GPU memory for training: 1.1639018058776855                          

The whole process took 63.45043683052063 seconds
