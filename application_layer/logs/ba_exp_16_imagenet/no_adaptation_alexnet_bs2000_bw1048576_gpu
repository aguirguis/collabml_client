Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 905.8753724602726 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 118734896.81911285 118734896.81911285
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  266.27734375 647.1533203125 913.4306640625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  266.27734375 647.1533203125 913.4306640625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2081868648529053 seconds
Streaming imagenet data took 2.2355902194976807 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37454771995544434
Time for copying to cuda: 0.018919944763183594
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1515915393829346 seconds
Streaming imagenet data took 2.179363250732422 seconds
Time for forward pass: 2.9900572299957275
Time for backpropagation: 0.049654245376586914
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.5343544483184814 seconds
Index: 0
Then, training+dataloading take 3.534550189971924 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3421897888183594
Time for copying to cuda: 0.01841259002685547
Time for forward pass: 0.07303500175476074
Time for backpropagation: 0.003412485122680664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.526665210723877 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.173983335494995 seconds
Streaming imagenet data took 2.20137357711792 seconds
Then, training+dataloading take 2.2078912258148193 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4248497486114502
Time for copying to cuda: 0.01850414276123047
Time for forward pass: 0.07555437088012695
Time for backpropagation: 0.0027604103088378906
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6303431987762451 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.166126012802124 seconds
Streaming imagenet data took 2.193819284439087 seconds
Then, training+dataloading take 2.19823956489563 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35643482208251953
Time for copying to cuda: 0.01854729652404785
Time for forward pass: 0.0755929946899414
Time for backpropagation: 0.0029125213623046875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5455470085144043 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1773712635040283 seconds
Streaming imagenet data took 2.2047035694122314 seconds
Then, training+dataloading take 2.208998441696167 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35977697372436523
Time for copying to cuda: 0.01852250099182129
Time for forward pass: 0.07546043395996094
Time for backpropagation: 0.0025992393493652344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5550053119659424 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.022472858428955 seconds
Streaming imagenet data took 2.0498573780059814 seconds
Then, training+dataloading take 2.0542232990264893 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4009575843811035
Time for copying to cuda: 0.018483877182006836
Time for forward pass: 0.07560610771179199
Time for backpropagation: 0.002789020538330078
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6182143688201904 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1452953815460205 seconds
Streaming imagenet data took 2.1725757122039795 seconds
Then, training+dataloading take 2.176755666732788 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3550546169281006
Time for copying to cuda: 0.01828312873840332
Time for forward pass: 0.07550907135009766
Time for backpropagation: 0.0027108192443847656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5400960445404053 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0979623794555664 seconds
Streaming imagenet data took 2.12534761428833 seconds
Then, training+dataloading take 2.1300458908081055 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3633735179901123
Time for copying to cuda: 0.018609285354614258
Time for forward pass: 0.07556653022766113
Time for backpropagation: 0.002724885940551758
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5497543811798096 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.011577844619751 seconds
Streaming imagenet data took 2.0386674404144287 seconds
Then, training+dataloading take 2.0431013107299805 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3957045078277588
Time for copying to cuda: 0.018576622009277344
Time for forward pass: 0.07555127143859863
Time for backpropagation: 0.0026967525482177734
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5949301719665527 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1281392574310303 seconds
Streaming imagenet data took 2.15567684173584 seconds
Then, training+dataloading take 2.159989833831787 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35837841033935547
Time for copying to cuda: 0.0184476375579834
Time for forward pass: 0.07550168037414551
Time for backpropagation: 0.002705097198486328
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5538420677185059 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.18403697013855 seconds
Streaming imagenet data took 2.2110655307769775 seconds
Then, training+dataloading take 2.2161219120025635 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36408495903015137
Time for copying to cuda: 0.018602609634399414
Time for forward pass: 0.07568359375
Time for backpropagation: 0.0027627944946289062
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5476241111755371 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.025527238845825 seconds
Streaming imagenet data took 2.053016185760498 seconds
Then, training+dataloading take 2.057313919067383 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39728403091430664
Time for copying to cuda: 0.018489599227905273
Time for forward pass: 0.07550954818725586
Time for backpropagation: 0.002856016159057617
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5922648906707764 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1295385360717773 seconds
Streaming imagenet data took 2.156440496444702 seconds
Then, training+dataloading take 2.1607186794281006 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36263442039489746
Time for copying to cuda: 0.018598318099975586
Time for forward pass: 0.07549381256103516
Time for backpropagation: 0.002712249755859375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5563693046569824 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.187113046646118 seconds
Streaming imagenet data took 2.214728832244873 seconds
Then, training+dataloading take 2.219146490097046 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3633730411529541
Time for copying to cuda: 0.018570661544799805
Time for forward pass: 0.07560086250305176
Time for backpropagation: 0.002939462661743164
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5419268608093262 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.036801338195801 seconds
Streaming imagenet data took 2.0648326873779297 seconds
Then, training+dataloading take 2.0691709518432617 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.4374125003814697
Time for copying to cuda: 0.018666505813598633
Time for forward pass: 0.07548880577087402
Time for backpropagation: 0.0026595592498779297
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6213502883911133 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.088434934616089 seconds
Streaming imagenet data took 2.1157028675079346 seconds
Then, training+dataloading take 2.1184933185577393 seconds

Epoch: 0
Time of next(dataloader) is: 0.3614475727081299
Time for copying to cuda: 0.01864480972290039
Time for forward pass: 0.07541036605834961
Time for backpropagation: 0.0026128292083740234
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
The whole process took 43.93558406829834 seconds
