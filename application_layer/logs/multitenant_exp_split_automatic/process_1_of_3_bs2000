Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.4780771548186 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 118944966.52883638 118944966.52883638
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  3005.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (3005.0, 3.0)
Memory occpied: (3005.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1607041358947754 seconds
Streaming imagenet data took 2.1875970363616943 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3468608856201172
Time for copying to cuda: 0.018666982650756836
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.2412025928497314 seconds
Streaming imagenet data took 3.2687816619873047 seconds
Time for forward pass: 3.0966365337371826
Time for backpropagation: 0.05018138885498047
GPU memory for training: 1.102445125579834                          

Memory occpied: (3005.0, 3.0)
One training iteration takes: 3.5764384269714355 seconds
Index: 0
Then, training+dataloading take 3.576669692993164 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.27579760551452637
Time for copying to cuda: 0.018192768096923828
Time for forward pass: 0.07540535926818848
Time for backpropagation: 0.0039670467376708984
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4499232769012451 seconds
Index: 1
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.941697835922241 seconds
Streaming imagenet data took 2.9694080352783203 seconds
Then, training+dataloading take 2.9735946655273438 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.27794861793518066
Time for copying to cuda: 0.018023967742919922
Time for forward pass: 0.07581925392150879
Time for backpropagation: 0.002752065658569336
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4672989845275879 seconds
Index: 2
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.4082727432250977 seconds
Streaming imagenet data took 2.4356422424316406 seconds
Then, training+dataloading take 2.439190149307251 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.2961723804473877
Time for copying to cuda: 0.044585466384887695
Memory occpied: (3817.0, 1632.0)
Time for forward pass: 0.07581734657287598
Time for backpropagation: 0.002679586410522461
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4941132068634033 seconds
Index: 3
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.105156660079956 seconds
Streaming imagenet data took 2.1325597763061523 seconds
Then, training+dataloading take 2.135812759399414 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.27756166458129883
Time for copying to cuda: 0.018151044845581055
Time for forward pass: 0.07551360130310059
Time for backpropagation: 0.002691984176635742
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4450709819793701 seconds
Index: 4
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.598612070083618 seconds
Streaming imagenet data took 2.6257693767547607 seconds
Then, training+dataloading take 2.6289989948272705 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3199152946472168
Time for copying to cuda: 0.01813507080078125
Time for forward pass: 0.07567429542541504
Time for backpropagation: 0.0027205944061279297
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.48940372467041016 seconds
Index: 5
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.2749671936035156 seconds
Streaming imagenet data took 3.302072763442993 seconds
Then, training+dataloading take 3.3052549362182617 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.28164052963256836
Time for copying to cuda: 0.01839280128479004
Time for forward pass: 0.07556605339050293
Time for backpropagation: 0.0026912689208984375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4617736339569092 seconds
Index: 6
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.0737946033477783 seconds
Streaming imagenet data took 3.101283311843872 seconds
Then, training+dataloading take 3.1034843921661377 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.2788870334625244
Time for copying to cuda: 0.018195152282714844
Time for forward pass: 0.07557034492492676
Time for backpropagation: 0.0027060508728027344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.443922758102417 seconds
Index: 7
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.0053977966308594 seconds
Streaming imagenet data took 3.033083438873291 seconds
Then, training+dataloading take 3.036353349685669 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.31029582023620605
Time for copying to cuda: 0.018269062042236328
Memory occpied: (3817.0, 1632.0)
Time for forward pass: 0.07562899589538574
Time for backpropagation: 0.002704143524169922
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4896876811981201 seconds
Index: 8
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3026843070983887 seconds
Streaming imagenet data took 2.329707622528076 seconds
Then, training+dataloading take 2.3329885005950928 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.311542272567749
Time for copying to cuda: 0.018224239349365234
Time for forward pass: 0.07563233375549316
Time for backpropagation: 0.0026977062225341797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.4940152168273926 seconds
Index: 9
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.150038480758667 seconds
Streaming imagenet data took 2.1773996353149414 seconds
Then, training+dataloading take 2.1796247959136963 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.279940128326416
Time for copying to cuda: 0.0181119441986084
Time for forward pass: 0.0755922794342041
Time for backpropagation: 0.002713918685913086
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.45929574966430664 seconds
Index: 10
Memory occpied: (3817.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.595508337020874 seconds
Streaming imagenet data took 2.6231765747070312 seconds
Then, training+dataloading take 2.6263952255249023 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.306427001953125
Time for copying to cuda: 0.01812434196472168
Time for forward pass: 0.07558798789978027
Time for backpropagation: 0.00269317626953125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.47895288467407227 seconds
Index: 11
Memory occpied: (3817.0, 1632.0)
Read 11.263076782226562 MBs for this batch
Executing all posts took 0.9210796356201172 seconds
Streaming imagenet data took 0.9261140823364258 seconds
Then, training+dataloading take 0.926774263381958 seconds

Epoch: 0
Time of next(dataloader) is: 0.23702096939086914
Time for copying to cuda: 0.003145456314086914
Time for forward pass: 0.031072616577148438
Time for backpropagation: 0.0026178359985351562
GPU memory for training: 1.0984325408935547                          

The whole process took 39.242509841918945 seconds
