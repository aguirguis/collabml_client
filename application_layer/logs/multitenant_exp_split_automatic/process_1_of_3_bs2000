Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.332279323149 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119056928.51544379 119056928.51544379
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.033341646194458 seconds
Streaming imagenet data took 2.0602622032165527 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4000124931335449
Time for copying to cuda: 0.019085168838500977
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0321409702301025 seconds
Streaming imagenet data took 2.059786081314087 seconds
Time for forward pass: 3.0770277976989746
Time for backpropagation: 0.05015087127685547
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.652801036834717 seconds
Index: 0
Then, training+dataloading take 3.6529781818389893 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.37406206130981445
Time for copying to cuda: 0.01879405975341797
Time for forward pass: 0.07541799545288086
Time for backpropagation: 0.003693103790283203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5692539215087891 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.235591411590576 seconds
Streaming imagenet data took 3.2633986473083496 seconds
Then, training+dataloading take 3.2649855613708496 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.43070197105407715
Time for copying to cuda: 0.01856398582458496
Time for forward pass: 0.07565093040466309
Time for backpropagation: 0.002790212631225586
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6592550277709961 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1404592990875244 seconds
Streaming imagenet data took 2.1681880950927734 seconds
Then, training+dataloading take 2.1736509799957275 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39173293113708496
Time for copying to cuda: 0.01865863800048828
Time for forward pass: 0.07555842399597168
Time for backpropagation: 0.002766847610473633
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5795943737030029 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.469647169113159 seconds
Streaming imagenet data took 2.4970879554748535 seconds
Then, training+dataloading take 2.502795934677124 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3903350830078125
Time for copying to cuda: 0.018394947052001953
Time for forward pass: 0.07572579383850098
Time for backpropagation: 0.0028676986694335938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5882370471954346 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1544580459594727 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.181746244430542 seconds
Then, training+dataloading take 2.1871252059936523 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3921477794647217
Time for copying to cuda: 0.018500804901123047
Time for forward pass: 0.07552695274353027
Time for backpropagation: 0.002732992172241211
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5859217643737793 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.6217517852783203 seconds
Streaming imagenet data took 2.649242639541626 seconds
Then, training+dataloading take 2.654729127883911 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3904714584350586
Time for copying to cuda: 0.018585920333862305
Time for forward pass: 0.07564020156860352
Time for backpropagation: 0.002749204635620117
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.581608772277832 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2123959064483643 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.2400057315826416 seconds
Then, training+dataloading take 2.245608329772949 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38939762115478516
Time for copying to cuda: 0.018546342849731445
Time for forward pass: 0.07549834251403809
Time for backpropagation: 0.0026733875274658203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5849335193634033 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.540959119796753 seconds
Streaming imagenet data took 2.568049669265747 seconds
Then, training+dataloading take 2.5737404823303223 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39437270164489746
Time for copying to cuda: 0.018599271774291992
Time for forward pass: 0.07562947273254395
Time for backpropagation: 0.002690553665161133
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5918176174163818 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.5445363521575928 seconds
Streaming imagenet data took 2.572294235229492 seconds
Then, training+dataloading take 2.577080249786377 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3947288990020752
Time for copying to cuda: 0.018584728240966797
Time for forward pass: 0.07554125785827637
Time for backpropagation: 0.0027604103088378906
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.573986291885376 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.700427532196045 seconds
Streaming imagenet data took 2.7280893325805664 seconds
Then, training+dataloading take 2.7328882217407227 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4138610363006592
Time for copying to cuda: 0.01840662956237793
Time for forward pass: 0.07667350769042969
Time for backpropagation: 0.003204345703125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6127262115478516 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.6216483116149902 seconds
Streaming imagenet data took 2.6487550735473633 seconds
Then, training+dataloading take 2.653541326522827 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.43775486946105957
Time for copying to cuda: 0.01848149299621582
Time for forward pass: 0.0754861831665039
Time for backpropagation: 0.002669095993041992
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6488950252532959 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 11.263076782226562 MBs for this batch
Executing all posts took 0.8127937316894531 seconds
Streaming imagenet data took 0.817814826965332 seconds
Then, training+dataloading take 0.8184013366699219 seconds

Epoch: 0
Time of next(dataloader) is: 0.3695390224456787
Time for copying to cuda: 0.003248929977416992
Time for forward pass: 0.031124591827392578
Time for backpropagation: 0.0028030872344970703
GPU memory for training: 1.0984325408935547                          

The whole process took 39.4672486782074 seconds
