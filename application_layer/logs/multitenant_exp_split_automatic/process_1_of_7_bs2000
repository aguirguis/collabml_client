Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.1941503364792 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119038823.672903 119038823.672903
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1011204719543457 seconds
Streaming imagenet data took 2.1280581951141357 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38624072074890137
Time for copying to cuda: 0.019097089767456055
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9602375030517578 seconds
Streaming imagenet data took 1.987746000289917 seconds
Time for forward pass: 3.068998098373413
Time for backpropagation: 0.05114912986755371
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.6257007122039795 seconds
Index: 0
Then, training+dataloading take 3.6258749961853027 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3988771438598633
Time for copying to cuda: 0.01908397674560547
Time for forward pass: 0.07548165321350098
Time for backpropagation: 0.0035088062286376953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5871098041534424 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3451523780822754 seconds
Streaming imagenet data took 2.415431022644043 seconds
Then, training+dataloading take 2.423704147338867 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4437117576599121
Time for copying to cuda: 0.01868605613708496
Time for forward pass: 0.07565975189208984
Time for backpropagation: 0.0029144287109375
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6319081783294678 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1444427967071533 seconds
Streaming imagenet data took 2.1715009212493896 seconds
Then, training+dataloading take 2.1764068603515625 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39760375022888184
Time for copying to cuda: 0.0187685489654541
Time for forward pass: 0.07557463645935059
Time for backpropagation: 0.0027964115142822266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5949060916900635 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.5403711795806885 seconds
Streaming imagenet data took 2.5676193237304688 seconds
Then, training+dataloading take 2.5726447105407715 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42784714698791504
Time for copying to cuda: 0.018545150756835938
Time for forward pass: 0.07564711570739746
Time for backpropagation: 0.0027430057525634766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6292357444763184 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2627.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.0236339569091797 seconds
Streaming imagenet data took 3.0938222408294678 seconds
Then, training+dataloading take 3.1014323234558105 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Memory occpied: (3035.0, 1632.0)
Time of next(dataloader) is: 0.4661884307861328
Time for copying to cuda: 0.018402814865112305
Time for forward pass: 0.08075571060180664
Time for backpropagation: 0.0027964115142822266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6678347587585449 seconds
Index: 5
Memory occpied: (3517.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.840561628341675 seconds
Streaming imagenet data took 2.8683674335479736 seconds
Then, training+dataloading take 2.8733315467834473 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4129176139831543
Time for copying to cuda: 0.018412351608276367
Time for forward pass: 0.07557392120361328
Time for backpropagation: 0.0027332305908203125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.597135066986084 seconds
Index: 6
Memory occpied: (3837.0, 1632.0)
Memory occpied: (3837.0, 1632.0)
Memory occpied: (3837.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.692237377166748 seconds
Streaming imagenet data took 3.719639301300049 seconds
Then, training+dataloading take 3.7244300842285156 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41518235206604004
Time for copying to cuda: 0.018169879913330078
Time for forward pass: 0.07608389854431152
Time for backpropagation: 0.002837657928466797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6217989921569824 seconds
Index: 7
Memory occpied: (3909.0, 1961.0)
Memory occpied: (3909.0, 2383.0)
Memory occpied: (3909.0, 2837.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.5838677883148193 seconds
Streaming imagenet data took 3.615605115890503 seconds
Then, training+dataloading take 3.619858741760254 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41738438606262207
Time for copying to cuda: 0.019321203231811523
Time for forward pass: 0.07757830619812012
Time for backpropagation: 0.003069639205932617
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.629969596862793 seconds
Index: 8
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 4.212416172027588 seconds
Streaming imagenet data took 4.241413354873657 seconds
Then, training+dataloading take 4.246391296386719 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41499829292297363
Time for copying to cuda: 0.02059316635131836
Time for forward pass: 0.10367369651794434
Time for backpropagation: 0.0031659603118896484
GPU memory for training: 1.2580008506774902                          

Memory occpied: (4649.0, 3261.0)
One training iteration takes: 0.6399190425872803 seconds
Index: 9
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 5.523560285568237 seconds
Memory occpied: (4649.0, 3261.0)
Streaming imagenet data took 5.553929567337036 seconds
Then, training+dataloading take 5.558934450149536 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41286468505859375
Time for copying to cuda: 0.018278121948242188
Time for forward pass: 0.07566261291503906
Time for backpropagation: 0.002850055694580078
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.612293004989624 seconds
Index: 10
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 6.0355119705200195 seconds
Streaming imagenet data took 6.106781244277954 seconds
Then, training+dataloading take 6.114171266555786 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Time of next(dataloader) is: 0.44872164726257324
Time for copying to cuda: 0.018584251403808594
Time for forward pass: 0.07438325881958008
Time for backpropagation: 0.0027513504028320312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6400775909423828 seconds
Index: 11
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 11.263076782226562 MBs for this batch
Executing all posts took 4.217358589172363 seconds
Streaming imagenet data took 4.222317934036255 seconds
Then, training+dataloading take 4.223045110702515 seconds

Epoch: 0
Time of next(dataloader) is: 0.37865757942199707
Time for copying to cuda: 0.0032935142517089844
Time for forward pass: 0.03258633613586426
Time for backpropagation: 0.002627134323120117
GPU memory for training: 1.0984325408935547                          

The whole process took 53.4387366771698 seconds
