Namespace(all_in_cos=False, batch_size=8000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 44.34507465596485 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 5812397.625306625 5812397.625306625
All candidates indexes:  (array([], dtype=int64),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 1419.4921875 1718.58984375 17704.6484375
Fixed, scale_with_bsz  0 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 8000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 24.583340406417847 seconds
Streaming imagenet data took 24.63274574279785 seconds
The mode is:  split
Start 8000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.5002419948577881
Time for copying to cuda: 0.03272199630737305
Time for forward pass: 2.9910178184509277
Time for backpropagation: 0.07700228691101074
GPU memory for training: 1.263702392578125                          

Memory occpied: (1514.0, 3.0)
One training iteration takes: 3.6810302734375 seconds
Index: 0
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 24.998034954071045 seconds
Streaming imagenet data took 25.047117233276367 seconds
Then, training+dataloading take 25.050087690353394 seconds
The mode is:  split
Start 16000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.47602176666259766
Time for copying to cuda: 0.032006263732910156
Time for forward pass: 0.09116411209106445
Time for backpropagation: 0.0029473304748535156
GPU memory for training: 1.4203567504882812                          

One training iteration takes: 0.7374348640441895 seconds
Index: 1
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 24.747578859329224 seconds
Streaming imagenet data took 24.796573877334595 seconds
Then, training+dataloading take 24.799683570861816 seconds
The mode is:  split
Start 24000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.45861268043518066
Time for copying to cuda: 0.0883941650390625
Time for forward pass: 0.11311888694763184
Time for backpropagation: 0.0032029151916503906
GPU memory for training: 1.4203567504882812                          

Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
One training iteration takes: 5.691367864608765 seconds
Index: 2
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 24.902047157287598 seconds
Streaming imagenet data took 24.951306581497192 seconds
Then, training+dataloading take 24.954399824142456 seconds

Epoch: 0
Time of next(dataloader) is: 0.4781336784362793
Time for copying to cuda: 0.03204035758972168
Time for forward pass: 0.09219622611999512
Time for backpropagation: 0.0032606124877929688
GPU memory for training: 1.4203567504882812                          

Memory occpied: (2354.0, 1712.0)
The whole process took 107.72965860366821 seconds
