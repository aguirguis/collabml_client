Namespace(batch_size=512, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='vit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Start 0, end 512, post_step 128

Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Decompress data took 0.011941671371459961 seconds
Total decompress data took 0.3461759090423584 seconds
Decompress data took 0.011390924453735352 seconds
Memory occpied: (1630.0, 3.0)
Total decompress data took 0.3875713348388672 seconds
Decompress data took 0.011586904525756836 seconds
Total decompress data took 0.3329043388366699 seconds
Decompress data took 0.011121511459350586 seconds
Total decompress data took 0.3271186351776123 seconds
Read 78.09912967681885 MBs for this batch
Streaming imagenet data took 3.2484285831451416 seconds
The mode is:  vanilla
Start 512, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4955000877380371
Time for copying to cuda: 0.09070968627929688
Decompress data took 0.02780008316040039 seconds
Total decompress data took 0.3626883029937744 seconds
Decompress data took 0.011940479278564453 seconds
Total decompress data took 0.3213653564453125 seconds
Decompress data took 0.01150059700012207 seconds
Total decompress data took 0.3244919776916504 seconds
Decompress data took 0.011842489242553711 seconds
Total decompress data took 0.32669734954833984 seconds
Read 79.72594451904297 MBs for this batch
Streaming imagenet data took 2.4074227809906006 seconds
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 433, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 421, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 238, in forward
    x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 199, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
RuntimeError: CUDA out of memory. Tried to allocate 456.00 MiB (GPU 0; 14.76 GiB total capacity; 12.54 GiB already allocated; 311.75 MiB free; 13.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Memory occpied: (1630.0, 15058.0)
The whole process took 16.339402675628662 seconds
