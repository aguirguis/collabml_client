Namespace(all_in_cos=False, batch_size=512, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=11, model='myresnet18', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 906.5041704087532 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 4.816896e+06
 4.816896e+06 2.408448e+06 2.408448e+06 1.204224e+06 1.204224e+06
 6.021120e+05 6.021120e+05 2.048000e+03 4.000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118817314.6238161 118817314.6238161
All candidates indexes:  (array([12, 13]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 11
Intermediate:  0.095703125
6.125
Total layers size  27.185455322265625
Server, client, server+client, vanilla  259.0654296875 197.5966796875 456.662109375 3578.5966796875
Fixed, scale_with_bsz  0 6.69921875
Mem usage  1336.0 3.0
Using split index: 11
Freezing the lower layers of the model (myresnet18) till index 11
The mode is:  split
Start 0, end 512, post_step 128

Memory occpied: (1336.0, 3.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.057239055633545 seconds
Streaming imagenet data took 1.0759952068328857 seconds
The mode is:  split
Start 512, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4094276428222656
Time for copying to cuda: 0.013620376586914062
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9813404083251953 seconds
Streaming imagenet data took 1.0004122257232666 seconds
Time for forward pass: 3.216691493988037
Time for backpropagation: 0.40840816497802734
GPU memory for training: 4.581666946411133                          

One training iteration takes: 4.145070552825928 seconds
Index: 0
Then, training+dataloading take 4.1452319622039795 seconds
The mode is:  split
Start 1024, end 1536, post_step 128


Epoch: 0
Memory occpied: (1336.0, 3532.0)
Time of next(dataloader) is: 0.36519527435302734
Time for copying to cuda: 0.013175249099731445
Time for forward pass: 0.02095627784729004
Time for backpropagation: 0.004643678665161133
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5080950260162354 seconds
Index: 1
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8498241901397705 seconds
Streaming imagenet data took 0.8690323829650879 seconds
Then, training+dataloading take 0.8697428703308105 seconds
The mode is:  split
Start 1536, end 2048, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4217076301574707
Time for copying to cuda: 0.013500213623046875
Time for forward pass: 0.019037485122680664
Time for backpropagation: 0.0053937435150146484
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5936739444732666 seconds
Index: 2
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8697583675384521 seconds
Streaming imagenet data took 0.8883364200592041 seconds
Then, training+dataloading take 0.8891096115112305 seconds
The mode is:  split
Start 2048, end 2560, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37889981269836426
Time for copying to cuda: 0.014760971069335938
Time for forward pass: 0.02782464027404785
Time for backpropagation: 0.005043745040893555
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5257360935211182 seconds
Index: 3
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9980559349060059 seconds
Streaming imagenet data took 1.0165343284606934 seconds
Then, training+dataloading take 1.0174262523651123 seconds
The mode is:  split
Start 2560, end 3072, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3893132209777832
Time for copying to cuda: 0.013928651809692383
Time for forward pass: 0.02679443359375
Time for backpropagation: 0.00507354736328125
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5125637054443359 seconds
Index: 4
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.955045223236084 seconds
Streaming imagenet data took 1.0166451930999756 seconds
Then, training+dataloading take 1.0189661979675293 seconds
The mode is:  split
Start 3072, end 3584, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.4215259552001953
Time for copying to cuda: 0.01513671875
Time for forward pass: 0.02641892433166504
Time for backpropagation: 0.005192279815673828
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.551032543182373 seconds
Index: 5
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8213729858398438 seconds
Streaming imagenet data took 0.8401274681091309 seconds
Then, training+dataloading take 0.8411133289337158 seconds
The mode is:  split
Start 3584, end 4096, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3797900676727295
Time for copying to cuda: 0.014091968536376953
Time for forward pass: 0.02654743194580078
Time for backpropagation: 0.005250692367553711
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5430154800415039 seconds
Index: 6
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9441468715667725 seconds
Streaming imagenet data took 0.9634671211242676 seconds
Then, training+dataloading take 0.9643032550811768 seconds
The mode is:  split
Start 4096, end 4608, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37229394912719727
Time for copying to cuda: 0.013338804244995117
Time for forward pass: 0.026438236236572266
Time for backpropagation: 0.010991811752319336
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5391151905059814 seconds
Index: 7
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.994110107421875 seconds
Streaming imagenet data took 1.012763261795044 seconds
Then, training+dataloading take 1.013702154159546 seconds
The mode is:  split
Start 4608, end 5120, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3749885559082031
Time for copying to cuda: 0.013957023620605469
Time for forward pass: 0.0286252498626709
Time for backpropagation: 0.005074977874755859
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.511991024017334 seconds
Index: 8
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8791086673736572 seconds
Streaming imagenet data took 0.8980042934417725 seconds
Then, training+dataloading take 0.8987843990325928 seconds
The mode is:  split
Start 5120, end 5632, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.42276835441589355
Time for copying to cuda: 0.01741194725036621
Time for forward pass: 0.02661752700805664
Time for backpropagation: 0.005060434341430664
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5846381187438965 seconds
Index: 9
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9576034545898438 seconds
Streaming imagenet data took 0.976818323135376 seconds
Then, training+dataloading take 0.9777271747589111 seconds
The mode is:  split
Start 5632, end 6144, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3743729591369629
Time for copying to cuda: 0.013986825942993164
Time for forward pass: 0.026337385177612305
Time for backpropagation: 0.0055065155029296875
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.4961118698120117 seconds
Index: 10
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8833651542663574 seconds
Memory occpied: (3622.0, 3548.0)
Streaming imagenet data took 0.9023211002349854 seconds
Then, training+dataloading take 0.9033665657043457 seconds
The mode is:  split
Start 6144, end 6656, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3767273426055908
Time for copying to cuda: 0.013514518737792969
Time for forward pass: 0.026384353637695312
Time for backpropagation: 0.004492044448852539
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5186059474945068 seconds
Index: 11
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8409337997436523 seconds
Streaming imagenet data took 0.8600518703460693 seconds
Then, training+dataloading take 0.8607723712921143 seconds
The mode is:  split
Start 6656, end 7168, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4308810234069824
Time for copying to cuda: 0.013475418090820312
Time for forward pass: 0.032998085021972656
Time for backpropagation: 0.0052509307861328125
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.6012389659881592 seconds
Index: 12
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9258744716644287 seconds
Streaming imagenet data took 0.944584846496582 seconds
Then, training+dataloading take 0.9453587532043457 seconds
The mode is:  split
Start 7168, end 7680, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4034006595611572
Time for copying to cuda: 0.013826608657836914
Time for forward pass: 0.026369810104370117
Time for backpropagation: 0.0050334930419921875
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.531818151473999 seconds
Index: 13
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0836491584777832 seconds
Streaming imagenet data took 1.1024799346923828 seconds
Then, training+dataloading take 1.103405475616455 seconds
The mode is:  split
Start 7680, end 8192, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3959207534790039
Time for copying to cuda: 0.015100955963134766
Time for forward pass: 0.026414155960083008
Time for backpropagation: 0.00503993034362793
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5263381004333496 seconds
Index: 14
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7978670597076416 seconds
Streaming imagenet data took 0.816619873046875 seconds
Then, training+dataloading take 0.8173446655273438 seconds
The mode is:  split
Start 8192, end 8704, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4370005130767822
Time for copying to cuda: 0.013947010040283203
Time for forward pass: 0.02642989158630371
Time for backpropagation: 0.005079984664916992
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5932638645172119 seconds
Index: 15
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9591078758239746 seconds
Streaming imagenet data took 0.9783816337585449 seconds
Then, training+dataloading take 0.9791789054870605 seconds
The mode is:  split
Start 8704, end 9216, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3772552013397217
Time for copying to cuda: 0.013687849044799805
Time for forward pass: 0.03174948692321777
Time for backpropagation: 0.005160093307495117
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5047659873962402 seconds
Index: 16
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8976454734802246 seconds
Memory occpied: (3622.0, 3548.0)
Streaming imagenet data took 0.9164416790008545 seconds
Then, training+dataloading take 0.9173200130462646 seconds
The mode is:  split
Start 9216, end 9728, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39261317253112793
Time for copying to cuda: 0.014286518096923828
Time for forward pass: 0.027855873107910156
Time for backpropagation: 0.005028963088989258
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5209672451019287 seconds
Index: 17
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9386191368103027 seconds
Streaming imagenet data took 0.9572358131408691 seconds
Then, training+dataloading take 0.9579916000366211 seconds
The mode is:  split
Start 9728, end 10240, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.418637752532959
Time for copying to cuda: 0.013976097106933594
Time for forward pass: 0.026914596557617188
Time for backpropagation: 0.00522923469543457
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5900001525878906 seconds
Index: 18
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8581643104553223 seconds
Streaming imagenet data took 0.8772227764129639 seconds
Then, training+dataloading take 0.8779480457305908 seconds
The mode is:  split
Start 10240, end 10752, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3808743953704834
Time for copying to cuda: 0.01357889175415039
Time for forward pass: 0.0264279842376709
Time for backpropagation: 0.0052144527435302734
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5272469520568848 seconds
Index: 19
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0434472560882568 seconds
Streaming imagenet data took 1.062424898147583 seconds
Then, training+dataloading take 1.0632572174072266 seconds
The mode is:  split
Start 10752, end 11264, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37900710105895996
Time for copying to cuda: 0.013704299926757812
Time for forward pass: 0.027207374572753906
Time for backpropagation: 0.00528407096862793
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5138225555419922 seconds
Index: 20
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.775048017501831 seconds
Streaming imagenet data took 0.7943024635314941 seconds
Then, training+dataloading take 0.7950770854949951 seconds
The mode is:  split
Start 11264, end 11776, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.43279194831848145
Time for copying to cuda: 0.013550519943237305
Time for forward pass: 0.031343936920166016
Time for backpropagation: 0.0052089691162109375
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.607856273651123 seconds
Index: 21
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9535326957702637 seconds
Streaming imagenet data took 0.972848653793335 seconds
Then, training+dataloading take 0.9736127853393555 seconds
The mode is:  split
Start 11776, end 12288, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37676405906677246
Time for copying to cuda: 0.01632213592529297
Time for forward pass: 0.027477741241455078
Time for backpropagation: 0.0052165985107421875
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5092999935150146 seconds
Index: 22
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0303056240081787 seconds
Streaming imagenet data took 1.048886775970459 seconds
Then, training+dataloading take 1.0497050285339355 seconds
The mode is:  split
Start 12288, end 12800, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3934149742126465
Time for copying to cuda: 0.013551473617553711
Time for forward pass: 0.026468276977539062
Time for backpropagation: 0.004601955413818359
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5114612579345703 seconds
Index: 23
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0625863075256348 seconds
Streaming imagenet data took 1.0817835330963135 seconds
Then, training+dataloading take 1.0829322338104248 seconds
The mode is:  split
Start 12800, end 13312, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.3727686405181885
Time for copying to cuda: 0.013887643814086914
Time for forward pass: 0.026746273040771484
Time for backpropagation: 0.005002498626708984
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.49637770652770996 seconds
Index: 24
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9527690410614014 seconds
Streaming imagenet data took 0.9719810485839844 seconds
Then, training+dataloading take 0.9727675914764404 seconds
The mode is:  split
Start 13312, end 13824, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4209423065185547
Time for copying to cuda: 0.01405644416809082
Time for forward pass: 0.02646470069885254
Time for backpropagation: 0.0052530765533447266
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5811643600463867 seconds
Index: 25
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.075129508972168 seconds
Streaming imagenet data took 1.0937917232513428 seconds
Then, training+dataloading take 1.09456205368042 seconds
The mode is:  split
Start 13824, end 14336, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39165782928466797
Time for copying to cuda: 0.01347970962524414
Time for forward pass: 0.032747507095336914
Time for backpropagation: 0.005250215530395508
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5491182804107666 seconds
Index: 26
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9178404808044434 seconds
Streaming imagenet data took 0.9368045330047607 seconds
Then, training+dataloading take 0.9376440048217773 seconds
The mode is:  split
Start 14336, end 14848, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37538981437683105
Time for copying to cuda: 0.015617132186889648
Time for forward pass: 0.026974201202392578
Time for backpropagation: 0.005157947540283203
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5010025501251221 seconds
Index: 27
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.946779727935791 seconds
Streaming imagenet data took 1.006885051727295 seconds
Then, training+dataloading take 1.0092227458953857 seconds
The mode is:  split
Start 14848, end 15360, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.38002467155456543
Time for copying to cuda: 0.01344156265258789
Time for forward pass: 0.02665996551513672
Time for backpropagation: 0.004739999771118164
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5142073631286621 seconds
Index: 28
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9042127132415771 seconds
Streaming imagenet data took 0.9230971336364746 seconds
Then, training+dataloading take 0.9239287376403809 seconds
The mode is:  split
Start 15360, end 15872, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.43256330490112305
Time for copying to cuda: 0.013858795166015625
Time for forward pass: 0.02659296989440918
Time for backpropagation: 0.004895925521850586
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5992677211761475 seconds
Index: 29
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0243337154388428 seconds
Streaming imagenet data took 1.0431792736053467 seconds
Then, training+dataloading take 1.0439746379852295 seconds
The mode is:  split
Start 15872, end 16384, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.377948522567749
Time for copying to cuda: 0.01360464096069336
Time for forward pass: 0.026348590850830078
Time for backpropagation: 0.004633665084838867
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5171339511871338 seconds
Index: 30
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8767597675323486 seconds
Streaming imagenet data took 0.8959918022155762 seconds
Then, training+dataloading take 0.8969354629516602 seconds
The mode is:  split
Start 16384, end 16896, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37615966796875
Time for copying to cuda: 0.014378547668457031
Time for forward pass: 0.026645183563232422
Time for backpropagation: 0.005041360855102539
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5014097690582275 seconds
Index: 31
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7809150218963623 seconds
Streaming imagenet data took 0.7998168468475342 seconds
Then, training+dataloading take 0.8005516529083252 seconds
The mode is:  split
Start 16896, end 17408, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4257986545562744
Time for copying to cuda: 0.014121770858764648
Time for forward pass: 0.026645898818969727
Time for backpropagation: 0.005108833312988281
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5837855339050293 seconds
Index: 32
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9020349979400635 seconds
Streaming imagenet data took 0.920889139175415 seconds
Then, training+dataloading take 0.9216752052307129 seconds
The mode is:  split
Start 17408, end 17920, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38014984130859375
Time for copying to cuda: 0.013404607772827148
Time for forward pass: 0.03138327598571777
Time for backpropagation: 0.00527191162109375
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5080747604370117 seconds
Index: 33
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0027451515197754 seconds
Streaming imagenet data took 1.0214250087738037 seconds
Then, training+dataloading take 1.0222108364105225 seconds
The mode is:  split
Start 17920, end 18432, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3891422748565674
Time for copying to cuda: 0.013413429260253906
Time for forward pass: 0.026404380798339844
Time for backpropagation: 0.005124807357788086
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5174112319946289 seconds
Index: 34
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0108938217163086 seconds
Streaming imagenet data took 1.0304687023162842 seconds
Then, training+dataloading take 1.0315237045288086 seconds
The mode is:  split
Start 18432, end 18944, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4246044158935547
Time for copying to cuda: 0.013962507247924805
Time for forward pass: 0.028758764266967773
Time for backpropagation: 0.005359649658203125
GPU memory for training: 0.7408351898193359                          

Memory occpied: (3622.0, 3548.0)
One training iteration takes: 0.5612187385559082 seconds
Index: 35
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8169519901275635 seconds
Streaming imagenet data took 0.8358767032623291 seconds
Then, training+dataloading take 0.8366022109985352 seconds
The mode is:  split
Start 18944, end 19456, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.41262054443359375
Time for copying to cuda: 0.014109134674072266
Time for forward pass: 0.029029369354248047
Time for backpropagation: 0.005341529846191406
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5486114025115967 seconds
Index: 36
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0540721416473389 seconds
Streaming imagenet data took 1.0728604793548584 seconds
Then, training+dataloading take 1.073697566986084 seconds
The mode is:  split
Start 19456, end 19968, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3779747486114502
Time for copying to cuda: 0.01347208023071289
Time for forward pass: 0.027497053146362305
Time for backpropagation: 0.005211353302001953
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5130746364593506 seconds
Index: 37
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7905547618865967 seconds
Streaming imagenet data took 0.809220552444458 seconds
Then, training+dataloading take 0.810046911239624 seconds
The mode is:  split
Start 19968, end 20480, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4352092742919922
Time for copying to cuda: 0.013872385025024414
Time for forward pass: 0.026851177215576172
Time for backpropagation: 0.0050623416900634766
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5921106338500977 seconds
Index: 38
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9147214889526367 seconds
Streaming imagenet data took 0.9335281848907471 seconds
Then, training+dataloading take 0.934295654296875 seconds
The mode is:  split
Start 20480, end 20992, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37790489196777344
Time for copying to cuda: 0.013445377349853516
Time for forward pass: 0.0771031379699707
Time for backpropagation: 0.005023479461669922
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5501198768615723 seconds
Index: 39
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.898698091506958 seconds
Streaming imagenet data took 0.9176571369171143 seconds
Then, training+dataloading take 0.9195241928100586 seconds
The mode is:  split
Start 20992, end 21504, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.39661240577697754
Time for copying to cuda: 0.01451730728149414
Time for forward pass: 0.026472091674804688
Time for backpropagation: 0.004855155944824219
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5211646556854248 seconds
Index: 40
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9145073890686035 seconds
Streaming imagenet data took 0.9331824779510498 seconds
Then, training+dataloading take 0.9341526031494141 seconds
The mode is:  split
Start 21504, end 22016, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4310455322265625
Time for copying to cuda: 0.013561248779296875
Time for forward pass: 0.02639150619506836
Time for backpropagation: 0.004801511764526367
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.6167089939117432 seconds
Index: 41
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9392685890197754 seconds
Streaming imagenet data took 0.9580473899841309 seconds
Then, training+dataloading take 0.9587337970733643 seconds
The mode is:  split
Start 22016, end 22528, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37318897247314453
Time for copying to cuda: 0.01353907585144043
Time for forward pass: 0.030833721160888672
Time for backpropagation: 0.0055882930755615234
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5207576751708984 seconds
Index: 42
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8302361965179443 seconds
Streaming imagenet data took 0.8913285732269287 seconds
Then, training+dataloading take 0.8936491012573242 seconds
The mode is:  split
Start 22528, end 23040, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.3862786293029785
Time for copying to cuda: 0.013655424118041992
Time for forward pass: 0.026846885681152344
Time for backpropagation: 0.006251096725463867
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5292720794677734 seconds
Index: 43
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7984614372253418 seconds
Streaming imagenet data took 0.8170874118804932 seconds
Then, training+dataloading take 0.8181068897247314 seconds
The mode is:  split
Start 23040, end 23552, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.438063383102417
Time for copying to cuda: 0.014512777328491211
Time for forward pass: 0.026740312576293945
Time for backpropagation: 0.005210399627685547
GPU memory for training: 0.7408351898193359                          

Memory occpied: (3622.0, 3548.0)
One training iteration takes: 0.5638582706451416 seconds
Index: 44
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9596319198608398 seconds
Streaming imagenet data took 0.9784846305847168 seconds
Then, training+dataloading take 0.9791562557220459 seconds
The mode is:  split
Start 23552, end 24064, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.40836095809936523
Time for copying to cuda: 0.014264583587646484
Time for forward pass: 0.026578664779663086
Time for backpropagation: 0.005050182342529297
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5845675468444824 seconds
Index: 45
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0595097541809082 seconds
Streaming imagenet data took 1.0782744884490967 seconds
Then, training+dataloading take 1.0791072845458984 seconds
The mode is:  split
Start 24064, end 24576, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3790016174316406
Time for copying to cuda: 0.01377248764038086
Time for forward pass: 0.0263979434967041
Time for backpropagation: 0.01130223274230957
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5121266841888428 seconds
Index: 46
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8641259670257568 seconds
Streaming imagenet data took 0.8832945823669434 seconds
Then, training+dataloading take 0.8851680755615234 seconds
The mode is:  split
Start 24576, end 25088, post_step 128


Epoch: 0
Memory occpied: (3622.0, 3548.0)
Time of next(dataloader) is: 0.40669870376586914
Time for copying to cuda: 0.014089584350585938
Time for forward pass: 0.026855945587158203
Time for backpropagation: 0.005746364593505859
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.528754711151123 seconds
Index: 47
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.924715518951416 seconds
Streaming imagenet data took 0.943610668182373 seconds
Then, training+dataloading take 0.9443743228912354 seconds
The mode is:  split
Start 25088, end 25600, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4235265254974365
Time for copying to cuda: 0.013755321502685547
Time for forward pass: 0.03057074546813965
Time for backpropagation: 0.00524592399597168
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.6045660972595215 seconds
Index: 48
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9522953033447266 seconds
Streaming imagenet data took 0.9710855484008789 seconds
Then, training+dataloading take 0.9718496799468994 seconds
The mode is:  split
Start 25600, end 26112, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.41370725631713867
Time for copying to cuda: 0.014223337173461914
Time for forward pass: 0.026714086532592773
Time for backpropagation: 0.011154413223266602
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5506415367126465 seconds
Index: 49
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9842934608459473 seconds
Streaming imagenet data took 1.002892255783081 seconds
Then, training+dataloading take 1.0037462711334229 seconds
The mode is:  split
Start 26112, end 26624, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37569403648376465
Time for copying to cuda: 0.013981103897094727
Time for forward pass: 0.027831554412841797
Time for backpropagation: 0.005197286605834961
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5103671550750732 seconds
Index: 50
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7841622829437256 seconds
Streaming imagenet data took 0.8033897876739502 seconds
Then, training+dataloading take 0.8041210174560547 seconds
The mode is:  split
Start 26624, end 27136, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.42752718925476074
Time for copying to cuda: 0.015257596969604492
Time for forward pass: 0.026387929916381836
Time for backpropagation: 0.005041360855102539
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.601952075958252 seconds
Index: 51
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8743927478790283 seconds
Streaming imagenet data took 0.8929629325866699 seconds
Then, training+dataloading take 0.8937418460845947 seconds
The mode is:  split
Start 27136, end 27648, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3781576156616211
Time for copying to cuda: 0.01692938804626465
Time for forward pass: 0.026681900024414062
Time for backpropagation: 0.005004405975341797
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.508554220199585 seconds
Index: 52
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8405506610870361 seconds
Streaming imagenet data took 0.8618655204772949 seconds
Then, training+dataloading take 0.8634698390960693 seconds
The mode is:  split
Start 27648, end 28160, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.44315528869628906
Time for copying to cuda: 0.013987064361572266
Time for forward pass: 0.02676534652709961
Time for backpropagation: 0.005204439163208008
GPU memory for training: 0.7408351898193359                          

Memory occpied: (3622.0, 3548.0)
One training iteration takes: 0.5671412944793701 seconds
Index: 53
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9302103519439697 seconds
Streaming imagenet data took 0.9491219520568848 seconds
Then, training+dataloading take 0.9501276016235352 seconds
The mode is:  split
Start 28160, end 28672, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38726305961608887
Time for copying to cuda: 0.013773918151855469
Time for forward pass: 0.0321502685546875
Time for backpropagation: 0.005146503448486328
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5191676616668701 seconds
Index: 54
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9769697189331055 seconds
Streaming imagenet data took 0.9956119060516357 seconds
Then, training+dataloading take 0.9964432716369629 seconds
The mode is:  split
Start 28672, end 29184, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3787665367126465
Time for copying to cuda: 0.013920783996582031
Time for forward pass: 0.02923297882080078
Time for backpropagation: 0.0050373077392578125
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5067565441131592 seconds
Index: 55
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.7940702438354492 seconds
Streaming imagenet data took 0.8132643699645996 seconds
Then, training+dataloading take 0.8140475749969482 seconds
The mode is:  split
Start 29184, end 29696, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.43782973289489746
Time for copying to cuda: 0.013581991195678711
Time for forward pass: 0.0264890193939209
Time for backpropagation: 0.0057795047760009766
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.6095471382141113 seconds
Index: 56
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8747572898864746 seconds
Streaming imagenet data took 0.8935160636901855 seconds
Then, training+dataloading take 0.8942949771881104 seconds
The mode is:  split
Start 29696, end 30208, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3864405155181885
Time for copying to cuda: 0.01397562026977539
Time for forward pass: 0.02646493911743164
Time for backpropagation: 0.0051937103271484375
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5199429988861084 seconds
Index: 57
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.04789400100708 seconds
Streaming imagenet data took 1.066955327987671 seconds
Then, training+dataloading take 1.0677216053009033 seconds
The mode is:  split
Start 30208, end 30720, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4044334888458252
Time for copying to cuda: 0.013740062713623047
Time for forward pass: 0.026487350463867188
Time for backpropagation: 0.011358022689819336
GPU memory for training: 0.7408351898193359                          

Read 49.02341079711914 MBs for this batch
Executing all posts took 0.8320684432983398 seconds
Streaming imagenet data took 0.8505604267120361 seconds
Memory occpied: (3622.0, 3548.0)
Memory occpied: (3622.0, 3548.0)
Memory occpied: (3622.0, 3548.0)
Memory occpied: (3622.0, 3548.0)
One training iteration takes: 5.492076396942139 seconds
Index: 58
Then, training+dataloading take 5.492191314697266 seconds
The mode is:  split
Start 30720, end 31232, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37864041328430176
Time for copying to cuda: 0.01356959342956543
Time for forward pass: 0.026462078094482422
Time for backpropagation: 0.005271196365356445
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5161032676696777 seconds
Index: 59
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 1.0125465393066406 seconds
Streaming imagenet data took 1.0311768054962158 seconds
Then, training+dataloading take 1.0318443775177002 seconds
The mode is:  split
Start 31232, end 31744, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38761305809020996
Time for copying to cuda: 0.013640403747558594
Time for forward pass: 0.030871152877807617
Time for backpropagation: 0.005353689193725586
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5340006351470947 seconds
Index: 60
Memory occpied: (3622.0, 3548.0)
Read 49.02341079711914 MBs for this batch
Executing all posts took 0.9407429695129395 seconds
Streaming imagenet data took 0.959660530090332 seconds
Then, training+dataloading take 0.9604296684265137 seconds
The mode is:  split
Start 31744, end 32000, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38675713539123535
Time for copying to cuda: 0.013457059860229492
Time for forward pass: 0.02633953094482422
Time for backpropagation: 0.0048334598541259766
GPU memory for training: 0.7408351898193359                          

One training iteration takes: 0.5309610366821289 seconds
Index: 61
Read 24.51170539855957 MBs for this batch
Executing all posts took 0.5663015842437744 seconds
Streaming imagenet data took 0.5770478248596191 seconds
Then, training+dataloading take 0.577735185623169 seconds

Epoch: 0
Time of next(dataloader) is: 0.42977237701416016
Time for copying to cuda: 0.04836702346801758
Memory occpied: (3622.0, 3548.0)
Time for forward pass: 0.19058704376220703
Time for backpropagation: 0.19820308685302734
GPU memory for training: 3.425413131713867                          

The whole process took 74.87620329856873 seconds
