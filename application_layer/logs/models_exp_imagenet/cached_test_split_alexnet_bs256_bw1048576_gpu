Namespace(batch_size=256, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5033942494733 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119079356.89106697 119079356.89106697
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 417.84765625 716.9453125 911.28515625
Candidate split  6
Server, client, server+client, vanilla  299.09765625 417.84765625 716.9453125 911.28515625
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 256, post_step 128

Memory occpied: (1514.0, 3.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8492822647094727 seconds
Streaming imagenet data took 0.8616147041320801 seconds
The mode is:  split
Start 256, end 512, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.2667973041534424
Time for copying to cuda: 0.009140729904174805
Memory occpied: (1546.0, 124.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8493461608886719 seconds
Streaming imagenet data took 0.8621530532836914 seconds
Memory occpied: (1546.0, 594.0)
Memory occpied: (1546.0, 1000.0)
Time for forward pass: 3.56645131111145
Time for backpropagation: 0.092803955078125
GPU memory for training: 2.067789077758789                          

Memory occpied: (1812.0, 2166.0)
One training iteration takes: 3.998326539993286 seconds
Index: 0
Then, training+dataloading take 3.9985249042510986 seconds
The mode is:  split
Start 512, end 768, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3057389259338379
Time for copying to cuda: 0.008655548095703125
Time for forward pass: 0.03754281997680664
Time for backpropagation: 0.0029664039611816406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4273416996002197 seconds
Index: 1
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8859152793884277 seconds
Streaming imagenet data took 0.8983848094940186 seconds
Then, training+dataloading take 0.898928165435791 seconds
The mode is:  split
Start 768, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.362656831741333
Time for copying to cuda: 0.008565664291381836
Time for forward pass: 0.037071943283081055
Time for backpropagation: 0.002707958221435547
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.509962797164917 seconds
Index: 2
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.84139084815979 seconds
Streaming imagenet data took 0.8543424606323242 seconds
Then, training+dataloading take 0.8547320365905762 seconds
The mode is:  split
Start 1024, end 1280, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31484293937683105
Time for copying to cuda: 0.008485555648803711
Time for forward pass: 0.0460355281829834
Time for backpropagation: 0.0029287338256835938
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4510204792022705 seconds
Index: 3
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9077057838439941 seconds
Memory occpied: (2566.0, 2174.0)
Streaming imagenet data took 0.9153661727905273 seconds
Then, training+dataloading take 0.9160575866699219 seconds
The mode is:  split
Start 1280, end 1536, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3131842613220215
Time for copying to cuda: 0.008444070816040039
Time for forward pass: 0.047833919525146484
Time for backpropagation: 0.0029382705688476562
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4470832347869873 seconds
Index: 4
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9809839725494385 seconds
Streaming imagenet data took 0.993565559387207 seconds
Then, training+dataloading take 0.9939615726470947 seconds
The mode is:  split
Start 1536, end 1792, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3587203025817871
Time for copying to cuda: 0.008634805679321289
Time for forward pass: 0.04809117317199707
Time for backpropagation: 0.0027642250061035156
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5303597450256348 seconds
Index: 5
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8088099956512451 seconds
Streaming imagenet data took 0.8163974285125732 seconds
Then, training+dataloading take 0.8167726993560791 seconds
The mode is:  split
Start 1792, end 2048, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3256998062133789
Time for copying to cuda: 0.008642196655273438
Time for forward pass: 0.048105478286743164
Time for backpropagation: 0.0027611255645751953
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4681394100189209 seconds
Index: 6
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8719086647033691 seconds
Streaming imagenet data took 0.880073070526123 seconds
Then, training+dataloading take 0.8804836273193359 seconds
The mode is:  split
Start 2048, end 2304, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3665792942047119
Time for copying to cuda: 0.008566856384277344
Time for forward pass: 0.047882795333862305
Time for backpropagation: 0.0025992393493652344
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5055468082427979 seconds
Index: 7
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8033852577209473 seconds
Streaming imagenet data took 0.8109073638916016 seconds
Then, training+dataloading take 0.8113007545471191 seconds
The mode is:  split
Start 2304, end 2560, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31758570671081543
Time for copying to cuda: 0.008620262145996094
Time for forward pass: 0.04795336723327637
Time for backpropagation: 0.0027167797088623047
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45909857749938965 seconds
Index: 8
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8323960304260254 seconds
Streaming imagenet data took 0.8405895233154297 seconds
Then, training+dataloading take 0.841012716293335 seconds
The mode is:  split
Start 2560, end 2816, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3136889934539795
Time for copying to cuda: 0.008533954620361328
Time for forward pass: 0.047821760177612305
Time for backpropagation: 0.0026082992553710938
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4517190456390381 seconds
Index: 9
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8371288776397705 seconds
Streaming imagenet data took 0.8519020080566406 seconds
Then, training+dataloading take 0.8529078960418701 seconds
The mode is:  split
Start 2816, end 3072, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3582804203033447
Time for copying to cuda: 0.008525371551513672
Time for forward pass: 0.04776334762573242
Time for backpropagation: 0.0026166439056396484
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.4985232353210449 seconds
Index: 10
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8012945652008057 seconds
Streaming imagenet data took 0.809281587600708 seconds
Then, training+dataloading take 0.8097574710845947 seconds
The mode is:  split
Start 3072, end 3328, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32767605781555176
Time for copying to cuda: 0.008613824844360352
Time for forward pass: 0.04795050621032715
Time for backpropagation: 0.002753734588623047
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4541022777557373 seconds
Index: 11
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9070086479187012 seconds
Streaming imagenet data took 0.9144525527954102 seconds
Then, training+dataloading take 0.9149186611175537 seconds
The mode is:  split
Start 3328, end 3584, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3180201053619385
Time for copying to cuda: 0.008508920669555664
Time for forward pass: 0.04796195030212402
Time for backpropagation: 0.002642393112182617
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4534320831298828 seconds
Index: 12
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.791956901550293 seconds
Streaming imagenet data took 0.7999773025512695 seconds
Then, training+dataloading take 0.8003573417663574 seconds
The mode is:  split
Start 3584, end 3840, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36785364151000977
Time for copying to cuda: 0.008646488189697266
Time for forward pass: 0.04809069633483887
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.002899169921875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5020761489868164 seconds
Index: 13
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8055994510650635 seconds
Streaming imagenet data took 0.8131697177886963 seconds
Then, training+dataloading take 0.813544750213623 seconds
The mode is:  split
Start 3840, end 4096, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32671141624450684
Time for copying to cuda: 0.008642196655273438
Time for forward pass: 0.04795265197753906
Time for backpropagation: 0.0027387142181396484
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.47386932373046875 seconds
Index: 14
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9060075283050537 seconds
Streaming imagenet data took 0.9140877723693848 seconds
Then, training+dataloading take 0.914506196975708 seconds
The mode is:  split
Start 4096, end 4352, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3254380226135254
Time for copying to cuda: 0.008663177490234375
Time for forward pass: 0.04793691635131836
Time for backpropagation: 0.00267791748046875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46993398666381836 seconds
Index: 15
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8010003566741943 seconds
Streaming imagenet data took 0.8085882663726807 seconds
Then, training+dataloading take 0.8089966773986816 seconds
The mode is:  split
Start 4352, end 4608, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3795475959777832
Time for copying to cuda: 0.008605241775512695
Time for forward pass: 0.04797649383544922
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.0029757022857666016
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5158066749572754 seconds
Index: 16
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8058664798736572 seconds
Streaming imagenet data took 0.8139655590057373 seconds
Then, training+dataloading take 0.8143281936645508 seconds
The mode is:  split
Start 4608, end 4864, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3195364475250244
Time for copying to cuda: 0.008641481399536133
Time for forward pass: 0.047858476638793945
Time for backpropagation: 0.0027534961700439453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45316481590270996 seconds
Index: 17
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8865792751312256 seconds
Streaming imagenet data took 0.8942334651947021 seconds
Then, training+dataloading take 0.8947150707244873 seconds
The mode is:  split
Start 4864, end 5120, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3221762180328369
Time for copying to cuda: 0.008491039276123047
Time for forward pass: 0.04781317710876465
Time for backpropagation: 0.0026040077209472656
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.458388090133667 seconds
Index: 18
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7976939678192139 seconds
Streaming imagenet data took 0.8057117462158203 seconds
Then, training+dataloading take 0.8060910701751709 seconds
The mode is:  split
Start 5120, end 5376, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35494112968444824
Time for copying to cuda: 0.008490800857543945
Time for forward pass: 0.04794764518737793
Time for backpropagation: 0.0027201175689697266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5325675010681152 seconds
Index: 19
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.846996545791626 seconds
Streaming imagenet data took 0.8546104431152344 seconds
Then, training+dataloading take 0.8549926280975342 seconds
The mode is:  split
Start 5376, end 5632, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3160834312438965
Time for copying to cuda: 0.008567333221435547
Time for forward pass: 0.04784250259399414
Time for backpropagation: 0.0026307106018066406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45502734184265137 seconds
Index: 20
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9107761383056641 seconds
Streaming imagenet data took 0.9191083908081055 seconds
Then, training+dataloading take 0.9197070598602295 seconds
The mode is:  split
Start 5632, end 5888, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3163118362426758
Time for copying to cuda: 0.008642911911010742
Time for forward pass: 0.04786515235900879
Time for backpropagation: 0.0026090145111083984
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4401078224182129 seconds
Index: 21
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.808983325958252 seconds
Streaming imagenet data took 0.8166429996490479 seconds
Then, training+dataloading take 0.817047119140625 seconds
The mode is:  split
Start 5888, end 6144, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38964223861694336
Time for copying to cuda: 0.008654117584228516
Time for forward pass: 0.048059701919555664
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.0029611587524414062
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.526618480682373 seconds
Index: 22
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8008551597595215 seconds
Streaming imagenet data took 0.8089804649353027 seconds
Then, training+dataloading take 0.8093390464782715 seconds
The mode is:  split
Start 6144, end 6400, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3172135353088379
Time for copying to cuda: 0.008575439453125
Time for forward pass: 0.0478968620300293
Time for backpropagation: 0.002690553665161133
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4481682777404785 seconds
Index: 23
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9062924385070801 seconds
Streaming imagenet data took 0.9139494895935059 seconds
Then, training+dataloading take 0.9144401550292969 seconds
The mode is:  split
Start 6400, end 6656, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31754112243652344
Time for copying to cuda: 0.00858926773071289
Time for forward pass: 0.04794454574584961
Time for backpropagation: 0.0027375221252441406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4588954448699951 seconds
Index: 24
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8063409328460693 seconds
Streaming imagenet data took 0.8144450187683105 seconds
Then, training+dataloading take 0.8148543834686279 seconds
The mode is:  split
Start 6656, end 6912, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3749661445617676
Time for copying to cuda: 0.008619308471679688
Time for forward pass: 0.04795098304748535
Time for backpropagation: 0.002696990966796875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5331981182098389 seconds
Index: 25
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8478748798370361 seconds
Streaming imagenet data took 0.8554871082305908 seconds
Then, training+dataloading take 0.8559014797210693 seconds
The mode is:  split
Start 6912, end 7168, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3144257068634033
Time for copying to cuda: 0.008543729782104492
Time for forward pass: 0.0479280948638916
Time for backpropagation: 0.0025980472564697266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4471743106842041 seconds
Index: 26
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8948204517364502 seconds
Streaming imagenet data took 0.9105727672576904 seconds
Then, training+dataloading take 0.9111239910125732 seconds
The mode is:  split
Start 7168, end 7424, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3237583637237549
Time for copying to cuda: 0.008508920669555664
Time for forward pass: 0.04796648025512695
Time for backpropagation: 0.0027489662170410156
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45853543281555176 seconds
Index: 27
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8461017608642578 seconds
Streaming imagenet data took 0.8536968231201172 seconds
Then, training+dataloading take 0.8541216850280762 seconds
The mode is:  split
Start 7424, end 7680, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35628366470336914
Time for copying to cuda: 0.008626461029052734
Time for forward pass: 0.04800915718078613
Time for backpropagation: 0.002724885940551758
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5152528285980225 seconds
Index: 28
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8019022941589355 seconds
Streaming imagenet data took 0.8099255561828613 seconds
Then, training+dataloading take 0.8102834224700928 seconds
The mode is:  split
Start 7680, end 7936, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3151977062225342
Time for copying to cuda: 0.008532047271728516
Time for forward pass: 0.04792451858520508
Time for backpropagation: 0.002707242965698242
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4510498046875 seconds
Index: 29
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8465609550476074 seconds
Streaming imagenet data took 0.85872483253479 seconds
Then, training+dataloading take 0.8593838214874268 seconds
The mode is:  split
Start 7936, end 8192, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35227012634277344
Time for copying to cuda: 0.008472919464111328
Time for forward pass: 0.04782819747924805
Time for backpropagation: 0.002820253372192383
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.4860711097717285 seconds
Index: 30
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7996604442596436 seconds
Streaming imagenet data took 0.8077540397644043 seconds
Then, training+dataloading take 0.80814528465271 seconds
The mode is:  split
Start 8192, end 8448, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3138730525970459
Time for copying to cuda: 0.00857090950012207
Time for forward pass: 0.04781389236450195
Time for backpropagation: 0.002643108367919922
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.450786828994751 seconds
Index: 31
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8699426651000977 seconds
Streaming imagenet data took 0.8775684833526611 seconds
Then, training+dataloading take 0.8781566619873047 seconds
The mode is:  split
Start 8448, end 8704, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31821274757385254
Time for copying to cuda: 0.008501291275024414
Time for forward pass: 0.04787778854370117
Time for backpropagation: 0.002670764923095703
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4511587619781494 seconds
Index: 32
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8331568241119385 seconds
Streaming imagenet data took 0.8412685394287109 seconds
Then, training+dataloading take 0.8416588306427002 seconds
The mode is:  split
Start 8704, end 8960, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35648250579833984
Time for copying to cuda: 0.00856328010559082
Time for forward pass: 0.047974586486816406
Time for backpropagation: 0.002741575241088867
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5226953029632568 seconds
Index: 33
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8373949527740479 seconds
Streaming imagenet data took 0.844994306564331 seconds
Then, training+dataloading take 0.8454012870788574 seconds
The mode is:  split
Start 8960, end 9216, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31711339950561523
Time for copying to cuda: 0.00849151611328125
Time for forward pass: 0.0479581356048584
Time for backpropagation: 0.0027849674224853516
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4478940963745117 seconds
Index: 34
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8353226184844971 seconds
Streaming imagenet data took 0.8940145969390869 seconds
Then, training+dataloading take 0.89546799659729 seconds
The mode is:  split
Start 9216, end 9472, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3161959648132324
Time for copying to cuda: 0.00849771499633789
Time for forward pass: 0.047814369201660156
Time for backpropagation: 0.0026111602783203125
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4581592082977295 seconds
Index: 35
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8067517280578613 seconds
Streaming imagenet data took 0.8143188953399658 seconds
Then, training+dataloading take 0.8148303031921387 seconds
The mode is:  split
Start 9472, end 9728, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3325929641723633
Time for copying to cuda: 0.008618831634521484
Time for forward pass: 0.04806113243103027
Time for backpropagation: 0.03856921195983887
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5187475681304932 seconds
Index: 36
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8321783542633057 seconds
Streaming imagenet data took 0.840355634689331 seconds
Then, training+dataloading take 0.8407213687896729 seconds
The mode is:  split
Start 9728, end 9984, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31397223472595215
Time for copying to cuda: 0.00846552848815918
Time for forward pass: 0.048035621643066406
Time for backpropagation: 0.002768278121948242
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4611630439758301 seconds
Index: 37
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.869046688079834 seconds
Streaming imagenet data took 0.8766598701477051 seconds
Then, training+dataloading take 0.8772451877593994 seconds
The mode is:  split
Start 9984, end 10240, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3177762031555176
Time for copying to cuda: 0.008607625961303711
Time for forward pass: 0.04803800582885742
Time for backpropagation: 0.002702951431274414
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4612307548522949 seconds
Index: 38
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7988355159759521 seconds
Streaming imagenet data took 0.8069281578063965 seconds
Then, training+dataloading take 0.8073029518127441 seconds
The mode is:  split
Start 10240, end 10496, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36400651931762695
Time for copying to cuda: 0.008726358413696289
Time for forward pass: 0.04780936241149902
Time for backpropagation: 0.002838611602783203
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5440168380737305 seconds
Index: 39
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8417301177978516 seconds
Streaming imagenet data took 0.8492608070373535 seconds
Then, training+dataloading take 0.8496880531311035 seconds
The mode is:  split
Start 10496, end 10752, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32596850395202637
Time for copying to cuda: 0.008589029312133789
Time for forward pass: 0.0478358268737793
Time for backpropagation: 0.002604246139526367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4603848457336426 seconds
Index: 40
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9209818840026855 seconds
Streaming imagenet data took 0.9374487400054932 seconds
Then, training+dataloading take 0.938002347946167 seconds
The mode is:  split
Start 10752, end 11008, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.33605432510375977
Time for copying to cuda: 0.008590936660766602
Time for forward pass: 0.047908782958984375
Time for backpropagation: 0.002670764923095703
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4778420925140381 seconds
Index: 41
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8028655052185059 seconds
Streaming imagenet data took 0.8104734420776367 seconds
Then, training+dataloading take 0.8109035491943359 seconds
The mode is:  split
Start 11008, end 11264, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35655927658081055
Time for copying to cuda: 0.008698225021362305
Time for forward pass: 0.04815101623535156
Time for backpropagation: 0.002736806869506836
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5292563438415527 seconds
Index: 42
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8377013206481934 seconds
Streaming imagenet data took 0.8457889556884766 seconds
Then, training+dataloading take 0.8461503982543945 seconds
The mode is:  split
Start 11264, end 11520, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3195991516113281
Time for copying to cuda: 0.008530855178833008
Time for forward pass: 0.04797196388244629
Time for backpropagation: 0.0030426979064941406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4569356441497803 seconds
Index: 43
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8433096408843994 seconds
Streaming imagenet data took 0.8936967849731445 seconds
Then, training+dataloading take 0.8953642845153809 seconds
The mode is:  split
Start 11520, end 11776, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3224911689758301
Time for copying to cuda: 0.008655071258544922
Time for forward pass: 0.04793858528137207
Time for backpropagation: 0.0027217864990234375
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45960140228271484 seconds
Index: 44
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8110995292663574 seconds
Streaming imagenet data took 0.8192071914672852 seconds
Then, training+dataloading take 0.8196985721588135 seconds
The mode is:  split
Start 11776, end 12032, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33229827880859375
Time for copying to cuda: 0.008601665496826172
Time for forward pass: 0.04804348945617676
Time for backpropagation: 0.039063215255737305
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5116829872131348 seconds
Index: 45
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8565177917480469 seconds
Streaming imagenet data took 0.8641147613525391 seconds
Then, training+dataloading take 0.8644988536834717 seconds
The mode is:  split
Start 12032, end 12288, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3193519115447998
Time for copying to cuda: 0.008678913116455078
Time for forward pass: 0.04792642593383789
Time for backpropagation: 0.0026237964630126953
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.467787504196167 seconds
Index: 46
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9017367362976074 seconds
Streaming imagenet data took 0.9099123477935791 seconds
Then, training+dataloading take 0.91031813621521 seconds
The mode is:  split
Start 12288, end 12544, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32645416259765625
Time for copying to cuda: 0.00872039794921875
Time for forward pass: 0.047943830490112305
Time for backpropagation: 0.002714395523071289
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46155476570129395 seconds
Index: 47
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8423159122467041 seconds
Streaming imagenet data took 0.8499724864959717 seconds
Then, training+dataloading take 0.8503823280334473 seconds
The mode is:  split
Start 12544, end 12800, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3568854331970215
Time for copying to cuda: 0.008522748947143555
Time for forward pass: 0.04794669151306152
Time for backpropagation: 0.002699613571166992
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5159482955932617 seconds
Index: 48
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.803950309753418 seconds
Streaming imagenet data took 0.8119328022003174 seconds
Then, training+dataloading take 0.8123118877410889 seconds
The mode is:  split
Start 12800, end 13056, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3176298141479492
Time for copying to cuda: 0.008540868759155273
Time for forward pass: 0.04791736602783203
Time for backpropagation: 0.0028967857360839844
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4632899761199951 seconds
Index: 49
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9271543025970459 seconds
Streaming imagenet data took 0.9416122436523438 seconds
Then, training+dataloading take 0.9422893524169922 seconds
The mode is:  split
Start 13056, end 13312, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.31803274154663086
Time for copying to cuda: 0.008562326431274414
Time for forward pass: 0.04784107208251953
Time for backpropagation: 0.0026865005493164062
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4621756076812744 seconds
Index: 50
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.796764612197876 seconds
Streaming imagenet data took 0.8049159049987793 seconds
Then, training+dataloading take 0.8053338527679443 seconds
The mode is:  split
Start 13312, end 13568, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33445310592651367
Time for copying to cuda: 0.008574247360229492
Time for forward pass: 0.04814887046813965
Time for backpropagation: 0.03934168815612793
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5212695598602295 seconds
Index: 51
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8915741443634033 seconds
Streaming imagenet data took 0.899162769317627 seconds
Then, training+dataloading take 0.8995277881622314 seconds
The mode is:  split
Start 13568, end 13824, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3198890686035156
Time for copying to cuda: 0.008523225784301758
Time for forward pass: 0.047971487045288086
Time for backpropagation: 0.0026624202728271484
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4663352966308594 seconds
Index: 52
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8711309432983398 seconds
Streaming imagenet data took 0.8793258666992188 seconds
Then, training+dataloading take 0.8798279762268066 seconds
The mode is:  split
Start 13824, end 14080, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3175027370452881
Time for copying to cuda: 0.008540630340576172
Time for forward pass: 0.047875165939331055
Time for backpropagation: 0.0027153491973876953
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4531557559967041 seconds
Index: 53
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8484382629394531 seconds
Streaming imagenet data took 0.8559465408325195 seconds
Then, training+dataloading take 0.8563497066497803 seconds
The mode is:  split
Start 14080, end 14336, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3894670009613037
Memory occpied: (2566.0, 2174.0)
Time for copying to cuda: 0.008758068084716797
Time for forward pass: 0.047898292541503906
Time for backpropagation: 0.0026760101318359375
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5215620994567871 seconds
Index: 54
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7971169948577881 seconds
Streaming imagenet data took 0.8051319122314453 seconds
Then, training+dataloading take 0.8054845333099365 seconds
The mode is:  split
Start 14336, end 14592, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32581567764282227
Time for copying to cuda: 0.008502960205078125
Time for forward pass: 0.04789900779724121
Time for backpropagation: 0.0027446746826171875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.47005271911621094 seconds
Index: 55
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9208879470825195 seconds
Streaming imagenet data took 0.9284951686859131 seconds
Then, training+dataloading take 0.9289331436157227 seconds
The mode is:  split
Start 14592, end 14848, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3165242671966553
Time for copying to cuda: 0.008527040481567383
Time for forward pass: 0.04792904853820801
Time for backpropagation: 0.0028145313262939453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.44997715950012207 seconds
Index: 56
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8428604602813721 seconds
Streaming imagenet data took 0.8509349822998047 seconds
Then, training+dataloading take 0.8513669967651367 seconds
The mode is:  split
Start 14848, end 15104, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3550717830657959
Time for copying to cuda: 0.008452415466308594
Time for forward pass: 0.04784274101257324
Time for backpropagation: 0.0026602745056152344
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5226538181304932 seconds
Index: 57
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8456332683563232 seconds
Streaming imagenet data took 0.8532447814941406 seconds
Then, training+dataloading take 0.8536491394042969 seconds
The mode is:  split
Start 15104, end 15360, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3274078369140625
Time for copying to cuda: 0.008578777313232422
Time for forward pass: 0.04780268669128418
Time for backpropagation: 0.002590656280517578
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4632902145385742 seconds
Index: 58
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8761568069458008 seconds
Streaming imagenet data took 0.891899585723877 seconds
Then, training+dataloading take 0.8928177356719971 seconds
The mode is:  split
Start 15360, end 15616, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3253636360168457
Time for copying to cuda: 0.008577108383178711
Time for forward pass: 0.04800558090209961
Time for backpropagation: 0.002736806869506836
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4750792980194092 seconds
Index: 59
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.798715353012085 seconds
Streaming imagenet data took 0.8064107894897461 seconds
Then, training+dataloading take 0.8068511486053467 seconds
The mode is:  split
Start 15616, end 15872, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32906293869018555
Time for copying to cuda: 0.009628057479858398
Time for forward pass: 0.048316001892089844
Time for backpropagation: 0.0027751922607421875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.47090911865234375 seconds
Index: 60
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8014869689941406 seconds
Streaming imagenet data took 0.8095698356628418 seconds
Then, training+dataloading take 0.8099451065063477 seconds
The mode is:  split
Start 15872, end 16128, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31639719009399414
Time for copying to cuda: 0.008608818054199219
Time for forward pass: 0.04788780212402344
Time for backpropagation: 0.002635955810546875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4498097896575928 seconds
Index: 61
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8696722984313965 seconds
Streaming imagenet data took 0.8850626945495605 seconds
Then, training+dataloading take 0.8858702182769775 seconds
The mode is:  split
Start 16128, end 16384, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.333158016204834
Time for copying to cuda: 0.008675098419189453
Time for forward pass: 0.04799246788024902
Time for backpropagation: 0.0027632713317871094
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4678215980529785 seconds
Index: 62
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8091638088226318 seconds
Streaming imagenet data took 0.8173441886901855 seconds
Then, training+dataloading take 0.8177909851074219 seconds
The mode is:  split
Start 16384, end 16640, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36354637145996094
Time for copying to cuda: 0.008673429489135742
Time for forward pass: 0.048014163970947266
Time for backpropagation: 0.0028247833251953125
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5482134819030762 seconds
Index: 63
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8462238311767578 seconds
Streaming imagenet data took 0.8538882732391357 seconds
Then, training+dataloading take 0.8543288707733154 seconds
The mode is:  split
Start 16640, end 16896, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3292083740234375
Time for copying to cuda: 0.008613348007202148
Time for forward pass: 0.04794478416442871
Time for backpropagation: 0.002726316452026367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4718363285064697 seconds
Index: 64
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8453330993652344 seconds
Streaming imagenet data took 0.8891925811767578 seconds
Then, training+dataloading take 0.8906042575836182 seconds
The mode is:  split
Start 16896, end 17152, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.321197509765625
Time for copying to cuda: 0.008629322052001953
Time for forward pass: 0.04787468910217285
Time for backpropagation: 0.002693653106689453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46279358863830566 seconds
Index: 65
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8073153495788574 seconds
Streaming imagenet data took 0.8149268627166748 seconds
Then, training+dataloading take 0.8154363632202148 seconds
The mode is:  split
Start 17152, end 17408, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3344595432281494
Time for copying to cuda: 0.008683204650878906
Time for forward pass: 0.04806351661682129
Time for backpropagation: 0.039293527603149414
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5161964893341064 seconds
Index: 66
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9022784233093262 seconds
Streaming imagenet data took 0.9102978706359863 seconds
Then, training+dataloading take 0.910675048828125 seconds
The mode is:  split
Start 17408, end 17664, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32240986824035645
Time for copying to cuda: 0.008585691452026367
Time for forward pass: 0.047910451889038086
Time for backpropagation: 0.0026688575744628906
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46811747550964355 seconds
Index: 67
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8745622634887695 seconds
Streaming imagenet data took 0.8821201324462891 seconds
Then, training+dataloading take 0.8826069831848145 seconds
The mode is:  split
Start 17664, end 17920, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3182516098022461
Time for copying to cuda: 0.00851297378540039
Time for forward pass: 0.04788661003112793
Time for backpropagation: 0.0026972293853759766
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4582555294036865 seconds
Index: 68
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7975499629974365 seconds
Streaming imagenet data took 0.8055415153503418 seconds
Then, training+dataloading take 0.8059120178222656 seconds
The mode is:  split
Start 17920, end 18176, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3645901679992676
Time for copying to cuda: 0.00848388671875
Time for forward pass: 0.04776930809020996
Time for backpropagation: 0.0025801658630371094
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.520313024520874 seconds
Index: 69
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8089311122894287 seconds
Streaming imagenet data took 0.8165278434753418 seconds
Then, training+dataloading take 0.816903829574585 seconds
The mode is:  split
Start 18176, end 18432, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31488633155822754
Time for copying to cuda: 0.008495092391967773
Time for forward pass: 0.04792308807373047
Time for backpropagation: 0.0026285648345947266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45876526832580566 seconds
Index: 70
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9192981719970703 seconds
Streaming imagenet data took 0.9352564811706543 seconds
Then, training+dataloading take 0.9361028671264648 seconds
The mode is:  split
Start 18432, end 18688, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3271501064300537
Time for copying to cuda: 0.008464574813842773
Time for forward pass: 0.04787731170654297
Time for backpropagation: 0.002669811248779297
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4698207378387451 seconds
Index: 71
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8034238815307617 seconds
Streaming imagenet data took 0.811105489730835 seconds
Then, training+dataloading take 0.8115100860595703 seconds
The mode is:  split
Start 18688, end 18944, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34175920486450195
Time for copying to cuda: 0.008653640747070312
Time for forward pass: 0.04802846908569336
Time for backpropagation: 0.04867434501647949
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5320544242858887 seconds
Index: 72
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8377904891967773 seconds
Streaming imagenet data took 0.8458495140075684 seconds
Then, training+dataloading take 0.8462004661560059 seconds
The mode is:  split
Start 18944, end 19200, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32126593589782715
Time for copying to cuda: 0.00867152214050293
Time for forward pass: 0.047837018966674805
Time for backpropagation: 0.002658843994140625
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4552640914916992 seconds
Index: 73
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9130716323852539 seconds
Streaming imagenet data took 0.9206283092498779 seconds
Then, training+dataloading take 0.9211022853851318 seconds
The mode is:  split
Start 19200, end 19456, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31926751136779785
Time for copying to cuda: 0.00861501693725586
Time for forward pass: 0.04792356491088867
Time for backpropagation: 0.0027365684509277344
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46465277671813965 seconds
Index: 74
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8398749828338623 seconds
Streaming imagenet data took 0.8480029106140137 seconds
Then, training+dataloading take 0.8483891487121582 seconds
The mode is:  split
Start 19456, end 19712, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3596382141113281
Time for copying to cuda: 0.008603096008300781
Time for forward pass: 0.04783058166503906
Time for backpropagation: 0.002656221389770508
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5167386531829834 seconds
Index: 75
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7992188930511475 seconds
Streaming imagenet data took 0.8067984580993652 seconds
Then, training+dataloading take 0.8072054386138916 seconds
The mode is:  split
Start 19712, end 19968, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3180844783782959
Time for copying to cuda: 0.008674383163452148
Time for forward pass: 0.04795122146606445
Time for backpropagation: 0.002814769744873047
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4618370532989502 seconds
Index: 76
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8376047611236572 seconds
Streaming imagenet data took 0.850865364074707 seconds
Then, training+dataloading take 0.85148024559021 seconds
The mode is:  split
Start 19968, end 20224, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.35761070251464844
Time for copying to cuda: 0.008554935455322266
Time for forward pass: 0.04790759086608887
Time for backpropagation: 0.002634763717651367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49026989936828613 seconds
Index: 77
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8056371212005615 seconds
Streaming imagenet data took 0.813239336013794 seconds
Then, training+dataloading take 0.8136756420135498 seconds
The mode is:  split
Start 20224, end 20480, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.316586971282959
Time for copying to cuda: 0.008545398712158203
Time for forward pass: 0.04795527458190918
Time for backpropagation: 0.0026590824127197266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46384692192077637 seconds
Index: 78
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.832951545715332 seconds
Streaming imagenet data took 0.8411085605621338 seconds
Then, training+dataloading take 0.8415274620056152 seconds
The mode is:  split
Start 20480, end 20736, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3162689208984375
Time for copying to cuda: 0.008530616760253906
Time for forward pass: 0.04779481887817383
Time for backpropagation: 0.0026051998138427734
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4639744758605957 seconds
Index: 79
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.871837854385376 seconds
Streaming imagenet data took 0.9179787635803223 seconds
Then, training+dataloading take 0.919586181640625 seconds
The mode is:  split
Start 20736, end 20992, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.31812453269958496
Time for copying to cuda: 0.008543014526367188
Time for forward pass: 0.047902822494506836
Time for backpropagation: 0.0026710033416748047
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4523332118988037 seconds
Index: 80
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8376386165618896 seconds
Streaming imagenet data took 0.8457152843475342 seconds
Then, training+dataloading take 0.8461992740631104 seconds
The mode is:  split
Start 20992, end 21248, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39259982109069824
Time for copying to cuda: 0.008654356002807617
Time for forward pass: 0.04807758331298828
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.0032663345336914062
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5471377372741699 seconds
Index: 81
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8075335025787354 seconds
Streaming imagenet data took 0.8150327205657959 seconds
Then, training+dataloading take 0.8154160976409912 seconds
The mode is:  split
Start 21248, end 21504, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3215446472167969
Time for copying to cuda: 0.008570194244384766
Time for forward pass: 0.04798603057861328
Time for backpropagation: 0.002750873565673828
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45931148529052734 seconds
Index: 82
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8895256519317627 seconds
Streaming imagenet data took 0.8976454734802246 seconds
Then, training+dataloading take 0.8980820178985596 seconds
The mode is:  split
Start 21504, end 21760, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3193790912628174
Time for copying to cuda: 0.008562564849853516
Time for forward pass: 0.04805254936218262
Time for backpropagation: 0.002729177474975586
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.453479528427124 seconds
Index: 83
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.795548677444458 seconds
Streaming imagenet data took 0.8031539916992188 seconds
Then, training+dataloading take 0.8035430908203125 seconds
The mode is:  split
Start 21760, end 22016, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39382505416870117
Time for copying to cuda: 0.008697748184204102
Time for forward pass: 0.04804515838623047
Time for backpropagation: 0.0027120113372802734
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5338296890258789 seconds
Index: 84
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8381052017211914 seconds
Streaming imagenet data took 0.8461036682128906 seconds
Then, training+dataloading take 0.8464596271514893 seconds
The mode is:  split
Start 22016, end 22272, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31839847564697266
Time for copying to cuda: 0.00861811637878418
Time for forward pass: 0.04786491394042969
Time for backpropagation: 0.0026292800903320312
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45771026611328125 seconds
Index: 85
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 1.0315802097320557 seconds
Streaming imagenet data took 1.0391919612884521 seconds
Then, training+dataloading take 1.0396840572357178 seconds
The mode is:  split
Start 22272, end 22528, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32068967819213867
Time for copying to cuda: 0.008623600006103516
Time for forward pass: 0.04796719551086426
Time for backpropagation: 0.0027709007263183594
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45027828216552734 seconds
Index: 86
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8073463439941406 seconds
Streaming imagenet data took 0.8154149055480957 seconds
Then, training+dataloading take 0.8158152103424072 seconds
The mode is:  split
Start 22528, end 22784, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3562147617340088
Time for copying to cuda: 0.00847935676574707
Time for forward pass: 0.04786944389343262
Time for backpropagation: 0.0026636123657226562
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5322222709655762 seconds
Index: 87
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.809049129486084 seconds
Streaming imagenet data took 0.8166193962097168 seconds
Then, training+dataloading take 0.817039966583252 seconds
The mode is:  split
Start 22784, end 23040, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31563782691955566
Time for copying to cuda: 0.008515357971191406
Time for forward pass: 0.04792475700378418
Time for backpropagation: 0.0026471614837646484
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45713305473327637 seconds
Index: 88
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.869542121887207 seconds
Streaming imagenet data took 0.9187049865722656 seconds
Then, training+dataloading take 0.9203457832336426 seconds
The mode is:  split
Start 23040, end 23296, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3165252208709717
Time for copying to cuda: 0.008650064468383789
Time for forward pass: 0.04814505577087402
Time for backpropagation: 0.0027403831481933594
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45796680450439453 seconds
Index: 89
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8944361209869385 seconds
Streaming imagenet data took 0.9020054340362549 seconds
Then, training+dataloading take 0.9025039672851562 seconds
The mode is:  split
Start 23296, end 23552, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3905010223388672
Time for copying to cuda: 0.008591175079345703
Time for forward pass: 0.04806375503540039
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.002876758575439453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5324995517730713 seconds
Index: 90
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8455173969268799 seconds
Streaming imagenet data took 0.8535106182098389 seconds
Then, training+dataloading take 0.8539001941680908 seconds
The mode is:  split
Start 23552, end 23808, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31648731231689453
Time for copying to cuda: 0.00855708122253418
Time for forward pass: 0.047959327697753906
Time for backpropagation: 0.002712249755859375
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4667642116546631 seconds
Index: 91
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8621103763580322 seconds
Streaming imagenet data took 0.8697495460510254 seconds
Then, training+dataloading take 0.8702456951141357 seconds
The mode is:  split
Start 23808, end 24064, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31641578674316406
Time for copying to cuda: 0.008659124374389648
Time for forward pass: 0.07636117935180664
Time for backpropagation: 0.0026764869689941406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4750549793243408 seconds
Index: 92
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8347556591033936 seconds
Streaming imagenet data took 0.8427581787109375 seconds
Then, training+dataloading take 0.8431437015533447 seconds
The mode is:  split
Start 24064, end 24320, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3569040298461914
Time for copying to cuda: 0.008705377578735352
Time for forward pass: 0.04803109169006348
Time for backpropagation: 0.0027086734771728516
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.516071081161499 seconds
Index: 93
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8032464981079102 seconds
Streaming imagenet data took 0.8108911514282227 seconds
Then, training+dataloading take 0.8112771511077881 seconds
The mode is:  split
Start 24320, end 24576, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32614660263061523
Time for copying to cuda: 0.008685111999511719
Time for forward pass: 0.04806256294250488
Time for backpropagation: 0.002677440643310547
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4620969295501709 seconds
Index: 94
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9124484062194824 seconds
Streaming imagenet data took 0.9286606311798096 seconds
Then, training+dataloading take 0.9295399188995361 seconds
The mode is:  split
Start 24576, end 24832, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3243696689605713
Time for copying to cuda: 0.008640766143798828
Time for forward pass: 0.047971248626708984
Time for backpropagation: 0.0027742385864257812
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46703457832336426 seconds
Index: 95
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8033928871154785 seconds
Streaming imagenet data took 0.8110582828521729 seconds
Then, training+dataloading take 0.8115074634552002 seconds
The mode is:  split
Start 24832, end 25088, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34281301498413086
Time for copying to cuda: 0.008666038513183594
Time for forward pass: 0.04812121391296387
Time for backpropagation: 0.03904151916503906
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5210623741149902 seconds
Index: 96
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.803408145904541 seconds
Streaming imagenet data took 0.816307544708252 seconds
Then, training+dataloading take 0.8166613578796387 seconds
The mode is:  split
Start 25088, end 25344, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31992459297180176
Time for copying to cuda: 0.00865626335144043
Time for forward pass: 0.04783964157104492
Time for backpropagation: 0.0026361942291259766
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4663820266723633 seconds
Index: 97
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9138896465301514 seconds
Streaming imagenet data took 0.9215428829193115 seconds
Then, training+dataloading take 0.9222691059112549 seconds
The mode is:  split
Start 25344, end 25600, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3154892921447754
Time for copying to cuda: 0.00854635238647461
Time for forward pass: 0.0477910041809082
Time for backpropagation: 0.002633810043334961
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4583747386932373 seconds
Index: 98
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.800121545791626 seconds
Streaming imagenet data took 0.808190107345581 seconds
Then, training+dataloading take 0.8085734844207764 seconds
The mode is:  split
Start 25600, end 25856, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.364093542098999
Time for copying to cuda: 0.008625984191894531
Time for forward pass: 0.0478665828704834
Time for backpropagation: 0.0025582313537597656
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5302555561065674 seconds
Index: 99
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8383219242095947 seconds
Streaming imagenet data took 0.8458998203277588 seconds
Then, training+dataloading take 0.8463306427001953 seconds
The mode is:  split
Start 25856, end 26112, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3206033706665039
Time for copying to cuda: 0.008692026138305664
Time for forward pass: 0.04792356491088867
Time for backpropagation: 0.002727985382080078
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45438647270202637 seconds
Index: 100
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8298323154449463 seconds
Streaming imagenet data took 0.8783483505249023 seconds
Then, training+dataloading take 0.879793643951416 seconds
The mode is:  split
Start 26112, end 26368, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.32251739501953125
Time for copying to cuda: 0.008579492568969727
Time for forward pass: 0.0478978157043457
Time for backpropagation: 0.0026848316192626953
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4564485549926758 seconds
Index: 101
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8041255474090576 seconds
Streaming imagenet data took 0.8117375373840332 seconds
Then, training+dataloading take 0.8125772476196289 seconds
The mode is:  split
Start 26368, end 26624, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34144115447998047
Time for copying to cuda: 0.008638143539428711
Time for forward pass: 0.048002004623413086
Time for backpropagation: 0.03859591484069824
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5133988857269287 seconds
Index: 102
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8016660213470459 seconds
Streaming imagenet data took 0.814608097076416 seconds
Then, training+dataloading take 0.8149795532226562 seconds
The mode is:  split
Start 26624, end 26880, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32181310653686523
Time for copying to cuda: 0.00873255729675293
Time for forward pass: 0.04809832572937012
Time for backpropagation: 0.0026869773864746094
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46639442443847656 seconds
Index: 103
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.901857852935791 seconds
Memory occpied: (2566.0, 2174.0)
Streaming imagenet data took 0.909599781036377 seconds
Then, training+dataloading take 0.9103105068206787 seconds
The mode is:  split
Start 26880, end 27136, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.314685583114624
Time for copying to cuda: 0.008630752563476562
Time for forward pass: 0.04788565635681152
Time for backpropagation: 0.002743959426879883
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4516282081604004 seconds
Index: 104
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9689459800720215 seconds
Streaming imagenet data took 0.9818019866943359 seconds
Then, training+dataloading take 0.9821774959564209 seconds
The mode is:  split
Start 27136, end 27392, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35640573501586914
Time for copying to cuda: 0.008516073226928711
Time for forward pass: 0.047879934310913086
Time for backpropagation: 0.0026140213012695312
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5142555236816406 seconds
Index: 105
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8479719161987305 seconds
Streaming imagenet data took 0.8555293083190918 seconds
Then, training+dataloading take 0.8562088012695312 seconds
The mode is:  split
Start 27392, end 27648, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3197028636932373
Time for copying to cuda: 0.008603811264038086
Time for forward pass: 0.047884225845336914
Time for backpropagation: 0.002689361572265625
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4578719139099121 seconds
Index: 106
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9086065292358398 seconds
Memory occpied: (2566.0, 2174.0)
Streaming imagenet data took 0.9213628768920898 seconds
Then, training+dataloading take 0.9218597412109375 seconds
The mode is:  split
Start 27648, end 27904, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3195815086364746
Time for copying to cuda: 0.008608818054199219
Time for forward pass: 0.04787468910217285
Time for backpropagation: 0.0026466846466064453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46036219596862793 seconds
Index: 107
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8441781997680664 seconds
Streaming imagenet data took 0.8518145084381104 seconds
Then, training+dataloading take 0.8525421619415283 seconds
The mode is:  split
Start 27904, end 28160, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3539600372314453
Time for copying to cuda: 0.008655309677124023
Time for forward pass: 0.04786825180053711
Time for backpropagation: 0.002679586410522461
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5354876518249512 seconds
Index: 108
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8444271087646484 seconds
Streaming imagenet data took 0.857175350189209 seconds
Then, training+dataloading take 0.8575689792633057 seconds
The mode is:  split
Start 28160, end 28416, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3194296360015869
Time for copying to cuda: 0.008505582809448242
Time for forward pass: 0.047904014587402344
Time for backpropagation: 0.0028417110443115234
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45920586585998535 seconds
Index: 109
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.842597484588623 seconds
Streaming imagenet data took 0.8929586410522461 seconds
Then, training+dataloading take 0.8945386409759521 seconds
The mode is:  split
Start 28416, end 28672, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3166065216064453
Time for copying to cuda: 0.008545398712158203
Time for forward pass: 0.047928810119628906
Time for backpropagation: 0.0027353763580322266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.450545072555542 seconds
Index: 110
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8391284942626953 seconds
Streaming imagenet data took 0.8520481586456299 seconds
Then, training+dataloading take 0.8525502681732178 seconds
The mode is:  split
Start 28672, end 28928, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39083075523376465
Time for copying to cuda: 0.008772134780883789
Time for forward pass: 0.04810357093811035
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.002935647964477539
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5405480861663818 seconds
Index: 111
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8018515110015869 seconds
Streaming imagenet data took 0.8094878196716309 seconds
Then, training+dataloading take 0.8101584911346436 seconds
The mode is:  split
Start 28928, end 29184, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3154013156890869
Time for copying to cuda: 0.00856924057006836
Time for forward pass: 0.047850847244262695
Time for backpropagation: 0.0026352405548095703
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46106648445129395 seconds
Index: 112
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9048726558685303 seconds
Streaming imagenet data took 0.9177467823028564 seconds
Then, training+dataloading take 0.9181623458862305 seconds
The mode is:  split
Start 29184, end 29440, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32268285751342773
Time for copying to cuda: 0.008514881134033203
Time for forward pass: 0.0478208065032959
Time for backpropagation: 0.0025937557220458984
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46415138244628906 seconds
Index: 113
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8375751972198486 seconds
Streaming imagenet data took 0.8452179431915283 seconds
Then, training+dataloading take 0.8459274768829346 seconds
The mode is:  split
Start 29440, end 29696, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3637564182281494
Time for copying to cuda: 0.008639812469482422
Time for forward pass: 0.04803943634033203
Time for backpropagation: 0.0026397705078125
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5308830738067627 seconds
Index: 114
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8082938194274902 seconds
Streaming imagenet data took 0.8213248252868652 seconds
Then, training+dataloading take 0.8217370510101318 seconds
The mode is:  split
Start 29696, end 29952, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32094907760620117
Time for copying to cuda: 0.008573770523071289
Time for forward pass: 0.04782819747924805
Time for backpropagation: 0.002640247344970703
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.44762754440307617 seconds
Index: 115
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8322479724884033 seconds
Streaming imagenet data took 0.8474061489105225 seconds
Then, training+dataloading take 0.8483898639678955 seconds
The mode is:  split
Start 29952, end 30208, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37199926376342773
Time for copying to cuda: 0.008606195449829102
Time for forward pass: 0.047902822494506836
Time for backpropagation: 0.002636432647705078
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2174.0)
One training iteration takes: 0.5176248550415039 seconds
Index: 116
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7933895587921143 seconds
Streaming imagenet data took 0.806523323059082 seconds
Then, training+dataloading take 0.8069884777069092 seconds
The mode is:  split
Start 30208, end 30464, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3244156837463379
Time for copying to cuda: 0.00877070426940918
Time for forward pass: 0.047838449478149414
Time for backpropagation: 0.0026679039001464844
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.46048784255981445 seconds
Index: 117
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.9034209251403809 seconds
Streaming imagenet data took 0.9110443592071533 seconds
Then, training+dataloading take 0.9117553234100342 seconds
The mode is:  split
Start 30464, end 30720, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3293435573577881
Time for copying to cuda: 0.008653640747070312
Time for forward pass: 0.04792213439941406
Time for backpropagation: 0.0027353763580322266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4649784564971924 seconds
Index: 118
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8436605930328369 seconds
Streaming imagenet data took 0.8568041324615479 seconds
Then, training+dataloading take 0.8571991920471191 seconds
The mode is:  split
Start 30720, end 30976, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3566441535949707
Time for copying to cuda: 0.008718729019165039
Time for forward pass: 0.04799199104309082
Time for backpropagation: 0.003010988235473633
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5156829357147217 seconds
Index: 119
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8377604484558105 seconds
Streaming imagenet data took 0.845348596572876 seconds
Then, training+dataloading take 0.8460094928741455 seconds
The mode is:  split
Start 30976, end 31232, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32381629943847656
Time for copying to cuda: 0.008717775344848633
Time for forward pass: 0.047986507415771484
Time for backpropagation: 0.002772092819213867
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45058655738830566 seconds
Index: 120
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8350684642791748 seconds
Streaming imagenet data took 0.8862841129302979 seconds
Then, training+dataloading take 0.8877139091491699 seconds
The mode is:  split
Start 31232, end 31488, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2174.0)
Memory occpied: (2566.0, 2174.0)
Time of next(dataloader) is: 0.3207554817199707
Time for copying to cuda: 0.008553266525268555
Time for forward pass: 0.0479588508605957
Time for backpropagation: 0.002748250961303711
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.45508289337158203 seconds
Index: 121
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8105847835540771 seconds
Streaming imagenet data took 0.818122148513794 seconds
Then, training+dataloading take 0.8185946941375732 seconds
The mode is:  split
Start 31488, end 31744, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39574146270751953
Time for copying to cuda: 0.008725166320800781
Time for forward pass: 0.04802227020263672
Memory occpied: (2566.0, 2174.0)
Time for backpropagation: 0.0029747486114501953
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5309832096099854 seconds
Index: 122
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8402433395385742 seconds
Streaming imagenet data took 0.848358154296875 seconds
Then, training+dataloading take 0.8487255573272705 seconds
The mode is:  split
Start 31744, end 32000, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3199024200439453
Time for copying to cuda: 0.008644342422485352
Time for forward pass: 0.04785752296447754
Time for backpropagation: 0.002654552459716797
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4527926445007324 seconds
Index: 123
Memory occpied: (2566.0, 2174.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.8719031810760498 seconds
Streaming imagenet data took 0.8796384334564209 seconds
Then, training+dataloading take 0.8801448345184326 seconds

Epoch: 0
Time of next(dataloader) is: 0.3316648006439209
Time for copying to cuda: 0.008613824844360352
Time for forward pass: 0.04812145233154297
Time for backpropagation: 0.0028374195098876953
GPU memory for training: 1.3573789596557617                          

The whole process took 117.8432412147522 seconds
