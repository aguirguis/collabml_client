Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5716219276605 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119088299.62930232 119088299.62930232
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0444300174713135 seconds
Streaming imagenet data took 2.0717129707336426 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37809014320373535
Time for copying to cuda: 0.019149065017700195
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9205031394958496 seconds
Streaming imagenet data took 1.9486737251281738 seconds
Time for forward pass: 2.9964818954467773
Time for backpropagation: 0.04878711700439453
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.568575859069824 seconds
Index: 0
Then, training+dataloading take 3.5688605308532715 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3918271064758301
Time for copying to cuda: 0.01845860481262207
Time for forward pass: 0.07539176940917969
Time for backpropagation: 0.0036678314208984375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.568206787109375 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0068652629852295 seconds
Streaming imagenet data took 2.0338852405548096 seconds
Then, training+dataloading take 2.040341377258301 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37837886810302734
Time for copying to cuda: 0.018525362014770508
Time for forward pass: 0.07679033279418945
Time for backpropagation: 0.0032520294189453125
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5682947635650635 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9496405124664307 seconds
Streaming imagenet data took 1.9773213863372803 seconds
Then, training+dataloading take 1.9823341369628906 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37258315086364746
Time for copying to cuda: 0.018435001373291016
Time for forward pass: 0.07535839080810547
Time for backpropagation: 0.0026082992553710938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5690226554870605 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8815760612487793 seconds
Streaming imagenet data took 1.9092800617218018 seconds
Then, training+dataloading take 1.9134256839752197 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42705321311950684
Time for copying to cuda: 0.0181577205657959
Time for forward pass: 0.07539677619934082
Time for backpropagation: 0.002665281295776367
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6323628425598145 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9247982501983643 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.952193021774292 seconds
Then, training+dataloading take 1.9570069313049316 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3720414638519287
Time for copying to cuda: 0.018035411834716797
Time for forward pass: 0.07547950744628906
Time for backpropagation: 0.002637147903442383
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.559706449508667 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8683850765228271 seconds
Streaming imagenet data took 1.8957006931304932 seconds
Then, training+dataloading take 1.899744987487793 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3786501884460449
Time for copying to cuda: 0.01827216148376465
Time for forward pass: 0.07621455192565918
Time for backpropagation: 0.0032625198364257812
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5809624195098877 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.94254732131958 seconds
Streaming imagenet data took 1.9695992469787598 seconds
Then, training+dataloading take 1.9746284484863281 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40195512771606445
Time for copying to cuda: 0.018379688262939453
Time for forward pass: 0.07548403739929199
Time for backpropagation: 0.0027039051055908203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5857682228088379 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.894007921218872 seconds
Streaming imagenet data took 1.9221060276031494 seconds
Then, training+dataloading take 1.926274061203003 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4579029083251953
Time for copying to cuda: 0.018138408660888672
Time for forward pass: 0.07535195350646973
Time for backpropagation: 0.00258636474609375
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6413404941558838 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9738786220550537 seconds
Streaming imagenet data took 2.001539945602417 seconds
Then, training+dataloading take 2.00592303276062 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38071703910827637
Time for copying to cuda: 0.018242835998535156
Time for forward pass: 0.07532739639282227
Time for backpropagation: 0.002637624740600586
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5785174369812012 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8723723888397217 seconds
Streaming imagenet data took 1.899890661239624 seconds
Then, training+dataloading take 1.904252290725708 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4312093257904053
Time for copying to cuda: 0.01840066909790039
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07543516159057617
Time for backpropagation: 0.002657175064086914
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6153230667114258 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9368412494659424 seconds
Streaming imagenet data took 1.9644501209259033 seconds
Then, training+dataloading take 1.968493938446045 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3821280002593994
Time for copying to cuda: 0.018274545669555664
Time for forward pass: 0.06962275505065918
Time for backpropagation: 0.0027713775634765625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5657973289489746 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8693106174468994 seconds
Streaming imagenet data took 1.8970723152160645 seconds
Then, training+dataloading take 1.901167631149292 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4306671619415283
Time for copying to cuda: 0.01832723617553711
Time for forward pass: 0.07549357414245605
Time for backpropagation: 0.0027153491973876953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6213104724884033 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9191083908081055 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9470572471618652 seconds
Then, training+dataloading take 1.9518897533416748 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39915943145751953
Time for copying to cuda: 0.018422842025756836
Time for forward pass: 0.07527327537536621
Time for backpropagation: 0.002552509307861328
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5798766613006592 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8290598392486572 seconds
Streaming imagenet data took 1.8563592433929443 seconds
Then, training+dataloading take 1.860433578491211 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3880608081817627
Time for copying to cuda: 0.01852583885192871
Time for forward pass: 0.08483004570007324
Time for backpropagation: 0.0032279491424560547
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5908732414245605 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.929772138595581 seconds
Streaming imagenet data took 1.9571270942687988 seconds
Then, training+dataloading take 1.9620280265808105 seconds

Epoch: 0
Time of next(dataloader) is: 0.3785421848297119
Time for copying to cuda: 0.01845836639404297
Time for forward pass: 0.07513999938964844
Time for backpropagation: 0.002733469009399414
GPU memory for training: 1.2580008506774902                          

The whole process took 40.165194272994995 seconds
