Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='vit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=False, use_intermediate=False)
Nb GPUS  2
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Start 0, end 2000, post_step 1000

Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Decompress data took 0.08271503448486328 seconds
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Total decompress data took 3.650937557220459 seconds
Decompress data took 0.08655166625976562 seconds
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Total decompress data took 3.5765762329101562 seconds
Read 252.732816696167 MBs for this batch
Streaming imagenet data took 10.481711864471436 seconds
The mode is:  vanilla
Start 2000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Decompress data took 0.08299016952514648 seconds
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Total decompress data took 3.76123046875 seconds
Decompress data took 0.0836946964263916 seconds
Memory occpied: (1630.0, 3.0)
Time of next(dataloader) is: 6.761162281036377
Time for copying to cuda: 0.29309797286987305
Memory occpied: (2780.0, 938.0)
Memory occpied: (2780.0, 1398.0)
Total decompress data took 3.5907838344573975 seconds
Read 244.98475742340088 MBs for this batch
Streaming imagenet data took 9.926166772842407 seconds
Memory occpied: (2780.0, 1812.0)
Memory occpied: (15026.0, 13254.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 433, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 421, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 238, in forward
    x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 199, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
RuntimeError: CUDA out of memory. Tried to allocate 1.74 GiB (GPU 0; 14.76 GiB total capacity; 12.21 GiB already allocated; 83.75 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 29.08398962020874 seconds
