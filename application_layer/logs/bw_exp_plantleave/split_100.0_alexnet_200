Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 88.79540529533553 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 11638591.362870218 11638591.362870218
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 257.6746826171875 526.7537841796875 660.8973388671875
Candidate split  13
Server, client, server+client, vanilla  269.0791015625 257.6746826171875 526.7537841796875 660.8973388671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9301791191101074 seconds
Streaming plantleave data took 0.9335660934448242 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33438849449157715
Time for copying to cuda: 0.0022296905517578125
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9069263935089111 seconds
Streaming plantleave data took 0.9102311134338379 seconds
Time for forward pass: 2.9481396675109863
Time for backpropagation: 0.05187654495239258
GPU memory for training: 0.8697309494018555                          

One training iteration takes: 3.4329333305358887 seconds
Index: 0
Then, training+dataloading take 3.43308162689209 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Memory occpied: (1500.0, 1500.0)
Time of next(dataloader) is: 0.3436102867126465
Time for copying to cuda: 0.002321004867553711
Time for forward pass: 0.027866601943969727
Time for backpropagation: 0.003901958465576172
GPU memory for training: 0.9962124824523926                          

One training iteration takes: 0.4615328311920166 seconds
Index: 1
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9170498847961426 seconds
Streaming plantleave data took 0.9200928211212158 seconds
Then, training+dataloading take 0.9204471111297607 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41532301902770996
Time for copying to cuda: 0.002251148223876953
Time for forward pass: 0.028141260147094727
Time for backpropagation: 0.00413203239440918
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5576879978179932 seconds
Index: 2
Memory occpied: (2086.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9049153327941895 seconds
Streaming plantleave data took 0.9083402156829834 seconds
Then, training+dataloading take 0.9086503982543945 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38376426696777344
Time for copying to cuda: 0.0022008419036865234
Time for forward pass: 0.027807235717773438
Time for backpropagation: 0.0026311874389648438
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.4991018772125244 seconds
Index: 3
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9352569580078125 seconds
Streaming plantleave data took 0.9371378421783447 seconds
Then, training+dataloading take 0.9375 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35803651809692383
Time for copying to cuda: 0.0022430419921875
Time for forward pass: 0.02791881561279297
Time for backpropagation: 0.002915620803833008
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.47722578048706055 seconds
Index: 4
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8911991119384766 seconds
Streaming plantleave data took 0.8935596942901611 seconds
Then, training+dataloading take 0.8938553333282471 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3969297409057617
Time for copying to cuda: 0.0022144317626953125
Time for forward pass: 0.028001785278320312
Time for backpropagation: 0.0029554367065429688
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5042541027069092 seconds
Index: 5
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9428486824035645 seconds
Streaming plantleave data took 0.9459116458892822 seconds
Then, training+dataloading take 0.9462347030639648 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3651773929595947
Time for copying to cuda: 0.002243518829345703
Time for forward pass: 0.02791595458984375
Time for backpropagation: 0.0027501583099365234
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.48731470108032227 seconds
Index: 6
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.950228214263916 seconds
Streaming plantleave data took 0.9522514343261719 seconds
Then, training+dataloading take 0.952627420425415 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3489084243774414
Time for copying to cuda: 0.0023322105407714844
Time for forward pass: 0.027853727340698242
Time for backpropagation: 0.0026416778564453125
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.47048449516296387 seconds
Index: 7
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.876152753829956 seconds
Streaming plantleave data took 0.8785264492034912 seconds
Then, training+dataloading take 0.8788471221923828 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38957691192626953
Time for copying to cuda: 0.0022678375244140625
Time for forward pass: 0.0278170108795166
Time for backpropagation: 0.002723217010498047
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5583748817443848 seconds
Index: 8
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.932347297668457 seconds
Streaming plantleave data took 0.9342830181121826 seconds
Then, training+dataloading take 0.9346253871917725 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3517923355102539
Time for copying to cuda: 0.002192974090576172
Time for forward pass: 0.02782607078552246
Time for backpropagation: 0.0029783248901367188
GPU memory for training: 0.9956474304199219                          

Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9102222919464111 seconds
Streaming plantleave data took 0.915583610534668 seconds
Memory occpied: (2150.0, 1508.0)
Memory occpied: (2150.0, 1508.0)
Memory occpied: (2150.0, 1508.0)
Memory occpied: (2150.0, 1508.0)
One training iteration takes: 5.396354913711548 seconds
Index: 9
Then, training+dataloading take 5.39644718170166 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39150404930114746
Time for copying to cuda: 0.002267122268676758
Time for forward pass: 0.0278170108795166
Time for backpropagation: 0.0028307437896728516
GPU memory for training: 0.9956474304199219                          

Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9280848503112793 seconds
Streaming plantleave data took 0.9316232204437256 seconds
Memory occpied: (2150.0, 1508.0)
Memory occpied: (2150.0, 1508.0)
Memory occpied: (2150.0, 1508.0)
One training iteration takes: 5.436004161834717 seconds
Index: 10
Then, training+dataloading take 5.436150550842285 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Memory occpied: (2150.0, 1508.0)
Time of next(dataloader) is: 0.3958930969238281
Time for copying to cuda: 0.002197265625
Time for forward pass: 0.027728796005249023
Time for backpropagation: 0.002725839614868164
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5237138271331787 seconds
Index: 11
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9044888019561768 seconds
Streaming plantleave data took 0.9065108299255371 seconds
Then, training+dataloading take 0.906898021697998 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4163937568664551
Time for copying to cuda: 0.0021724700927734375
Time for forward pass: 0.02781200408935547
Time for backpropagation: 0.0028116703033447266
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5570328235626221 seconds
Index: 12
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8891901969909668 seconds
Streaming plantleave data took 0.8916163444519043 seconds
Then, training+dataloading take 0.8919405937194824 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35159897804260254
Time for copying to cuda: 0.002180337905883789
Time for forward pass: 0.028142213821411133
Time for backpropagation: 0.002830982208251953
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.4761364459991455 seconds
Index: 13
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9941673278808594 seconds
Streaming plantleave data took 0.9960741996765137 seconds
Then, training+dataloading take 0.99643874168396 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39519429206848145
Time for copying to cuda: 0.0022466182708740234
Time for forward pass: 0.027895689010620117
Time for backpropagation: 0.0029404163360595703
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5177299976348877 seconds
Index: 14
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8542482852935791 seconds
Streaming plantleave data took 0.8566262722015381 seconds
Then, training+dataloading take 0.8569507598876953 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3965139389038086
Time for copying to cuda: 0.0022039413452148438
Time for forward pass: 0.02772212028503418
Time for backpropagation: 0.0027365684509277344
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5424880981445312 seconds
Index: 15
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9075591564178467 seconds
Streaming plantleave data took 0.9095275402069092 seconds
Then, training+dataloading take 0.9098501205444336 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3522224426269531
Time for copying to cuda: 0.0021860599517822266
Time for forward pass: 0.027791976928710938
Time for backpropagation: 0.0028421878814697266
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.4744434356689453 seconds
Index: 16
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8895514011383057 seconds
Streaming plantleave data took 0.8941905498504639 seconds
Then, training+dataloading take 0.8948521614074707 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Memory occpied: (2150.0, 1508.0)
Time of next(dataloader) is: 0.3652331829071045
Time for copying to cuda: 0.002197265625
Time for forward pass: 0.027843475341796875
Time for backpropagation: 0.0027997493743896484
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.4798760414123535 seconds
Index: 17
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8943440914154053 seconds
Streaming plantleave data took 0.8962721824645996 seconds
Then, training+dataloading take 0.8966832160949707 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.437103271484375
Time for copying to cuda: 0.0021514892578125
Time for forward pass: 0.027828454971313477
Time for backpropagation: 0.0027725696563720703
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5846090316772461 seconds
Index: 18
Memory occpied: (2150.0, 1508.0)
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.8528690338134766 seconds
Streaming plantleave data took 0.8552703857421875 seconds
Then, training+dataloading take 0.8555641174316406 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35141706466674805
Time for copying to cuda: 0.0022292137145996094
Time for forward pass: 0.027794599533081055
Time for backpropagation: 0.0026845932006835938
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.4563162326812744 seconds
Index: 19
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9235832691192627 seconds
Streaming plantleave data took 0.967829704284668 seconds
Then, training+dataloading take 0.9691047668457031 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (2150.0, 1508.0)
Time of next(dataloader) is: 0.3859109878540039
Time for copying to cuda: 0.002340555191040039
Time for forward pass: 0.027959108352661133
Time for backpropagation: 0.0028128623962402344
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.5010795593261719 seconds
Index: 20
Read 7.039783477783203 MBs for this batch
Executing all posts took 0.9323325157165527 seconds
Streaming plantleave data took 0.9347050189971924 seconds
Then, training+dataloading take 0.9353184700012207 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.421095609664917
Time for copying to cuda: 0.0022287368774414062
Time for forward pass: 0.027902603149414062
Time for backpropagation: 0.002760171890258789
GPU memory for training: 0.9956474304199219                          

One training iteration takes: 0.562570333480835 seconds
Index: 21
Read 3.5903921127319336 MBs for this batch
Executing all posts took 0.5895750522613525 seconds
Streaming plantleave data took 0.5931224822998047 seconds
Then, training+dataloading take 0.5935876369476318 seconds

Epoch: 0
Memory occpied: (2150.0, 1508.0)
Time of next(dataloader) is: 0.3692152500152588
Time for copying to cuda: 0.0012698173522949219
Time for forward pass: 0.025074005126953125
Time for backpropagation: 0.0031232833862304688
GPU memory for training: 0.9909195899963379                          

The whole process took 39.78243660926819 seconds
