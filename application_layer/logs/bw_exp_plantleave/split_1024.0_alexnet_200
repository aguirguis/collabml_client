Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5457553430368 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119084909.24432252 119084909.24432252
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5073807239532471 seconds
Streaming plantleave data took 0.5173277854919434 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33857154846191406
Time for copying to cuda: 0.008273601531982422
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5284197330474854 seconds
Streaming plantleave data took 0.5385787487030029 seconds
Memory occpied: (1526.0, 240.0)
Memory occpied: (1526.0, 668.0)
Memory occpied: (1526.0, 1138.0)
Time for forward pass: 3.5465540885925293
Time for backpropagation: 0.056746721267700195
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.026172399520874 seconds
Index: 0
Then, training+dataloading take 4.026238441467285 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4132957458496094
Time for copying to cuda: 0.007266521453857422
Time for forward pass: 0.0343935489654541
Time for backpropagation: 0.003513813018798828
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6174843311309814 seconds
Index: 1
Memory occpied: (1978.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7425525188446045 seconds
Streaming plantleave data took 0.7526199817657471 seconds
Then, training+dataloading take 0.7529737949371338 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37738800048828125
Time for copying to cuda: 0.0072231292724609375
Time for forward pass: 0.03345179557800293
Time for backpropagation: 0.0036983489990234375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.4985523223876953 seconds
Index: 2
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5500762462615967 seconds
Streaming plantleave data took 0.5603148937225342 seconds
Then, training+dataloading take 0.5606858730316162 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41355228424072266
Time for copying to cuda: 0.00767207145690918
Time for forward pass: 0.04065871238708496
Time for backpropagation: 0.0037107467651367188
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5652422904968262 seconds
Index: 3
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5991528034210205 seconds
Memory occpied: (2314.0, 2364.0)
Streaming plantleave data took 0.6053929328918457 seconds
Then, training+dataloading take 0.6059660911560059 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37653589248657227
Time for copying to cuda: 0.007190227508544922
Time for forward pass: 0.043654441833496094
Time for backpropagation: 0.0031440258026123047
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5281350612640381 seconds
Index: 4
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5488693714141846 seconds
Streaming plantleave data took 0.5552594661712646 seconds
Then, training+dataloading take 0.5555839538574219 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3982963562011719
Time for copying to cuda: 0.007409572601318359
Time for forward pass: 0.10064911842346191
Time for backpropagation: 0.005787372589111328
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6217451095581055 seconds
Index: 5
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6510312557220459 seconds
Streaming plantleave data took 0.6635379791259766 seconds
Then, training+dataloading take 0.6641180515289307 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.39980387687683105
Time for copying to cuda: 0.0073680877685546875
Time for forward pass: 0.04443764686584473
Time for backpropagation: 0.003145933151245117
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5557332038879395 seconds
Index: 6
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5651838779449463 seconds
Streaming plantleave data took 0.5754067897796631 seconds
Then, training+dataloading take 0.5757582187652588 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3740248680114746
Time for copying to cuda: 0.007592201232910156
Time for forward pass: 0.04383516311645508
Time for backpropagation: 0.0032646656036376953
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5349993705749512 seconds
Index: 7
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5911145210266113 seconds
Streaming plantleave data took 0.5974206924438477 seconds
Then, training+dataloading take 0.5979769229888916 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47040534019470215
Time for copying to cuda: 0.008697032928466797
Time for forward pass: 0.04387164115905762
Time for backpropagation: 0.0037679672241210938
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6027750968933105 seconds
Streaming plantleave data took 0.612987756729126 seconds
One training iteration takes: 0.6177875995635986 seconds
Index: 8
Then, training+dataloading take 0.6178240776062012 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3868753910064697
Time for copying to cuda: 0.007180213928222656
Time for forward pass: 0.043855905532836914
Time for backpropagation: 0.003923654556274414
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5179684162139893 seconds
Index: 9
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5695676803588867 seconds
Streaming plantleave data took 0.5795893669128418 seconds
Then, training+dataloading take 0.5801455974578857 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38880157470703125
Time for copying to cuda: 0.007289409637451172
Time for forward pass: 0.07572817802429199
Time for backpropagation: 0.012030839920043945
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6024067401885986 seconds
Index: 10
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.662024974822998 seconds
Streaming plantleave data took 0.6734340190887451 seconds
Then, training+dataloading take 0.6738080978393555 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.3914804458618164
Time for copying to cuda: 0.007561206817626953
Time for forward pass: 0.0438232421875
Time for backpropagation: 0.0032939910888671875
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5487215518951416 seconds
Index: 11
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5684220790863037 seconds
Streaming plantleave data took 0.574643611907959 seconds
Then, training+dataloading take 0.5752096176147461 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39118146896362305
Time for copying to cuda: 0.007551670074462891
Time for forward pass: 0.04381108283996582
Time for backpropagation: 0.0030624866485595703
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.564523458480835 seconds
Index: 12
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5953867435455322 seconds
Streaming plantleave data took 0.6482217311859131 seconds
Then, training+dataloading take 0.6494846343994141 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.39718103408813477
Time for copying to cuda: 0.007261991500854492
Time for forward pass: 0.04675173759460449
Time for backpropagation: 0.007927894592285156
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5581009387969971 seconds
Index: 13
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.568070650100708 seconds
Streaming plantleave data took 0.5743041038513184 seconds
Then, training+dataloading take 0.5750529766082764 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4201326370239258
Time for copying to cuda: 0.00754237174987793
Time for forward pass: 0.04444098472595215
Time for backpropagation: 0.0031599998474121094
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5823817253112793 seconds
Index: 14
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6327497959136963 seconds
Streaming plantleave data took 0.6430044174194336 seconds
Then, training+dataloading take 0.6433343887329102 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4506809711456299
Time for copying to cuda: 0.007746696472167969
Time for forward pass: 0.04406142234802246
Time for backpropagation: 0.0036728382110595703
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5863046646118164 seconds
One training iteration takes: 0.5906705856323242 seconds
Index: 15
Streaming plantleave data took 0.5963606834411621 seconds
Then, training+dataloading take 0.5969054698944092 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3857550621032715
Time for copying to cuda: 0.007480621337890625
Time for forward pass: 0.044075965881347656
Time for backpropagation: 0.0034835338592529297
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5177993774414062 seconds
Index: 16
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5606250762939453 seconds
Streaming plantleave data took 0.5707881450653076 seconds
Then, training+dataloading take 0.5711150169372559 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3898806571960449
Time for copying to cuda: 0.0077588558197021484
Time for forward pass: 0.0554502010345459
Time for backpropagation: 0.004191160202026367
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5804469585418701 seconds
Index: 17
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6387081146240234 seconds
Streaming plantleave data took 0.6450009346008301 seconds
Then, training+dataloading take 0.6455931663513184 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.3980100154876709
Time for copying to cuda: 0.007280588150024414
Time for forward pass: 0.043829917907714844
Time for backpropagation: 0.0032553672790527344
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5682876110076904 seconds
Index: 18
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5825293064117432 seconds
Streaming plantleave data took 0.592498779296875 seconds
Then, training+dataloading take 0.5928328037261963 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40073108673095703
Time for copying to cuda: 0.007495880126953125
Time for forward pass: 0.0447845458984375
Time for backpropagation: 0.003266572952270508
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5675244331359863 seconds
Index: 19
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6598029136657715 seconds
Streaming plantleave data took 0.6721312999725342 seconds
Then, training+dataloading take 0.673011064529419 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.45125436782836914
Time for copying to cuda: 0.008689165115356445
Time for forward pass: 0.04384922981262207
Time for backpropagation: 0.003087282180786133
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5929358005523682 seconds
Index: 20
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6081783771514893 seconds
Streaming plantleave data took 0.6181888580322266 seconds
Then, training+dataloading take 0.6186258792877197 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.383897066116333
Time for copying to cuda: 0.007619380950927734
Time for forward pass: 0.043817758560180664
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.4478466510772705 seconds
Time for backpropagation: 0.059584617614746094
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5085511207580566 seconds
One training iteration takes: 0.6104907989501953 seconds
Index: 21
Then, training+dataloading take 0.610675573348999 seconds

Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.3782961368560791
Time for copying to cuda: 0.0037491321563720703
Time for forward pass: 0.21006345748901367
Time for backpropagation: 0.00711369514465332
GPU memory for training: 1.6732282638549805                          

The whole process took 25.054938077926636 seconds
