Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 1815.1162204867653 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 237910913.2516413 237910913.2516413
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.41464996337890625 seconds
Streaming plantleave data took 0.42463231086730957 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32523298263549805
Time for copying to cuda: 0.01058650016784668
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.43337392807006836 seconds
Streaming plantleave data took 0.4461948871612549 seconds
Memory occpied: (1526.0, 280.0)
Memory occpied: (1526.0, 690.0)
Memory occpied: (1526.0, 1166.0)
Time for forward pass: 3.581050157546997
Time for backpropagation: 0.056310176849365234
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.054229974746704 seconds
Index: 0
Then, training+dataloading take 4.054291009902954 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4799621105194092
Time for copying to cuda: 0.008081912994384766
Time for forward pass: 0.04010272026062012
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5435311794281006 seconds
Time for backpropagation: 0.014729976654052734
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5556223392486572 seconds
One training iteration takes: 0.6817338466644287 seconds
Index: 1
Then, training+dataloading take 0.6819593906402588 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.3974781036376953
Time for copying to cuda: 0.008177042007446289
Time for forward pass: 0.03478646278381348
Time for backpropagation: 0.003652811050415039
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4863908290863037 seconds
Streaming plantleave data took 0.4968690872192383 seconds
One training iteration takes: 0.5421535968780518 seconds
Index: 2
Then, training+dataloading take 0.5421972274780273 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38149046897888184
Time for copying to cuda: 0.007416486740112305
Time for forward pass: 0.0355679988861084
Time for backpropagation: 0.00481104850769043
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4755210876464844 seconds
Streaming plantleave data took 0.48688435554504395 seconds
One training iteration takes: 0.5134665966033936 seconds
Index: 3
Then, training+dataloading take 0.5135104656219482 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5007696151733398
Time for copying to cuda: 0.007246732711791992
Time for forward pass: 0.04478883743286133
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5739710330963135 seconds
Time for backpropagation: 0.021521568298339844
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5867207050323486 seconds
One training iteration takes: 0.6905727386474609 seconds
Index: 4
Then, training+dataloading take 0.6907036304473877 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.4398641586303711
Time for copying to cuda: 0.00821232795715332
Time for forward pass: 0.04665946960449219
Time for backpropagation: 0.007655143737792969
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5142455101013184 seconds
Streaming plantleave data took 0.5266318321228027 seconds
One training iteration takes: 0.6015675067901611 seconds
Index: 5
Then, training+dataloading take 0.6016106605529785 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3997321128845215
Time for copying to cuda: 0.007675647735595703
Time for forward pass: 0.04837632179260254
Time for backpropagation: 0.004094123840332031
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4849545955657959 seconds
Streaming plantleave data took 0.4952547550201416 seconds
One training iteration takes: 0.5500195026397705 seconds
Index: 6
Then, training+dataloading take 0.5500648021697998 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5220630168914795
Time for copying to cuda: 0.010176897048950195
Time for forward pass: 0.04793906211853027
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6049380302429199 seconds
Time for backpropagation: 0.02405548095703125
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.6179239749908447 seconds
Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.690532922744751 seconds
Index: 7
Then, training+dataloading take 0.690575122833252 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.40888118743896484
Time for copying to cuda: 0.007875442504882812
Time for forward pass: 0.044175148010253906
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.47934722900390625 seconds
Time for backpropagation: 0.01878666877746582
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.4938013553619385 seconds
One training iteration takes: 0.5579702854156494 seconds
Index: 8
Then, training+dataloading take 0.5580132007598877 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4857645034790039
Time for copying to cuda: 0.008426189422607422
Time for forward pass: 0.04684305191040039
Time for backpropagation: 0.014142990112304688
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6509370803833008 seconds
Streaming plantleave data took 0.6636810302734375 seconds
Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.7150888442993164 seconds
Index: 9
Then, training+dataloading take 0.7151315212249756 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42038464546203613
Time for copying to cuda: 0.009945154190063477
Time for forward pass: 0.044457435607910156
Time for backpropagation: 0.005148410797119141
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.49819302558898926 seconds
Streaming plantleave data took 0.5086052417755127 seconds
One training iteration takes: 0.5778188705444336 seconds
Index: 10
Then, training+dataloading take 0.5778629779815674 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4026055335998535
Time for copying to cuda: 0.00760340690612793
Time for forward pass: 0.09038472175598145
Time for backpropagation: 0.016693115234375
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5467612743377686 seconds
Streaming plantleave data took 0.5584292411804199 seconds
One training iteration takes: 0.6182763576507568 seconds
Index: 11
Then, training+dataloading take 0.6183958053588867 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.45142626762390137
Time for copying to cuda: 0.008407831192016602
Time for forward pass: 0.04473710060119629
Time for backpropagation: 0.0068836212158203125
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5406632423400879 seconds
Streaming plantleave data took 0.550649881362915 seconds
One training iteration takes: 0.6043257713317871 seconds
Index: 12
Then, training+dataloading take 0.6043689250946045 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41265416145324707
Time for copying to cuda: 0.010865211486816406
Time for forward pass: 0.05001211166381836
Time for backpropagation: 0.004343509674072266
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4885866641998291 seconds
Streaming plantleave data took 0.5029594898223877 seconds
One training iteration takes: 0.6012449264526367 seconds
Index: 13
Then, training+dataloading take 0.6013720035552979 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.48636841773986816
Time for copying to cuda: 0.008865833282470703
Time for forward pass: 0.04446911811828613
Time for backpropagation: 0.003801584243774414
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5649361610412598 seconds
Streaming plantleave data took 0.5786974430084229 seconds
Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.6494283676147461 seconds
Index: 14
Then, training+dataloading take 0.6494667530059814 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4284353256225586
Time for copying to cuda: 0.009435415267944336
Time for forward pass: 0.04705357551574707
Time for backpropagation: 0.018210411071777344
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5288770198822021 seconds
Streaming plantleave data took 0.5410139560699463 seconds
One training iteration takes: 0.6148273944854736 seconds
Index: 15
Then, training+dataloading take 0.6148703098297119 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4477241039276123
Time for copying to cuda: 0.009029865264892578
Time for forward pass: 0.04979205131530762
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5798032283782959 seconds
Time for backpropagation: 0.0709531307220459
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5957522392272949 seconds
Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.6834495067596436 seconds
Index: 16
Then, training+dataloading take 0.6834917068481445 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42902278900146484
Time for copying to cuda: 0.008051395416259766
Time for forward pass: 0.05488228797912598
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5051097869873047 seconds
Time for backpropagation: 0.012645721435546875
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5212249755859375 seconds
One training iteration takes: 0.5831859111785889 seconds
Index: 17
Then, training+dataloading take 0.5832316875457764 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44843006134033203
Time for copying to cuda: 0.012450218200683594
Time for forward pass: 0.04727959632873535
Time for backpropagation: 0.0041887760162353516
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5363035202026367 seconds
One training iteration takes: 0.6083159446716309 seconds
Index: 18
Streaming plantleave data took 0.6195387840270996 seconds
Then, training+dataloading take 0.6204736232757568 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.43117713928222656
Time for copying to cuda: 0.008332490921020508
Time for forward pass: 0.04832887649536133
Time for backpropagation: 0.00470423698425293
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5239644050598145 seconds
Streaming plantleave data took 0.5341711044311523 seconds
One training iteration takes: 0.583014965057373 seconds
Index: 19
Then, training+dataloading take 0.5830576419830322 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44515132904052734
Time for copying to cuda: 0.009088993072509766
Time for forward pass: 0.04407477378845215
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5246322154998779 seconds
Time for backpropagation: 0.07413554191589355
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5884685516357422 seconds
One training iteration takes: 0.7012546062469482 seconds
Index: 20
Then, training+dataloading take 0.7014343738555908 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.43630385398864746
Time for copying to cuda: 0.008551359176635742
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.4612863063812256 seconds
Streaming plantleave data took 0.48146653175354004 seconds
Time for forward pass: 0.04387784004211426
Time for backpropagation: 0.0026044845581054688
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5838947296142578 seconds
Index: 21
Then, training+dataloading take 0.5839369297027588 seconds

Epoch: 0
Time of next(dataloader) is: 0.38367128372192383
Time for copying to cuda: 0.0037353038787841797
Time for forward pass: 0.24010896682739258
Time for backpropagation: 0.010541439056396484
GPU memory for training: 1.6732282638549805                          

Memory occpied: (2128.0, 2214.0)
The whole process took 25.72291350364685 seconds
