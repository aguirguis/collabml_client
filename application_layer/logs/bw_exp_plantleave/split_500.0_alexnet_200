Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 443.77739055019157 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 58166790.13419471 58166790.13419471
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7152886390686035 seconds
Streaming plantleave data took 0.7247285842895508 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3144829273223877
Time for copying to cuda: 0.007844686508178711
Memory occpied: (1526.0, 170.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7999825477600098 seconds
Streaming plantleave data took 0.8100571632385254 seconds
Memory occpied: (1526.0, 604.0)
Memory occpied: (1526.0, 1068.0)
Time for forward pass: 3.551576614379883
Time for backpropagation: 0.05704522132873535
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.001682758331299 seconds
Index: 0
Then, training+dataloading take 4.00174880027771 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4342508316040039
Time for copying to cuda: 0.007161378860473633
Time for forward pass: 0.03444552421569824
Time for backpropagation: 0.003027677536010742
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6140413284301758 seconds
Index: 1
Memory occpied: (1978.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.833526611328125 seconds
Streaming plantleave data took 0.843703031539917 seconds
Then, training+dataloading take 0.8440604209899902 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4105563163757324
Time for copying to cuda: 0.007497549057006836
Time for forward pass: 0.03345203399658203
Time for backpropagation: 0.0030677318572998047
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5536372661590576 seconds
Index: 2
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7546446323394775 seconds
Streaming plantleave data took 0.7649097442626953 seconds
Then, training+dataloading take 0.7652676105499268 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.476731538772583
Time for copying to cuda: 0.007237911224365234
Time for forward pass: 0.04146409034729004
Time for backpropagation: 0.0028793811798095703
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.6208202838897705 seconds
Index: 3
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.780022144317627 seconds
Streaming plantleave data took 0.7862813472747803 seconds
Then, training+dataloading take 0.7868874073028564 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36983585357666016
Time for copying to cuda: 0.008050918579101562
Time for forward pass: 0.0455021858215332
Time for backpropagation: 0.003099679946899414
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5234634876251221 seconds
Index: 4
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7729337215423584 seconds
Streaming plantleave data took 0.778878927230835 seconds
Then, training+dataloading take 0.7792220115661621 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4401512145996094
Time for copying to cuda: 0.007088422775268555
Time for forward pass: 0.04361677169799805
Time for backpropagation: 0.0031452178955078125
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6139025688171387 seconds
Index: 5
Memory occpied: (2314.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7929325103759766 seconds
Streaming plantleave data took 0.7990546226501465 seconds
Then, training+dataloading take 0.7993993759155273 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4098782539367676
Time for copying to cuda: 0.0076160430908203125
Time for forward pass: 0.04370284080505371
Time for backpropagation: 0.003023862838745117
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5633916854858398 seconds
Index: 6
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7709121704101562 seconds
Streaming plantleave data took 0.7810275554656982 seconds
Then, training+dataloading take 0.7813668251037598 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42589664459228516
Time for copying to cuda: 0.00732421875
Time for forward pass: 0.04358530044555664
Time for backpropagation: 0.00289154052734375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6019034385681152 seconds
Index: 7
Memory occpied: (2314.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.8232462406158447 seconds
Streaming plantleave data took 0.8332417011260986 seconds
Then, training+dataloading take 0.833592414855957 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37273240089416504
Time for copying to cuda: 0.007510185241699219
Time for forward pass: 0.044290781021118164
Time for backpropagation: 0.0028896331787109375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5003859996795654 seconds
Index: 8
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7367560863494873 seconds
Streaming plantleave data took 0.7430291175842285 seconds
Then, training+dataloading take 0.7438478469848633 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.4881892204284668
Time for copying to cuda: 0.007231235504150391
Time for forward pass: 0.043633460998535156
Time for backpropagation: 0.0029675960540771484
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6481802463531494 seconds
Index: 9
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.8046841621398926 seconds
Streaming plantleave data took 0.8146908283233643 seconds
Then, training+dataloading take 0.8150451183319092 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38283443450927734
Time for copying to cuda: 0.0071544647216796875
Time for forward pass: 0.04381728172302246
Time for backpropagation: 0.0032880306243896484
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5451345443725586 seconds
Index: 10
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7547144889831543 seconds
Streaming plantleave data took 0.76104736328125 seconds
Then, training+dataloading take 0.7616188526153564 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.46016454696655273
Time for copying to cuda: 0.007099151611328125
Time for forward pass: 0.04359602928161621
Time for backpropagation: 0.003025054931640625
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.5926780700683594 seconds
Index: 11
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.762075662612915 seconds
Streaming plantleave data took 0.772261381149292 seconds
Then, training+dataloading take 0.7726192474365234 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4253544807434082
Time for copying to cuda: 0.009398698806762695
Time for forward pass: 0.04478025436401367
Time for backpropagation: 0.0030364990234375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5725579261779785 seconds
Index: 12
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7488582134246826 seconds
Streaming plantleave data took 0.7589821815490723 seconds
Then, training+dataloading take 0.7593114376068115 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.501600980758667
Time for copying to cuda: 0.007781028747558594
Time for forward pass: 0.045198917388916016
Time for backpropagation: 0.0030515193939208984
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.6327345371246338 seconds
Index: 13
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7999670505523682 seconds
Streaming plantleave data took 0.8060903549194336 seconds
Then, training+dataloading take 0.806851863861084 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39887118339538574
Time for copying to cuda: 0.008386850357055664
Time for forward pass: 0.0438380241394043
Time for backpropagation: 0.003136157989501953
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5423705577850342 seconds
Index: 14
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7051312923431396 seconds
Streaming plantleave data took 0.7153744697570801 seconds
Then, training+dataloading take 0.7156982421875 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5350043773651123
Time for copying to cuda: 0.007310628890991211
Time for forward pass: 0.043665170669555664
Time for backpropagation: 0.003051280975341797
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.6813144683837891 seconds
Index: 15
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.886831521987915 seconds
Streaming plantleave data took 0.8930599689483643 seconds
Then, training+dataloading take 0.8936388492584229 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38837742805480957
Time for copying to cuda: 0.00719904899597168
Time for forward pass: 0.043702125549316406
Time for backpropagation: 0.0031239986419677734
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5359869003295898 seconds
Index: 16
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.8736302852630615 seconds
Streaming plantleave data took 0.8839483261108398 seconds
Then, training+dataloading take 0.8844354152679443 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4297358989715576
Time for copying to cuda: 0.007699012756347656
Time for forward pass: 0.04372739791870117
Time for backpropagation: 0.0030074119567871094
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2364.0)
One training iteration takes: 0.5608386993408203 seconds
Index: 17
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.71103835105896 seconds
Streaming plantleave data took 0.7172551155090332 seconds
Then, training+dataloading take 0.717893123626709 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.402315616607666
Time for copying to cuda: 0.007391452789306641
Time for forward pass: 0.04377174377441406
Time for backpropagation: 0.0031201839447021484
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5473973751068115 seconds
Index: 18
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7890160083770752 seconds
Streaming plantleave data took 0.7989637851715088 seconds
Then, training+dataloading take 0.7992823123931885 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.441420316696167
Time for copying to cuda: 0.0070383548736572266
Time for forward pass: 0.04576706886291504
Time for backpropagation: 0.0027620792388916016
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6209485530853271 seconds
Index: 19
Memory occpied: (2314.0, 2364.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7705214023590088 seconds
Streaming plantleave data took 0.7767317295074463 seconds
Then, training+dataloading take 0.7773404121398926 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37769246101379395
Time for copying to cuda: 0.007127046585083008
Time for forward pass: 0.04379439353942871
Time for backpropagation: 0.0031859874725341797
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.51578688621521 seconds
Index: 20
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.7260193824768066 seconds
Streaming plantleave data took 0.7359952926635742 seconds
Then, training+dataloading take 0.7363619804382324 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4174041748046875
Time for copying to cuda: 0.007099628448486328
Time for forward pass: 0.04358339309692383
Time for backpropagation: 0.002778768539428711
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5811643600463867 seconds
Index: 21
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.6002757549285889 seconds
Streaming plantleave data took 0.6073040962219238 seconds
Then, training+dataloading take 0.6077685356140137 seconds

Epoch: 0
Memory occpied: (2314.0, 2364.0)
Time of next(dataloader) is: 0.3597564697265625
Time for copying to cuda: 0.0036966800689697266
Time for forward pass: 0.2192833423614502
Time for backpropagation: 0.007994651794433594
GPU memory for training: 1.6737470626831055                          

The whole process took 28.629677057266235 seconds
