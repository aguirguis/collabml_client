Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 4410.65967683223 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 578113985.161754 578113985.161754
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3477013111114502 seconds
Streaming plantleave data took 0.35739755630493164 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32518577575683594
Time for copying to cuda: 0.025991201400756836
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3526020050048828 seconds
Streaming plantleave data took 0.3633537292480469 seconds
Memory occpied: (1526.0, 326.0)
Memory occpied: (1526.0, 766.0)
Memory occpied: (1526.0, 1192.0)
Time for forward pass: 3.589348793029785
Time for backpropagation: 0.05106472969055176
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.052967071533203 seconds
Index: 0
Then, training+dataloading take 4.05303168296814 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.380462646484375
Time for copying to cuda: 0.05055379867553711
Time for forward pass: 0.03391909599304199
Time for backpropagation: 0.002835988998413086
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5763003826141357 seconds
Index: 1
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6039769649505615 seconds
Streaming plantleave data took 0.6142454147338867 seconds
Then, training+dataloading take 0.6145904064178467 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.46573948860168457 seconds
Time of next(dataloader) is: 0.4654829502105713
Time for copying to cuda: 0.006987571716308594
Streaming plantleave data took 0.4790918827056885 seconds
Time for forward pass: 0.03337740898132324
Time for backpropagation: 0.0024957656860351562
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5921823978424072 seconds
Index: 2
Then, training+dataloading take 0.59222412109375 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4478418827056885
Time for copying to cuda: 0.05088973045349121
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5191173553466797 seconds
Streaming plantleave data took 0.5314822196960449 seconds
Time for forward pass: 0.037610530853271484
Time for backpropagation: 0.002791166305541992
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6333014965057373 seconds
Index: 3
Then, training+dataloading take 0.6334891319274902 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.4112374782562256
Time for copying to cuda: 0.012021780014038086
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.453411340713501 seconds
Streaming plantleave data took 0.4637792110443115 seconds
Time for forward pass: 0.04432559013366699
Time for backpropagation: 0.0026237964630126953
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5647227764129639 seconds
Index: 4
Then, training+dataloading take 0.5647668838500977 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4571561813354492 seconds
Time of next(dataloader) is: 0.45793771743774414
Time for copying to cuda: 0.007040977478027344
Streaming plantleave data took 0.470104455947876 seconds
Time for forward pass: 0.04355335235595703
Time for backpropagation: 0.002454042434692383
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6128301620483398 seconds
Index: 5
Then, training+dataloading take 0.6129705905914307 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5056400299072266 seconds
Time of next(dataloader) is: 0.5063936710357666
Time for copying to cuda: 0.007183551788330078
Streaming plantleave data took 0.5227129459381104 seconds
Time for forward pass: 0.04386329650878906
Time for backpropagation: 0.0026273727416992188
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.660754919052124 seconds
Index: 6
Then, training+dataloading take 0.660797119140625 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4613687992095947 seconds
Time of next(dataloader) is: 0.46214985847473145
Time for copying to cuda: 0.007334470748901367
Streaming plantleave data took 0.47876644134521484 seconds
Time for forward pass: 0.043688297271728516
Time for backpropagation: 0.0025091171264648438
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6092915534973145 seconds
Index: 7
Then, training+dataloading take 0.6093337535858154 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5277876853942871 seconds
Time of next(dataloader) is: 0.5279946327209473
Time for copying to cuda: 0.00704503059387207
Streaming plantleave data took 0.541050910949707 seconds
Time for forward pass: 0.04356503486633301
Time for backpropagation: 0.002519845962524414
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6964874267578125 seconds
Index: 8
Then, training+dataloading take 0.6966111660003662 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.4640023708343506
Time for copying to cuda: 0.008753538131713867
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4866373538970947 seconds
Streaming plantleave data took 0.501960039138794 seconds
Time for forward pass: 0.048273324966430664
Time for backpropagation: 0.002611875534057617
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6253378391265869 seconds
Index: 9
Then, training+dataloading take 0.6253805160522461 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4348764419555664 seconds
Time of next(dataloader) is: 0.4349982738494873
Time for copying to cuda: 0.007409334182739258
Streaming plantleave data took 0.45193028450012207 seconds
Time for forward pass: 0.08013272285461426
Time for backpropagation: 0.0030853748321533203
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6455557346343994 seconds
Index: 10
Then, training+dataloading take 0.6456749439239502 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.4208993911743164
Time for copying to cuda: 0.017004728317260742
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4501795768737793 seconds
Streaming plantleave data took 0.4651002883911133 seconds
Time for forward pass: 0.0446324348449707
Time for backpropagation: 0.002658843994140625
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5695734024047852 seconds
Index: 11
Then, training+dataloading take 0.5696139335632324 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.413588285446167
Time for copying to cuda: 0.010666608810424805
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4655036926269531 seconds
Time for forward pass: 0.04412388801574707
Time for backpropagation: 0.0031137466430664062
GPU memory for training: 1.2220048904418945                          

Streaming plantleave data took 0.4818599224090576 seconds
One training iteration takes: 0.5677731037139893 seconds
Index: 12
Then, training+dataloading take 0.5678129196166992 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.46683335304260254
Time for copying to cuda: 0.009525060653686523
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4893949031829834 seconds
Streaming plantleave data took 0.4996509552001953 seconds
Time for forward pass: 0.043761253356933594
Time for backpropagation: 0.0025649070739746094
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.657188892364502 seconds
Index: 13
Then, training+dataloading take 0.6573283672332764 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.4339945316314697
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4404289722442627 seconds
Time for copying to cuda: 0.01002192497253418
Streaming plantleave data took 0.4551506042480469 seconds
Time for forward pass: 0.044240474700927734
Time for backpropagation: 0.002615213394165039
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5856826305389404 seconds
Index: 14
Then, training+dataloading take 0.5857264995574951 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4249417781829834
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4354391098022461 seconds
Time for copying to cuda: 0.010231494903564453
Streaming plantleave data took 0.4525415897369385 seconds
Time for forward pass: 0.04366254806518555
Time for backpropagation: 0.0026247501373291016
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5708978176116943 seconds
Index: 15
Then, training+dataloading take 0.5710785388946533 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.551133394241333 seconds
Time of next(dataloader) is: 0.5521883964538574
Time for copying to cuda: 0.006985902786254883
Streaming plantleave data took 0.5682220458984375 seconds
Time for forward pass: 0.04374527931213379
Time for backpropagation: 0.0027222633361816406
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.7042739391326904 seconds
Index: 16
Then, training+dataloading take 0.7043168544769287 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44776415824890137
Time for copying to cuda: 0.008994579315185547
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.48372578620910645 seconds
Streaming plantleave data took 0.49404478073120117 seconds
Time for forward pass: 0.04388594627380371
Time for backpropagation: 0.002681255340576172
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5925602912902832 seconds
Index: 17
Then, training+dataloading take 0.5926029682159424 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4837772846221924 seconds
Time of next(dataloader) is: 0.4837667942047119
Time for copying to cuda: 0.007055759429931641
Streaming plantleave data took 0.4969184398651123 seconds
Time for forward pass: 0.043601036071777344
Time for backpropagation: 0.0025665760040283203
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6691858768463135 seconds
Index: 18
Then, training+dataloading take 0.6693177223205566 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Memory occpied: (2380.0, 1862.0)
Time of next(dataloader) is: 0.4255197048187256
Time for copying to cuda: 0.02314138412475586
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4585573673248291 seconds
Streaming plantleave data took 0.475482702255249 seconds
Time for forward pass: 0.04387402534484863
Time for backpropagation: 0.0026938915252685547
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.5990571975708008 seconds
Index: 19
Then, training+dataloading take 0.5990984439849854 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4513585567474365
Time for copying to cuda: 0.015722990036010742
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4676172733306885 seconds
Streaming plantleave data took 0.48467564582824707 seconds
Time for forward pass: 0.04381585121154785
Time for backpropagation: 0.0028519630432128906
GPU memory for training: 1.2220048904418945                          

One training iteration takes: 0.6029410362243652 seconds
Index: 20
Then, training+dataloading take 0.6030662059783936 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.46197962760925293 seconds
Time of next(dataloader) is: 0.4626929759979248
Time for copying to cuda: 0.008974790573120117
Streaming plantleave data took 0.4834566116333008 seconds
Time for forward pass: 0.043668270111083984
Time for backpropagation: 0.002698183059692383
GPU memory for training: 1.2220048904418945                          

Memory occpied: (2380.0, 1862.0)
One training iteration takes: 0.6250905990600586 seconds
Index: 21
Then, training+dataloading take 0.625131368637085 seconds

Epoch: 0
Time of next(dataloader) is: 0.4014101028442383
Time for copying to cuda: 0.0037806034088134766
Time for forward pass: 0.19661808013916016
Time for backpropagation: 0.003335714340209961
GPU memory for training: 1.673959732055664                          

The whole process took 24.81293773651123 seconds
