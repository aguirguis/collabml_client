Namespace(batch_size=500, cpuonly=False, dataset='inaturalist', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='vit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Start 0, end 500, post_step 250

Memory occpied: (1654.0, 3.0)
Decompress data took 0.029297351837158203 seconds
Total decompress data took 0.7849347591400146 seconds
Decompress data took 0.02748417854309082 seconds
Memory occpied: (1654.0, 3.0)
Total decompress data took 0.6702296733856201 seconds
Read 80.46689224243164 MBs for this batch
Streaming inaturalist data took 2.118337392807007 seconds
The mode is:  vanilla
Start 500, end 1000, post_step 250


Epoch: 0
Time of next(dataloader) is: 0.46077728271484375
Memory occpied: (1654.0, 3.0)
Time for copying to cuda: 0.08247566223144531
Decompress data took 0.05899405479431152 seconds
Memory occpied: (1942.0, 564.0)
Total decompress data took 0.7975876331329346 seconds
Decompress data took 0.028397798538208008 seconds
Total decompress data took 0.6602354049682617 seconds
Read 79.7220230102539 MBs for this batch
Streaming inaturalist data took 2.6478230953216553 seconds
Memory occpied: (1942.0, 1034.0)
Memory occpied: (5764.0, 2060.0)
Memory occpied: (14686.0, 9678.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 433, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 421, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 239, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/layers/mlp.py", line 27, in forward
    x = self.act(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/activation.py", line 670, in forward
    return F.gelu(input)
RuntimeError: CUDA out of memory. Tried to allocate 578.00 MiB (GPU 0; 14.76 GiB total capacity; 12.69 GiB already allocated; 291.75 MiB free; 13.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 14.25935435295105 seconds
