Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4643743803026 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119074242.47877502 119074242.47877502
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9737498760223389 seconds
Streaming imagenet data took 2.001274824142456 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3517038822174072
Time for copying to cuda: 0.01882314682006836
Memory occpied: (1586.0, 36.0)
Memory occpied: (1586.0, 574.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9828100204467773 seconds
Streaming imagenet data took 2.010153293609619 seconds
Memory occpied: (1586.0, 1036.0)
Time for forward pass: 3.187021017074585
Time for backpropagation: 0.049466609954833984
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.682774305343628 seconds
Index: 0
Then, training+dataloading take 3.6830356121063232 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38849806785583496
Time for copying to cuda: 0.018411874771118164
Time for forward pass: 0.06792306900024414
Time for backpropagation: 0.003662109375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5977065563201904 seconds
Index: 1
Memory occpied: (2100.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1457505226135254 seconds
Streaming imagenet data took 2.172569990158081 seconds
Then, training+dataloading take 2.177170753479004 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38324761390686035
Time for copying to cuda: 0.018455982208251953
Time for forward pass: 0.07540774345397949
Time for backpropagation: 0.0026144981384277344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5647494792938232 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.92557954788208 seconds
Streaming imagenet data took 1.992720603942871 seconds
Then, training+dataloading take 2.00032901763916 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40600061416625977
Time for copying to cuda: 0.018338441848754883
Time for forward pass: 0.07539224624633789
Time for backpropagation: 0.0025577545166015625
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5947492122650146 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.92262601852417 seconds
Streaming imagenet data took 1.9505136013031006 seconds
Then, training+dataloading take 1.956047773361206 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3768484592437744
Time for copying to cuda: 0.018406391143798828
Time for forward pass: 0.07071089744567871
Time for backpropagation: 0.0026671886444091797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5702359676361084 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9011683464050293 seconds
Streaming imagenet data took 1.928293228149414 seconds
Then, training+dataloading take 1.9329931735992432 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.44035887718200684
Time for copying to cuda: 0.018526315689086914
Time for forward pass: 0.0755319595336914
Time for backpropagation: 0.002725839614868164
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6299793720245361 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.957716941833496 seconds
Streaming imagenet data took 1.9847478866577148 seconds
Then, training+dataloading take 1.988976001739502 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36584973335266113
Time for copying to cuda: 0.01843738555908203
Time for forward pass: 0.07563400268554688
Time for backpropagation: 0.002783536911010742
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5524365901947021 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9282736778259277 seconds
Streaming imagenet data took 1.9563612937927246 seconds
Then, training+dataloading take 1.9641928672790527 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.4114649295806885
Time for copying to cuda: 0.018354177474975586
Time for forward pass: 0.07557821273803711
Time for backpropagation: 0.0028734207153320312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6016848087310791 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9209442138671875 seconds
Streaming imagenet data took 1.9483847618103027 seconds
Then, training+dataloading take 1.9527981281280518 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.373089075088501
Time for copying to cuda: 0.018565654754638672
Time for forward pass: 0.0702216625213623
Time for backpropagation: 0.0026178359985351562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5777571201324463 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.972102165222168 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9999301433563232 seconds
Then, training+dataloading take 2.0044116973876953 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.374035120010376
Time for copying to cuda: 0.01849842071533203
Time for forward pass: 0.07541275024414062
Time for backpropagation: 0.0027811527252197266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5629780292510986 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9057800769805908 seconds
Streaming imagenet data took 1.933150053024292 seconds
Then, training+dataloading take 1.9376626014709473 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4109511375427246
Time for copying to cuda: 0.018526315689086914
Time for forward pass: 0.07540464401245117
Time for backpropagation: 0.002597332000732422
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6285133361816406 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.910649061203003 seconds
Streaming imagenet data took 1.9377851486206055 seconds
Then, training+dataloading take 1.9429264068603516 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36444783210754395
Time for copying to cuda: 0.01828932762145996
Time for forward pass: 0.07534337043762207
Time for backpropagation: 0.0026178359985351562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5564799308776855 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8493542671203613 seconds
Streaming imagenet data took 1.8763487339019775 seconds
Then, training+dataloading take 1.8808317184448242 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3742086887359619
Time for copying to cuda: 0.01877450942993164
Time for forward pass: 0.07655048370361328
Time for backpropagation: 0.0033020973205566406
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5583956241607666 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.95017409324646 seconds
Streaming imagenet data took 1.9776027202606201 seconds
Then, training+dataloading take 1.9820947647094727 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36612582206726074
Time for copying to cuda: 0.018692731857299805
Time for forward pass: 0.07562565803527832
Time for backpropagation: 0.0029425621032714844
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5523693561553955 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8279502391815186 seconds
Streaming imagenet data took 1.855722188949585 seconds
Then, training+dataloading take 1.8602232933044434 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4072732925415039
Time for copying to cuda: 0.018578529357910156
Time for forward pass: 0.06881499290466309
Time for backpropagation: 0.002566814422607422
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6203374862670898 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.960707664489746 seconds
Streaming imagenet data took 1.9880926609039307 seconds
Then, training+dataloading take 1.9932503700256348 seconds

Epoch: 0
Time of next(dataloader) is: 0.3654968738555908
Time for copying to cuda: 0.018455028533935547
Time for forward pass: 0.07564210891723633
Time for backpropagation: 0.002796173095703125
GPU memory for training: 1.2580008506774902                          

The whole process took 40.56950044631958 seconds
