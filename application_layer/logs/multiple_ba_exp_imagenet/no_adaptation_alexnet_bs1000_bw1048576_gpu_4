Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3094301522502 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119053933.62891574 119053933.62891574
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7665116786956787 seconds
Streaming imagenet data took 1.7803316116333008 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.29648542404174805
Time for copying to cuda: 0.010113000869750977
Memory occpied: (1550.0, 214.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6938514709472656 seconds
Streaming imagenet data took 1.7429885864257812 seconds
Memory occpied: (1550.0, 668.0)
Memory occpied: (1550.0, 1078.0)
Time for forward pass: 3.2619872093200684
Time for backpropagation: 0.049152374267578125
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.688511610031128 seconds
Index: 0
Then, training+dataloading take 3.6887154579162598 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.334453821182251
Time for copying to cuda: 0.009444713592529297
Time for forward pass: 0.09300804138183594
Time for backpropagation: 0.005021810531616211
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.5373759269714355 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8200607299804688 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.8340134620666504 seconds
Then, training+dataloading take 1.8363313674926758 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3473927974700928
Time for copying to cuda: 0.009292364120483398
Time for forward pass: 0.049362897872924805
Time for backpropagation: 0.00281524658203125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4937245845794678 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.646111249923706 seconds
Streaming imagenet data took 1.6601016521453857 seconds
Then, training+dataloading take 1.6625304222106934 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3300516605377197
Time for copying to cuda: 0.009398460388183594
Time for forward pass: 0.04935717582702637
Time for backpropagation: 0.002641439437866211
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4707920551300049 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6408638954162598 seconds
Streaming imagenet data took 1.6545910835266113 seconds
Then, training+dataloading take 1.6570367813110352 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4159266948699951
Time for copying to cuda: 0.0093994140625
Time for forward pass: 0.04928016662597656
Time for backpropagation: 0.0026903152465820312
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5619330406188965 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7108492851257324 seconds
Streaming imagenet data took 1.7247965335845947 seconds
Then, training+dataloading take 1.7272400856018066 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3293783664703369
Time for copying to cuda: 0.009424924850463867
Time for forward pass: 0.04936814308166504
Time for backpropagation: 0.002747058868408203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4704170227050781 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6360256671905518 seconds
Streaming imagenet data took 1.650001049041748 seconds
Then, training+dataloading take 1.6524441242218018 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33406519889831543
Time for copying to cuda: 0.009396553039550781
Time for forward pass: 0.049407958984375
Time for backpropagation: 0.002721071243286133
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48289060592651367 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6974782943725586 seconds
Streaming imagenet data took 1.7126493453979492 seconds
Then, training+dataloading take 1.7142534255981445 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38997554779052734
Time for copying to cuda: 0.009446144104003906
Time for forward pass: 0.0493011474609375
Time for backpropagation: 0.0026369094848632812
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5357606410980225 seconds
Index: 7
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.717853307723999 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7321557998657227 seconds
Then, training+dataloading take 1.7345831394195557 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.332977294921875
Time for copying to cuda: 0.00943303108215332
Time for forward pass: 0.04929375648498535
Time for backpropagation: 0.0026047229766845703
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48169445991516113 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6334805488586426 seconds
Streaming imagenet data took 1.6476469039916992 seconds
Then, training+dataloading take 1.6501574516296387 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33205270767211914
Time for copying to cuda: 0.009351015090942383
Time for forward pass: 0.04926633834838867
Time for backpropagation: 0.0026519298553466797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.478008508682251 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6272172927856445 seconds
Streaming imagenet data took 1.6411385536193848 seconds
Then, training+dataloading take 1.643622875213623 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41390132904052734
Time for copying to cuda: 0.00944375991821289
Time for forward pass: 0.0493159294128418
Time for backpropagation: 0.002652406692504883
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5612201690673828 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.682478666305542 seconds
Streaming imagenet data took 1.6961984634399414 seconds
Then, training+dataloading take 1.6986544132232666 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33963727951049805
Time for copying to cuda: 0.009344339370727539
Time for forward pass: 0.04923534393310547
Time for backpropagation: 0.0025887489318847656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4856407642364502 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6800765991210938 seconds
Streaming imagenet data took 1.6939895153045654 seconds
Then, training+dataloading take 1.6965157985687256 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32912182807922363
Time for copying to cuda: 0.009410619735717773
Time for forward pass: 0.049276113510131836
Time for backpropagation: 0.0026078224182128906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47855353355407715 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7253389358520508 seconds
Streaming imagenet data took 1.7792401313781738 seconds
Then, training+dataloading take 1.7836017608642578 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.34487485885620117
Time for copying to cuda: 0.009490966796875
Time for forward pass: 0.04932594299316406
Time for backpropagation: 0.0027163028717041016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48302268981933594 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6564793586730957 seconds
Streaming imagenet data took 1.6701958179473877 seconds
Then, training+dataloading take 1.6727635860443115 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3328063488006592
Time for copying to cuda: 0.009414196014404297
Time for forward pass: 0.049288272857666016
Time for backpropagation: 0.0026078224182128906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4879920482635498 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.63505220413208 seconds
Streaming imagenet data took 1.648970603942871 seconds
Then, training+dataloading take 1.6515333652496338 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3992640972137451
Time for copying to cuda: 0.009362459182739258
Time for forward pass: 0.04944491386413574
Time for backpropagation: 0.002676248550415039
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5621058940887451 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6408889293670654 seconds
Streaming imagenet data took 1.692551612854004 seconds
Then, training+dataloading take 1.6969194412231445 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3948502540588379
Time for copying to cuda: 0.00933218002319336
Time for forward pass: 0.049338340759277344
Time for backpropagation: 0.002743959426879883
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5324299335479736 seconds
Index: 16
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7138104438781738 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7278437614440918 seconds
Then, training+dataloading take 1.7304494380950928 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34702396392822266
Time for copying to cuda: 0.009399890899658203
Time for forward pass: 0.04933619499206543
Time for backpropagation: 0.0026443004608154297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49407172203063965 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.648050308227539 seconds
Streaming imagenet data took 1.66194748878479 seconds
Then, training+dataloading take 1.6644854545593262 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33187031745910645
Time for copying to cuda: 0.00937962532043457
Time for forward pass: 0.04925727844238281
Time for backpropagation: 0.0025169849395751953
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48679518699645996 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6391079425811768 seconds
Streaming imagenet data took 1.6531012058258057 seconds
Then, training+dataloading take 1.6555957794189453 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3743746280670166
Time for copying to cuda: 0.009410619735717773
Time for forward pass: 0.049191951751708984
Time for backpropagation: 0.002614736557006836
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5334532260894775 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6833481788635254 seconds
Streaming imagenet data took 1.6974022388458252 seconds
Then, training+dataloading take 1.6998636722564697 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.374345064163208
Time for copying to cuda: 0.009594440460205078
Time for forward pass: 0.04938101768493652
Time for backpropagation: 0.002704143524169922
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5193386077880859 seconds
Index: 20
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7023849487304688 seconds
Streaming imagenet data took 1.716296672821045 seconds
Then, training+dataloading take 1.7185938358306885 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33376312255859375
Time for copying to cuda: 0.009498119354248047
Time for forward pass: 0.0492551326751709
Time for backpropagation: 0.002633333206176758
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48415637016296387 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6279935836791992 seconds
Streaming imagenet data took 1.6419768333435059 seconds
Then, training+dataloading take 1.644437313079834 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3363344669342041
Time for copying to cuda: 0.009481430053710938
Time for forward pass: 0.0493466854095459
Time for backpropagation: 0.002653360366821289
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4790511131286621 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.646866798400879 seconds
Streaming imagenet data took 1.6609787940979004 seconds
Then, training+dataloading take 1.6634769439697266 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3825109004974365
Time for copying to cuda: 0.009490013122558594
Time for forward pass: 0.04928278923034668
Time for backpropagation: 0.0027909278869628906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5551080703735352 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7016170024871826 seconds
Streaming imagenet data took 1.715956687927246 seconds
Then, training+dataloading take 1.7183074951171875 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3714561462402344
Time for copying to cuda: 0.00934743881225586
Time for forward pass: 0.04930520057678223
Time for backpropagation: 0.0026209354400634766
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5070738792419434 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7332944869995117 seconds
Streaming imagenet data took 1.747197151184082 seconds
Then, training+dataloading take 1.7497460842132568 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3370473384857178
Time for copying to cuda: 0.009420156478881836
Time for forward pass: 0.04944205284118652
Time for backpropagation: 0.002718210220336914
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4851338863372803 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6244158744812012 seconds
Streaming imagenet data took 1.6381518840789795 seconds
Then, training+dataloading take 1.6406700611114502 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3349001407623291
Time for copying to cuda: 0.009345769882202148
Time for forward pass: 0.04924964904785156
Time for backpropagation: 0.0026493072509765625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4630441665649414 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6295931339263916 seconds
Streaming imagenet data took 1.6434221267700195 seconds
Then, training+dataloading take 1.645960807800293 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36731863021850586
Time for copying to cuda: 0.009493589401245117
Time for forward pass: 0.04927945137023926
Time for backpropagation: 0.002811431884765625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5131585597991943 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7049572467803955 seconds
Streaming imagenet data took 1.7194063663482666 seconds
Then, training+dataloading take 1.7217488288879395 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3715946674346924
Time for copying to cuda: 0.009362936019897461
Time for forward pass: 0.049320220947265625
Time for backpropagation: 0.002597808837890625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5239036083221436 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6818180084228516 seconds
Streaming imagenet data took 1.695695161819458 seconds
Then, training+dataloading take 1.6981878280639648 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3286099433898926
Time for copying to cuda: 0.009557485580444336
Time for forward pass: 0.049288034439086914
Time for backpropagation: 0.002641916275024414
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4758110046386719 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6285619735717773 seconds
Streaming imagenet data took 1.6423497200012207 seconds
Then, training+dataloading take 1.644873857498169 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3412911891937256
Time for copying to cuda: 0.009626626968383789
Time for forward pass: 0.04958152770996094
Time for backpropagation: 0.03958702087402344
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5272946357727051 seconds
Index: 30
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7046642303466797 seconds
Streaming imagenet data took 1.720405101776123 seconds
Then, training+dataloading take 1.7236113548278809 seconds

Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3463151454925537
Time for copying to cuda: 0.009300470352172852
Time for forward pass: 0.04931783676147461
Time for backpropagation: 0.0026161670684814453
GPU memory for training: 1.1639018058776855                          

The whole process took 63.69355869293213 seconds
