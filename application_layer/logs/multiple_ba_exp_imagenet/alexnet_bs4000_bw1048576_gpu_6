Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=4000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.8251482419016 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118990457.83036253 118990457.83036253
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Candidate split  16
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 4000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.2500617504119873 seconds
Streaming imagenet data took 2.275360584259033 seconds
The mode is:  split
Start 4000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36104536056518555
Time for copying to cuda: 0.016963958740234375
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.103766679763794 seconds
Streaming imagenet data took 2.1289734840393066 seconds
Time for forward pass: 2.992950439453125
Time for backpropagation: 0.05185294151306152
GPU memory for training: 1.089247226715088                          

One training iteration takes: 3.51229190826416 seconds
Index: 0
Then, training+dataloading take 3.512510299682617 seconds
The mode is:  split
Start 8000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1756.0)
Time of next(dataloader) is: 0.35232114791870117
Time for copying to cuda: 0.01659536361694336
Time for forward pass: 0.056165218353271484
Time for backpropagation: 0.002752542495727539
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5073821544647217 seconds
Index: 1
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.1859443187713623 seconds
Streaming imagenet data took 2.2110114097595215 seconds
Then, training+dataloading take 2.2127065658569336 seconds
The mode is:  split
Start 12000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40963029861450195
Time for copying to cuda: 0.016429424285888672
Time for forward pass: 0.055939435958862305
Time for backpropagation: 0.0025947093963623047
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.596388578414917 seconds
Index: 2
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0704457759857178 seconds
Streaming imagenet data took 2.0950565338134766 seconds
Then, training+dataloading take 2.0967655181884766 seconds
The mode is:  split
Start 16000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3668181896209717
Time for copying to cuda: 0.016527175903320312
Time for forward pass: 0.05607795715332031
Time for backpropagation: 0.0026984214782714844
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5248265266418457 seconds
Index: 3
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.2032854557037354 seconds
Streaming imagenet data took 2.228325366973877 seconds
Then, training+dataloading take 2.230713367462158 seconds
The mode is:  split
Start 20000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38036108016967773
Time for copying to cuda: 0.016527652740478516
Time for forward pass: 0.05599856376647949
Time for backpropagation: 0.002783060073852539
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5363266468048096 seconds
Index: 4
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.062404155731201 seconds
Streaming imagenet data took 2.0878124237060547 seconds
Then, training+dataloading take 2.0895328521728516 seconds
The mode is:  split
Start 24000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41363048553466797
Time for copying to cuda: 0.016605854034423828
Time for forward pass: 0.0560908317565918
Time for backpropagation: 0.0027191638946533203
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.6105124950408936 seconds
Index: 5
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0820136070251465 seconds
Streaming imagenet data took 2.1073718070983887 seconds
Then, training+dataloading take 2.1090922355651855 seconds
The mode is:  split
Start 28000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37166881561279297
Time for copying to cuda: 0.016568422317504883
Time for forward pass: 0.05606794357299805
Time for backpropagation: 0.0027265548706054688
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.527388334274292 seconds
Index: 6
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.214087963104248 seconds
Streaming imagenet data took 2.239150285720825 seconds
Then, training+dataloading take 2.2415287494659424 seconds

Epoch: 0
Time of next(dataloader) is: 0.36629176139831543
Time for copying to cuda: 0.016427993774414062
Time for forward pass: 0.056111812591552734
Time for backpropagation: 0.0027456283569335938
GPU memory for training: 1.2448029518127441                          

The whole process took 26.17506980895996 seconds
