Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.0951604601657 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119025848.87183484 119025848.87183484
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.065553665161133 seconds
Streaming imagenet data took 2.0926976203918457 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.350954532623291
Time for copying to cuda: 0.019058704376220703
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9217782020568848 seconds
Streaming imagenet data took 1.9491848945617676 seconds
Time for forward pass: 2.9934146404266357
Time for backpropagation: 0.04891538619995117
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.5236778259277344 seconds
Index: 0
Then, training+dataloading take 3.5239200592041016 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.35195064544677734
Time for copying to cuda: 0.01863837242126465
Time for forward pass: 0.07546877861022949
Time for backpropagation: 0.003525257110595703
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5470340251922607 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.024034261703491 seconds
Streaming imagenet data took 2.051205635070801 seconds
Then, training+dataloading take 2.056140899658203 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40456533432006836
Time for copying to cuda: 0.01861286163330078
Time for forward pass: 0.07562565803527832
Time for backpropagation: 0.0028057098388671875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6006839275360107 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9819931983947754 seconds
Streaming imagenet data took 2.0100808143615723 seconds
Then, training+dataloading take 2.0145835876464844 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35642075538635254
Time for copying to cuda: 0.01856207847595215
Time for forward pass: 0.0754251480102539
Time for backpropagation: 0.0029172897338867188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.54083251953125 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8660404682159424 seconds
Streaming imagenet data took 1.8938417434692383 seconds
Then, training+dataloading take 1.8983852863311768 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4193568229675293
Time for copying to cuda: 0.01876091957092285
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07560515403747559
Time for backpropagation: 0.002741575241088867
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6053256988525391 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9441719055175781 seconds
Streaming imagenet data took 1.9710874557495117 seconds
Then, training+dataloading take 1.975501537322998 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3565554618835449
Time for copying to cuda: 0.018464326858520508
Time for forward pass: 0.07544398307800293
Time for backpropagation: 0.002896547317504883
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5456271171569824 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8508152961730957 seconds
Streaming imagenet data took 1.8784816265106201 seconds
Then, training+dataloading take 1.8826839923858643 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4009227752685547
Time for copying to cuda: 0.01823735237121582
Time for forward pass: 0.0753936767578125
Time for backpropagation: 0.002686738967895508
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.596428394317627 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.94677734375 seconds
Streaming imagenet data took 1.9736216068267822 seconds
Then, training+dataloading take 1.9778614044189453 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36391425132751465
Time for copying to cuda: 0.01834416389465332
Time for forward pass: 0.07542061805725098
Time for backpropagation: 0.0026030540466308594
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5485789775848389 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8623771667480469 seconds
Streaming imagenet data took 1.8899450302124023 seconds
Then, training+dataloading take 1.8941287994384766 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39375972747802734
Time for copying to cuda: 0.018370389938354492
Time for forward pass: 0.07551765441894531
Time for backpropagation: 0.002651691436767578
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5916099548339844 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.955967664718628 seconds
Streaming imagenet data took 1.9829096794128418 seconds
Then, training+dataloading take 1.9872913360595703 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3597724437713623
Time for copying to cuda: 0.0188291072845459
Time for forward pass: 0.07541060447692871
Time for backpropagation: 0.002676725387573242
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.54410719871521 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8848717212677002 seconds
Streaming imagenet data took 1.9119305610656738 seconds
Then, training+dataloading take 1.916250228881836 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41535258293151855
Time for copying to cuda: 0.01872992515563965
Time for forward pass: 0.07537126541137695
Time for backpropagation: 0.002624988555908203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6321117877960205 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9774501323699951 seconds
Streaming imagenet data took 2.0052907466888428 seconds
Then, training+dataloading take 2.0104618072509766 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36226606369018555
Time for copying to cuda: 0.018527746200561523
Time for forward pass: 0.07545995712280273
Time for backpropagation: 0.002692699432373047
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.544219970703125 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8575334548950195 seconds
Streaming imagenet data took 1.884871482849121 seconds
Then, training+dataloading take 1.8892490863800049 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4116241931915283
Time for copying to cuda: 0.018476009368896484
Time for forward pass: 0.07556867599487305
Time for backpropagation: 0.0026824474334716797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.631638765335083 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9299943447113037 seconds
Streaming imagenet data took 1.9570820331573486 seconds
Then, training+dataloading take 1.9621555805206299 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3554553985595703
Time for copying to cuda: 0.018524646759033203
Time for forward pass: 0.07066226005554199
Time for backpropagation: 0.002589702606201172
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5292494297027588 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8732411861419678 seconds
Streaming imagenet data took 1.9011685848236084 seconds
Then, training+dataloading take 1.9056031703948975 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4115307331085205
Time for copying to cuda: 0.018691062927246094
Time for forward pass: 0.07543563842773438
Time for backpropagation: 0.0025968551635742188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6101274490356445 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9284870624542236 seconds
Streaming imagenet data took 1.956327199935913 seconds
Then, training+dataloading take 1.9614014625549316 seconds

Epoch: 0
Time of next(dataloader) is: 0.35741758346557617
Time for copying to cuda: 0.018296480178833008
Time for forward pass: 0.07540082931518555
Time for backpropagation: 0.002760648727416992
GPU memory for training: 1.2580008506774902                          

The whole process took 40.31064558029175 seconds
