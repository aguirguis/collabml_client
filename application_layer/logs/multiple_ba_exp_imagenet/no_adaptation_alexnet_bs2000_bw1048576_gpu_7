Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.263585437954 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119047924.67052351 119047924.67052351
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.222315788269043 seconds
Streaming imagenet data took 2.249467134475708 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3876321315765381
Time for copying to cuda: 0.019098281860351562
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.126237154006958 seconds
Streaming imagenet data took 2.1541829109191895 seconds
Time for forward pass: 3.050633192062378
Time for backpropagation: 0.04904437065124512
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.6149532794952393 seconds
Index: 0
Then, training+dataloading take 3.6151294708251953 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3537466526031494
Time for copying to cuda: 0.018828153610229492
Time for forward pass: 0.07543396949768066
Time for backpropagation: 0.0038394927978515625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5353696346282959 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1981191635131836 seconds
Streaming imagenet data took 2.224973440170288 seconds
Then, training+dataloading take 2.2311933040618896 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3965296745300293
Time for copying to cuda: 0.018390655517578125
Time for forward pass: 0.0753791332244873
Time for backpropagation: 0.00262451171875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5966496467590332 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1867992877960205 seconds
Streaming imagenet data took 2.214125871658325 seconds
Then, training+dataloading take 2.2186264991760254 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3580939769744873
Time for copying to cuda: 0.018338680267333984
Time for forward pass: 0.07532405853271484
Time for backpropagation: 0.0025904178619384766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5384728908538818 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1342613697052 seconds
Streaming imagenet data took 2.161982536315918 seconds
Then, training+dataloading take 2.1668550968170166 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3615257740020752
Time for copying to cuda: 0.01828455924987793
Time for forward pass: 0.07550811767578125
Time for backpropagation: 0.003035306930541992
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5455045700073242 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0534040927886963 seconds
Streaming imagenet data took 2.080695152282715 seconds
Then, training+dataloading take 2.08520770072937 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4007680416107178
Time for copying to cuda: 0.018572568893432617
Time for forward pass: 0.07536768913269043
Time for backpropagation: 0.0026068687438964844
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6067357063293457 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1284098625183105 seconds
Streaming imagenet data took 2.1562089920043945 seconds
Then, training+dataloading take 2.1604080200195312 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3627171516418457
Time for copying to cuda: 0.018439054489135742
Time for forward pass: 0.07538294792175293
Time for backpropagation: 0.0026013851165771484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.547921895980835 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.139030933380127 seconds
Streaming imagenet data took 2.1664464473724365 seconds
Then, training+dataloading take 2.1716253757476807 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36454248428344727
Time for copying to cuda: 0.018789291381835938
Time for forward pass: 0.07536649703979492
Time for backpropagation: 0.0026214122772216797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5402071475982666 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1099674701690674 seconds
Streaming imagenet data took 2.137383222579956 seconds
Then, training+dataloading take 2.141634941101074 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4053051471710205
Time for copying to cuda: 0.01841282844543457
Time for forward pass: 0.07556509971618652
Time for backpropagation: 0.0028336048126220703
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6040501594543457 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1722283363342285 seconds
Streaming imagenet data took 2.1999847888946533 seconds
Then, training+dataloading take 2.2042641639709473 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3627326488494873
Time for copying to cuda: 0.018648624420166016
Time for forward pass: 0.07565784454345703
Time for backpropagation: 0.003129243850708008
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.549107551574707 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.165518283843994 seconds
Streaming imagenet data took 2.1937050819396973 seconds
Then, training+dataloading take 2.1979212760925293 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37250661849975586
Time for copying to cuda: 0.01834583282470703
Time for forward pass: 0.07553553581237793
Time for backpropagation: 0.002856731414794922
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5569562911987305 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.111816644668579 seconds
Streaming imagenet data took 2.1783664226531982 seconds
Then, training+dataloading take 2.1864185333251953 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.4039738178253174
Time for copying to cuda: 0.018364429473876953
Time for forward pass: 0.07531428337097168
Time for backpropagation: 0.0026941299438476562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5941963195800781 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.148345470428467 seconds
Streaming imagenet data took 2.17641282081604 seconds
Then, training+dataloading take 2.18080997467041 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4003434181213379
Time for copying to cuda: 0.018362760543823242
Time for forward pass: 0.07535815238952637
Time for backpropagation: 0.002707958221435547
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6005051136016846 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1965906620025635 seconds
Streaming imagenet data took 2.2239603996276855 seconds
Then, training+dataloading take 2.2283592224121094 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37503838539123535
Time for copying to cuda: 0.018433809280395508
Time for forward pass: 0.07548260688781738
Time for backpropagation: 0.002986431121826172
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.56490159034729 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2276251316070557 seconds
Streaming imagenet data took 2.2551472187042236 seconds
Then, training+dataloading take 2.259457588195801 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3606717586517334
Time for copying to cuda: 0.01824498176574707
Time for forward pass: 0.07531905174255371
Time for backpropagation: 0.0029349327087402344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5284285545349121 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.181209087371826 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.208345651626587 seconds
Then, training+dataloading take 2.2118375301361084 seconds

Epoch: 0
Time of next(dataloader) is: 0.36125993728637695
Time for copying to cuda: 0.018290996551513672
Time for forward pass: 0.0753474235534668
Time for backpropagation: 0.00272369384765625
GPU memory for training: 1.2580008506774902                          

The whole process took 43.99060845375061 seconds
