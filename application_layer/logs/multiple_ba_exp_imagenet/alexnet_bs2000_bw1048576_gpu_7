Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3227562152523 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119055680.30264555 119055680.30264555
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.050485134124756 seconds
Streaming imagenet data took 2.0776989459991455 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.379835844039917
Time for copying to cuda: 0.018809080123901367
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9705133438110352 seconds
Streaming imagenet data took 1.9981365203857422 seconds
Time for forward pass: 2.9760305881500244
Time for backpropagation: 0.049205780029296875
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.526381015777588 seconds
Index: 0
Then, training+dataloading take 3.526615619659424 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3485605716705322
Time for copying to cuda: 0.018439769744873047
Time for forward pass: 0.0755760669708252
Time for backpropagation: 0.003626585006713867
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5307974815368652 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0029091835021973 seconds
Streaming imagenet data took 2.030705213546753 seconds
Then, training+dataloading take 2.037067174911499 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42326855659484863
Time for copying to cuda: 0.018395423889160156
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07565641403198242
Time for backpropagation: 0.0027306079864501953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6109044551849365 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9825055599212646 seconds
Streaming imagenet data took 2.009481430053711 seconds
Then, training+dataloading take 2.0139400959014893 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3628270626068115
Time for copying to cuda: 0.01828289031982422
Time for forward pass: 0.07543706893920898
Time for backpropagation: 0.002817869186401367
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5500316619873047 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9561834335327148 seconds
Streaming imagenet data took 1.9837963581085205 seconds
Then, training+dataloading take 1.9888238906860352 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41358327865600586
Time for copying to cuda: 0.01845264434814453
Time for forward pass: 0.07552170753479004
Time for backpropagation: 0.0026710033416748047
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5978457927703857 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9732708930969238 seconds
Streaming imagenet data took 2.0009567737579346 seconds
Then, training+dataloading take 2.0057144165039062 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.365079402923584
Time for copying to cuda: 0.01840066909790039
Time for forward pass: 0.07533812522888184
Time for backpropagation: 0.002638101577758789
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5599329471588135 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8626470565795898 seconds
Streaming imagenet data took 1.889986515045166 seconds
Then, training+dataloading take 1.894620656967163 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.44260334968566895
Time for copying to cuda: 0.018512725830078125
Time for forward pass: 0.07551360130310059
Time for backpropagation: 0.002696514129638672
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6275129318237305 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.951103925704956 seconds
Streaming imagenet data took 1.9787330627441406 seconds
Then, training+dataloading take 1.982940435409546 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3607289791107178
Time for copying to cuda: 0.01839280128479004
Time for forward pass: 0.07542300224304199
Time for backpropagation: 0.002660512924194336
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5479726791381836 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8545584678649902 seconds
Streaming imagenet data took 1.9208168983459473 seconds
Then, training+dataloading take 1.928654432296753 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4212648868560791
Time for copying to cuda: 0.018557310104370117
Time for forward pass: 0.07537555694580078
Time for backpropagation: 0.0027265548706054688
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6052887439727783 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.922722339630127 seconds
Streaming imagenet data took 1.95060133934021 seconds
Then, training+dataloading take 1.9551301002502441 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36112165451049805
Time for copying to cuda: 0.018726825714111328
Time for forward pass: 0.07190799713134766
Time for backpropagation: 0.002711772918701172
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5465500354766846 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8810069561004639 seconds
Streaming imagenet data took 1.9080336093902588 seconds
Then, training+dataloading take 1.9123635292053223 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40338945388793945
Time for copying to cuda: 0.018648386001586914
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.0757441520690918
Time for backpropagation: 0.002900838851928711
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5823800563812256 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9590389728546143 seconds
Streaming imagenet data took 1.9864532947540283 seconds
Then, training+dataloading take 1.9906325340270996 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3634929656982422
Time for copying to cuda: 0.018330097198486328
Time for forward pass: 0.07543730735778809
Time for backpropagation: 0.0030405521392822266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5552539825439453 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8970110416412354 seconds
Streaming imagenet data took 1.964214563369751 seconds
Then, training+dataloading take 1.9719033241271973 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.401644229888916
Time for copying to cuda: 0.0184478759765625
Time for forward pass: 0.07552242279052734
Time for backpropagation: 0.002990245819091797
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.574774980545044 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.930656909942627 seconds
Streaming imagenet data took 1.9578049182891846 seconds
Then, training+dataloading take 1.9631261825561523 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3637666702270508
Time for copying to cuda: 0.01828455924987793
Time for forward pass: 0.0753636360168457
Time for backpropagation: 0.0027070045471191406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.560612678527832 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.857605218887329 seconds
Streaming imagenet data took 1.884917974472046 seconds
Then, training+dataloading take 1.8878147602081299 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40113401412963867
Time for copying to cuda: 0.018372535705566406
Time for forward pass: 0.07532525062561035
Time for backpropagation: 0.002730131149291992
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5985629558563232 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.971573829650879 seconds
Streaming imagenet data took 1.9986586570739746 seconds
Then, training+dataloading take 2.003082036972046 seconds

Epoch: 0
Time of next(dataloader) is: 0.3600120544433594
Time for copying to cuda: 0.01841259002685547
Time for forward pass: 0.0754079818725586
Time for backpropagation: 0.0027468204498291016
GPU memory for training: 1.2580008506774902                          

The whole process took 40.451494455337524 seconds
