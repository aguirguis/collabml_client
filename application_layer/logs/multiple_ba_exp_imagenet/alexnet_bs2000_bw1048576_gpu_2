Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.3669642649785 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118930402.74013926 118930402.74013926
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.066462516784668 seconds
Streaming imagenet data took 2.0939860343933105 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35364294052124023
Time for copying to cuda: 0.01874542236328125
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9440174102783203 seconds
Streaming imagenet data took 1.9713609218597412 seconds
Time for forward pass: 3.000990629196167
Time for backpropagation: 0.04941582679748535
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.520845651626587 seconds
Index: 0
Then, training+dataloading take 3.5210328102111816 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3451673984527588
Time for copying to cuda: 0.018546104431152344
Time for forward pass: 0.07552123069763184
Time for backpropagation: 0.0037763118743896484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5300498008728027 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0173895359039307 seconds
Streaming imagenet data took 2.0444204807281494 seconds
Then, training+dataloading take 2.0473318099975586 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3995997905731201
Time for copying to cuda: 0.018411636352539062
Time for forward pass: 0.07561683654785156
Time for backpropagation: 0.0028176307678222656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6169118881225586 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9369640350341797 seconds
Streaming imagenet data took 1.9639675617218018 seconds
Then, training+dataloading take 1.968463659286499 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3729126453399658
Time for copying to cuda: 0.018544435501098633
Time for forward pass: 0.07535743713378906
Time for backpropagation: 0.0026836395263671875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5621926784515381 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8868513107299805 seconds
Streaming imagenet data took 1.9146370887756348 seconds
Then, training+dataloading take 1.9188761711120605 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40445876121520996
Time for copying to cuda: 0.01852107048034668
Time for forward pass: 0.07549428939819336
Time for backpropagation: 0.002836465835571289
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6049470901489258 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9336822032928467 seconds
Streaming imagenet data took 1.961116075515747 seconds
Then, training+dataloading take 1.9662268161773682 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37061500549316406
Time for copying to cuda: 0.018549203872680664
Time for forward pass: 0.07556819915771484
Time for backpropagation: 0.0027234554290771484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5530312061309814 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.866607427597046 seconds
Streaming imagenet data took 1.894704818725586 seconds
Then, training+dataloading take 1.8988583087921143 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42946434020996094
Time for copying to cuda: 0.01888275146484375
Time for forward pass: 0.07543635368347168
Time for backpropagation: 0.0027773380279541016
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6444923877716064 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9122915267944336 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.940272331237793 seconds
Then, training+dataloading take 1.9452488422393799 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3788290023803711
Time for copying to cuda: 0.01856207847595215
Time for forward pass: 0.07537364959716797
Time for backpropagation: 0.002626657485961914
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5710775852203369 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8837146759033203 seconds
Streaming imagenet data took 1.9112722873687744 seconds
Then, training+dataloading take 1.9154930114746094 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4405171871185303
Time for copying to cuda: 0.018714427947998047
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07565140724182129
Time for backpropagation: 0.002816438674926758
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.619330644607544 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9260451793670654 seconds
Streaming imagenet data took 1.9538073539733887 seconds
Then, training+dataloading take 1.957974910736084 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36507725715637207
Time for copying to cuda: 0.018424510955810547
Time for forward pass: 0.0703122615814209
Time for backpropagation: 0.002778291702270508
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5538961887359619 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8707904815673828 seconds
Streaming imagenet data took 1.8985202312469482 seconds
Then, training+dataloading take 1.902702808380127 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40152907371520996
Time for copying to cuda: 0.018410921096801758
Time for forward pass: 0.07546114921569824
Time for backpropagation: 0.002818584442138672
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6129770278930664 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9471237659454346 seconds
Streaming imagenet data took 1.9741103649139404 seconds
Then, training+dataloading take 1.9791080951690674 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3609631061553955
Time for copying to cuda: 0.018689870834350586
Time for forward pass: 0.07528328895568848
Time for backpropagation: 0.0027463436126708984
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.550929069519043 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8460543155670166 seconds
Streaming imagenet data took 1.874183177947998 seconds
Then, training+dataloading take 1.878382682800293 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4182295799255371
Time for copying to cuda: 0.018603801727294922
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07562661170959473
Time for backpropagation: 0.003064393997192383
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6077897548675537 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.989593744277954 seconds
Streaming imagenet data took 2.0169332027435303 seconds
Then, training+dataloading take 2.0213332176208496 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3647141456604004
Time for copying to cuda: 0.018296003341674805
Time for forward pass: 0.07541275024414062
Time for backpropagation: 0.0027687549591064453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5529053211212158 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8750104904174805 seconds
Streaming imagenet data took 1.9025824069976807 seconds
Then, training+dataloading take 1.9068098068237305 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.46047472953796387
Time for copying to cuda: 0.01812148094177246
Time for forward pass: 0.07541322708129883
Time for backpropagation: 0.0026891231536865234
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6437678337097168 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.930558204650879 seconds
Streaming imagenet data took 1.9579992294311523 seconds
Then, training+dataloading take 1.9623935222625732 seconds

Epoch: 0
Time of next(dataloader) is: 0.38616085052490234
Time for copying to cuda: 0.01828765869140625
Time for forward pass: 0.07435250282287598
Time for backpropagation: 0.0028629302978515625
GPU memory for training: 1.2580008506774902                          

The whole process took 39.97754502296448 seconds
