Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=7000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4926406498366 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119077947.39525539 119077947.39525539
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 1271.23779296875 1570.33544921875 15520.74951171875
Candidate split  16
Server, client, server+client, vanilla  299.09765625 1271.23779296875 1570.33544921875 15520.74951171875
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 7000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 109.61774253845215 MBs for this batch
Executing all posts took 50.47364568710327 seconds
Streaming imagenet data took 50.5166699886322 seconds
The mode is:  split
Start 7000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36074376106262207
Time for copying to cuda: 0.06018471717834473
Memory occpied: (1624.0, 18.0)
Memory occpied: (1624.0, 578.0)
Memory occpied: (1624.0, 1016.0)
Time for forward pass: 3.3238131999969482
Time for backpropagation: 0.06828832626342773
GPU memory for training: 1.2197346687316895                          

One training iteration takes: 3.900830030441284 seconds
Index: 0
Memory occpied: (2334.0, 1822.0)
Memory occpied: (2334.0, 1822.0)
Memory occpied: (2334.0, 1822.0)
Read 109.61774253845215 MBs for this batch
Executing all posts took 6.986259460449219 seconds
Streaming imagenet data took 7.029868841171265 seconds
Then, training+dataloading take 7.032597303390503 seconds
The mode is:  split
Start 14000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40676450729370117
Time for copying to cuda: 0.028595924377441406
Time for forward pass: 0.09730958938598633
Time for backpropagation: 0.0033054351806640625
GPU memory for training: 1.3751225471496582                          

One training iteration takes: 0.6259169578552246 seconds
Index: 1
Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
Read 109.61774253845215 MBs for this batch
Executing all posts took 3.8056695461273193 seconds
Streaming imagenet data took 3.8498687744140625 seconds
Then, training+dataloading take 3.8526816368103027 seconds
The mode is:  split
Start 21000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4568967819213867
Time for copying to cuda: 0.02863621711730957
Time for forward pass: 0.08231210708618164
Time for backpropagation: 0.0027015209197998047
GPU memory for training: 1.3751225471496582                          

Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
Read 109.61774253845215 MBs for this batch
Executing all posts took 3.907438278198242 seconds
Streaming imagenet data took 3.9510419368743896 seconds
Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
One training iteration takes: 5.6085569858551025 seconds
Index: 2
Then, training+dataloading take 5.61013650894165 seconds
The mode is:  split
Start 28000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39446520805358887
Time for copying to cuda: 0.02918386459350586
Time for forward pass: 0.08222126960754395
Time for backpropagation: 0.0026159286499023438
GPU memory for training: 1.3751225471496582                          

One training iteration takes: 0.6022429466247559 seconds
Index: 3
Memory occpied: (2496.0, 1830.0)
Memory occpied: (2496.0, 1830.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.6775896549224854 seconds
Streaming imagenet data took 2.7021241188049316 seconds
Then, training+dataloading take 2.7040083408355713 seconds

Epoch: 0
Time of next(dataloader) is: 0.37360620498657227
Time for copying to cuda: 0.016695022583007812
Time for forward pass: 0.05603504180908203
Time for backpropagation: 0.0026311874389648438
GPU memory for training: 1.243452548980713                          

The whole process took 76.79856991767883 seconds
