Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5345660300026 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119083442.6386845 119083442.6386845
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0209968090057373 seconds
Streaming imagenet data took 2.0480477809906006 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3348679542541504
Time for copying to cuda: 0.018982410430908203
Memory occpied: (1586.0, 22.0)
Memory occpied: (1586.0, 606.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9784696102142334 seconds
Streaming imagenet data took 2.006514549255371 seconds
Memory occpied: (1586.0, 1020.0)
Time for forward pass: 3.198296308517456
Time for backpropagation: 0.04871654510498047
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.67238450050354 seconds
Index: 0
Then, training+dataloading take 3.6726300716400146 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4180481433868408
Time for copying to cuda: 0.0185546875
Memory occpied: (2100.0, 1632.0)
Time for forward pass: 0.0731208324432373
Time for backpropagation: 0.0035390853881835938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.581756591796875 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.097055435180664 seconds
Streaming imagenet data took 2.1248860359191895 seconds
Then, training+dataloading take 2.1312332153320312 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36607789993286133
Time for copying to cuda: 0.018469572067260742
Time for forward pass: 0.07551145553588867
Time for backpropagation: 0.002739429473876953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5826311111450195 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9611797332763672 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9886269569396973 seconds
Then, training+dataloading take 1.993863582611084 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36760449409484863
Time for copying to cuda: 0.01839613914489746
Time for forward pass: 0.07538557052612305
Time for backpropagation: 0.00272369384765625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5617678165435791 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8839683532714844 seconds
Streaming imagenet data took 1.9108622074127197 seconds
Then, training+dataloading take 1.9153244495391846 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4061858654022217
Time for copying to cuda: 0.018467187881469727
Time for forward pass: 0.07533788681030273
Time for backpropagation: 0.002680540084838867
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6228682994842529 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.961057424545288 seconds
Streaming imagenet data took 1.9883522987365723 seconds
Then, training+dataloading take 1.9935712814331055 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3713841438293457
Time for copying to cuda: 0.018332719802856445
Time for forward pass: 0.07544946670532227
Time for backpropagation: 0.0027093887329101562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5586960315704346 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8922996520996094 seconds
Streaming imagenet data took 1.9199879169464111 seconds
Then, training+dataloading take 1.9242236614227295 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40879368782043457
Time for copying to cuda: 0.018162250518798828
Time for forward pass: 0.07563161849975586
Time for backpropagation: 0.0027923583984375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6092467308044434 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9835402965545654 seconds
Streaming imagenet data took 2.0108659267425537 seconds
Then, training+dataloading take 2.0160598754882812 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37069272994995117
Time for copying to cuda: 0.018392324447631836
Time for forward pass: 0.0755913257598877
Time for backpropagation: 0.002755880355834961
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5715463161468506 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8993003368377686 seconds
Streaming imagenet data took 1.9261844158172607 seconds
Then, training+dataloading take 1.9304699897766113 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41071200370788574
Time for copying to cuda: 0.01841878890991211
Time for forward pass: 0.07543230056762695
Time for backpropagation: 0.002772092819213867
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6251926422119141 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9406535625457764 seconds
Streaming imagenet data took 1.9680256843566895 seconds
Then, training+dataloading take 1.9732277393341064 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36688709259033203
Time for copying to cuda: 0.018201589584350586
Time for forward pass: 0.07422828674316406
Time for backpropagation: 0.0027070045471191406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5503125190734863 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8993170261383057 seconds
Streaming imagenet data took 1.9262135028839111 seconds
Then, training+dataloading take 1.930464267730713 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42603325843811035
Time for copying to cuda: 0.01856851577758789
Time for forward pass: 0.07557868957519531
Time for backpropagation: 0.0027856826782226562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6386215686798096 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.923949956893921 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9523200988769531 seconds
Then, training+dataloading take 1.9575440883636475 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3722705841064453
Time for copying to cuda: 0.018324851989746094
Time for forward pass: 0.07543158531188965
Time for backpropagation: 0.002771615982055664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5594367980957031 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8993618488311768 seconds
Streaming imagenet data took 1.926391363143921 seconds
Then, training+dataloading take 1.9307503700256348 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42321062088012695
Time for copying to cuda: 0.018433570861816406
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07575392723083496
Time for backpropagation: 0.002950429916381836
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6050360202789307 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.967698097229004 seconds
Streaming imagenet data took 1.9945991039276123 seconds
Then, training+dataloading take 1.9990403652191162 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3658270835876465
Time for copying to cuda: 0.018358230590820312
Time for forward pass: 0.07542872428894043
Time for backpropagation: 0.002897024154663086
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5436065196990967 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.869974136352539 seconds
Streaming imagenet data took 1.9373843669891357 seconds
Then, training+dataloading take 1.9451982975006104 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40871238708496094
Time for copying to cuda: 0.018399953842163086
Time for forward pass: 0.07546830177307129
Time for backpropagation: 0.002707958221435547
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5919132232666016 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9276940822601318 seconds
Streaming imagenet data took 1.9549448490142822 seconds
Then, training+dataloading take 1.9604129791259766 seconds

Epoch: 0
Time of next(dataloader) is: 0.37091803550720215
Time for copying to cuda: 0.018541574478149414
Time for forward pass: 0.0754246711730957
Time for backpropagation: 0.0027265548706054688
GPU memory for training: 1.2580008506774902                          

The whole process took 40.63572287559509 seconds
