Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.4325425026897 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118938998.21091254 118938998.21091254
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7328951358795166 seconds
Streaming imagenet data took 1.7467246055603027 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.30301356315612793
Time for copying to cuda: 0.0100860595703125
Memory occpied: (1550.0, 226.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7368052005767822 seconds
Streaming imagenet data took 1.7962327003479004 seconds
Memory occpied: (1550.0, 654.0)
Memory occpied: (1550.0, 1122.0)
Time for forward pass: 3.2211694717407227
Time for backpropagation: 0.0494236946105957
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.6510772705078125 seconds
Index: 0
Then, training+dataloading take 3.6512644290924072 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3206164836883545
Time for copying to cuda: 0.009433984756469727
Time for forward pass: 0.04974174499511719
Time for backpropagation: 0.003308534622192383
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.4718780517578125 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7663865089416504 seconds
Streaming imagenet data took 1.8178322315216064 seconds
Then, training+dataloading take 1.8220665454864502 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3311164379119873
Time for copying to cuda: 0.009260177612304688
Time for forward pass: 0.04919314384460449
Time for backpropagation: 0.002577543258666992
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4727957248687744 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.635556936264038 seconds
Streaming imagenet data took 1.6493589878082275 seconds
Then, training+dataloading take 1.6519513130187988 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33222436904907227
Time for copying to cuda: 0.009427547454833984
Time for forward pass: 0.04920077323913574
Time for backpropagation: 0.002816915512084961
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4782261848449707 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6707983016967773 seconds
Streaming imagenet data took 1.684617280960083 seconds
Then, training+dataloading take 1.6869449615478516 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37186717987060547
Time for copying to cuda: 0.009441852569580078
Time for forward pass: 0.0492861270904541
Time for backpropagation: 0.0025320053100585938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5434732437133789 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6999752521514893 seconds
Streaming imagenet data took 1.751537561416626 seconds
Then, training+dataloading take 1.7558953762054443 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33553171157836914
Time for copying to cuda: 0.009484529495239258
Time for forward pass: 0.049371957778930664
Time for backpropagation: 0.0027151107788085938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47812891006469727 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6519811153411865 seconds
Streaming imagenet data took 1.665924072265625 seconds
Then, training+dataloading take 1.6683475971221924 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33266115188598633
Time for copying to cuda: 0.00925445556640625
Time for forward pass: 0.04929828643798828
Time for backpropagation: 0.0026302337646484375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4758470058441162 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6548621654510498 seconds
Streaming imagenet data took 1.6686875820159912 seconds
Then, training+dataloading take 1.670992374420166 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37423014640808105
Time for copying to cuda: 0.009274959564208984
Time for forward pass: 0.04913640022277832
Time for backpropagation: 0.002566099166870117
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5339727401733398 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6795768737792969 seconds
Streaming imagenet data took 1.693735122680664 seconds
Then, training+dataloading take 1.6960115432739258 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3767280578613281
Time for copying to cuda: 0.009499788284301758
Time for forward pass: 0.049393653869628906
Time for backpropagation: 0.002695322036743164
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5185086727142334 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7546558380126953 seconds
Streaming imagenet data took 1.7687063217163086 seconds
Then, training+dataloading take 1.7711150646209717 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3302013874053955
Time for copying to cuda: 0.009501934051513672
Time for forward pass: 0.04927992820739746
Time for backpropagation: 0.002721548080444336
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47269296646118164 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6918704509735107 seconds
Streaming imagenet data took 1.7056477069854736 seconds
Then, training+dataloading take 1.7081212997436523 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3325796127319336
Time for copying to cuda: 0.009427309036254883
Time for forward pass: 0.04928922653198242
Time for backpropagation: 0.0027992725372314453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4753546714782715 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6454949378967285 seconds
Streaming imagenet data took 1.697599172592163 seconds
Then, training+dataloading take 1.7018330097198486 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3751082420349121
Time for copying to cuda: 0.009440183639526367
Time for forward pass: 0.04922842979431152
Time for backpropagation: 0.0025212764739990234
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5237908363342285 seconds
Index: 11
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7051994800567627 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7193968296051025 seconds
Then, training+dataloading take 1.7218382358551025 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33811426162719727
Time for copying to cuda: 0.009598493576049805
Time for forward pass: 0.04927563667297363
Time for backpropagation: 0.0026361942291259766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48682379722595215 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6550848484039307 seconds
Streaming imagenet data took 1.6689064502716064 seconds
Then, training+dataloading take 1.6714346408843994 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33325695991516113
Time for copying to cuda: 0.009402036666870117
Time for forward pass: 0.049393415451049805
Time for backpropagation: 0.0027277469635009766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4812438488006592 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.639533519744873 seconds
Streaming imagenet data took 1.6537721157073975 seconds
Then, training+dataloading take 1.6563377380371094 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3715813159942627
Time for copying to cuda: 0.009442806243896484
Time for forward pass: 0.04918241500854492
Time for backpropagation: 0.0025932788848876953
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5534727573394775 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6291007995605469 seconds
Streaming imagenet data took 1.6812832355499268 seconds
Then, training+dataloading take 1.6855316162109375 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.374636173248291
Time for copying to cuda: 0.009424924850463867
Time for forward pass: 0.049254655838012695
Time for backpropagation: 0.0025377273559570312
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.530493974685669 seconds
Index: 15
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7163927555084229 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7303905487060547 seconds
Then, training+dataloading take 1.7329449653625488 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3316376209259033
Time for copying to cuda: 0.009518623352050781
Time for forward pass: 0.04919624328613281
Time for backpropagation: 0.002524852752685547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4838902950286865 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6615042686462402 seconds
Streaming imagenet data took 1.6754789352416992 seconds
Then, training+dataloading take 1.6780893802642822 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3326759338378906
Time for copying to cuda: 0.009486913681030273
Time for forward pass: 0.049425363540649414
Time for backpropagation: 0.002673625946044922
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47881197929382324 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6655240058898926 seconds
Streaming imagenet data took 1.6792545318603516 seconds
Then, training+dataloading take 1.6817781925201416 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37268638610839844
Time for copying to cuda: 0.00958561897277832
Time for forward pass: 0.04920792579650879
Time for backpropagation: 0.0026314258575439453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5308313369750977 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6642751693725586 seconds
Streaming imagenet data took 1.6784658432006836 seconds
Then, training+dataloading take 1.680208444595337 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37070679664611816
Time for copying to cuda: 0.009415149688720703
Time for forward pass: 0.049419403076171875
Time for backpropagation: 0.0026597976684570312
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5213882923126221 seconds
Index: 19
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7116813659667969 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7253427505493164 seconds
Then, training+dataloading take 1.7278671264648438 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3468508720397949
Time for copying to cuda: 0.009567499160766602
Time for forward pass: 0.049202680587768555
Time for backpropagation: 0.002574443817138672
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4868009090423584 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6542942523956299 seconds
Streaming imagenet data took 1.6682374477386475 seconds
Then, training+dataloading take 1.6708784103393555 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3460097312927246
Time for copying to cuda: 0.00939631462097168
Time for forward pass: 0.049216270446777344
Time for backpropagation: 0.0025987625122070312
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4944887161254883 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6872828006744385 seconds
Streaming imagenet data took 1.7011585235595703 seconds
Then, training+dataloading take 1.7038326263427734 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3728456497192383
Time for copying to cuda: 0.009514093399047852
Time for forward pass: 0.04925704002380371
Time for backpropagation: 0.002592802047729492
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5402822494506836 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6706209182739258 seconds
Streaming imagenet data took 1.6848652362823486 seconds
Then, training+dataloading take 1.6864917278289795 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38288378715515137
Time for copying to cuda: 0.009513616561889648
Time for forward pass: 0.04922771453857422
Time for backpropagation: 0.0025954246520996094
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5294222831726074 seconds
Index: 23
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6950271129608154 seconds
Streaming imagenet data took 1.7108056545257568 seconds
Then, training+dataloading take 1.7133655548095703 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3291001319885254
Time for copying to cuda: 0.009632349014282227
Time for forward pass: 0.049318552017211914
Time for backpropagation: 0.002655029296875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47266364097595215 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6494030952453613 seconds
Streaming imagenet data took 1.663118600845337 seconds
Then, training+dataloading take 1.6654751300811768 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3343830108642578
Time for copying to cuda: 0.009495735168457031
Time for forward pass: 0.049208879470825195
Time for backpropagation: 0.0027480125427246094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.477799654006958 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6459801197052002 seconds
Streaming imagenet data took 1.6600120067596436 seconds
Then, training+dataloading take 1.6624751091003418 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3752615451812744
Time for copying to cuda: 0.009346485137939453
Time for forward pass: 0.04918408393859863
Time for backpropagation: 0.002786397933959961
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5379600524902344 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6893479824066162 seconds
Streaming imagenet data took 1.7032737731933594 seconds
Then, training+dataloading take 1.7056331634521484 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.40908265113830566
Time for copying to cuda: 0.00940084457397461
Time for forward pass: 0.04936408996582031
Time for backpropagation: 0.002657651901245117
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.553931713104248 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6745071411132812 seconds
Streaming imagenet data took 1.688387393951416 seconds
Then, training+dataloading take 1.6908814907073975 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3496887683868408
Time for copying to cuda: 0.00947117805480957
Time for forward pass: 0.04940485954284668
Time for backpropagation: 0.0026993751525878906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49898481369018555 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6605253219604492 seconds
Streaming imagenet data took 1.6747667789459229 seconds
Then, training+dataloading take 1.677196979522705 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40737366676330566
Time for copying to cuda: 0.00945281982421875
Time for forward pass: 0.0495913028717041
Memory occpied: (2290.0, 1578.0)
Time for backpropagation: 0.0027801990509033203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5516154766082764 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.702265977859497 seconds
Streaming imagenet data took 1.7161500453948975 seconds
Then, training+dataloading take 1.7185215950012207 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33606576919555664
Time for copying to cuda: 0.009291887283325195
Time for forward pass: 0.049198150634765625
Time for backpropagation: 0.0025331974029541016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4808998107910156 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6270740032196045 seconds
Streaming imagenet data took 1.641258716583252 seconds
Then, training+dataloading take 1.6437203884124756 seconds

Epoch: 0
Time of next(dataloader) is: 0.3356456756591797
Time for copying to cuda: 0.009449005126953125
Time for forward pass: 0.04927873611450195
Time for backpropagation: 0.0027036666870117188
GPU memory for training: 1.1639018058776855                          

The whole process took 63.2611939907074 seconds
