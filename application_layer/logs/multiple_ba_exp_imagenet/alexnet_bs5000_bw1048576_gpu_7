Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=5000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.250358177547 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118915118.94704744 118915118.94704744
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 974.72900390625 1273.82666015625 11152.95166015625
Candidate split  16
Server, client, server+client, vanilla  299.09765625 974.72900390625 1273.82666015625 11152.95166015625
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 5000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 2.6150593757629395 seconds
Streaming imagenet data took 2.646202564239502 seconds
The mode is:  split
Start 5000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36321353912353516
Time for copying to cuda: 0.020778894424438477
Memory occpied: (1594.0, 290.0)
Memory occpied: (1594.0, 742.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 2.594602584838867 seconds
Streaming imagenet data took 2.6260437965393066 seconds
Memory occpied: (1594.0, 1190.0)
Time for forward pass: 3.31532621383667
Time for backpropagation: 0.05476856231689453
GPU memory for training: 1.1339058876037598                          

One training iteration takes: 3.849748373031616 seconds
Index: 0
Then, training+dataloading take 3.8500561714172363 seconds
The mode is:  split
Start 10000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3750429153442383
Time for copying to cuda: 0.02079606056213379
Time for forward pass: 0.06061148643493652
Time for backpropagation: 0.003567218780517578
GPU memory for training: 1.2909655570983887                          

One training iteration takes: 0.5793972015380859 seconds
Index: 1
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 3.6687252521514893 seconds
Streaming imagenet data took 3.699908971786499 seconds
Then, training+dataloading take 3.70238995552063 seconds
The mode is:  split
Start 15000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3912208080291748
Time for copying to cuda: 0.02062511444091797
Time for forward pass: 0.07825851440429688
Time for backpropagation: 0.0032052993774414062
GPU memory for training: 1.2909655570983887                          

One training iteration takes: 0.599785566329956 seconds
Index: 2
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 2.499384880065918 seconds
Streaming imagenet data took 2.5310778617858887 seconds
Then, training+dataloading take 2.533066749572754 seconds
The mode is:  split
Start 20000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39113473892211914
Time for copying to cuda: 0.020618677139282227
Time for forward pass: 0.07327461242675781
Time for backpropagation: 0.0035583972930908203
GPU memory for training: 1.2909655570983887                          

Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 3.5479164123535156 seconds
Streaming imagenet data took 3.579403877258301 seconds
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
One training iteration takes: 5.5113911628723145 seconds
Index: 3
Then, training+dataloading take 5.5119733810424805 seconds
The mode is:  split
Start 25000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39035534858703613
Time for copying to cuda: 0.020573139190673828
Time for forward pass: 0.06341242790222168
Time for backpropagation: 0.00264739990234375
GPU memory for training: 1.2909655570983887                          

One training iteration takes: 0.5580885410308838 seconds
Index: 4
Memory occpied: (2494.0, 1788.0)
Memory occpied: (2494.0, 1788.0)
Read 78.29838752746582 MBs for this batch
Executing all posts took 2.60447359085083 seconds
Streaming imagenet data took 2.635392904281616 seconds
Then, training+dataloading take 2.6373729705810547 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4147789478302002
Time for copying to cuda: 0.020125150680541992
Time for forward pass: 0.06340265274047852
Time for backpropagation: 0.002679586410522461
GPU memory for training: 1.2909655570983887                          

One training iteration takes: 0.580657958984375 seconds
Index: 5
Memory occpied: (2494.0, 1788.0)
Read 31.319355010986328 MBs for this batch
Executing all posts took 1.7253954410552979 seconds
Streaming imagenet data took 1.739758014678955 seconds
Then, training+dataloading take 1.740854263305664 seconds

Epoch: 0
Time of next(dataloader) is: 0.4497494697570801
Time for copying to cuda: 0.008267879486083984
Time for forward pass: 0.03516411781311035
Time for backpropagation: 0.0026197433471679688
GPU memory for training: 1.1563701629638672                          

Memory occpied: (2494.0, 1788.0)
The whole process took 30.63227915763855 seconds
