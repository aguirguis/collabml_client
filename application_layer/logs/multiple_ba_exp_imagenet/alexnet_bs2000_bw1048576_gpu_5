Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.1858309439907 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118906661.23349075 118906661.23349075
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0313098430633545 seconds
Streaming imagenet data took 2.05851411819458 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36430954933166504
Time for copying to cuda: 0.01900029182434082
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9017348289489746 seconds
Streaming imagenet data took 1.9291965961456299 seconds
Time for forward pass: 2.985603094100952
Time for backpropagation: 0.049512624740600586
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.529208183288574 seconds
Index: 0
Then, training+dataloading take 3.5294113159179688 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3470890522003174
Time for copying to cuda: 0.018424034118652344
Time for forward pass: 0.07546472549438477
Time for backpropagation: 0.0036122798919677734
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5280280113220215 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9793851375579834 seconds
Streaming imagenet data took 2.0068631172180176 seconds
Then, training+dataloading take 2.0098650455474854 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3688693046569824
Time for copying to cuda: 0.018387317657470703
Time for forward pass: 0.08185243606567383
Time for backpropagation: 0.0034792423248291016
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5609097480773926 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.918050765991211 seconds
Streaming imagenet data took 1.9454214572906494 seconds
Then, training+dataloading take 1.9503910541534424 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36136317253112793
Time for copying to cuda: 0.0182192325592041
Time for forward pass: 0.07546758651733398
Time for backpropagation: 0.002663850784301758
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5411570072174072 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8747119903564453 seconds
Streaming imagenet data took 1.9022767543792725 seconds
Then, training+dataloading take 1.9064393043518066 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.45781946182250977
Time for copying to cuda: 0.018241167068481445
Time for forward pass: 0.07560181617736816
Time for backpropagation: 0.002718687057495117
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6260519027709961 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9232001304626465 seconds
Streaming imagenet data took 1.950190544128418 seconds
Then, training+dataloading take 1.954406976699829 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3746531009674072
Time for copying to cuda: 0.01825714111328125
Time for forward pass: 0.07537317276000977
Time for backpropagation: 0.002732992172241211
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5615479946136475 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.87030029296875 seconds
Streaming imagenet data took 1.9390935897827148 seconds
Then, training+dataloading take 1.9466948509216309 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40238213539123535
Time for copying to cuda: 0.018284320831298828
Time for forward pass: 0.07559084892272949
Time for backpropagation: 0.002736330032348633
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5921993255615234 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9107897281646729 seconds
Streaming imagenet data took 1.9380736351013184 seconds
Then, training+dataloading take 1.9426178932189941 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3650634288787842
Time for copying to cuda: 0.018362998962402344
Time for forward pass: 0.07531857490539551
Time for backpropagation: 0.002832651138305664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5612626075744629 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8671939373016357 seconds
Streaming imagenet data took 1.894716501235962 seconds
Then, training+dataloading take 1.9001593589782715 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4137699604034424
Time for copying to cuda: 0.01844477653503418
Time for forward pass: 0.07541298866271973
Time for backpropagation: 0.002618074417114258
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6252632141113281 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9614298343658447 seconds
Streaming imagenet data took 1.9890942573547363 seconds
Then, training+dataloading take 1.9940524101257324 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37989330291748047
Time for copying to cuda: 0.018299102783203125
Time for forward pass: 0.07555413246154785
Time for backpropagation: 0.0026874542236328125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5488302707672119 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.894946813583374 seconds
Streaming imagenet data took 1.9220354557037354 seconds
Then, training+dataloading take 1.9264633655548096 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4035308361053467
Time for copying to cuda: 0.0184633731842041
Time for forward pass: 0.07548713684082031
Time for backpropagation: 0.0028061866760253906
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6164577007293701 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9544944763183594 seconds
Streaming imagenet data took 1.981954574584961 seconds
Then, training+dataloading take 1.9869177341461182 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3612227439880371
Time for copying to cuda: 0.01831650733947754
Time for forward pass: 0.07538270950317383
Time for backpropagation: 0.0026721954345703125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5429379940032959 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8916270732879639 seconds
Streaming imagenet data took 1.9184763431549072 seconds
Then, training+dataloading take 1.922776460647583 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4154071807861328
Time for copying to cuda: 0.018227100372314453
Time for forward pass: 0.07549190521240234
Time for backpropagation: 0.0027260780334472656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.627793550491333 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9474449157714844 seconds
Streaming imagenet data took 1.9746856689453125 seconds
Then, training+dataloading take 1.978956699371338 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3636023998260498
Time for copying to cuda: 0.018519163131713867
Time for forward pass: 0.07557559013366699
Time for backpropagation: 0.0027043819427490234
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5628318786621094 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9029757976531982 seconds
Streaming imagenet data took 1.9306576251983643 seconds
Then, training+dataloading take 1.935067892074585 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4016144275665283
Time for copying to cuda: 0.018431901931762695
Time for forward pass: 0.07541561126708984
Time for backpropagation: 0.0027256011962890625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6036052703857422 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8968055248260498 seconds
Streaming imagenet data took 1.9237794876098633 seconds
Then, training+dataloading take 1.9272949695587158 seconds

Epoch: 0
Time of next(dataloader) is: 0.3833122253417969
Time for copying to cuda: 0.018400192260742188
Time for forward pass: 0.0692136287689209
Time for backpropagation: 0.0027015209197998047
GPU memory for training: 1.2580008506774902                          

The whole process took 40.27451944351196 seconds
