Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.539182725981 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118952975.75825979 118952975.75825979
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.639113426208496 seconds
Streaming imagenet data took 1.6530532836914062 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.29426074028015137
Time for copying to cuda: 0.010141134262084961
Memory occpied: (1550.0, 278.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5821616649627686 seconds
Streaming imagenet data took 1.5963540077209473 seconds
Memory occpied: (1550.0, 698.0)
Memory occpied: (1550.0, 1156.0)
Time for forward pass: 3.228299379348755
Time for backpropagation: 0.04903578758239746
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.6548871994018555 seconds
Index: 0
Then, training+dataloading take 3.655080795288086 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32291197776794434
Time for copying to cuda: 0.009549140930175781
Time for forward pass: 0.04976081848144531
Time for backpropagation: 0.0034923553466796875
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.46847081184387207 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5795557498931885 seconds
Streaming imagenet data took 1.5937271118164062 seconds
Then, training+dataloading take 1.5959525108337402 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3796830177307129
Time for copying to cuda: 0.009348392486572266
Time for forward pass: 0.04929828643798828
Time for backpropagation: 0.0025751590728759766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5392448902130127 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4972822666168213 seconds
Streaming imagenet data took 1.511350393295288 seconds
Then, training+dataloading take 1.5136971473693848 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3715851306915283
Time for copying to cuda: 0.009448528289794922
Time for forward pass: 0.049233198165893555
Time for backpropagation: 0.0026235580444335938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.556887149810791 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4835498332977295 seconds
Streaming imagenet data took 1.4973716735839844 seconds
Then, training+dataloading take 1.4996747970581055 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3714425563812256
Time for copying to cuda: 0.009373664855957031
Time for forward pass: 0.04925370216369629
Time for backpropagation: 0.002563953399658203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5511884689331055 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.498178482055664 seconds
Streaming imagenet data took 1.512117862701416 seconds
Then, training+dataloading take 1.5144038200378418 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3964884281158447
Time for copying to cuda: 0.009344100952148438
Time for forward pass: 0.049211978912353516
Time for backpropagation: 0.002554655075073242
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5580708980560303 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4920613765716553 seconds
Streaming imagenet data took 1.5058138370513916 seconds
Then, training+dataloading take 1.5081233978271484 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3708498477935791
Time for copying to cuda: 0.00946950912475586
Time for forward pass: 0.04928779602050781
Time for backpropagation: 0.0026171207427978516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.549189567565918 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.527707815170288 seconds
Streaming imagenet data took 1.5415935516357422 seconds
Then, training+dataloading take 1.5438978672027588 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4231867790222168
Time for copying to cuda: 0.009464263916015625
Time for forward pass: 0.049222707748413086
Time for backpropagation: 0.002597808837890625
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5588564872741699 seconds
Index: 7
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4807896614074707 seconds
Streaming imagenet data took 1.4943859577178955 seconds
Then, training+dataloading take 1.496755599975586 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3808572292327881
Time for copying to cuda: 0.009387969970703125
Time for forward pass: 0.04923105239868164
Time for backpropagation: 0.0025849342346191406
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5618627071380615 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5343971252441406 seconds
Streaming imagenet data took 1.548191785812378 seconds
Then, training+dataloading take 1.5504987239837646 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38619112968444824
Time for copying to cuda: 0.009375572204589844
Time for forward pass: 0.04915118217468262
Time for backpropagation: 0.002595186233520508
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5528173446655273 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4533660411834717 seconds
Streaming imagenet data took 1.467268466949463 seconds
Then, training+dataloading take 1.4695892333984375 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37237024307250977
Time for copying to cuda: 0.009311676025390625
Time for forward pass: 0.04930377006530762
Time for backpropagation: 0.002611875534057617
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5375831127166748 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.48750638961792 seconds
Streaming imagenet data took 1.5013456344604492 seconds
Then, training+dataloading take 1.5036725997924805 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37210917472839355
Time for copying to cuda: 0.009278297424316406
Time for forward pass: 0.04923200607299805
Time for backpropagation: 0.0025856494903564453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5484926700592041 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4884424209594727 seconds
Streaming imagenet data took 1.5020828247070312 seconds
Then, training+dataloading take 1.5043435096740723 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3770008087158203
Time for copying to cuda: 0.009539127349853516
Time for forward pass: 0.04940342903137207
Time for backpropagation: 0.0026993751525878906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5391213893890381 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4868500232696533 seconds
Streaming imagenet data took 1.5009150505065918 seconds
Then, training+dataloading take 1.5032157897949219 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3692619800567627
Time for copying to cuda: 0.009356021881103516
Time for forward pass: 0.049289703369140625
Time for backpropagation: 0.0026710033416748047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5322012901306152 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4912943840026855 seconds
Streaming imagenet data took 1.5050005912780762 seconds
Then, training+dataloading take 1.50728178024292 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3670685291290283
Time for copying to cuda: 0.009305477142333984
Time for forward pass: 0.04925203323364258
Time for backpropagation: 0.0027971267700195312
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5472838878631592 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.482712745666504 seconds
Streaming imagenet data took 1.4965295791625977 seconds
Then, training+dataloading take 1.498826503753662 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3712782859802246
Time for copying to cuda: 0.009443998336791992
Time for forward pass: 0.04921889305114746
Time for backpropagation: 0.0026025772094726562
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5302023887634277 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4906895160675049 seconds
Streaming imagenet data took 1.504697322845459 seconds
Then, training+dataloading take 1.507021188735962 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3772401809692383
Time for copying to cuda: 0.009441614151000977
Time for forward pass: 0.04948782920837402
Time for backpropagation: 0.0026628971099853516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5474812984466553 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4928488731384277 seconds
Streaming imagenet data took 1.5065631866455078 seconds
Then, training+dataloading take 1.5088307857513428 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37637853622436523
Time for copying to cuda: 0.00938272476196289
Time for forward pass: 0.049233198165893555
Time for backpropagation: 0.002594470977783203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5389971733093262 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4623956680297852 seconds
Streaming imagenet data took 1.476135015487671 seconds
Then, training+dataloading take 1.4783785343170166 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38205814361572266
Time for copying to cuda: 0.009405374526977539
Time for forward pass: 0.04929852485656738
Time for backpropagation: 0.0025920867919921875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5440683364868164 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5263516902923584 seconds
Streaming imagenet data took 1.5400855541229248 seconds
Then, training+dataloading take 1.5423834323883057 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37331342697143555
Time for copying to cuda: 0.00929570198059082
Time for forward pass: 0.04924416542053223
Time for backpropagation: 0.002622365951538086
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5336930751800537 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4969918727874756 seconds
Streaming imagenet data took 1.5108270645141602 seconds
Then, training+dataloading take 1.5132155418395996 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41120290756225586
Time for copying to cuda: 0.00948953628540039
Time for forward pass: 0.04928851127624512
Time for backpropagation: 0.0028197765350341797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5557501316070557 seconds
Index: 20
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5140221118927002 seconds
Streaming imagenet data took 1.565680980682373 seconds
Then, training+dataloading take 1.5699419975280762 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3505246639251709
Time for copying to cuda: 0.009389400482177734
Time for forward pass: 0.04935312271118164
Time for backpropagation: 0.002705812454223633
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5001397132873535 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5107176303863525 seconds
Streaming imagenet data took 1.5245764255523682 seconds
Then, training+dataloading take 1.5271217823028564 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3357551097869873
Time for copying to cuda: 0.0093994140625
Time for forward pass: 0.04937624931335449
Time for backpropagation: 0.002641916275024414
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4788014888763428 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5092453956604004 seconds
Streaming imagenet data took 1.523430585861206 seconds
Then, training+dataloading take 1.5259523391723633 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3310239315032959
Time for copying to cuda: 0.009293317794799805
Time for forward pass: 0.04925394058227539
Time for backpropagation: 0.002624988555908203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4679269790649414 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4871559143066406 seconds
Streaming imagenet data took 1.5008795261383057 seconds
Then, training+dataloading take 1.5033602714538574 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3682594299316406
Time for copying to cuda: 0.009291887283325195
Time for forward pass: 0.04921746253967285
Time for backpropagation: 0.0026595592498779297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5302982330322266 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4921846389770508 seconds
Streaming imagenet data took 1.5062267780303955 seconds
Then, training+dataloading take 1.5086703300476074 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3701965808868408
Time for copying to cuda: 0.00947260856628418
Time for forward pass: 0.04932999610900879
Time for backpropagation: 0.0027027130126953125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5516016483306885 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4680426120758057 seconds
Streaming imagenet data took 1.4817461967468262 seconds
Then, training+dataloading take 1.4841344356536865 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37735676765441895
Time for copying to cuda: 0.009439945220947266
Time for forward pass: 0.04925107955932617
Time for backpropagation: 0.0026187896728515625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5513148307800293 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.486360788345337 seconds
Streaming imagenet data took 1.5002610683441162 seconds
Then, training+dataloading take 1.50264310836792 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42749929428100586
Time for copying to cuda: 0.009476184844970703
Time for forward pass: 0.04922842979431152
Time for backpropagation: 0.002610445022583008
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5557990074157715 seconds
Index: 27
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4976434707641602 seconds
Streaming imagenet data took 1.5112757682800293 seconds
Then, training+dataloading take 1.5136988162994385 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3678171634674072
Time for copying to cuda: 0.009386301040649414
Time for forward pass: 0.04921150207519531
Time for backpropagation: 0.0026133060455322266
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5479583740234375 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.487229347229004 seconds
Streaming imagenet data took 1.501110553741455 seconds
Then, training+dataloading take 1.5034801959991455 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37038588523864746
Time for copying to cuda: 0.009397268295288086
Time for forward pass: 0.049272775650024414
Time for backpropagation: 0.002683877944946289
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5494875907897949 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4862241744995117 seconds
Streaming imagenet data took 1.499908208847046 seconds
Then, training+dataloading take 1.502295970916748 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37058091163635254
Time for copying to cuda: 0.009405851364135742
Time for forward pass: 0.04922342300415039
Time for backpropagation: 0.002559185028076172
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.549527645111084 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5057713985443115 seconds
Streaming imagenet data took 1.519751787185669 seconds
Then, training+dataloading take 1.5221562385559082 seconds

Epoch: 0
Time of next(dataloader) is: 0.3773074150085449
Time for copying to cuda: 0.009427309036254883
Time for forward pass: 0.049216508865356445
Time for backpropagation: 0.002574443817138672
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
The whole process took 58.79462718963623 seconds
