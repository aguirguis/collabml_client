Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2881018862869 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119051138.0904394 119051138.0904394
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8321850299835205 seconds
Streaming imagenet data took 1.8461968898773193 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.2958707809448242
Time for copying to cuda: 0.010019063949584961
Memory occpied: (1550.0, 184.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8126411437988281 seconds
Memory occpied: (1550.0, 590.0)
Streaming imagenet data took 1.826611042022705 seconds
Memory occpied: (1550.0, 1060.0)
Time for forward pass: 3.240583896636963
Time for backpropagation: 0.05045938491821289
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.67537522315979 seconds
Index: 0
Then, training+dataloading take 3.6755757331848145 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3297615051269531
Time for copying to cuda: 0.04478764533996582
Time for forward pass: 0.050232648849487305
Time for backpropagation: 0.04123711585998535
GPU memory for training: 1.1635355949401855                          

Memory occpied: (2226.0, 1578.0)
One training iteration takes: 0.5568122863769531 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8479530811309814 seconds
Streaming imagenet data took 1.8618128299713135 seconds
Then, training+dataloading take 1.8640484809875488 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33434343338012695
Time for copying to cuda: 0.009448051452636719
Time for forward pass: 0.0492551326751709
Time for backpropagation: 0.0026235580444335938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47232818603515625 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7082934379577637 seconds
Streaming imagenet data took 1.7220361232757568 seconds
Then, training+dataloading take 1.7244269847869873 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3341662883758545
Time for copying to cuda: 0.009462594985961914
Time for forward pass: 0.05467653274536133
Time for backpropagation: 0.0031447410583496094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5020198822021484 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7586054801940918 seconds
Streaming imagenet data took 1.7744765281677246 seconds
Then, training+dataloading take 1.777085781097412 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3335552215576172
Time for copying to cuda: 0.009471893310546875
Time for forward pass: 0.049360036849975586
Time for backpropagation: 0.0028290748596191406
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4816091060638428 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6902949810028076 seconds
Streaming imagenet data took 1.7039263248443604 seconds
Then, training+dataloading take 1.706291675567627 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33261537551879883
Time for copying to cuda: 0.009421110153198242
Time for forward pass: 0.049318552017211914
Time for backpropagation: 0.002643108367919922
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4809231758117676 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6760354042053223 seconds
Streaming imagenet data took 1.6900241374969482 seconds
Then, training+dataloading take 1.6924731731414795 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.40961194038391113
Time for copying to cuda: 0.009370088577270508
Time for forward pass: 0.04921102523803711
Time for backpropagation: 0.002628326416015625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.550431489944458 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7848963737487793 seconds
Streaming imagenet data took 1.7986016273498535 seconds
Then, training+dataloading take 1.8010106086730957 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34614109992980957
Time for copying to cuda: 0.009391069412231445
Time for forward pass: 0.04932808876037598
Time for backpropagation: 0.002644777297973633
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48825979232788086 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.682861089706421 seconds
Streaming imagenet data took 1.6966874599456787 seconds
Then, training+dataloading take 1.6990933418273926 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35568952560424805
Time for copying to cuda: 0.009523630142211914
Time for forward pass: 0.04950881004333496
Time for backpropagation: 0.040441036224365234
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5354752540588379 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7757737636566162 seconds
Streaming imagenet data took 1.789518117904663 seconds
Then, training+dataloading take 1.7902748584747314 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3332095146179199
Time for copying to cuda: 0.009468317031860352
Time for forward pass: 0.04923892021179199
Time for backpropagation: 0.002583742141723633
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.488201379776001 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6846294403076172 seconds
Streaming imagenet data took 1.6985952854156494 seconds
Then, training+dataloading take 1.7010276317596436 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3373408317565918
Time for copying to cuda: 0.00950932502746582
Time for forward pass: 0.04947090148925781
Time for backpropagation: 0.0026924610137939453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48407626152038574 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7381293773651123 seconds
Streaming imagenet data took 1.801633358001709 seconds
Then, training+dataloading take 1.8059892654418945 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.34467411041259766
Time for copying to cuda: 0.00942850112915039
Time for forward pass: 0.0493168830871582
Time for backpropagation: 0.002704620361328125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4930698871612549 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6680567264556885 seconds
Streaming imagenet data took 1.681861400604248 seconds
Then, training+dataloading take 1.6844701766967773 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34473443031311035
Time for copying to cuda: 0.009405136108398438
Time for forward pass: 0.049234628677368164
Time for backpropagation: 0.002615213394165039
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47307586669921875 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6710617542266846 seconds
Streaming imagenet data took 1.6850454807281494 seconds
Then, training+dataloading take 1.687577486038208 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3711419105529785
Time for copying to cuda: 0.009507417678833008
Time for forward pass: 0.04929351806640625
Time for backpropagation: 0.002599954605102539
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5327379703521729 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7532789707183838 seconds
Streaming imagenet data took 1.7678308486938477 seconds
Then, training+dataloading take 1.7721076011657715 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.32559680938720703
Time for copying to cuda: 0.009349822998046875
Time for forward pass: 0.04928994178771973
Time for backpropagation: 0.0026879310607910156
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.46984052658081055 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7219161987304688 seconds
Streaming imagenet data took 1.7357478141784668 seconds
Then, training+dataloading take 1.7382776737213135 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33135128021240234
Time for copying to cuda: 0.009389877319335938
Time for forward pass: 0.0492854118347168
Time for backpropagation: 0.0026018619537353516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4740147590637207 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6832895278930664 seconds
Streaming imagenet data took 1.6970710754394531 seconds
Then, training+dataloading take 1.6995482444763184 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3691442012786865
Time for copying to cuda: 0.009496688842773438
Time for forward pass: 0.04933428764343262
Time for backpropagation: 0.002673625946044922
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5516965389251709 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7227210998535156 seconds
Streaming imagenet data took 1.7748229503631592 seconds
Then, training+dataloading take 1.779200553894043 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.34583425521850586
Time for copying to cuda: 0.009348392486572266
Time for forward pass: 0.049375057220458984
Time for backpropagation: 0.0026702880859375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49387550354003906 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7217280864715576 seconds
Streaming imagenet data took 1.735530138015747 seconds
Then, training+dataloading take 1.7381963729858398 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3322768211364746
Time for copying to cuda: 0.009452104568481445
Time for forward pass: 0.04941201210021973
Time for backpropagation: 0.002632617950439453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4806182384490967 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.701284408569336 seconds
Streaming imagenet data took 1.7149920463562012 seconds
Then, training+dataloading take 1.7174992561340332 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3734703063964844
Time for copying to cuda: 0.009467840194702148
Time for forward pass: 0.049227237701416016
Time for backpropagation: 0.0028183460235595703
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5360627174377441 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7082226276397705 seconds
Streaming imagenet data took 1.7604796886444092 seconds
Then, training+dataloading take 1.764496088027954 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33956122398376465
Time for copying to cuda: 0.00945734977722168
Time for forward pass: 0.049288272857666016
Time for backpropagation: 0.002664327621459961
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4878051280975342 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6705048084259033 seconds
Streaming imagenet data took 1.6843793392181396 seconds
Then, training+dataloading take 1.6869995594024658 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3399019241333008
Time for copying to cuda: 0.009389400482177734
Time for forward pass: 0.04928898811340332
Time for backpropagation: 0.0025911331176757812
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4848442077636719 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7275545597076416 seconds
Streaming imagenet data took 1.7414076328277588 seconds
Then, training+dataloading take 1.7439422607421875 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4071037769317627
Time for copying to cuda: 0.009455204010009766
Time for forward pass: 0.04931330680847168
Time for backpropagation: 0.0026025772094726562
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5558884143829346 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7671153545379639 seconds
Streaming imagenet data took 1.7812514305114746 seconds
Then, training+dataloading take 1.7836778163909912 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3499431610107422
Time for copying to cuda: 0.009521961212158203
Time for forward pass: 0.04923534393310547
Time for backpropagation: 0.0028133392333984375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49278855323791504 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6645698547363281 seconds
Streaming imagenet data took 1.6784141063690186 seconds
Then, training+dataloading take 1.6792409420013428 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35716986656188965
Time for copying to cuda: 0.009472370147705078
Time for forward pass: 0.04932975769042969
Time for backpropagation: 0.0026159286499023438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5165185928344727 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7766144275665283 seconds
Streaming imagenet data took 1.828847885131836 seconds
Then, training+dataloading take 1.8330152034759521 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3371238708496094
Time for copying to cuda: 0.009501457214355469
Time for forward pass: 0.049241065979003906
Time for backpropagation: 0.002754688262939453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47762298583984375 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6710121631622314 seconds
Streaming imagenet data took 1.685258150100708 seconds
Then, training+dataloading take 1.6879029273986816 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.338773250579834
Time for copying to cuda: 0.009548187255859375
Time for forward pass: 0.04929709434509277
Time for backpropagation: 0.0026383399963378906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4913294315338135 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6750414371490479 seconds
Streaming imagenet data took 1.6887333393096924 seconds
Then, training+dataloading take 1.6912338733673096 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3858373165130615
Time for copying to cuda: 0.009347915649414062
Time for forward pass: 0.04938650131225586
Time for backpropagation: 0.002696990966796875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5475425720214844 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.72113037109375 seconds
Streaming imagenet data took 1.7831435203552246 seconds
Then, training+dataloading take 1.7873003482818604 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3398563861846924
Time for copying to cuda: 0.009332895278930664
Time for forward pass: 0.04923653602600098
Time for backpropagation: 0.0026018619537353516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.46851229667663574 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6645302772521973 seconds
Streaming imagenet data took 1.6786766052246094 seconds
Then, training+dataloading take 1.6813328266143799 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3499412536621094
Time for copying to cuda: 0.00944209098815918
Time for forward pass: 0.04948139190673828
Time for backpropagation: 0.002902507781982422
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5027832984924316 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6696279048919678 seconds
Streaming imagenet data took 1.6840171813964844 seconds
Then, training+dataloading take 1.6848723888397217 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38507699966430664
Time for copying to cuda: 0.009880781173706055
Time for forward pass: 0.04925417900085449
Time for backpropagation: 0.0026412010192871094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5459651947021484 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7846801280975342 seconds
Streaming imagenet data took 1.7990214824676514 seconds
Then, training+dataloading take 1.8013036251068115 seconds

Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33377552032470703
Time for copying to cuda: 0.009483814239501953
Time for forward pass: 0.049355506896972656
Time for backpropagation: 0.0024919509887695312
GPU memory for training: 1.1639018058776855                          

The whole process took 65.21260142326355 seconds
