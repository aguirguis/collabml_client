Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=6000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.5162552242458 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119081042.60475235 119081042.60475235
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 1122.9833984375 1422.0810546875 13336.8505859375
Candidate split  16
Server, client, server+client, vanilla  299.09765625 1122.9833984375 1422.0810546875 13336.8505859375
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 6000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 93.95806503295898 MBs for this batch
Executing all posts took 3.086717128753662 seconds
Streaming imagenet data took 3.1234395503997803 seconds
The mode is:  split
Start 6000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.382021427154541
Time for copying to cuda: 0.024872541427612305
Memory occpied: (1608.0, 36.0)
Memory occpied: (1608.0, 624.0)
Memory occpied: (1608.0, 1034.0)
Read 93.95806503295898 MBs for this batch
Executing all posts took 3.6543405055999756 seconds
Time for forward pass: 3.274172782897949
Streaming imagenet data took 3.6945223808288574 seconds
Time for backpropagation: 0.05963492393493652
GPU memory for training: 1.1750011444091797                          

One training iteration takes: 3.825490951538086 seconds
Index: 0
Then, training+dataloading take 3.8258395195007324 seconds
The mode is:  split
Start 12000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4579625129699707
Time for copying to cuda: 0.02437901496887207
Time for forward pass: 0.07357478141784668
Time for backpropagation: 0.0027277469635009766
GPU memory for training: 1.3312716484069824                          

Memory occpied: (2266.0, 1796.0)
One training iteration takes: 0.649744987487793 seconds
Index: 1
Memory occpied: (2428.0, 1804.0)
Read 93.95806503295898 MBs for this batch
Executing all posts took 3.0005133152008057 seconds
Memory occpied: (2428.0, 1804.0)
Streaming imagenet data took 3.037998676300049 seconds
Then, training+dataloading take 3.04270339012146 seconds
The mode is:  split
Start 18000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40408897399902344
Time for copying to cuda: 0.024419546127319336
Time for forward pass: 0.07413315773010254
Time for backpropagation: 0.0027687549591064453
GPU memory for training: 1.3312716484069824                          

One training iteration takes: 0.599663257598877 seconds
Index: 2
Memory occpied: (2428.0, 1804.0)
Memory occpied: (2428.0, 1804.0)
Read 93.95806503295898 MBs for this batch
Executing all posts took 3.4934980869293213 seconds
Streaming imagenet data took 3.5710830688476562 seconds
Then, training+dataloading take 3.5899808406829834 seconds
The mode is:  split
Start 24000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2428.0, 1804.0)
Time of next(dataloader) is: 0.41324377059936523
Time for copying to cuda: 0.02429962158203125
Time for forward pass: 0.0740962028503418
Time for backpropagation: 0.0026657581329345703
GPU memory for training: 1.3312716484069824                          

One training iteration takes: 0.5902907848358154 seconds
Index: 3
Memory occpied: (2428.0, 1804.0)
Memory occpied: (2428.0, 1804.0)
Read 93.95806503295898 MBs for this batch
Executing all posts took 2.978076696395874 seconds
Streaming imagenet data took 3.016263246536255 seconds
Then, training+dataloading take 3.0187981128692627 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3963291645050049
Time for copying to cuda: 0.024187326431274414
Time for forward pass: 0.07502245903015137
Time for backpropagation: 0.0031995773315429688
GPU memory for training: 1.3312716484069824                          

One training iteration takes: 0.5996444225311279 seconds
Index: 4
Memory occpied: (2428.0, 1804.0)
Memory occpied: (2428.0, 1804.0)
Read 31.319355010986328 MBs for this batch
Executing all posts took 1.973944902420044 seconds
Streaming imagenet data took 1.988354206085205 seconds
Then, training+dataloading take 1.9910199642181396 seconds

Epoch: 0
Time of next(dataloader) is: 0.3540072441101074
Time for copying to cuda: 0.008398294448852539
Time for forward pass: 0.03900408744812012
Time for backpropagation: 0.002627849578857422
GPU memory for training: 1.1565666198730469                          

The whole process took 25.914478302001953 seconds
