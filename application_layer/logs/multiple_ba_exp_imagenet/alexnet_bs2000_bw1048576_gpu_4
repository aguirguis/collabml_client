Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.3326851502812 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118925909.70801766 118925909.70801766
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.020704746246338 seconds
Streaming imagenet data took 2.0478951930999756 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32884836196899414
Time for copying to cuda: 0.019328594207763672
Memory occpied: (1586.0, 22.0)
Memory occpied: (1586.0, 586.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9799470901489258 seconds
Streaming imagenet data took 2.007323980331421 seconds
Memory occpied: (1586.0, 1028.0)
Time for forward pass: 3.254335641860962
Time for backpropagation: 0.04958915710449219
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.71864652633667 seconds
Index: 0
Then, training+dataloading take 3.718939781188965 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39199137687683105
Time for copying to cuda: 0.0185549259185791
Time for forward pass: 0.07538628578186035
Time for backpropagation: 0.003523588180541992
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5864531993865967 seconds
Index: 1
Memory occpied: (2100.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1187102794647217 seconds
Streaming imagenet data took 2.1458096504211426 seconds
Then, training+dataloading take 2.1502442359924316 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3654477596282959
Time for copying to cuda: 0.018224239349365234
Time for forward pass: 0.07535934448242188
Time for backpropagation: 0.00261688232421875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5325939655303955 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8534295558929443 seconds
Streaming imagenet data took 1.8807132244110107 seconds
Then, training+dataloading take 1.8851318359375 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.44663119316101074
Time for copying to cuda: 0.018535852432250977
Time for forward pass: 0.0752573013305664
Time for backpropagation: 0.0025970935821533203
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6292366981506348 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9522194862365723 seconds
Streaming imagenet data took 1.9801201820373535 seconds
Then, training+dataloading take 1.9852423667907715 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3712470531463623
Time for copying to cuda: 0.018345117568969727
Time for forward pass: 0.0690622329711914
Time for backpropagation: 0.0029141902923583984
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5500807762145996 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8523354530334473 seconds
Streaming imagenet data took 1.879875898361206 seconds
Then, training+dataloading take 1.8840606212615967 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41345739364624023
Time for copying to cuda: 0.018300771713256836
Time for forward pass: 0.07551002502441406
Time for backpropagation: 0.0028524398803710938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.633845329284668 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9495048522949219 seconds
Streaming imagenet data took 1.977348804473877 seconds
Then, training+dataloading take 1.9824347496032715 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36530065536499023
Time for copying to cuda: 0.018136978149414062
Time for forward pass: 0.07515239715576172
Time for backpropagation: 0.0027866363525390625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5515801906585693 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8800125122070312 seconds
Streaming imagenet data took 1.9070868492126465 seconds
Then, training+dataloading take 1.9112539291381836 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40839052200317383
Time for copying to cuda: 0.018384218215942383
Time for forward pass: 0.07533812522888184
Time for backpropagation: 0.002646923065185547
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6242148876190186 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9862542152404785 seconds
Streaming imagenet data took 2.013209342956543 seconds
Then, training+dataloading take 2.017453193664551 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36980533599853516
Time for copying to cuda: 0.01839590072631836
Time for forward pass: 0.07551431655883789
Time for backpropagation: 0.0027742385864257812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5545487403869629 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.885866403579712 seconds
Streaming imagenet data took 1.9130017757415771 seconds
Then, training+dataloading take 1.9172704219818115 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4080016613006592
Time for copying to cuda: 0.018344402313232422
Time for forward pass: 0.07536578178405762
Time for backpropagation: 0.0026826858520507812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6264183521270752 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9565050601959229 seconds
Streaming imagenet data took 1.9839041233062744 seconds
Then, training+dataloading take 1.9881370067596436 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36554622650146484
Time for copying to cuda: 0.018244266510009766
Time for forward pass: 0.07505273818969727
Time for backpropagation: 0.0027985572814941406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5495121479034424 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.875866174697876 seconds
Streaming imagenet data took 1.9030029773712158 seconds
Then, training+dataloading take 1.9073753356933594 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4072301387786865
Time for copying to cuda: 0.01832294464111328
Time for forward pass: 0.07548356056213379
Time for backpropagation: 0.0027704238891601562
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6236240863800049 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.980642318725586 seconds
Streaming imagenet data took 2.007640838623047 seconds
Then, training+dataloading take 2.0119516849517822 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3696472644805908
Time for copying to cuda: 0.018319129943847656
Time for forward pass: 0.07557535171508789
Time for backpropagation: 0.0028219223022460938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5686073303222656 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8541834354400635 seconds
Streaming imagenet data took 1.8813674449920654 seconds
Then, training+dataloading take 1.8856287002563477 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4191412925720215
Time for copying to cuda: 0.018397808074951172
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07544970512390137
Time for backpropagation: 0.0031189918518066406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6106352806091309 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.951284646987915 seconds
Streaming imagenet data took 1.9782371520996094 seconds
Then, training+dataloading take 1.9825704097747803 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3673849105834961
Time for copying to cuda: 0.018461942672729492
Time for forward pass: 0.07557272911071777
Time for backpropagation: 0.002863168716430664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5493278503417969 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8515257835388184 seconds
Streaming imagenet data took 1.8792130947113037 seconds
Then, training+dataloading take 1.8835248947143555 seconds

Epoch: 0
Time of next(dataloader) is: 0.4448816776275635
Time for copying to cuda: 0.018245697021484375
Time for forward pass: 0.07534003257751465
Time for backpropagation: 0.0026793479919433594
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
The whole process took 41.21021771430969 seconds
