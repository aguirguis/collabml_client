Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=4000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3068758626167 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119053598.8330649 119053598.8330649
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Candidate split  16
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 4000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.2575936317443848 seconds
Streaming imagenet data took 2.28236722946167 seconds
The mode is:  split
Start 4000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3664696216583252
Time for copying to cuda: 0.01697540283203125
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0998847484588623 seconds
Streaming imagenet data took 2.1251702308654785 seconds
Time for forward pass: 2.9775102138519287
Time for backpropagation: 0.052138566970825195
GPU memory for training: 1.089247226715088                          

One training iteration takes: 3.5253050327301025 seconds
Index: 0
Then, training+dataloading take 3.5255112648010254 seconds
The mode is:  split
Start 8000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1756.0)
Time of next(dataloader) is: 0.3543071746826172
Time for copying to cuda: 0.016746997833251953
Time for forward pass: 0.05451202392578125
Time for backpropagation: 0.00284576416015625
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5303442478179932 seconds
Index: 1
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.1583950519561768 seconds
Streaming imagenet data took 2.18386173248291 seconds
Then, training+dataloading take 2.185565233230591 seconds
The mode is:  split
Start 12000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4120922088623047
Time for copying to cuda: 0.01640009880065918
Time for forward pass: 0.056014299392700195
Time for backpropagation: 0.0026624202728271484
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5882024765014648 seconds
Index: 2
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.191600799560547 seconds
Streaming imagenet data took 2.216158866882324 seconds
Then, training+dataloading take 2.2178032398223877 seconds
The mode is:  split
Start 16000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.370100736618042
Time for copying to cuda: 0.016436338424682617
Time for forward pass: 0.05602717399597168
Time for backpropagation: 0.0027196407318115234
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5277550220489502 seconds
Index: 3
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0836257934570312 seconds
Streaming imagenet data took 2.108447790145874 seconds
Then, training+dataloading take 2.1100940704345703 seconds
The mode is:  split
Start 20000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36963748931884766
Time for copying to cuda: 0.016612529754638672
Time for forward pass: 0.05614423751831055
Time for backpropagation: 0.0027985572814941406
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5323352813720703 seconds
Index: 4
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0955729484558105 seconds
Streaming imagenet data took 2.1205077171325684 seconds
Then, training+dataloading take 2.1222727298736572 seconds
The mode is:  split
Start 24000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4018435478210449
Time for copying to cuda: 0.016492843627929688
Time for forward pass: 0.05596280097961426
Time for backpropagation: 0.0026204586029052734
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5761809349060059 seconds
Index: 5
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.2108101844787598 seconds
Streaming imagenet data took 2.2357656955718994 seconds
Then, training+dataloading take 2.2374892234802246 seconds
The mode is:  split
Start 28000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3634791374206543
Time for copying to cuda: 0.01625680923461914
Time for forward pass: 0.055994510650634766
Time for backpropagation: 0.0026106834411621094
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5306520462036133 seconds
Index: 6
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0815513134002686 seconds
Streaming imagenet data took 2.106379985809326 seconds
Then, training+dataloading take 2.109555721282959 seconds

Epoch: 0
Time of next(dataloader) is: 0.3729090690612793
Time for copying to cuda: 0.016597270965576172
Time for forward pass: 0.05601096153259277
Time for backpropagation: 0.0026693344116210938
GPU memory for training: 1.2448029518127441                          

The whole process took 26.156105518341064 seconds
