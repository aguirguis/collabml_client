Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.5181780154272 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118950222.62883808 118950222.62883808
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7477126121520996 seconds
Streaming imagenet data took 1.7616705894470215 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.2968103885650635
Time for copying to cuda: 0.009914398193359375
Memory occpied: (1550.0, 214.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7401504516601562 seconds
Streaming imagenet data took 1.7902429103851318 seconds
Memory occpied: (1550.0, 680.0)
Memory occpied: (1550.0, 1114.0)
Time for forward pass: 3.216392755508423
Time for backpropagation: 0.049358367919921875
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.6309316158294678 seconds
Index: 0
Then, training+dataloading take 3.631124258041382 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32175517082214355
Time for copying to cuda: 0.009383440017700195
Time for forward pass: 0.04977154731750488
Time for backpropagation: 0.003274202346801758
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.46894073486328125 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7947924137115479 seconds
Streaming imagenet data took 1.8466300964355469 seconds
Then, training+dataloading take 1.8508107662200928 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33478641510009766
Time for copying to cuda: 0.009330987930297852
Time for forward pass: 0.049211740493774414
Time for backpropagation: 0.0025377273559570312
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47417497634887695 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6968133449554443 seconds
Streaming imagenet data took 1.7106711864471436 seconds
Then, training+dataloading take 1.7131576538085938 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3287692070007324
Time for copying to cuda: 0.009386301040649414
Time for forward pass: 0.04931473731994629
Time for backpropagation: 0.0025496482849121094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4562368392944336 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.65325927734375 seconds
Streaming imagenet data took 1.6671395301818848 seconds
Then, training+dataloading take 1.6695733070373535 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3882293701171875
Time for copying to cuda: 0.009463787078857422
Time for forward pass: 0.049516916275024414
Memory occpied: (2290.0, 1578.0)
Time for backpropagation: 0.002776622772216797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.534043550491333 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7332954406738281 seconds
Streaming imagenet data took 1.7473933696746826 seconds
Then, training+dataloading take 1.7497389316558838 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.338146448135376
Time for copying to cuda: 0.009375572204589844
Time for forward pass: 0.04928755760192871
Time for backpropagation: 0.0025942325592041016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47440171241760254 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6843996047973633 seconds
Streaming imagenet data took 1.6983585357666016 seconds
Then, training+dataloading take 1.7009608745574951 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3475165367126465
Time for copying to cuda: 0.009440422058105469
Time for forward pass: 0.04931187629699707
Time for backpropagation: 0.0026454925537109375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5292754173278809 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7211594581604004 seconds
Streaming imagenet data took 1.735213041305542 seconds
Then, training+dataloading take 1.7375032901763916 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37029457092285156
Time for copying to cuda: 0.00939178466796875
Time for forward pass: 0.04932141304016113
Time for backpropagation: 0.002559185028076172
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5180232524871826 seconds
Index: 7
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7085096836090088 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7230520248413086 seconds
Then, training+dataloading take 1.725475549697876 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.330826997756958
Time for copying to cuda: 0.009392261505126953
Time for forward pass: 0.04924607276916504
Time for backpropagation: 0.002506732940673828
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4786524772644043 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6915473937988281 seconds
Streaming imagenet data took 1.7053298950195312 seconds
Then, training+dataloading take 1.7077760696411133 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3304738998413086
Time for copying to cuda: 0.009438514709472656
Time for forward pass: 0.04932045936584473
Time for backpropagation: 0.002549886703491211
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47359681129455566 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6720693111419678 seconds
Streaming imagenet data took 1.7241475582122803 seconds
Then, training+dataloading take 1.7283594608306885 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36638712882995605
Time for copying to cuda: 0.009371519088745117
Time for forward pass: 0.04932427406311035
Time for backpropagation: 0.002607107162475586
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5113863945007324 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7640902996063232 seconds
Streaming imagenet data took 1.7778518199920654 seconds
Then, training+dataloading take 1.7804720401763916 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33450841903686523
Time for copying to cuda: 0.009410381317138672
Time for forward pass: 0.049265384674072266
Time for backpropagation: 0.0025391578674316406
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4828476905822754 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6473450660705566 seconds
Streaming imagenet data took 1.6611921787261963 seconds
Then, training+dataloading take 1.6637330055236816 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32649993896484375
Time for copying to cuda: 0.00950765609741211
Time for forward pass: 0.049407243728637695
Time for backpropagation: 0.0026268959045410156
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5145759582519531 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.662407398223877 seconds
Streaming imagenet data took 1.7141966819763184 seconds
Then, training+dataloading take 1.7180125713348389 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3689756393432617
Time for copying to cuda: 0.009299039840698242
Time for forward pass: 0.0492405891418457
Time for backpropagation: 0.002741575241088867
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.520127534866333 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6949362754821777 seconds
Streaming imagenet data took 1.7088615894317627 seconds
Then, training+dataloading take 1.7114627361297607 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3289828300476074
Time for copying to cuda: 0.0093841552734375
Time for forward pass: 0.04932141304016113
Time for backpropagation: 0.002530813217163086
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4565739631652832 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7027814388275146 seconds
Streaming imagenet data took 1.7166874408721924 seconds
Then, training+dataloading take 1.719236135482788 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3772714138031006
Time for copying to cuda: 0.009522676467895508
Time for forward pass: 0.04950666427612305
Time for backpropagation: 0.002862691879272461
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5592920780181885 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.693995475769043 seconds
Streaming imagenet data took 1.7079484462738037 seconds
Then, training+dataloading take 1.7096326351165771 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39959263801574707
Time for copying to cuda: 0.009564399719238281
Time for forward pass: 0.04935503005981445
Time for backpropagation: 0.002622842788696289
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5446979999542236 seconds
Index: 16
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.715623378753662 seconds
Streaming imagenet data took 1.7295811176300049 seconds
Then, training+dataloading take 1.7304518222808838 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3435704708099365
Time for copying to cuda: 0.009410381317138672
Time for forward pass: 0.049321889877319336
Time for backpropagation: 0.0026197433471679688
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4942972660064697 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.670133352279663 seconds
Streaming imagenet data took 1.6842782497406006 seconds
Then, training+dataloading take 1.6866512298583984 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3305857181549072
Time for copying to cuda: 0.00931859016418457
Time for forward pass: 0.049375295639038086
Time for backpropagation: 0.0026209354400634766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47237324714660645 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6939442157745361 seconds
Streaming imagenet data took 1.707594394683838 seconds
Then, training+dataloading take 1.710003137588501 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36403512954711914
Time for copying to cuda: 0.009393453598022461
Time for forward pass: 0.049233198165893555
Time for backpropagation: 0.002587556838989258
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5448031425476074 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6850135326385498 seconds
Streaming imagenet data took 1.699056625366211 seconds
Then, training+dataloading take 1.7014241218566895 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3717482089996338
Time for copying to cuda: 0.009486198425292969
Time for forward pass: 0.04928874969482422
Time for backpropagation: 0.002515554428100586
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5149796009063721 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6692161560058594 seconds
Streaming imagenet data took 1.6831159591674805 seconds
Then, training+dataloading take 1.6856677532196045 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33298492431640625
Time for copying to cuda: 0.009324789047241211
Time for forward pass: 0.049417972564697266
Time for backpropagation: 0.0027403831481933594
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4873225688934326 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.696629524230957 seconds
Streaming imagenet data took 1.710317611694336 seconds
Then, training+dataloading take 1.7127761840820312 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36562252044677734
Time for copying to cuda: 0.009405136108398438
Time for forward pass: 0.049308061599731445
Time for backpropagation: 0.0025787353515625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5264792442321777 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6889581680297852 seconds
Streaming imagenet data took 1.7404365539550781 seconds
Then, training+dataloading take 1.744767427444458 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3333415985107422
Time for copying to cuda: 0.009446382522583008
Time for forward pass: 0.04922819137573242
Time for backpropagation: 0.0025887489318847656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47771191596984863 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.657749891281128 seconds
Streaming imagenet data took 1.6716582775115967 seconds
Then, training+dataloading take 1.6743462085723877 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33150434494018555
Time for copying to cuda: 0.009433507919311523
Time for forward pass: 0.04931759834289551
Time for backpropagation: 0.002599000930786133
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47881197929382324 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7189276218414307 seconds
Streaming imagenet data took 1.7330777645111084 seconds
Then, training+dataloading take 1.7356669902801514 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3752779960632324
Time for copying to cuda: 0.009476423263549805
Time for forward pass: 0.0492863655090332
Time for backpropagation: 0.0026388168334960938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5566468238830566 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7176179885864258 seconds
Streaming imagenet data took 1.7319443225860596 seconds
Then, training+dataloading take 1.734419822692871 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37657833099365234
Time for copying to cuda: 0.009442567825317383
Time for forward pass: 0.04931354522705078
Time for backpropagation: 0.0025768280029296875
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5222251415252686 seconds
Index: 26
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.721297025680542 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.735466480255127 seconds
Then, training+dataloading take 1.7379846572875977 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3348221778869629
Time for copying to cuda: 0.009374856948852539
Time for forward pass: 0.049367427825927734
Time for backpropagation: 0.0025565624237060547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47460436820983887 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6549150943756104 seconds
Streaming imagenet data took 1.668686866760254 seconds
Then, training+dataloading take 1.6713166236877441 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32947516441345215
Time for copying to cuda: 0.009410858154296875
Time for forward pass: 0.049297332763671875
Time for backpropagation: 0.0025649070739746094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48023438453674316 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6698079109191895 seconds
Streaming imagenet data took 1.6836540699005127 seconds
Then, training+dataloading take 1.6862003803253174 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3761589527130127
Time for copying to cuda: 0.009317636489868164
Time for forward pass: 0.049193382263183594
Time for backpropagation: 0.002696990966796875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5374913215637207 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7768511772155762 seconds
Streaming imagenet data took 1.7909746170043945 seconds
Then, training+dataloading take 1.7934143543243408 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.32875752449035645
Time for copying to cuda: 0.009313821792602539
Time for forward pass: 0.04918980598449707
Time for backpropagation: 0.0026018619537353516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.46915173530578613 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6735832691192627 seconds
Streaming imagenet data took 1.6874616146087646 seconds
Then, training+dataloading take 1.6900768280029297 seconds

Epoch: 0
Time of next(dataloader) is: 0.32256531715393066
Time for copying to cuda: 0.009363651275634766
Time for forward pass: 0.049355268478393555
Time for backpropagation: 0.002712249755859375
GPU memory for training: 1.1639018058776855                          

The whole process took 63.978771448135376 seconds
