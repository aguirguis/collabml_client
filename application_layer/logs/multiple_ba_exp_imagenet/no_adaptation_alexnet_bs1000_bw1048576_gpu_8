Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.4808591615943 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118945331.17202848 118945331.17202848
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8189935684204102 seconds
Streaming imagenet data took 1.8327562808990479 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.30963802337646484
Time for copying to cuda: 0.010025978088378906
Memory occpied: (1550.0, 196.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7538912296295166 seconds
Streaming imagenet data took 1.8125243186950684 seconds
Memory occpied: (1550.0, 662.0)
Memory occpied: (1550.0, 1082.0)
Time for forward pass: 3.223137140274048
Time for backpropagation: 0.049954891204833984
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.6477670669555664 seconds
Index: 0
Then, training+dataloading take 3.647954225540161 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32567715644836426
Time for copying to cuda: 0.009656429290771484
Time for forward pass: 0.04977679252624512
Time for backpropagation: 0.003360271453857422
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.4923577308654785 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8663580417633057 seconds
Streaming imagenet data took 1.880028247833252 seconds
Then, training+dataloading take 1.8808341026306152 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3254542350769043
Time for copying to cuda: 0.009454488754272461
Time for forward pass: 0.04937577247619629
Time for backpropagation: 0.002605915069580078
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4641294479370117 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.691171646118164 seconds
Streaming imagenet data took 1.704984188079834 seconds
Then, training+dataloading take 1.707275390625 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3321824073791504
Time for copying to cuda: 0.009521722793579102
Time for forward pass: 0.049204111099243164
Time for backpropagation: 0.0025665760040283203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48758697509765625 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7054879665374756 seconds
Streaming imagenet data took 1.7564606666564941 seconds
Then, training+dataloading take 1.7606818675994873 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33895325660705566
Time for copying to cuda: 0.009379863739013672
Time for forward pass: 0.049259185791015625
Time for backpropagation: 0.002551555633544922
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48514246940612793 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6532611846923828 seconds
Streaming imagenet data took 1.667170763015747 seconds
Then, training+dataloading take 1.6697478294372559 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34508633613586426
Time for copying to cuda: 0.009521722793579102
Time for forward pass: 0.049275875091552734
Time for backpropagation: 0.0026679039001464844
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49144625663757324 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6699411869049072 seconds
Streaming imagenet data took 1.6842217445373535 seconds
Then, training+dataloading take 1.6866817474365234 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38169097900390625
Time for copying to cuda: 0.009313821792602539
Time for forward pass: 0.04932427406311035
Time for backpropagation: 0.00250244140625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5409319400787354 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7137084007263184 seconds
Streaming imagenet data took 1.7654533386230469 seconds
Then, training+dataloading take 1.7696990966796875 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33323025703430176
Time for copying to cuda: 0.009385108947753906
Time for forward pass: 0.049268245697021484
Time for backpropagation: 0.0026192665100097656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4611680507659912 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6746442317962646 seconds
Streaming imagenet data took 1.6884839534759521 seconds
Then, training+dataloading take 1.691063404083252 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3293747901916504
Time for copying to cuda: 0.00937199592590332
Time for forward pass: 0.049269914627075195
Time for backpropagation: 0.0025093555450439453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47324037551879883 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6982009410858154 seconds
Streaming imagenet data took 1.7122001647949219 seconds
Then, training+dataloading take 1.7146859169006348 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36739230155944824
Time for copying to cuda: 0.00945281982421875
Time for forward pass: 0.04922008514404297
Time for backpropagation: 0.002516031265258789
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5353114604949951 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.766502857208252 seconds
Streaming imagenet data took 1.7807581424713135 seconds
Then, training+dataloading take 1.7837834358215332 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33646488189697266
Time for copying to cuda: 0.009469032287597656
Time for forward pass: 0.04944109916687012
Time for backpropagation: 0.00266265869140625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4762847423553467 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.688767671585083 seconds
Streaming imagenet data took 1.7030727863311768 seconds
Then, training+dataloading take 1.7055370807647705 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3314521312713623
Time for copying to cuda: 0.009390115737915039
Time for forward pass: 0.049303531646728516
Time for backpropagation: 0.0025870800018310547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48433566093444824 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.654886245727539 seconds
Streaming imagenet data took 1.668860673904419 seconds
Then, training+dataloading take 1.6713087558746338 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.424236536026001
Time for copying to cuda: 0.00939631462097168
Time for forward pass: 0.049185991287231445
Time for backpropagation: 0.0025577545166015625
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.566727876663208 seconds
Index: 12
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6569015979766846 seconds
Streaming imagenet data took 1.7084259986877441 seconds
Then, training+dataloading take 1.7127735614776611 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3488903045654297
Time for copying to cuda: 0.009435892105102539
Time for forward pass: 0.04927420616149902
Time for backpropagation: 0.0025548934936523438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49749755859375 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6710689067840576 seconds
Streaming imagenet data took 1.6849684715270996 seconds
Then, training+dataloading take 1.6876404285430908 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34322237968444824
Time for copying to cuda: 0.009387493133544922
Time for forward pass: 0.0493316650390625
Time for backpropagation: 0.0026383399963378906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4977846145629883 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6665682792663574 seconds
Streaming imagenet data took 1.6802656650543213 seconds
Then, training+dataloading take 1.6827239990234375 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3807227611541748
Time for copying to cuda: 0.00943899154663086
Time for forward pass: 0.04932117462158203
Time for backpropagation: 0.0028390884399414062
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5406591892242432 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7191963195800781 seconds
Streaming imagenet data took 1.7702548503875732 seconds
Then, training+dataloading take 1.7741525173187256 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33572840690612793
Time for copying to cuda: 0.00942087173461914
Time for forward pass: 0.04927492141723633
Time for backpropagation: 0.0025844573974609375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4846494197845459 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.675743818283081 seconds
Streaming imagenet data took 1.689514398574829 seconds
Then, training+dataloading take 1.6921017169952393 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3316071033477783
Time for copying to cuda: 0.009344100952148438
Time for forward pass: 0.049263715744018555
Time for backpropagation: 0.0025348663330078125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4760565757751465 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7047317028045654 seconds
Streaming imagenet data took 1.7187020778656006 seconds
Then, training+dataloading take 1.7211339473724365 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37081098556518555
Time for copying to cuda: 0.009422540664672852
Time for forward pass: 0.04918265342712402
Time for backpropagation: 0.002516508102416992
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5324022769927979 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.691185474395752 seconds
Streaming imagenet data took 1.7430152893066406 seconds
Then, training+dataloading take 1.7470972537994385 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3288900852203369
Time for copying to cuda: 0.009417295455932617
Time for forward pass: 0.04940938949584961
Time for backpropagation: 0.002635955810546875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.480121374130249 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.684629201889038 seconds
Streaming imagenet data took 1.698591709136963 seconds
Then, training+dataloading take 1.7011759281158447 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32945990562438965
Time for copying to cuda: 0.009378671646118164
Time for forward pass: 0.04920554161071777
Time for backpropagation: 0.0026025772094726562
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4819295406341553 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6677627563476562 seconds
Streaming imagenet data took 1.6815378665924072 seconds
Then, training+dataloading take 1.6840136051177979 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41681766510009766
Time for copying to cuda: 0.009478330612182617
Memory occpied: (2290.0, 1578.0)
Time for forward pass: 0.04943370819091797
Time for backpropagation: 0.0025606155395507812
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5555176734924316 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7671959400177002 seconds
Streaming imagenet data took 1.781184196472168 seconds
Then, training+dataloading take 1.7835261821746826 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3298952579498291
Time for copying to cuda: 0.009398698806762695
Time for forward pass: 0.04923057556152344
Time for backpropagation: 0.002598285675048828
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48695898056030273 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.703073263168335 seconds
Streaming imagenet data took 1.7168645858764648 seconds
Then, training+dataloading take 1.719285011291504 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3873331546783447
Time for copying to cuda: 0.009424686431884766
Time for forward pass: 0.04947400093078613
Time for backpropagation: 0.03944849967956543
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5859246253967285 seconds
Index: 23
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.760016918182373 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.7743840217590332 seconds
Then, training+dataloading take 1.776688575744629 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33961987495422363
Time for copying to cuda: 0.009355306625366211
Time for forward pass: 0.049304962158203125
Time for backpropagation: 0.002543210983276367
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47394657135009766 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6715965270996094 seconds
Streaming imagenet data took 1.6853551864624023 seconds
Then, training+dataloading take 1.6877942085266113 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3337721824645996
Time for copying to cuda: 0.009478330612182617
Time for forward pass: 0.04934215545654297
Time for backpropagation: 0.002667665481567383
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4767153263092041 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6566293239593506 seconds
Streaming imagenet data took 1.670879602432251 seconds
Then, training+dataloading take 1.6732573509216309 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3717613220214844
Time for copying to cuda: 0.00937795639038086
Time for forward pass: 0.04937577247619629
Time for backpropagation: 0.002666473388671875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5516352653503418 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7155494689941406 seconds
Streaming imagenet data took 1.7674782276153564 seconds
Then, training+dataloading take 1.7716460227966309 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3419373035430908
Time for copying to cuda: 0.009302377700805664
Time for forward pass: 0.049230098724365234
Time for backpropagation: 0.0025141239166259766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49083614349365234 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6999483108520508 seconds
Streaming imagenet data took 1.7139346599578857 seconds
Then, training+dataloading take 1.7164864540100098 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34369754791259766
Time for copying to cuda: 0.009349346160888672
Time for forward pass: 0.04916191101074219
Time for backpropagation: 0.002569913864135742
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48932480812072754 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6713652610778809 seconds
Streaming imagenet data took 1.68528151512146 seconds
Then, training+dataloading take 1.6877415180206299 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3778049945831299
Time for copying to cuda: 0.009475231170654297
Time for forward pass: 0.04929089546203613
Time for backpropagation: 0.002616405487060547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5408158302307129 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.693192958831787 seconds
Streaming imagenet data took 1.74509859085083 seconds
Then, training+dataloading take 1.7493605613708496 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33321356773376465
Time for copying to cuda: 0.009457588195800781
Time for forward pass: 0.049245357513427734
Time for backpropagation: 0.0026259422302246094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4777688980102539 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6770720481872559 seconds
Streaming imagenet data took 1.6911966800689697 seconds
Then, training+dataloading take 1.6938164234161377 seconds

Epoch: 0
Time of next(dataloader) is: 0.3311026096343994
Time for copying to cuda: 0.009365081787109375
Time for forward pass: 0.049307823181152344
Time for backpropagation: 0.0024874210357666016
GPU memory for training: 1.1639018058776855                          

The whole process took 64.19215106964111 seconds
