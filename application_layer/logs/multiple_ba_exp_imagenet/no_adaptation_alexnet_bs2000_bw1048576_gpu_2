Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.0687293503923 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119022384.49341463 119022384.49341463
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2614753246307373 seconds
Streaming imagenet data took 2.288541078567505 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37670016288757324
Time for copying to cuda: 0.018979787826538086
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.161712408065796 seconds
Streaming imagenet data took 2.1892952919006348 seconds
Time for forward pass: 2.9940545558929443
Time for backpropagation: 0.049074649810791016
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.5455737113952637 seconds
Index: 0
Then, training+dataloading take 3.545748233795166 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3535802364349365
Time for copying to cuda: 0.018553495407104492
Time for forward pass: 0.07547330856323242
Time for backpropagation: 0.0038313865661621094
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5329515933990479 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2857587337493896 seconds
Streaming imagenet data took 2.351879835128784 seconds
Then, training+dataloading take 2.3601696491241455 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4026954174041748
Time for copying to cuda: 0.018445730209350586
Time for forward pass: 0.075531005859375
Time for backpropagation: 0.0027709007263183594
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5964624881744385 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1624715328216553 seconds
Streaming imagenet data took 2.189399480819702 seconds
Then, training+dataloading take 2.192662000656128 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35688114166259766
Time for copying to cuda: 0.01817488670349121
Time for forward pass: 0.07552933692932129
Time for backpropagation: 0.002689838409423828
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5507848262786865 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.132676124572754 seconds
Streaming imagenet data took 2.1602253913879395 seconds
Then, training+dataloading take 2.165046215057373 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3662905693054199
Time for copying to cuda: 0.018305540084838867
Time for forward pass: 0.07563042640686035
Time for backpropagation: 0.002782106399536133
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5571131706237793 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2205207347869873 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.2478652000427246 seconds
Then, training+dataloading take 2.252639055252075 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3607470989227295
Time for copying to cuda: 0.018411874771118164
Time for forward pass: 0.0753786563873291
Time for backpropagation: 0.002577066421508789
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5443069934844971 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0804197788238525 seconds
Streaming imagenet data took 2.107884645462036 seconds
Then, training+dataloading take 2.112130880355835 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40318870544433594
Time for copying to cuda: 0.018368244171142578
Time for forward pass: 0.07536435127258301
Time for backpropagation: 0.0026350021362304688
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5990545749664307 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.260709285736084 seconds
Streaming imagenet data took 2.288003921508789 seconds
Then, training+dataloading take 2.292299747467041 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3575925827026367
Time for copying to cuda: 0.018524646759033203
Time for forward pass: 0.07545185089111328
Time for backpropagation: 0.0026519298553466797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5452923774719238 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2329065799713135 seconds
Streaming imagenet data took 2.2597720623016357 seconds
Then, training+dataloading take 2.2641124725341797 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35904741287231445
Time for copying to cuda: 0.0184175968170166
Time for forward pass: 0.07538199424743652
Time for backpropagation: 0.002582073211669922
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5461785793304443 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2582855224609375 seconds
Streaming imagenet data took 2.2852296829223633 seconds
Then, training+dataloading take 2.2887821197509766 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37199902534484863
Time for copying to cuda: 0.018389463424682617
Time for forward pass: 0.07545614242553711
Time for backpropagation: 0.0028908252716064453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5567922592163086 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.248584508895874 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.2759718894958496 seconds
Then, training+dataloading take 2.2803845405578613 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3580915927886963
Time for copying to cuda: 0.018292903900146484
Time for forward pass: 0.07539558410644531
Time for backpropagation: 0.0026063919067382812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5439612865447998 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1789321899414062 seconds
Streaming imagenet data took 2.2452287673950195 seconds
Then, training+dataloading take 2.253030776977539 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.39902687072753906
Time for copying to cuda: 0.018291950225830078
Time for forward pass: 0.07535171508789062
Time for backpropagation: 0.0028786659240722656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5661120414733887 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.038156509399414 seconds
Streaming imagenet data took 2.065352439880371 seconds
Then, training+dataloading take 2.0685205459594727 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3599395751953125
Time for copying to cuda: 0.05507779121398926
Time for forward pass: 0.08610391616821289
Time for backpropagation: 0.003155231475830078
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.592796802520752 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.17146897315979 seconds
Streaming imagenet data took 2.198732376098633 seconds
Then, training+dataloading take 2.201555013656616 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36284589767456055
Time for copying to cuda: 0.0185394287109375
Time for forward pass: 0.07543444633483887
Time for backpropagation: 0.0025756359100341797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5456099510192871 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.185638427734375 seconds
Streaming imagenet data took 2.212977886199951 seconds
Then, training+dataloading take 2.2173705101013184 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3618786334991455
Time for copying to cuda: 0.018602371215820312
Time for forward pass: 0.07555675506591797
Time for backpropagation: 0.002755403518676758
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5445585250854492 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.193152904510498 seconds
Streaming imagenet data took 2.221153736114502 seconds
Then, training+dataloading take 2.2262439727783203 seconds

Epoch: 0
Time of next(dataloader) is: 0.3614952564239502
Time for copying to cuda: 0.018742084503173828
Time for forward pass: 0.07541155815124512
Time for backpropagation: 0.0026912689208984375
GPU memory for training: 1.2580008506774902                          

The whole process took 44.37713956832886 seconds
