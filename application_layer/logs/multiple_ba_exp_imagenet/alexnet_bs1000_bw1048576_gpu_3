Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2575446079109 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119047132.88684809 119047132.88684809
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6285364627838135 seconds
Streaming imagenet data took 1.6424174308776855 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3057591915130615
Time for copying to cuda: 0.009997844696044922
Memory occpied: (1550.0, 270.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5109939575195312 seconds
Streaming imagenet data took 1.5251750946044922 seconds
Memory occpied: (1550.0, 694.0)
Memory occpied: (1550.0, 1152.0)
Time for forward pass: 3.2398624420166016
Time for backpropagation: 0.04954862594604492
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.697448253631592 seconds
Index: 0
Then, training+dataloading take 3.697664737701416 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3325190544128418
Time for copying to cuda: 0.009488582611083984
Time for forward pass: 0.04969024658203125
Time for backpropagation: 0.0034644603729248047
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.4791111946105957 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6282382011413574 seconds
Streaming imagenet data took 1.6420741081237793 seconds
Then, training+dataloading take 1.644345998764038 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3745861053466797
Time for copying to cuda: 0.009299039840698242
Time for forward pass: 0.0492403507232666
Time for backpropagation: 0.002663135528564453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5551462173461914 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4929914474487305 seconds
Streaming imagenet data took 1.5067856311798096 seconds
Then, training+dataloading take 1.5091092586517334 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37637805938720703
Time for copying to cuda: 0.009367704391479492
Time for forward pass: 0.049303293228149414
Time for backpropagation: 0.0026924610137939453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5457172393798828 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5061523914337158 seconds
Streaming imagenet data took 1.519965410232544 seconds
Then, training+dataloading take 1.522306203842163 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41037726402282715
Time for copying to cuda: 0.009616374969482422
Time for forward pass: 0.0494992733001709
Time for backpropagation: 0.0027914047241210938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5580925941467285 seconds
Index: 4
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5236852169036865 seconds
Streaming imagenet data took 1.5753183364868164 seconds
Then, training+dataloading take 1.5795605182647705 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3298170566558838
Time for copying to cuda: 0.009368658065795898
Time for forward pass: 0.04940176010131836
Time for backpropagation: 0.0025947093963623047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47874021530151367 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5427522659301758 seconds
Streaming imagenet data took 1.5565261840820312 seconds
Then, training+dataloading take 1.5589466094970703 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3321390151977539
Time for copying to cuda: 0.009361982345581055
Time for forward pass: 0.04921722412109375
Time for backpropagation: 0.002628803253173828
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4789731502532959 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4878370761871338 seconds
Streaming imagenet data took 1.501650094985962 seconds
Then, training+dataloading take 1.5039548873901367 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33292555809020996
Time for copying to cuda: 0.009481668472290039
Time for forward pass: 0.04932141304016113
Time for backpropagation: 0.002651691436767578
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47095203399658203 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4926083087921143 seconds
Streaming imagenet data took 1.506821870803833 seconds
Then, training+dataloading take 1.5091657638549805 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41310930252075195
Time for copying to cuda: 0.009452104568481445
Time for forward pass: 0.049312591552734375
Time for backpropagation: 0.0026671886444091797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5530500411987305 seconds
Index: 8
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.511270523071289 seconds
Streaming imagenet data took 1.5637431144714355 seconds
Then, training+dataloading take 1.5680370330810547 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.34762024879455566
Time for copying to cuda: 0.009465217590332031
Time for forward pass: 0.0493624210357666
Time for backpropagation: 0.002747774124145508
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4770822525024414 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5150516033172607 seconds
Streaming imagenet data took 1.5292530059814453 seconds
Then, training+dataloading take 1.5318450927734375 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3514564037322998
Time for copying to cuda: 0.009549379348754883
Time for forward pass: 0.04931187629699707
Time for backpropagation: 0.0026290416717529297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4969136714935303 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4901742935180664 seconds
Streaming imagenet data took 1.5044267177581787 seconds
Then, training+dataloading take 1.5068371295928955 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35190248489379883
Time for copying to cuda: 0.009473800659179688
Time for forward pass: 0.049195051193237305
Time for backpropagation: 0.0026230812072753906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5237751007080078 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4531996250152588 seconds
Streaming imagenet data took 1.4673771858215332 seconds
Then, training+dataloading take 1.469822883605957 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38246893882751465
Time for copying to cuda: 0.009572029113769531
Time for forward pass: 0.04938459396362305
Time for backpropagation: 0.0027430057525634766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.552565336227417 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4889092445373535 seconds
Streaming imagenet data took 1.5029852390289307 seconds
Then, training+dataloading take 1.5053799152374268 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3895456790924072
Time for copying to cuda: 0.009421825408935547
Time for forward pass: 0.049237966537475586
Time for backpropagation: 0.002617359161376953
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5726103782653809 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4993910789489746 seconds
Streaming imagenet data took 1.5137314796447754 seconds
Then, training+dataloading take 1.5160610675811768 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37317776679992676
Time for copying to cuda: 0.009359359741210938
Time for forward pass: 0.04932975769042969
Time for backpropagation: 0.0026814937591552734
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5362331867218018 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4729633331298828 seconds
Streaming imagenet data took 1.487074613571167 seconds
Then, training+dataloading take 1.4893791675567627 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3802945613861084
Time for copying to cuda: 0.009427309036254883
Time for forward pass: 0.04926109313964844
Time for backpropagation: 0.0026671886444091797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5416579246520996 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.490363359451294 seconds
Streaming imagenet data took 1.5040874481201172 seconds
Then, training+dataloading take 1.5064632892608643 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.378262996673584
Time for copying to cuda: 0.00941610336303711
Time for forward pass: 0.04936075210571289
Time for backpropagation: 0.002681732177734375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5396714210510254 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5019915103912354 seconds
Streaming imagenet data took 1.5156729221343994 seconds
Then, training+dataloading take 1.5179715156555176 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37509775161743164
Time for copying to cuda: 0.009413957595825195
Time for forward pass: 0.049249887466430664
Time for backpropagation: 0.0026702880859375
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5571718215942383 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5114860534667969 seconds
Streaming imagenet data took 1.5256116390228271 seconds
Then, training+dataloading take 1.5279924869537354 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4123682975769043
Time for copying to cuda: 0.009344816207885742
Time for forward pass: 0.04927825927734375
Time for backpropagation: 0.002610921859741211
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5563907623291016 seconds
Index: 18
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5797545909881592 seconds
Streaming imagenet data took 1.5938706398010254 seconds
Then, training+dataloading take 1.595386028289795 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.344738245010376
Time for copying to cuda: 0.009633779525756836
Time for forward pass: 0.04945516586303711
Time for backpropagation: 0.0027174949645996094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4900538921356201 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5015778541564941 seconds
Streaming imagenet data took 1.5157980918884277 seconds
Then, training+dataloading take 1.5183007717132568 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34868502616882324
Time for copying to cuda: 0.009388923645019531
Time for forward pass: 0.04920697212219238
Time for backpropagation: 0.002889394760131836
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5006239414215088 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.458237886428833 seconds
Streaming imagenet data took 1.4724040031433105 seconds
Then, training+dataloading take 1.4748270511627197 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33666062355041504
Time for copying to cuda: 0.00942087173461914
Time for forward pass: 0.049299001693725586
Time for backpropagation: 0.0025413036346435547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48782849311828613 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.463886022567749 seconds
Streaming imagenet data took 1.4779820442199707 seconds
Then, training+dataloading take 1.48040771484375 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38718247413635254
Time for copying to cuda: 0.009571313858032227
Time for forward pass: 0.04952716827392578
Memory occpied: (2290.0, 1578.0)
Time for backpropagation: 0.002966165542602539
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5392839908599854 seconds
Index: 22
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.532423496246338 seconds
Streaming imagenet data took 1.546708345413208 seconds
Then, training+dataloading take 1.5489490032196045 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3733508586883545
Time for copying to cuda: 0.009444236755371094
Time for forward pass: 0.04932045936584473
Time for backpropagation: 0.0026192665100097656
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5203075408935547 seconds
Index: 23
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4719886779785156 seconds
Streaming imagenet data took 1.4856748580932617 seconds
Then, training+dataloading take 1.488088846206665 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3699166774749756
Time for copying to cuda: 0.009389638900756836
Time for forward pass: 0.04923653602600098
Time for backpropagation: 0.0026018619537353516
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5477414131164551 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4631085395812988 seconds
Streaming imagenet data took 1.4772560596466064 seconds
Then, training+dataloading take 1.4796407222747803 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3915705680847168
Time for copying to cuda: 0.009400129318237305
Time for forward pass: 0.04937624931335449
Time for backpropagation: 0.0027992725372314453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5535638332366943 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.5095152854919434 seconds
Streaming imagenet data took 1.5234582424163818 seconds
Then, training+dataloading take 1.525836706161499 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37121129035949707
Time for copying to cuda: 0.009381771087646484
Time for forward pass: 0.04925966262817383
Time for backpropagation: 0.002587556838989258
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5308592319488525 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4801228046417236 seconds
Streaming imagenet data took 1.4939517974853516 seconds
Then, training+dataloading take 1.496300458908081 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37709569931030273
Time for copying to cuda: 0.009378910064697266
Time for forward pass: 0.04933047294616699
Time for backpropagation: 0.002621889114379883
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5377964973449707 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.482107400894165 seconds
Streaming imagenet data took 1.4959123134613037 seconds
Then, training+dataloading take 1.498272180557251 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37340235710144043
Time for copying to cuda: 0.009337902069091797
Time for forward pass: 0.049271583557128906
Time for backpropagation: 0.0026552677154541016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.558657169342041 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.4919743537902832 seconds
Streaming imagenet data took 1.5056886672973633 seconds
Then, training+dataloading take 1.5081002712249756 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41435909271240234
Time for copying to cuda: 0.009355545043945312
Time for forward pass: 0.049384117126464844
Time for backpropagation: 0.002710580825805664
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5584096908569336 seconds
Index: 29
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.488184928894043 seconds
Streaming imagenet data took 1.5019488334655762 seconds
Then, training+dataloading take 1.5043437480926514 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3795931339263916
Time for copying to cuda: 0.009382247924804688
Time for forward pass: 0.049329519271850586
Time for backpropagation: 0.002694845199584961
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.539325475692749 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.501061201095581 seconds
Streaming imagenet data took 1.514887809753418 seconds
Then, training+dataloading take 1.5172510147094727 seconds

Epoch: 0
Time of next(dataloader) is: 0.37374162673950195
Time for copying to cuda: 0.009465932846069336
Time for forward pass: 0.049332380294799805
Time for backpropagation: 0.002840757369995117
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
The whole process took 58.9986035823822 seconds
