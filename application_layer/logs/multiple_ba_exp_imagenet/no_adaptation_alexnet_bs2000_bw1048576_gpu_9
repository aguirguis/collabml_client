Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.6074799431318 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119092999.61110617 119092999.61110617
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.399667739868164 seconds
Streaming imagenet data took 2.4583497047424316 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 3.0)
Time of next(dataloader) is: 0.36147546768188477
Time for copying to cuda: 0.01901984214782715
Memory occpied: (1586.0, 438.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2375786304473877 seconds
Streaming imagenet data took 2.3023974895477295 seconds
Memory occpied: (1586.0, 866.0)
Memory occpied: (1586.0, 1624.0)
Time for forward pass: 3.3281397819519043
Time for backpropagation: 0.04988384246826172
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.8301658630371094 seconds
Index: 0
Then, training+dataloading take 3.830408811569214 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35275793075561523
Time for copying to cuda: 0.018739700317382812
Time for forward pass: 0.07547855377197266
Time for backpropagation: 0.003735065460205078
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5431172847747803 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.323094606399536 seconds
Streaming imagenet data took 2.3502273559570312 seconds
Then, training+dataloading take 2.353091239929199 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36617016792297363
Time for copying to cuda: 0.018316984176635742
Time for forward pass: 0.07545685768127441
Time for backpropagation: 0.0026557445526123047
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5557477474212646 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3733787536621094 seconds
Streaming imagenet data took 2.401116371154785 seconds
Then, training+dataloading take 2.4056191444396973 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3660140037536621
Time for copying to cuda: 0.01865673065185547
Time for forward pass: 0.07553815841674805
Time for backpropagation: 0.0027060508728027344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5584354400634766 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2862887382507324 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.314830780029297 seconds
Then, training+dataloading take 2.3197336196899414 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38315558433532715
Time for copying to cuda: 0.0184323787689209
Time for forward pass: 0.07551741600036621
Time for backpropagation: 0.002766132354736328
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5665493011474609 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.133061408996582 seconds
Streaming imagenet data took 2.1604301929473877 seconds
Then, training+dataloading take 2.1648101806640625 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4086425304412842
Time for copying to cuda: 0.018876314163208008
Time for forward pass: 0.07550263404846191
Time for backpropagation: 0.002888917922973633
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6089363098144531 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.316514730453491 seconds
Streaming imagenet data took 2.3436923027038574 seconds
Then, training+dataloading take 2.347942590713501 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3677811622619629
Time for copying to cuda: 0.01841592788696289
Time for forward pass: 0.07552003860473633
Time for backpropagation: 0.0028526782989501953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5771582126617432 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.325188398361206 seconds
Streaming imagenet data took 2.352421522140503 seconds
Then, training+dataloading take 2.356738567352295 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36850833892822266
Time for copying to cuda: 0.01842212677001953
Time for forward pass: 0.07546091079711914
Time for backpropagation: 0.002678394317626953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5625243186950684 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3724377155303955 seconds
Streaming imagenet data took 2.399695873260498 seconds
Then, training+dataloading take 2.40388822555542 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3844928741455078
Time for copying to cuda: 0.018476247787475586
Time for forward pass: 0.07552766799926758
Time for backpropagation: 0.002705097198486328
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.568314790725708 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2358224391937256 seconds
Streaming imagenet data took 2.2626991271972656 seconds
Then, training+dataloading take 2.267076253890991 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37780070304870605
Time for copying to cuda: 0.018485546112060547
Time for forward pass: 0.07551789283752441
Time for backpropagation: 0.002709627151489258
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5615842342376709 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.322593927383423 seconds
Streaming imagenet data took 2.3499534130096436 seconds
Then, training+dataloading take 2.353595733642578 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37412571907043457
Time for copying to cuda: 0.018419742584228516
Time for forward pass: 0.07541584968566895
Time for backpropagation: 0.002644062042236328
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5563509464263916 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2808640003204346 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.3077569007873535 seconds
Then, training+dataloading take 2.3123302459716797 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36255478858947754
Time for copying to cuda: 0.018592119216918945
Time for forward pass: 0.07548332214355469
Time for backpropagation: 0.0027077198028564453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5473880767822266 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1335067749023438 seconds
Streaming imagenet data took 2.161127805709839 seconds
Then, training+dataloading take 2.165499687194824 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40492844581604004
Time for copying to cuda: 0.018584251403808594
Time for forward pass: 0.07548308372497559
Time for backpropagation: 0.002634286880493164
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6028153896331787 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.189993381500244 seconds
Streaming imagenet data took 2.217275619506836 seconds
Then, training+dataloading take 2.2217445373535156 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3711721897125244
Time for copying to cuda: 0.018454551696777344
Time for forward pass: 0.07555079460144043
Time for backpropagation: 0.0029337406158447266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5541708469390869 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.201458215713501 seconds
Streaming imagenet data took 2.228905439376831 seconds
Then, training+dataloading take 2.2318360805511475 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3714301586151123
Time for copying to cuda: 0.0184633731842041
Time for forward pass: 0.07555556297302246
Time for backpropagation: 0.0026793479919433594
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5579345226287842 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.308589220046997 seconds
Streaming imagenet data took 2.3359005451202393 seconds
Then, training+dataloading take 2.341052770614624 seconds

Epoch: 0
Time of next(dataloader) is: 0.3647763729095459
Time for copying to cuda: 0.01843857765197754
Time for forward pass: 0.0753476619720459
Time for backpropagation: 0.0025463104248046875
GPU memory for training: 1.2580008506774902                          

The whole process took 45.88765573501587 seconds
