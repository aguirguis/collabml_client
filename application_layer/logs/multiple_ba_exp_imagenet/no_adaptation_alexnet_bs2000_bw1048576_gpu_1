Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.5764115650592 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118957855.41665544 118957855.41665544
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.311596393585205 seconds
Streaming imagenet data took 2.369863986968994 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37110257148742676
Time for copying to cuda: 0.01890110969543457
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.179579734802246 seconds
Streaming imagenet data took 2.2071855068206787 seconds
Time for forward pass: 2.959510564804077
Time for backpropagation: 0.04926753044128418
GPU memory for training: 1.102445125579834                          

Memory occpied: (1514.0, 3.0)
One training iteration takes: 3.4733588695526123 seconds
Index: 0
Then, training+dataloading take 3.4735963344573975 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3476066589355469
Time for copying to cuda: 0.018572568893432617
Time for forward pass: 0.07531213760375977
Time for backpropagation: 0.003587007522583008
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5245561599731445 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.28591251373291 seconds
Streaming imagenet data took 2.3512344360351562 seconds
Then, training+dataloading take 2.359555244445801 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3646965026855469
Time for copying to cuda: 0.0180814266204834
Time for forward pass: 0.07543468475341797
Time for backpropagation: 0.0026497840881347656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5476598739624023 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.173912286758423 seconds
Streaming imagenet data took 2.2007408142089844 seconds
Then, training+dataloading take 2.205458879470825 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3955235481262207
Time for copying to cuda: 0.018283367156982422
Time for forward pass: 0.07548809051513672
Time for backpropagation: 0.0026221275329589844
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6088471412658691 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.214061737060547 seconds
Streaming imagenet data took 2.2421295642852783 seconds
Then, training+dataloading take 2.246411085128784 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35849714279174805
Time for copying to cuda: 0.01846909523010254
Time for forward pass: 0.07541012763977051
Time for backpropagation: 0.002669095993041992
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5534615516662598 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.206986904144287 seconds
Streaming imagenet data took 2.2348551750183105 seconds
Then, training+dataloading take 2.2401599884033203 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3567066192626953
Time for copying to cuda: 0.018472909927368164
Time for forward pass: 0.07543349266052246
Time for backpropagation: 0.0026111602783203125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5485823154449463 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.212573289871216 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.2409780025482178 seconds
Then, training+dataloading take 2.245950937271118 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.363889217376709
Time for copying to cuda: 0.018387556076049805
Time for forward pass: 0.07554411888122559
Time for backpropagation: 0.002641439437866211
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5308513641357422 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1675217151641846 seconds
Streaming imagenet data took 2.2335033416748047 seconds
Then, training+dataloading take 2.2415013313293457 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.39968013763427734
Time for copying to cuda: 0.0183870792388916
Time for forward pass: 0.07555937767028809
Time for backpropagation: 0.0027441978454589844
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5833303928375244 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1307284832000732 seconds
Streaming imagenet data took 2.1580021381378174 seconds
Then, training+dataloading take 2.1625585556030273 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3620641231536865
Time for copying to cuda: 0.018632888793945312
Time for forward pass: 0.08198261260986328
Time for backpropagation: 0.003319263458251953
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5504436492919922 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1950743198394775 seconds
Streaming imagenet data took 2.2220208644866943 seconds
Then, training+dataloading take 2.226421356201172 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36098527908325195
Time for copying to cuda: 0.018449068069458008
Time for forward pass: 0.07552742958068848
Time for backpropagation: 0.0028657913208007812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5708460807800293 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1088991165161133 seconds
Streaming imagenet data took 2.1364126205444336 seconds
Then, training+dataloading take 2.141442060470581 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3591909408569336
Time for copying to cuda: 0.01853179931640625
Time for forward pass: 0.07551431655883789
Time for backpropagation: 0.002729654312133789
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.54372239112854 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0764927864074707 seconds
Streaming imagenet data took 2.1036767959594727 seconds
Then, training+dataloading take 2.1085565090179443 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40118885040283203
Time for copying to cuda: 0.018543004989624023
Time for forward pass: 0.07550287246704102
Time for backpropagation: 0.0027256011962890625
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5768210887908936 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2149817943573 seconds
Streaming imagenet data took 2.2427804470062256 seconds
Then, training+dataloading take 2.2470405101776123 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3612985610961914
Time for copying to cuda: 0.018553495407104492
Time for forward pass: 0.07560896873474121
Time for backpropagation: 0.0027573108673095703
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5639348030090332 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.209144115447998 seconds
Streaming imagenet data took 2.2361698150634766 seconds
Then, training+dataloading take 2.2406487464904785 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3638169765472412
Time for copying to cuda: 0.01855945587158203
Time for forward pass: 0.07542634010314941
Time for backpropagation: 0.0026078224182128906
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5499403476715088 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.176187515258789 seconds
Streaming imagenet data took 2.203493356704712 seconds
Then, training+dataloading take 2.2085702419281006 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35812926292419434
Time for copying to cuda: 0.018474340438842773
Time for forward pass: 0.0754997730255127
Time for backpropagation: 0.002664327621459961
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5384519100189209 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.048184871673584 seconds
Streaming imagenet data took 2.07539439201355 seconds
Then, training+dataloading take 2.079873561859131 seconds

Epoch: 0
Time of next(dataloader) is: 0.4021923542022705
Time for copying to cuda: 0.01851344108581543
Time for forward pass: 0.07542991638183594
Time for backpropagation: 0.002643585205078125
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
The whole process took 44.94620370864868 seconds
