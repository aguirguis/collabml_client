Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4244131369778 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119069004.67868996 119069004.67868996
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2545626163482666 seconds
Streaming imagenet data took 2.2821028232574463 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3574080467224121
Time for copying to cuda: 0.01903247833251953
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1431655883789062 seconds
Streaming imagenet data took 2.1704533100128174 seconds
Time for forward pass: 3.031479597091675
Time for backpropagation: 0.04912686347961426
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.5681312084198 seconds
Index: 0
Then, training+dataloading take 3.568329334259033 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.34407758712768555
Time for copying to cuda: 0.018601179122924805
Time for forward pass: 0.07306075096130371
Time for backpropagation: 0.0034341812133789062
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5235610008239746 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2087717056274414 seconds
Streaming imagenet data took 2.2364792823791504 seconds
Then, training+dataloading take 2.2409260272979736 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40487122535705566
Time for copying to cuda: 0.018400192260742188
Time for forward pass: 0.07554459571838379
Time for backpropagation: 0.002669811248779297
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6192541122436523 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.167968511581421 seconds
Streaming imagenet data took 2.19572377204895 seconds
Then, training+dataloading take 2.200798511505127 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3729434013366699
Time for copying to cuda: 0.01848459243774414
Time for forward pass: 0.07540369033813477
Time for backpropagation: 0.0025839805603027344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5563817024230957 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1939918994903564 seconds
Streaming imagenet data took 2.2221200466156006 seconds
Then, training+dataloading take 2.227238655090332 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36293935775756836
Time for copying to cuda: 0.01814746856689453
Time for forward pass: 0.07541894912719727
Time for backpropagation: 0.002653360366821289
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5366194248199463 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1860954761505127 seconds
Streaming imagenet data took 2.2525649070739746 seconds
Then, training+dataloading take 2.26070237159729 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.37131762504577637
Time for copying to cuda: 0.018557071685791016
Time for forward pass: 0.07556414604187012
Time for backpropagation: 0.0027055740356445312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5562536716461182 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.08036470413208 seconds
Streaming imagenet data took 2.1082370281219482 seconds
Then, training+dataloading take 2.1128432750701904 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4030578136444092
Time for copying to cuda: 0.018271684646606445
Time for forward pass: 0.07542204856872559
Time for backpropagation: 0.0026564598083496094
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6221103668212891 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.136537790298462 seconds
Streaming imagenet data took 2.1638636589050293 seconds
Then, training+dataloading take 2.1684064865112305 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38231325149536133
Time for copying to cuda: 0.018509864807128906
Time for forward pass: 0.07561111450195312
Time for backpropagation: 0.0027120113372802734
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5699672698974609 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.191500663757324 seconds
Streaming imagenet data took 2.2185170650482178 seconds
Then, training+dataloading take 2.2236647605895996 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37082386016845703
Time for copying to cuda: 0.01840972900390625
Time for forward pass: 0.07543492317199707
Time for backpropagation: 0.002638101577758789
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5603353977203369 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0574257373809814 seconds
Streaming imagenet data took 2.084789752960205 seconds
Then, training+dataloading take 2.0892276763916016 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4154939651489258
Time for copying to cuda: 0.01848769187927246
Time for forward pass: 0.07555055618286133
Time for backpropagation: 0.002758026123046875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6346838474273682 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1533021926879883 seconds
Streaming imagenet data took 2.180668354034424 seconds
Then, training+dataloading take 2.184967041015625 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3692946434020996
Time for copying to cuda: 0.01819777488708496
Time for forward pass: 0.07553219795227051
Time for backpropagation: 0.002873659133911133
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5614364147186279 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2305908203125 seconds
Streaming imagenet data took 2.2579448223114014 seconds
Then, training+dataloading take 2.2630863189697266 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36928224563598633
Time for copying to cuda: 0.018385648727416992
Time for forward pass: 0.07557320594787598
Time for backpropagation: 0.002753734588623047
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.555527925491333 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1949288845062256 seconds
Streaming imagenet data took 2.260948419570923 seconds
Then, training+dataloading take 2.2689006328582764 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3723170757293701
Time for copying to cuda: 0.01833820343017578
Time for forward pass: 0.07541203498840332
Time for backpropagation: 0.002628803253173828
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5624382495880127 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.06384015083313 seconds
Streaming imagenet data took 2.090834140777588 seconds
Then, training+dataloading take 2.0939230918884277 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41995692253112793
Time for copying to cuda: 0.018282413482666016
Time for forward pass: 0.07551407814025879
Time for backpropagation: 0.0026078224182128906
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6277215480804443 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1605374813079834 seconds
Streaming imagenet data took 2.1879804134368896 seconds
Then, training+dataloading take 2.1926040649414062 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36422133445739746
Time for copying to cuda: 0.018294572830200195
Time for forward pass: 0.07549834251403809
Time for backpropagation: 0.0026679039001464844
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5506472587585449 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.027627944946289 seconds
Streaming imagenet data took 2.0943896770477295 seconds
Then, training+dataloading take 2.1020264625549316 seconds

Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.37196993827819824
Time for copying to cuda: 0.018343687057495117
Time for forward pass: 0.07540774345397949
Time for backpropagation: 0.0027854442596435547
GPU memory for training: 1.2580008506774902                          

The whole process took 44.011582136154175 seconds
