Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.4564664251504 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118942133.96727732 118942133.96727732
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.280787944793701 seconds
Streaming imagenet data took 2.3079869747161865 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 3.0)
Time of next(dataloader) is: 0.38780927658081055
Time for copying to cuda: 0.019025087356567383
Memory occpied: (1586.0, 466.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2659709453582764 seconds
Streaming imagenet data took 2.293950080871582 seconds
Memory occpied: (1586.0, 874.0)
Time for forward pass: 3.2671124935150146
Time for backpropagation: 0.05330061912536621
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.8271126747131348 seconds
Index: 0
Then, training+dataloading take 3.827432155609131 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2100.0, 1624.0)
Time of next(dataloader) is: 0.3551304340362549
Time for copying to cuda: 0.018590927124023438
Time for forward pass: 0.07539033889770508
Time for backpropagation: 0.0033953189849853516
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5382528305053711 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.4357566833496094 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.463139533996582 seconds
Then, training+dataloading take 2.468306064605713 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3749246597290039
Time for copying to cuda: 0.018451929092407227
Time for forward pass: 0.07564878463745117
Time for backpropagation: 0.002682209014892578
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5627164840698242 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2990617752075195 seconds
Streaming imagenet data took 2.3670740127563477 seconds
Then, training+dataloading take 2.374694347381592 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3771827220916748
Time for copying to cuda: 0.01842951774597168
Time for forward pass: 0.0756523609161377
Time for backpropagation: 0.0026938915252685547
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.570016622543335 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0999507904052734 seconds
Streaming imagenet data took 2.1276519298553467 seconds
Then, training+dataloading take 2.1319339275360107 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.419445276260376
Time for copying to cuda: 0.01844644546508789
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07574677467346191
Time for backpropagation: 0.0027284622192382812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6153833866119385 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.200286626815796 seconds
Streaming imagenet data took 2.2272400856018066 seconds
Then, training+dataloading take 2.231736183166504 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37247490882873535
Time for copying to cuda: 0.01840829849243164
Time for forward pass: 0.09972119331359863
Time for backpropagation: 0.00328826904296875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.599921464920044 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.304046869277954 seconds
Streaming imagenet data took 2.3316478729248047 seconds
Then, training+dataloading take 2.3361449241638184 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37515854835510254
Time for copying to cuda: 0.018309593200683594
Time for forward pass: 0.07562971115112305
Time for backpropagation: 0.002904653549194336
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5446577072143555 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2537903785705566 seconds
Streaming imagenet data took 2.2810420989990234 seconds
Then, training+dataloading take 2.285360097885132 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37421083450317383
Time for copying to cuda: 0.018531084060668945
Time for forward pass: 0.07561230659484863
Time for backpropagation: 0.0027251243591308594
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5608580112457275 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3038415908813477 seconds
Streaming imagenet data took 2.330869197845459 seconds
Then, training+dataloading take 2.3359906673431396 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37031054496765137
Time for copying to cuda: 0.018178701400756836
Time for forward pass: 0.07543063163757324
Time for backpropagation: 0.002612590789794922
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5538320541381836 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.212054491043091 seconds
Streaming imagenet data took 2.2394325733184814 seconds
Then, training+dataloading take 2.2441065311431885 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.4075601100921631
Time for copying to cuda: 0.01873183250427246
Time for forward pass: 0.07550406455993652
Time for backpropagation: 0.002586841583251953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5919194221496582 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2301642894744873 seconds
Streaming imagenet data took 2.298621416091919 seconds
Then, training+dataloading take 2.3065481185913086 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.4373650550842285
Time for copying to cuda: 0.01856255531311035
Time for forward pass: 0.07554769515991211
Time for backpropagation: 0.0026674270629882812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6343967914581299 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.196589946746826 seconds
Streaming imagenet data took 2.2239158153533936 seconds
Then, training+dataloading take 2.2284979820251465 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3849368095397949
Time for copying to cuda: 0.018705129623413086
Time for forward pass: 0.07692289352416992
Time for backpropagation: 0.0037000179290771484
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5865817070007324 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.168849468231201 seconds
Streaming imagenet data took 2.196176528930664 seconds
Then, training+dataloading take 2.2006123065948486 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38593602180480957
Time for copying to cuda: 0.018657684326171875
Time for forward pass: 0.0756521224975586
Time for backpropagation: 0.0026824474334716797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6091163158416748 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.210146427154541 seconds
Streaming imagenet data took 2.2380199432373047 seconds
Then, training+dataloading take 2.2434191703796387 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3835766315460205
Time for copying to cuda: 0.01866745948791504
Time for forward pass: 0.07546305656433105
Time for backpropagation: 0.0025663375854492188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5538313388824463 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2642290592193604 seconds
Streaming imagenet data took 2.2917439937591553 seconds
Then, training+dataloading take 2.297227382659912 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39617323875427246
Time for copying to cuda: 0.01868462562561035
Time for forward pass: 0.07544493675231934
Time for backpropagation: 0.0026259422302246094
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5898959636688232 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0938615798950195 seconds
Streaming imagenet data took 2.1625943183898926 seconds
Then, training+dataloading take 2.1707136631011963 seconds

Epoch: 0
Time of next(dataloader) is: 0.42035865783691406
Time for copying to cuda: 0.01867079734802246
Time for forward pass: 0.07542729377746582
Time for backpropagation: 0.002577066421508789
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
The whole process took 46.065555572509766 seconds
