Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=4000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3257753578232 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119056076.0277006 119056076.0277006
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Candidate split  16
Server, client, server+client, vanilla  299.09765625 826.474609375 1125.572265625 8969.052734375
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 4000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.3202176094055176 seconds
Streaming imagenet data took 2.375645160675049 seconds
The mode is:  split
Start 4000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.372098445892334
Time for copying to cuda: 0.016829967498779297
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.2126288414001465 seconds
Streaming imagenet data took 2.238027334213257 seconds
Time for forward pass: 2.9629693031311035
Time for backpropagation: 0.0519862174987793
GPU memory for training: 1.089247226715088                          

Memory occpied: (1514.0, 3.0)
One training iteration takes: 3.479267120361328 seconds
Index: 0
Then, training+dataloading take 3.4795119762420654 seconds
The mode is:  split
Start 8000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34958839416503906
Time for copying to cuda: 0.016573667526245117
Time for forward pass: 0.051779985427856445
Time for backpropagation: 0.002624034881591797
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.49738144874572754 seconds
Index: 1
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.3636651039123535 seconds
Memory occpied: (2350.0, 1764.0)
Streaming imagenet data took 2.389035224914551 seconds
Then, training+dataloading take 2.392080307006836 seconds
The mode is:  split
Start 12000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.366131067276001
Time for copying to cuda: 0.0164334774017334
Time for forward pass: 0.05609273910522461
Time for backpropagation: 0.002725839614868164
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5239083766937256 seconds
Index: 2
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.0016655921936035 seconds
Streaming imagenet data took 2.026235818862915 seconds
Then, training+dataloading take 2.0278987884521484 seconds
The mode is:  split
Start 16000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42214202880859375
Time for copying to cuda: 0.016564607620239258
Time for forward pass: 0.056053876876831055
Time for backpropagation: 0.0026535987854003906
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.6079227924346924 seconds
Index: 3
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.114647150039673 seconds
Streaming imagenet data took 2.1397218704223633 seconds
Then, training+dataloading take 2.141422748565674 seconds
The mode is:  split
Start 20000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36771297454833984
Time for copying to cuda: 0.016498327255249023
Time for forward pass: 0.056006431579589844
Time for backpropagation: 0.0026094913482666016
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5274593830108643 seconds
Index: 4
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.070711374282837 seconds
Streaming imagenet data took 2.133793592453003 seconds
Then, training+dataloading take 2.146228313446045 seconds
The mode is:  split
Start 24000, end 28000, post_step 1000


Epoch: 0
Memory occpied: (2350.0, 1764.0)
Time of next(dataloader) is: 0.3732306957244873
Time for copying to cuda: 0.01643967628479004
Time for forward pass: 0.05601763725280762
Time for backpropagation: 0.0026264190673828125
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.538783073425293 seconds
Index: 5
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.1787240505218506 seconds
Streaming imagenet data took 2.2040741443634033 seconds
Then, training+dataloading take 2.2058584690093994 seconds
The mode is:  split
Start 28000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40752339363098145
Time for copying to cuda: 0.0163726806640625
Time for forward pass: 0.055968523025512695
Time for backpropagation: 0.002572774887084961
GPU memory for training: 1.2448029518127441                          

One training iteration takes: 0.5840659141540527 seconds
Index: 6
Memory occpied: (2350.0, 1764.0)
Memory occpied: (2350.0, 1764.0)
Read 62.638710021972656 MBs for this batch
Executing all posts took 2.1231467723846436 seconds
Streaming imagenet data took 2.1477322578430176 seconds
Then, training+dataloading take 2.149374485015869 seconds

Epoch: 0
Time of next(dataloader) is: 0.37856149673461914
Time for copying to cuda: 0.01632094383239746
Time for forward pass: 0.056005001068115234
Time for backpropagation: 0.0027589797973632812
GPU memory for training: 1.2448029518127441                          

The whole process took 26.03502058982849 seconds
