Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.919885189091 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119002875.19150454 119002875.19150454
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 440.30517578125 739.40283203125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8259727954864502 seconds
Streaming imagenet data took 1.8396570682525635 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.2863759994506836
Time for copying to cuda: 0.010119915008544922
Memory occpied: (1550.0, 202.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7857394218444824 seconds
Streaming imagenet data took 1.8372905254364014 seconds
Memory occpied: (1550.0, 618.0)
Memory occpied: (1550.0, 1086.0)
Time for forward pass: 3.2757463455200195
Time for backpropagation: 0.049215078353881836
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.6798386573791504 seconds
Index: 0
Then, training+dataloading take 3.680025339126587 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3242835998535156
Time for copying to cuda: 0.009464025497436523
Time for forward pass: 0.049692630767822266
Time for backpropagation: 0.0033371448516845703
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.47331976890563965 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8785269260406494 seconds
Streaming imagenet data took 1.8922717571258545 seconds
Then, training+dataloading take 1.8947782516479492 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33216094970703125
Time for copying to cuda: 0.009579896926879883
Time for forward pass: 0.04918503761291504
Time for backpropagation: 0.0025701522827148438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47919130325317383 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6853210926055908 seconds
Streaming imagenet data took 1.6994616985321045 seconds
Then, training+dataloading take 1.7020766735076904 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3337240219116211
Time for copying to cuda: 0.009536027908325195
Time for forward pass: 0.04931783676147461
Time for backpropagation: 0.0027511119842529297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5172019004821777 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.727031946182251 seconds
Streaming imagenet data took 1.778954267501831 seconds
Then, training+dataloading take 1.783416986465454 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33037710189819336
Time for copying to cuda: 0.009635448455810547
Time for forward pass: 0.049271583557128906
Time for backpropagation: 0.0026159286499023438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4750990867614746 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7386343479156494 seconds
Streaming imagenet data took 1.7526726722717285 seconds
Then, training+dataloading take 1.7554755210876465 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3334331512451172
Time for copying to cuda: 0.009668827056884766
Time for forward pass: 0.04939460754394531
Time for backpropagation: 0.002857685089111328
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4841008186340332 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6922752857208252 seconds
Streaming imagenet data took 1.7060844898223877 seconds
Then, training+dataloading take 1.7087044715881348 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3665595054626465
Time for copying to cuda: 0.009438753128051758
Time for forward pass: 0.04922747611999512
Time for backpropagation: 0.0026006698608398438
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5445003509521484 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7047545909881592 seconds
Streaming imagenet data took 1.7563951015472412 seconds
Then, training+dataloading take 1.760819673538208 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33698058128356934
Time for copying to cuda: 0.00941777229309082
Time for forward pass: 0.04926276206970215
Time for backpropagation: 0.003080129623413086
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4884374141693115 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.708913803100586 seconds
Streaming imagenet data took 1.7228562831878662 seconds
Then, training+dataloading take 1.725653886795044 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33586978912353516
Time for copying to cuda: 0.009510278701782227
Time for forward pass: 0.04932045936584473
Time for backpropagation: 0.002594470977783203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4904053211212158 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.701500415802002 seconds
Streaming imagenet data took 1.7155568599700928 seconds
Then, training+dataloading take 1.7181591987609863 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3794388771057129
Time for copying to cuda: 0.009583473205566406
Time for forward pass: 0.0493016242980957
Time for backpropagation: 0.0027322769165039062
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5567481517791748 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7168805599212646 seconds
Streaming imagenet data took 1.7693686485290527 seconds
Then, training+dataloading take 1.773782730102539 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3311483860015869
Time for copying to cuda: 0.009556770324707031
Time for forward pass: 0.04924750328063965
Time for backpropagation: 0.0025339126586914062
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4808034896850586 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6870853900909424 seconds
Streaming imagenet data took 1.7011916637420654 seconds
Then, training+dataloading take 1.7039554119110107 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33323216438293457
Time for copying to cuda: 0.009509801864624023
Time for forward pass: 0.049304962158203125
Time for backpropagation: 0.0026090145111083984
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48051905632019043 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.719672441482544 seconds
Streaming imagenet data took 1.7334868907928467 seconds
Then, training+dataloading take 1.7361814975738525 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3737015724182129
Time for copying to cuda: 0.009502410888671875
Time for forward pass: 0.04929327964782715
Time for backpropagation: 0.002668619155883789
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5404341220855713 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7824833393096924 seconds
Streaming imagenet data took 1.7968456745147705 seconds
Then, training+dataloading take 1.798588514328003 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3318212032318115
Time for copying to cuda: 0.009562969207763672
Time for forward pass: 0.04926919937133789
Time for backpropagation: 0.002637624740600586
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4736762046813965 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.719850778579712 seconds
Streaming imagenet data took 1.7335336208343506 seconds
Then, training+dataloading take 1.7361526489257812 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34194016456604004
Time for copying to cuda: 0.009362936019897461
Time for forward pass: 0.04930925369262695
Time for backpropagation: 0.002598285675048828
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4852409362792969 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6812107563018799 seconds
Streaming imagenet data took 1.6949388980865479 seconds
Then, training+dataloading take 1.6975162029266357 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.4272940158843994
Time for copying to cuda: 0.009453773498535156
Time for forward pass: 0.04925417900085449
Time for backpropagation: 0.0025870800018310547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5717103481292725 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7816855907440186 seconds
Streaming imagenet data took 1.7955353260040283 seconds
Then, training+dataloading take 1.7979850769042969 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33031797409057617
Time for copying to cuda: 0.009435176849365234
Time for forward pass: 0.04922199249267578
Time for backpropagation: 0.0026121139526367188
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4578585624694824 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6978082656860352 seconds
Streaming imagenet data took 1.7114951610565186 seconds
Then, training+dataloading take 1.713996410369873 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3458280563354492
Time for copying to cuda: 0.009628057479858398
Time for forward pass: 0.04957771301269531
Time for backpropagation: 0.04057598114013672
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5189743041992188 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7890057563781738 seconds
Streaming imagenet data took 1.8030991554260254 seconds
Then, training+dataloading take 1.8055047988891602 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33628344535827637
Time for copying to cuda: 0.009336233139038086
Time for forward pass: 0.049341440200805664
Time for backpropagation: 0.0026404857635498047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4799809455871582 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6863315105438232 seconds
Streaming imagenet data took 1.6999945640563965 seconds
Then, training+dataloading take 1.7024235725402832 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33297252655029297
Time for copying to cuda: 0.009367942810058594
Time for forward pass: 0.049257755279541016
Time for backpropagation: 0.002809286117553711
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.47168993949890137 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7264196872711182 seconds
Streaming imagenet data took 1.779102087020874 seconds
Then, training+dataloading take 1.783437967300415 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3371419906616211
Time for copying to cuda: 0.009472370147705078
Time for forward pass: 0.04935884475708008
Time for backpropagation: 0.002620220184326172
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4918348789215088 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6778688430786133 seconds
Streaming imagenet data took 1.6919941902160645 seconds
Then, training+dataloading take 1.6946277618408203 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33335256576538086
Time for copying to cuda: 0.009508609771728516
Time for forward pass: 0.04935765266418457
Time for backpropagation: 0.0026535987854003906
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4797675609588623 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7032718658447266 seconds
Streaming imagenet data took 1.7174088954925537 seconds
Then, training+dataloading take 1.7199387550354004 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3934366703033447
Time for copying to cuda: 0.00945281982421875
Time for forward pass: 0.04922056198120117
Time for backpropagation: 0.0025615692138671875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5538575649261475 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7141120433807373 seconds
Streaming imagenet data took 1.7661311626434326 seconds
Then, training+dataloading take 1.7704861164093018 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3417329788208008
Time for copying to cuda: 0.009383440017700195
Time for forward pass: 0.04926180839538574
Time for backpropagation: 0.002815723419189453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4702925682067871 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7414302825927734 seconds
Streaming imagenet data took 1.755340337753296 seconds
Then, training+dataloading take 1.7580444812774658 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3358879089355469
Time for copying to cuda: 0.00940847396850586
Time for forward pass: 0.049242496490478516
Time for backpropagation: 0.0025746822357177734
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48277854919433594 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6752526760101318 seconds
Streaming imagenet data took 1.689000129699707 seconds
Then, training+dataloading take 1.6914639472961426 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.373093843460083
Time for copying to cuda: 0.009404420852661133
Time for forward pass: 0.04926466941833496
Time for backpropagation: 0.0025980472564697266
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5574071407318115 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.714433193206787 seconds
Streaming imagenet data took 1.7667148113250732 seconds
Then, training+dataloading take 1.77105712890625 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.36594128608703613
Time for copying to cuda: 0.0094757080078125
Time for forward pass: 0.049221038818359375
Time for backpropagation: 0.0025954246520996094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5125024318695068 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6889379024505615 seconds
Streaming imagenet data took 1.7031059265136719 seconds
Then, training+dataloading take 1.705779790878296 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33611464500427246
Time for copying to cuda: 0.009429454803466797
Time for forward pass: 0.0493466854095459
Time for backpropagation: 0.0026204586029052734
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4747939109802246 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.679445743560791 seconds
Streaming imagenet data took 1.6936285495758057 seconds
Then, training+dataloading take 1.6961829662322998 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3916964530944824
Time for copying to cuda: 0.009796857833862305
Time for forward pass: 0.04930520057678223
Time for backpropagation: 0.0027861595153808594
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.572906494140625 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.726623296737671 seconds
Streaming imagenet data took 1.7791781425476074 seconds
Then, training+dataloading take 1.7834722995758057 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3439774513244629
Time for copying to cuda: 0.009453296661376953
Time for forward pass: 0.049346208572387695
Time for backpropagation: 0.0026340484619140625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4878425598144531 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.67484450340271 seconds
Streaming imagenet data took 1.688866376876831 seconds
Then, training+dataloading take 1.6915857791900635 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3451685905456543
Time for copying to cuda: 0.009462118148803711
Time for forward pass: 0.049286603927612305
Time for backpropagation: 0.0026721954345703125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4924297332763672 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.666426181793213 seconds
Streaming imagenet data took 1.680199146270752 seconds
Then, training+dataloading take 1.6827630996704102 seconds

Epoch: 0
Time of next(dataloader) is: 0.398730993270874
Time for copying to cuda: 0.009491443634033203
Time for forward pass: 0.04957079887390137
Memory occpied: (2290.0, 1578.0)
Time for backpropagation: 0.002828359603881836
GPU memory for training: 1.1639018058776855                          

The whole process took 65.70535349845886 seconds
