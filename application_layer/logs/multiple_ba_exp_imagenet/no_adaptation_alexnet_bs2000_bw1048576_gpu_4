Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3330400824624 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119057028.22968851 119057028.22968851
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.295596122741699 seconds
Streaming imagenet data took 2.3545148372650146 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3661341667175293
Time for copying to cuda: 0.018960237503051758
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.306731939315796 seconds
Streaming imagenet data took 2.3340470790863037 seconds
Time for forward pass: 2.9675514698028564
Time for backpropagation: 0.049401283264160156
GPU memory for training: 1.102445125579834                          

Memory occpied: (1514.0, 3.0)
One training iteration takes: 3.4800593852996826 seconds
Index: 0
Then, training+dataloading take 3.4803531169891357 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34644389152526855
Time for copying to cuda: 0.01856255531311035
Time for forward pass: 0.06994152069091797
Time for backpropagation: 0.0036973953247070312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5061123371124268 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.4171247482299805 seconds
Streaming imagenet data took 2.4442875385284424 seconds
Then, training+dataloading take 2.4493706226348877 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37220263481140137
Time for copying to cuda: 0.01823902130126953
Time for forward pass: 0.07548809051513672
Time for backpropagation: 0.0027570724487304688
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5697357654571533 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.213320016860962 seconds
Streaming imagenet data took 2.2791943550109863 seconds
Then, training+dataloading take 2.286766529083252 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.35939645767211914
Time for copying to cuda: 0.018445253372192383
Time for forward pass: 0.07535433769226074
Time for backpropagation: 0.0025861263275146484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5524702072143555 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2362678050994873 seconds
Streaming imagenet data took 2.264012336730957 seconds
Then, training+dataloading take 2.2683098316192627 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3984103202819824
Time for copying to cuda: 0.01832294464111328
Time for forward pass: 0.07543587684631348
Time for backpropagation: 0.0026879310607910156
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5962374210357666 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3075602054595947 seconds
Streaming imagenet data took 2.3347253799438477 seconds
Then, training+dataloading take 2.3393867015838623 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3788156509399414
Time for copying to cuda: 0.018652915954589844
Time for forward pass: 0.0755615234375
Time for backpropagation: 0.002758502960205078
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.566547155380249 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2520577907562256 seconds
Streaming imagenet data took 2.2801520824432373 seconds
Then, training+dataloading take 2.2844350337982178 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38539671897888184
Time for copying to cuda: 0.018598556518554688
Time for forward pass: 0.07550644874572754
Time for backpropagation: 0.0028352737426757812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5825541019439697 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1822433471679688 seconds
Streaming imagenet data took 2.209648370742798 seconds
Then, training+dataloading take 2.2151687145233154 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37738990783691406
Time for copying to cuda: 0.018421411514282227
Time for forward pass: 0.0753626823425293
Time for backpropagation: 0.002689361572265625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5659162998199463 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2402777671813965 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.268606662750244 seconds
Then, training+dataloading take 2.273808002471924 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3602638244628906
Time for copying to cuda: 0.018462181091308594
Time for forward pass: 0.07535552978515625
Time for backpropagation: 0.002643108367919922
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5529899597167969 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2982845306396484 seconds
Streaming imagenet data took 2.3655214309692383 seconds
Then, training+dataloading take 2.3733294010162354 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3656771183013916
Time for copying to cuda: 0.0183413028717041
Time for forward pass: 0.07540130615234375
Time for backpropagation: 0.0026972293853759766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5338165760040283 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.139065980911255 seconds
Streaming imagenet data took 2.166583776473999 seconds
Then, training+dataloading take 2.1713554859161377 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4023277759552002
Time for copying to cuda: 0.018430709838867188
Time for forward pass: 0.07540035247802734
Time for backpropagation: 0.0026929378509521484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6010396480560303 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3219571113586426 seconds
Streaming imagenet data took 2.3492822647094727 seconds
Then, training+dataloading take 2.353878974914551 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3761579990386963
Time for copying to cuda: 0.018280744552612305
Time for forward pass: 0.07538628578186035
Time for backpropagation: 0.0026845932006835938
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5594089031219482 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.3010480403900146 seconds
Streaming imagenet data took 2.3288309574127197 seconds
Then, training+dataloading take 2.333054780960083 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38900232315063477
Time for copying to cuda: 0.018481731414794922
Time for forward pass: 0.07555937767028809
Time for backpropagation: 0.0028073787689208984
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5572402477264404 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2864253520965576 seconds
Streaming imagenet data took 2.31339955329895 seconds
Then, training+dataloading take 2.3179123401641846 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37928295135498047
Time for copying to cuda: 0.01842355728149414
Time for forward pass: 0.07550597190856934
Time for backpropagation: 0.0027124881744384766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5664689540863037 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.335911273956299 seconds
Streaming imagenet data took 2.363316059112549 seconds
Then, training+dataloading take 2.3684194087982178 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3781120777130127
Time for copying to cuda: 0.01855301856994629
Time for forward pass: 0.0754399299621582
Time for backpropagation: 0.0026884078979492188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5567293167114258 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2477965354919434 seconds
Streaming imagenet data took 2.275552749633789 seconds
Then, training+dataloading take 2.2792465686798096 seconds

Epoch: 0
Time of next(dataloader) is: 0.3809032440185547
Time for copying to cuda: 0.0185091495513916
Time for forward pass: 0.07537150382995605
Time for backpropagation: 0.0026352405548095703
GPU memory for training: 1.2580008506774902                          

The whole process took 45.4782600402832 seconds
