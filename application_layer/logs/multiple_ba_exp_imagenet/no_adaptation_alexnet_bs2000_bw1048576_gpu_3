Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.5840728689359 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 118958859.59907717 118958859.59907717
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2612974643707275 seconds
Streaming imagenet data took 2.288264513015747 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4190099239349365
Time for copying to cuda: 0.019029855728149414
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2056562900543213 seconds
Streaming imagenet data took 2.2337350845336914 seconds
Time for forward pass: 2.9987354278564453
Time for backpropagation: 0.04924201965332031
GPU memory for training: 1.102445125579834                          

Memory occpied: (1514.0, 3.0)
One training iteration takes: 3.5573959350585938 seconds
Index: 0
Then, training+dataloading take 3.5576281547546387 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34704017639160156
Time for copying to cuda: 0.018683195114135742
Time for forward pass: 0.0741586685180664
Time for backpropagation: 0.0036284923553466797
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5265414714813232 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1769039630889893 seconds
Streaming imagenet data took 2.2434468269348145 seconds
Then, training+dataloading take 2.251774311065674 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41910457611083984
Time for copying to cuda: 0.01825237274169922
Time for forward pass: 0.07545685768127441
Time for backpropagation: 0.002679586410522461
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.603039026260376 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1740758419036865 seconds
Streaming imagenet data took 2.2016208171844482 seconds
Then, training+dataloading take 2.2062127590179443 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36884093284606934
Time for copying to cuda: 0.018565654754638672
Time for forward pass: 0.0754854679107666
Time for backpropagation: 0.002987384796142578
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5505282878875732 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.172900915145874 seconds
Streaming imagenet data took 2.2008936405181885 seconds
Then, training+dataloading take 2.204747438430786 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3614654541015625
Time for copying to cuda: 0.018427371978759766
Time for forward pass: 0.07546877861022949
Time for backpropagation: 0.0026967525482177734
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5591824054718018 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2260711193084717 seconds
Streaming imagenet data took 2.25359845161438 seconds
Then, training+dataloading take 2.2580912113189697 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.359633207321167
Time for copying to cuda: 0.018329620361328125
Time for forward pass: 0.07545757293701172
Time for backpropagation: 0.003046751022338867
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5455818176269531 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.161839008331299 seconds
Streaming imagenet data took 2.228642702102661 seconds
Then, training+dataloading take 2.236405372619629 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3980824947357178
Time for copying to cuda: 0.018503427505493164
Time for forward pass: 0.07560300827026367
Time for backpropagation: 0.0027904510498046875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5669510364532471 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.140242338180542 seconds
Streaming imagenet data took 2.167933464050293 seconds
Then, training+dataloading take 2.172773599624634 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36403846740722656
Time for copying to cuda: 0.01851797103881836
Time for forward pass: 0.0768136978149414
Time for backpropagation: 0.003263711929321289
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5545520782470703 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.119520664215088 seconds
Streaming imagenet data took 2.1468429565429688 seconds
Then, training+dataloading take 2.1513671875 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3601341247558594
Time for copying to cuda: 0.018389225006103516
Time for forward pass: 0.07556009292602539
Time for backpropagation: 0.002756834030151367
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5467581748962402 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1807546615600586 seconds
Streaming imagenet data took 2.2080440521240234 seconds
Then, training+dataloading take 2.213303327560425 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3609147071838379
Time for copying to cuda: 0.01849222183227539
Time for forward pass: 0.0754241943359375
Time for backpropagation: 0.0026764869689941406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5473787784576416 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2228405475616455 seconds
Streaming imagenet data took 2.2501423358917236 seconds
Then, training+dataloading take 2.2554826736450195 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3617851734161377
Time for copying to cuda: 0.018511533737182617
Time for forward pass: 0.0754098892211914
Time for backpropagation: 0.002642393112182617
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.540846586227417 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.323014259338379 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.3505613803863525 seconds
Then, training+dataloading take 2.3554065227508545 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36746740341186523
Time for copying to cuda: 0.018662452697753906
Time for forward pass: 0.07541298866271973
Time for backpropagation: 0.0026628971099853516
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5494132041931152 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0162603855133057 seconds
Streaming imagenet data took 2.043844223022461 seconds
Then, training+dataloading take 2.046879768371582 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4043140411376953
Time for copying to cuda: 0.018680810928344727
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07563281059265137
Time for backpropagation: 0.0027365684509277344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5871362686157227 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2206385135650635 seconds
Streaming imagenet data took 2.248068332672119 seconds
Then, training+dataloading take 2.2528276443481445 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3674163818359375
Time for copying to cuda: 0.018428802490234375
Time for forward pass: 0.07678341865539551
Time for backpropagation: 0.0032351016998291016
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5598475933074951 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1753199100494385 seconds
Streaming imagenet data took 2.2034575939178467 seconds
Then, training+dataloading take 2.208130121231079 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3707256317138672
Time for copying to cuda: 0.018489837646484375
Time for forward pass: 0.07551908493041992
Time for backpropagation: 0.0027418136596679688
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5387511253356934 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2701256275177 seconds
Streaming imagenet data took 2.29730486869812 seconds
Then, training+dataloading take 2.301755428314209 seconds

Epoch: 0
Time of next(dataloader) is: 0.36048245429992676
Time for copying to cuda: 0.01866936683654785
Time for forward pass: 0.07548713684082031
Time for backpropagation: 0.0027074813842773438
GPU memory for training: 1.2580008506774902                          

The whole process took 44.142266273498535 seconds
