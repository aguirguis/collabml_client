Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=17, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2762975052109 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 119049590.866603 119049590.866603
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 17 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  266.27734375 350.46142578125 616.73876953125 2386.10595703125
Fixed, scale_with_bsz  0 2.05126953125
Mem usage  1514.0 3.0
Using split index: 17
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.6586275100708008 seconds
Streaming imagenet data took 1.6650776863098145 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.30272817611694336
Time for copying to cuda: 0.005034446716308594
Memory occpied: (1530.0, 268.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.5055696964263916 seconds
Streaming imagenet data took 1.5252900123596191 seconds
Memory occpied: (1530.0, 678.0)
Memory occpied: (1530.0, 1136.0)
Time for forward pass: 3.2411985397338867
Time for backpropagation: 0.049756526947021484
GPU memory for training: 0.9570660591125488                          

One training iteration takes: 3.667287826538086 seconds
Index: 0
Then, training+dataloading take 3.6673595905303955 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.31424975395202637
Time for copying to cuda: 0.0044095516204833984
Time for forward pass: 0.03229188919067383
Time for backpropagation: 0.0034329891204833984
GPU memory for training: 1.1122322082519531                          

One training iteration takes: 0.435471773147583 seconds
Index: 1
Memory occpied: (2270.0, 1688.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.596757173538208 seconds
Streaming imagenet data took 1.6032311916351318 seconds
Then, training+dataloading take 1.6037724018096924 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.354856014251709
Time for copying to cuda: 0.004407405853271484
Time for forward pass: 0.030948162078857422
Time for backpropagation: 0.0025916099548339844
GPU memory for training: 1.1125984191894531                          

One training iteration takes: 0.5211081504821777 seconds
Index: 2
Memory occpied: (2270.0, 1688.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.4892501831054688 seconds
Streaming imagenet data took 1.4958903789520264 seconds
Then, training+dataloading take 1.4964473247528076 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Memory occpied: (2270.0, 1688.0)
Time of next(dataloader) is: 0.41740989685058594
Time for copying to cuda: 0.0044498443603515625
Time for forward pass: 0.031153202056884766
Time for backpropagation: 0.0027451515197753906
GPU memory for training: 1.1125984191894531                          

One training iteration takes: 0.5438792705535889 seconds
Index: 3
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.5625252723693848 seconds
Streaming imagenet data took 1.5692532062530518 seconds
Then, training+dataloading take 1.5699796676635742 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2270.0, 1688.0)
Time of next(dataloader) is: 0.32873988151550293
Time for copying to cuda: 0.004339694976806641
Time for forward pass: 0.031005144119262695
Time for backpropagation: 0.0025620460510253906
GPU memory for training: 1.1125984191894531                          

One training iteration takes: 0.44539856910705566 seconds
Index: 4
Memory occpied: (2270.0, 1688.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.4951226711273193 seconds
Streaming imagenet data took 1.4992685317993164 seconds
Then, training+dataloading take 1.4999258518218994 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3235468864440918
Time for copying to cuda: 0.004324913024902344
Time for forward pass: 0.03101348876953125
Time for backpropagation: 0.002604246139526367
GPU memory for training: 1.1125984191894531                          

One training iteration takes: 0.44376325607299805 seconds
Index: 5
Memory occpied: (2270.0, 1688.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.489175796508789 seconds
Streaming imagenet data took 1.4935173988342285 seconds
Then, training+dataloading take 1.494098424911499 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3236844539642334
Time for copying to cuda: 0.004329204559326172
Time for forward pass: 0.031018733978271484
Time for backpropagation: 0.0025947093963623047
GPU memory for training: 1.1125984191894531                          

One training iteration takes: 0.44408392906188965 seconds
Index: 6
Memory occpied: (2270.0, 1688.0)
Read 15.659677505493164 MBs for this batch
Executing all posts took 1.500356912612915 seconds
Streaming imagenet data took 1.5045194625854492 seconds
Then, training+dataloading take 1.505133867263794 seconds

Epoch: 0
Time of next(dataloader) is: 0.3790299892425537
Time for copying to cuda: 0.0043985843658447266
Time for forward pass: 0.031032085418701172
Time for backpropagation: 0.0025730133056640625
GPU memory for training: 1.1125984191894531                          

Memory occpied: (2270.0, 1688.0)
The whole process took 22.487842798233032 seconds
