Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.7276315151057 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119108748.11794794 119108748.11794794
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1663856506347656 seconds
Streaming imagenet data took 2.193742036819458 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42108678817749023
Time for copying to cuda: 0.018811702728271484
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1331286430358887 seconds
Streaming imagenet data took 2.161054849624634 seconds
Time for forward pass: 3.0024776458740234
Time for backpropagation: 0.04916882514953613
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.591073989868164 seconds
Index: 0
Then, training+dataloading take 3.5912578105926514 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3508639335632324
Time for copying to cuda: 0.01881122589111328
Time for forward pass: 0.07533621788024902
Time for backpropagation: 0.003838062286376953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5403444766998291 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2129194736480713 seconds
Streaming imagenet data took 2.2407495975494385 seconds
Then, training+dataloading take 2.2437281608581543 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.412214994430542
Time for copying to cuda: 0.018547534942626953
Time for forward pass: 0.07548642158508301
Time for backpropagation: 0.002701282501220703
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6352229118347168 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1323537826538086 seconds
Streaming imagenet data took 2.1601552963256836 seconds
Then, training+dataloading take 2.1653668880462646 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3645598888397217
Time for copying to cuda: 0.018490314483642578
Time for forward pass: 0.07547450065612793
Time for backpropagation: 0.002655506134033203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5482268333435059 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1644790172576904 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.192932367324829 seconds
Then, training+dataloading take 2.1977880001068115 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.368696928024292
Time for copying to cuda: 0.018318891525268555
Time for forward pass: 0.07555508613586426
Time for backpropagation: 0.0026497840881347656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5534803867340088 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.035949945449829 seconds
Streaming imagenet data took 2.0630180835723877 seconds
Then, training+dataloading take 2.0671427249908447 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4473083019256592
Time for copying to cuda: 0.018096208572387695
Time for forward pass: 0.07539916038513184
Time for backpropagation: 0.002604961395263672
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6414475440979004 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1082205772399902 seconds
Streaming imagenet data took 2.1354334354400635 seconds
Then, training+dataloading take 2.139402389526367 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36820054054260254
Time for copying to cuda: 0.018230199813842773
Time for forward pass: 0.07547140121459961
Time for backpropagation: 0.002553224563598633
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5600018501281738 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1525204181671143 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 2.1804516315460205 seconds
Then, training+dataloading take 2.184936761856079 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36911559104919434
Time for copying to cuda: 0.018323183059692383
Time for forward pass: 0.0755472183227539
Time for backpropagation: 0.0028905868530273438
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5754561424255371 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0772252082824707 seconds
Streaming imagenet data took 2.1044819355010986 seconds
Then, training+dataloading take 2.108837842941284 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4039742946624756
Time for copying to cuda: 0.018151521682739258
Time for forward pass: 0.07540774345397949
Time for backpropagation: 0.0025861263275146484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.621117115020752 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.123516321182251 seconds
Streaming imagenet data took 2.151296615600586 seconds
Then, training+dataloading take 2.1556813716888428 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3761768341064453
Time for copying to cuda: 0.018458127975463867
Time for forward pass: 0.07533478736877441
Time for backpropagation: 0.0025177001953125
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5584993362426758 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.077739953994751 seconds
Streaming imagenet data took 2.144672155380249 seconds
Then, training+dataloading take 2.1527607440948486 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.3682832717895508
Time for copying to cuda: 0.0184786319732666
Time for forward pass: 0.07553815841674805
Time for backpropagation: 0.0027277469635009766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5373797416687012 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.028249502182007 seconds
Streaming imagenet data took 2.0553126335144043 seconds
Then, training+dataloading take 2.0599071979522705 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4064362049102783
Time for copying to cuda: 0.018468141555786133
Time for forward pass: 0.0753173828125
Time for backpropagation: 0.0026030540466308594
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6075961589813232 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1008098125457764 seconds
Streaming imagenet data took 2.1284615993499756 seconds
Then, training+dataloading take 2.1329457759857178 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37256312370300293
Time for copying to cuda: 0.01856827735900879
Time for forward pass: 0.07544088363647461
Time for backpropagation: 0.0026311874389648438
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5626564025878906 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.058915376663208 seconds
Streaming imagenet data took 2.1257412433624268 seconds
Then, training+dataloading take 2.133418083190918 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.382800817489624
Time for copying to cuda: 0.01828908920288086
Time for forward pass: 0.0755000114440918
Time for backpropagation: 0.0026895999908447266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5659890174865723 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.043219566345215 seconds
Streaming imagenet data took 2.0710983276367188 seconds
Then, training+dataloading take 2.0757341384887695 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4323856830596924
Time for copying to cuda: 0.01871037483215332
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07569289207458496
Time for backpropagation: 0.002730846405029297
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6367392539978027 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.100902795791626 seconds
Streaming imagenet data took 2.1286916732788086 seconds
Then, training+dataloading take 2.133220911026001 seconds

Epoch: 0
Time of next(dataloader) is: 0.3729703426361084
Time for copying to cuda: 0.018419504165649414
Time for forward pass: 0.07547402381896973
Time for backpropagation: 0.0026900768280029297
GPU memory for training: 1.2580008506774902                          

The whole process took 42.77085638046265 seconds
