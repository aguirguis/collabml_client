Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.453621394375 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
448967248008533.3 119072833.06340352 119072833.06340352
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  299.09765625 647.1533203125 946.2509765625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0320732593536377 seconds
Streaming imagenet data took 2.0591442584991455 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3220999240875244
Time for copying to cuda: 0.018917083740234375
Memory occpied: (1586.0, 22.0)
Memory occpied: (1586.0, 564.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.959301471710205 seconds
Streaming imagenet data took 1.9869399070739746 seconds
Memory occpied: (1586.0, 1026.0)
Time for forward pass: 3.209329605102539
Time for backpropagation: 0.04928302764892578
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.6773946285247803 seconds
Index: 0
Then, training+dataloading take 3.6776487827301025 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40285611152648926
Time for copying to cuda: 0.0190432071685791
Memory occpied: (2100.0, 1632.0)
Time for forward pass: 0.07560563087463379
Time for backpropagation: 0.003668546676635742
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5814881324768066 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.052461862564087 seconds
Streaming imagenet data took 2.079690456390381 seconds
Then, training+dataloading take 2.083974599838257 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3726184368133545
Time for copying to cuda: 0.018167495727539062
Time for forward pass: 0.07553696632385254
Time for backpropagation: 0.0027837753295898438
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5599758625030518 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9676227569580078 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9956297874450684 seconds
Then, training+dataloading take 2.000667095184326 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3694150447845459
Time for copying to cuda: 0.018559694290161133
Time for forward pass: 0.07559895515441895
Time for backpropagation: 0.0027647018432617188
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5577852725982666 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8728466033935547 seconds
Streaming imagenet data took 1.9005239009857178 seconds
Then, training+dataloading take 1.9047250747680664 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37020158767700195
Time for copying to cuda: 0.01852560043334961
Time for forward pass: 0.07642173767089844
Time for backpropagation: 0.003499746322631836
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5553731918334961 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9728977680206299 seconds
Streaming imagenet data took 2.000096559524536 seconds
Then, training+dataloading take 2.002896785736084 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36649608612060547
Time for copying to cuda: 0.01819586753845215
Time for forward pass: 0.07542610168457031
Time for backpropagation: 0.0026314258575439453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5497541427612305 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8783371448516846 seconds
Streaming imagenet data took 1.9055895805358887 seconds
Then, training+dataloading take 1.9097645282745361 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4118204116821289
Time for copying to cuda: 0.018162250518798828
Time for forward pass: 0.07521891593933105
Time for backpropagation: 0.002639293670654297
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6308283805847168 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9392433166503906 seconds
Streaming imagenet data took 1.9665720462799072 seconds
Then, training+dataloading take 1.9715080261230469 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36850786209106445
Time for copying to cuda: 0.018241405487060547
Time for forward pass: 0.07553601264953613
Time for backpropagation: 0.0027518272399902344
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5545034408569336 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.88582181930542 seconds
Streaming imagenet data took 1.9131128787994385 seconds
Then, training+dataloading take 1.9173882007598877 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40921831130981445
Time for copying to cuda: 0.018439054489135742
Time for forward pass: 0.07551813125610352
Time for backpropagation: 0.002718210220336914
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6318573951721191 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9557764530181885 seconds
Streaming imagenet data took 1.9825661182403564 seconds
Then, training+dataloading take 1.9868464469909668 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37254881858825684
Time for copying to cuda: 0.018151044845581055
Time for forward pass: 0.07537102699279785
Time for backpropagation: 0.0028252601623535156
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.560164213180542 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8853142261505127 seconds
Streaming imagenet data took 1.9128010272979736 seconds
Then, training+dataloading take 1.9171152114868164 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41970157623291016
Time for copying to cuda: 0.018759727478027344
Time for forward pass: 0.07541537284851074
Time for backpropagation: 0.002633810043334961
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6250731945037842 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9569697380065918 seconds
Streaming imagenet data took 1.9839794635772705 seconds
Then, training+dataloading take 1.9891259670257568 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3753650188446045
Time for copying to cuda: 0.01843714714050293
Time for forward pass: 0.07551431655883789
Time for backpropagation: 0.0028455257415771484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5602102279663086 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.891108751296997 seconds
Streaming imagenet data took 1.9188077449798584 seconds
Then, training+dataloading take 1.9231441020965576 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.43211984634399414
Time for copying to cuda: 0.018449783325195312
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07569193840026855
Time for backpropagation: 0.002771615982055664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.618980884552002 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9730298519134521 seconds
Streaming imagenet data took 2.000701427459717 seconds
Then, training+dataloading take 2.005099058151245 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37375307083129883
Time for copying to cuda: 0.018307924270629883
Time for forward pass: 0.07532691955566406
Time for backpropagation: 0.0027132034301757812
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5569629669189453 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.866661787033081 seconds
Streaming imagenet data took 1.8940184116363525 seconds
Then, training+dataloading take 1.897001028060913 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4533829689025879
Time for copying to cuda: 0.01856851577758789
Time for forward pass: 0.07549619674682617
Time for backpropagation: 0.002896547317504883
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.6374242305755615 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9045209884643555 seconds
Streaming imagenet data took 1.932044506072998 seconds
Then, training+dataloading take 1.9371154308319092 seconds

Epoch: 0
Time of next(dataloader) is: 0.37047433853149414
Time for copying to cuda: 0.018414974212646484
Time for forward pass: 0.07546806335449219
Time for backpropagation: 0.0026772022247314453
GPU memory for training: 1.2580008506774902                          

The whole process took 40.52577590942383 seconds
