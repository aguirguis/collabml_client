Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=2000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 907.109016823336 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
1795868992034133.2 118896593.0530683 118896593.0530683
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  496.01953125 647.1533203125 1143.1728515625 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  496.01953125 647.1533203125 1143.1728515625 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.139909505844116 seconds
Streaming imagenet data took 2.1670196056365967 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3694450855255127
Time for copying to cuda: 0.018889904022216797
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0571320056915283 seconds
Streaming imagenet data took 2.0848097801208496 seconds
Time for forward pass: 2.983842372894287
Time for backpropagation: 0.04865384101867676
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.519824981689453 seconds
Index: 0
Then, training+dataloading take 3.5199942588806152 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.35869622230529785
Time for copying to cuda: 0.018476247787475586
Time for forward pass: 0.0754542350769043
Time for backpropagation: 0.0036127567291259766
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5421116352081299 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0359506607055664 seconds
Streaming imagenet data took 2.0631823539733887 seconds
Then, training+dataloading take 2.069524049758911 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4145691394805908
Time for copying to cuda: 0.018288850784301758
Time for forward pass: 0.0755300521850586
Time for backpropagation: 0.002797365188598633
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6134262084960938 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1250803470611572 seconds
Streaming imagenet data took 2.1527037620544434 seconds
Then, training+dataloading take 2.1571292877197266 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36377501487731934
Time for copying to cuda: 0.018390178680419922
Time for forward pass: 0.07550907135009766
Time for backpropagation: 0.002658843994140625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5611851215362549 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.028393268585205 seconds
Streaming imagenet data took 2.0942814350128174 seconds
Then, training+dataloading take 2.102020263671875 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.35799241065979004
Time for copying to cuda: 0.01846790313720703
Time for forward pass: 0.07545804977416992
Time for backpropagation: 0.0026013851165771484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5409626960754395 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.020350456237793 seconds
Streaming imagenet data took 2.047635316848755 seconds
Then, training+dataloading take 2.051961898803711 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40337228775024414
Time for copying to cuda: 0.018486976623535156
Time for forward pass: 0.07545304298400879
Time for backpropagation: 0.002696990966796875
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6171247959136963 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.02227783203125 seconds
Streaming imagenet data took 2.049515724182129 seconds
Then, training+dataloading take 2.0547146797180176 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36370086669921875
Time for copying to cuda: 0.018426895141601562
Time for forward pass: 0.07548832893371582
Time for backpropagation: 0.0027692317962646484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5509734153747559 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9263076782226562 seconds
Streaming imagenet data took 1.953770637512207 seconds
Then, training+dataloading take 1.958057165145874 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.44947314262390137
Time for copying to cuda: 0.018723249435424805
Time for forward pass: 0.07548761367797852
Time for backpropagation: 0.003074169158935547
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6400883197784424 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.014537811279297 seconds
Streaming imagenet data took 2.042285919189453 seconds
Then, training+dataloading take 2.046647787094116 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36185121536254883
Time for copying to cuda: 0.018451929092407227
Time for forward pass: 0.07543683052062988
Time for backpropagation: 0.002633333206176758
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5576207637786865 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0142252445220947 seconds
Streaming imagenet data took 2.041963815689087 seconds
Then, training+dataloading take 2.04622745513916 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.36733269691467285
Time for copying to cuda: 0.018477678298950195
Time for forward pass: 0.07564115524291992
Time for backpropagation: 0.002753019332885742
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5584805011749268 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.941307783126831 seconds
Streaming imagenet data took 1.9689362049102783 seconds
Then, training+dataloading take 1.9733448028564453 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41719818115234375
Time for copying to cuda: 0.018616914749145508
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07570672035217285
Time for backpropagation: 0.0027387142181396484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5966601371765137 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9970693588256836 seconds
Streaming imagenet data took 2.025233507156372 seconds
Then, training+dataloading take 2.028047561645508 seconds
The mode is:  split
Start 24000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.37246012687683105
Time for copying to cuda: 0.01854872703552246
Time for forward pass: 0.07547330856323242
Time for backpropagation: 0.0027523040771484375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5603015422821045 seconds
Index: 11
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9671330451965332 seconds
Streaming imagenet data took 2.0349135398864746 seconds
Then, training+dataloading take 2.042492389678955 seconds
The mode is:  split
Start 26000, end 28000, post_step 1000


Epoch: 0
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Time of next(dataloader) is: 0.35979461669921875
Time for copying to cuda: 0.01860952377319336
Time for forward pass: 0.07561182975769043
Time for backpropagation: 0.002763986587524414
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5464146137237549 seconds
Index: 12
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.930769681930542 seconds
Streaming imagenet data took 1.958383560180664 seconds
Then, training+dataloading take 1.9627430438995361 seconds
The mode is:  split
Start 28000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.363785982131958
Time for copying to cuda: 0.018578767776489258
Time for forward pass: 0.07692146301269531
Time for backpropagation: 0.0032885074615478516
GPU memory for training: 1.2580008506774902                          

Memory occpied: (2326.0, 1632.0)
One training iteration takes: 0.5574452877044678 seconds
Index: 13
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9862878322601318 seconds
Streaming imagenet data took 2.0135645866394043 seconds
Then, training+dataloading take 2.018843412399292 seconds
The mode is:  split
Start 30000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.379014253616333
Time for copying to cuda: 0.01846027374267578
Time for forward pass: 0.07550501823425293
Time for backpropagation: 0.002588510513305664
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5690968036651611 seconds
Index: 14
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.132976531982422 seconds
Streaming imagenet data took 2.1607415676116943 seconds
Then, training+dataloading take 2.165847063064575 seconds

Epoch: 0
Time of next(dataloader) is: 0.3660862445831299
Time for copying to cuda: 0.018677711486816406
Time for forward pass: 0.07564902305603027
Time for backpropagation: 0.002804994583129883
GPU memory for training: 1.2580008506774902                          

The whole process took 41.80773401260376 seconds
