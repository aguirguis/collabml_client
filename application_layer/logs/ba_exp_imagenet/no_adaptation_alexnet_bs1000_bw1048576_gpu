Cached  True
Transformed  True
All in COS  False
No adaptation  True
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=True, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3505885110393 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
1795868992034133.2 119059328.33731894 119059328.33731894
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  496.01953125 440.30517578125 936.32470703125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  496.01953125 440.30517578125 936.32470703125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7785413265228271 seconds
Streaming imagenet data took 1.7924163341522217 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3092644214630127
Time for copying to cuda: 0.009966850280761719
Memory occpied: (1550.0, 214.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7138733863830566 seconds
Streaming imagenet data took 1.7737579345703125 seconds
Memory occpied: (1550.0, 674.0)
Memory occpied: (1550.0, 1132.0)
Time for forward pass: 3.2762632369995117
Time for backpropagation: 0.05011630058288574
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.7219529151916504 seconds
Index: 0
Then, training+dataloading take 3.7221453189849854 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33144259452819824
Time for copying to cuda: 0.009445905685424805
Time for forward pass: 0.07415223121643066
Time for backpropagation: 0.004342317581176758
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.5159506797790527 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.79274320602417 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.8070180416107178 seconds
Then, training+dataloading take 1.809370517730713 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3400583267211914
Time for copying to cuda: 0.009454011917114258
Time for forward pass: 0.049237728118896484
Time for backpropagation: 0.002578258514404297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4897489547729492 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6560237407684326 seconds
Streaming imagenet data took 1.6699726581573486 seconds
Then, training+dataloading take 1.6724011898040771 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3518528938293457
Time for copying to cuda: 0.009468317031860352
Time for forward pass: 0.04922294616699219
Time for backpropagation: 0.0025398731231689453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49381470680236816 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6539945602416992 seconds
Streaming imagenet data took 1.667952537536621 seconds
Then, training+dataloading take 1.6703722476959229 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.41973042488098145
Time for copying to cuda: 0.00952601432800293
Time for forward pass: 0.04926323890686035
Time for backpropagation: 0.002580881118774414
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5646288394927979 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7250566482543945 seconds
Streaming imagenet data took 1.7392265796661377 seconds
Then, training+dataloading take 1.7416431903839111 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34454870223999023
Time for copying to cuda: 0.009405136108398438
Time for forward pass: 0.04922032356262207
Time for backpropagation: 0.0025665760040283203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4964735507965088 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6460058689117432 seconds
Streaming imagenet data took 1.6598765850067139 seconds
Then, training+dataloading take 1.6623203754425049 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35622739791870117
Time for copying to cuda: 0.009549140930175781
Time for forward pass: 0.08042073249816895
Time for backpropagation: 0.0031287670135498047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5586693286895752 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7068135738372803 seconds
Streaming imagenet data took 1.7210726737976074 seconds
Then, training+dataloading take 1.723409652709961 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38564395904541016
Time for copying to cuda: 0.009464740753173828
Time for forward pass: 0.04940319061279297
Time for backpropagation: 0.0029528141021728516
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.534231424331665 seconds
Index: 7
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.708003282546997 seconds
Streaming imagenet data took 1.7219023704528809 seconds
Then, training+dataloading take 1.724205493927002 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33931493759155273
Time for copying to cuda: 0.009469032287597656
Time for forward pass: 0.049330711364746094
Time for backpropagation: 0.0026803016662597656
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4879159927368164 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6390712261199951 seconds
Streaming imagenet data took 1.6531903743743896 seconds
Then, training+dataloading take 1.6556286811828613 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3436572551727295
Time for copying to cuda: 0.009458065032958984
Time for forward pass: 0.04933929443359375
Time for backpropagation: 0.0026166439056396484
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5001091957092285 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6483373641967773 seconds
Streaming imagenet data took 1.6623117923736572 seconds
Then, training+dataloading take 1.6647603511810303 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.378798246383667
Time for copying to cuda: 0.009543895721435547
Time for forward pass: 0.04924821853637695
Time for backpropagation: 0.0026099681854248047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5414149761199951 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6976921558380127 seconds
Streaming imagenet data took 1.7117764949798584 seconds
Then, training+dataloading take 1.7144379615783691 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3752443790435791
Time for copying to cuda: 0.009416818618774414
Time for forward pass: 0.04931783676147461
Time for backpropagation: 0.002843141555786133
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5205333232879639 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6779110431671143 seconds
Streaming imagenet data took 1.691817283630371 seconds
Then, training+dataloading take 1.6942710876464844 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3376200199127197
Time for copying to cuda: 0.00947117805480957
Time for forward pass: 0.04922652244567871
Time for backpropagation: 0.0025894641876220703
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48118162155151367 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6820828914642334 seconds
Streaming imagenet data took 1.696030616760254 seconds
Then, training+dataloading take 1.6985230445861816 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3778574466705322
Time for copying to cuda: 0.009538650512695312
Time for forward pass: 0.04933619499206543
Time for backpropagation: 0.002789020538330078
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5440695285797119 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6936290264129639 seconds
Streaming imagenet data took 1.708134412765503 seconds
Then, training+dataloading take 1.7105109691619873 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.39621901512145996
Time for copying to cuda: 0.009443283081054688
Time for forward pass: 0.04930734634399414
Time for backpropagation: 0.002553224563598633
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5472550392150879 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6923038959503174 seconds
Streaming imagenet data took 1.706251859664917 seconds
Then, training+dataloading take 1.7087323665618896 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3535952568054199
Time for copying to cuda: 0.009389400482177734
Time for forward pass: 0.04930400848388672
Time for backpropagation: 0.002597808837890625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49619340896606445 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.640087366104126 seconds
Streaming imagenet data took 1.653815507888794 seconds
Then, training+dataloading take 1.6563291549682617 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3515915870666504
Time for copying to cuda: 0.009474039077758789
Time for forward pass: 0.04958677291870117
Time for backpropagation: 0.04126095771789551
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5318849086761475 seconds
Index: 16
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.712430715560913 seconds
Streaming imagenet data took 1.7263963222503662 seconds
Then, training+dataloading take 1.7281570434570312 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.34720516204833984
Time for copying to cuda: 0.009303808212280273
Time for forward pass: 0.0492091178894043
Time for backpropagation: 0.0026214122772216797
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49482083320617676 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.643439531326294 seconds
Streaming imagenet data took 1.6572184562683105 seconds
Then, training+dataloading take 1.6580102443695068 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3410968780517578
Time for copying to cuda: 0.009328842163085938
Time for forward pass: 0.0492856502532959
Time for backpropagation: 0.0025472640991210938
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49085092544555664 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6344571113586426 seconds
Streaming imagenet data took 1.648653268814087 seconds
Then, training+dataloading take 1.6509761810302734 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3933687210083008
Time for copying to cuda: 0.009353399276733398
Time for forward pass: 0.04932093620300293
Time for backpropagation: 0.002618551254272461
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5560116767883301 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6284992694854736 seconds
Streaming imagenet data took 1.6817240715026855 seconds
Then, training+dataloading take 1.6860754489898682 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38187146186828613
Time for copying to cuda: 0.00933074951171875
Time for forward pass: 0.049384117126464844
Time for backpropagation: 0.0026597976684570312
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5118675231933594 seconds
Index: 20
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7362949848175049 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.750067949295044 seconds
Then, training+dataloading take 1.752427339553833 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3435797691345215
Time for copying to cuda: 0.009273052215576172
Time for forward pass: 0.04927468299865723
Time for backpropagation: 0.002534627914428711
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4931354522705078 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6777522563934326 seconds
Streaming imagenet data took 1.691917896270752 seconds
Then, training+dataloading take 1.694359302520752 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35746097564697266
Time for copying to cuda: 0.009372234344482422
Time for forward pass: 0.04920363426208496
Time for backpropagation: 0.0026013851165771484
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5351462364196777 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6838011741638184 seconds
Streaming imagenet data took 1.697791337966919 seconds
Then, training+dataloading take 1.7003583908081055 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.44257140159606934
Time for copying to cuda: 0.00937199592590332
Time for forward pass: 0.04932904243469238
Time for backpropagation: 0.0027234554290771484
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5861093997955322 seconds
Index: 23
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7414391040802002 seconds
Streaming imagenet data took 1.7558445930480957 seconds
Then, training+dataloading take 1.757375717163086 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3573489189147949
Time for copying to cuda: 0.009320735931396484
Time for forward pass: 0.04926013946533203
Time for backpropagation: 0.002543210983276367
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5033960342407227 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6403372287750244 seconds
Streaming imagenet data took 1.6542458534240723 seconds
Then, training+dataloading take 1.6568670272827148 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3564291000366211
Time for copying to cuda: 0.00950932502746582
Time for forward pass: 0.04939627647399902
Time for backpropagation: 0.0026242733001708984
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5041704177856445 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6322391033172607 seconds
Streaming imagenet data took 1.6463987827301025 seconds
Then, training+dataloading take 1.6489028930664062 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40799474716186523
Time for copying to cuda: 0.009381294250488281
Time for forward pass: 0.04925179481506348
Time for backpropagation: 0.0025682449340820312
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5780625343322754 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.639627456665039 seconds
Streaming imagenet data took 1.6938061714172363 seconds
Then, training+dataloading take 1.6980433464050293 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3965156078338623
Time for copying to cuda: 0.009421348571777344
Time for forward pass: 0.04922318458557129
Time for backpropagation: 0.0024559497833251953
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5385172367095947 seconds
Index: 27
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6959550380706787 seconds
Streaming imagenet data took 1.7101781368255615 seconds
Then, training+dataloading take 1.712082862854004 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3533782958984375
Time for copying to cuda: 0.009361505508422852
Time for forward pass: 0.04935622215270996
Time for backpropagation: 0.0026013851165771484
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4832801818847656 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.642923355102539 seconds
Streaming imagenet data took 1.6568427085876465 seconds
Then, training+dataloading take 1.6593334674835205 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35266757011413574
Time for copying to cuda: 0.009482145309448242
Time for forward pass: 0.04926252365112305
Time for backpropagation: 0.002625703811645508
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4910271167755127 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.640235185623169 seconds
Streaming imagenet data took 1.6547694206237793 seconds
Then, training+dataloading take 1.6572949886322021 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3939054012298584
Time for copying to cuda: 0.009503602981567383
Time for forward pass: 0.04924201965332031
Time for backpropagation: 0.0025794506072998047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.580540657043457 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.628028392791748 seconds
Streaming imagenet data took 1.6419930458068848 seconds
Then, training+dataloading take 1.6445503234863281 seconds

Epoch: 0
Time of next(dataloader) is: 0.394773006439209
Time for copying to cuda: 0.009424209594726562
Time for forward pass: 0.04935026168823242
Time for backpropagation: 0.0025887489318847656
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
The whole process took 64.42188501358032 seconds
