Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', no_adaptation=False, num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2339365928192 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
1795868992034133.2 119044038.537094 119044038.537094
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  496.01953125 440.30517578125 936.32470703125 2456.41845703125
Candidate split  13
Server, client, server+client, vanilla  496.01953125 440.30517578125 936.32470703125 2456.41845703125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.832613468170166 seconds
Streaming imagenet data took 1.846419095993042 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.293560266494751
Time for copying to cuda: 0.010039329528808594
Memory occpied: (1550.0, 192.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6303365230560303 seconds
Streaming imagenet data took 1.6793997287750244 seconds
Memory occpied: (1550.0, 610.0)
Memory occpied: (1550.0, 1084.0)
Time for forward pass: 3.2166857719421387
Time for backpropagation: 0.04914069175720215
GPU memory for training: 1.0087966918945312                          

One training iteration takes: 3.649808883666992 seconds
Index: 0
Then, training+dataloading take 3.6500015258789062 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.32759571075439453
Time for copying to cuda: 0.009567737579345703
Time for forward pass: 0.07203841209411621
Time for backpropagation: 0.004387378692626953
GPU memory for training: 1.1635355949401855                          

One training iteration takes: 0.525841474533081 seconds
Index: 1
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8473312854766846 seconds
Streaming imagenet data took 1.8613805770874023 seconds
Then, training+dataloading take 1.8636348247528076 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34387731552124023
Time for copying to cuda: 0.009415864944458008
Time for forward pass: 0.04926919937133789
Time for backpropagation: 0.0025947093963623047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49023866653442383 seconds
Index: 2
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6670377254486084 seconds
Streaming imagenet data took 1.680769920349121 seconds
Then, training+dataloading take 1.683161735534668 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3365650177001953
Time for copying to cuda: 0.009491205215454102
Time for forward pass: 0.04929757118225098
Time for backpropagation: 0.0026748180389404297
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5070369243621826 seconds
Index: 3
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7735774517059326 seconds
Streaming imagenet data took 1.8259105682373047 seconds
Then, training+dataloading take 1.8301708698272705 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.33920836448669434
Time for copying to cuda: 0.00945138931274414
Time for forward pass: 0.049239397048950195
Time for backpropagation: 0.002585887908935547
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4933338165283203 seconds
Index: 4
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7417011260986328 seconds
Streaming imagenet data took 1.7556860446929932 seconds
Then, training+dataloading take 1.7582740783691406 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33117008209228516
Time for copying to cuda: 0.00939035415649414
Time for forward pass: 0.049289703369140625
Time for backpropagation: 0.002580881118774414
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4800076484680176 seconds
Index: 5
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7733573913574219 seconds
Streaming imagenet data took 1.825911521911621 seconds
Then, training+dataloading take 1.8301665782928467 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3924698829650879
Time for copying to cuda: 0.009263753890991211
Time for forward pass: 0.049303531646728516
Time for backpropagation: 0.002650737762451172
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5411720275878906 seconds
Index: 6
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7864339351654053 seconds
Streaming imagenet data took 1.8003807067871094 seconds
Then, training+dataloading take 1.8028512001037598 seconds
The mode is:  split
Start 8000, end 9000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3537709712982178
Time for copying to cuda: 0.009306907653808594
Time for forward pass: 0.04925894737243652
Time for backpropagation: 0.002591371536254883
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49944615364074707 seconds
Index: 7
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7855556011199951 seconds
Streaming imagenet data took 1.7995216846466064 seconds
Then, training+dataloading take 1.8019189834594727 seconds
The mode is:  split
Start 9000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3758423328399658
Time for copying to cuda: 0.009356021881103516
Time for forward pass: 0.04918050765991211
Time for backpropagation: 0.002785205841064453
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.537111759185791 seconds
Index: 8
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8024053573608398 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.8168411254882812 seconds
Then, training+dataloading take 1.8191020488739014 seconds
The mode is:  split
Start 10000, end 11000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33684539794921875
Time for copying to cuda: 0.009401321411132812
Time for forward pass: 0.04922199249267578
Time for backpropagation: 0.0025179386138916016
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4838292598724365 seconds
Index: 9
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7266077995300293 seconds
Streaming imagenet data took 1.7404468059539795 seconds
Then, training+dataloading take 1.7429189682006836 seconds
The mode is:  split
Start 11000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33688855171203613
Time for copying to cuda: 0.00937199592590332
Time for forward pass: 0.049317121505737305
Time for backpropagation: 0.002666473388671875
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49227190017700195 seconds
Index: 10
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7500123977661133 seconds
Streaming imagenet data took 1.764355182647705 seconds
Then, training+dataloading take 1.7667450904846191 seconds
The mode is:  split
Start 12000, end 13000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3835258483886719
Time for copying to cuda: 0.009320974349975586
Time for forward pass: 0.04922819137573242
Time for backpropagation: 0.0025911331176757812
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5118374824523926 seconds
Index: 11
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8096683025360107 seconds
Streaming imagenet data took 1.8233892917633057 seconds
Then, training+dataloading take 1.8258824348449707 seconds
The mode is:  split
Start 13000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33664536476135254
Time for copying to cuda: 0.009500741958618164
Time for forward pass: 0.049260616302490234
Time for backpropagation: 0.0026733875274658203
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.49738597869873047 seconds
Index: 12
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7628424167633057 seconds
Streaming imagenet data took 1.7769982814788818 seconds
Then, training+dataloading take 1.7795495986938477 seconds
The mode is:  split
Start 14000, end 15000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35527873039245605
Time for copying to cuda: 0.009456634521484375
Time for forward pass: 0.04941534996032715
Time for backpropagation: 0.040780067443847656
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5436792373657227 seconds
Index: 13
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7948846817016602 seconds
Streaming imagenet data took 1.808830738067627 seconds
Then, training+dataloading take 1.811434030532837 seconds
The mode is:  split
Start 15000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3361492156982422
Time for copying to cuda: 0.009355306625366211
Time for forward pass: 0.04922056198120117
Time for backpropagation: 0.0025365352630615234
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4797251224517822 seconds
Index: 14
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7197530269622803 seconds
Streaming imagenet data took 1.7336769104003906 seconds
Then, training+dataloading take 1.7361764907836914 seconds
The mode is:  split
Start 16000, end 17000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3520538806915283
Time for copying to cuda: 0.009380340576171875
Time for forward pass: 0.060416460037231445
Time for backpropagation: 0.003150463104248047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5450773239135742 seconds
Index: 15
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8055624961853027 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.8197646141052246 seconds
Then, training+dataloading take 1.822209358215332 seconds
The mode is:  split
Start 17000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33556461334228516
Time for copying to cuda: 0.009431838989257812
Time for forward pass: 0.0494692325592041
Time for backpropagation: 0.0027387142181396484
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.475506067276001 seconds
Index: 16
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8031065464019775 seconds
Streaming imagenet data took 1.8169724941253662 seconds
Then, training+dataloading take 1.81947922706604 seconds
The mode is:  split
Start 18000, end 19000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3383655548095703
Time for copying to cuda: 0.009396553039550781
Time for forward pass: 0.06548810005187988
Time for backpropagation: 0.0030536651611328125
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5187058448791504 seconds
Index: 17
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8290941715240479 seconds
Streaming imagenet data took 1.843034267425537 seconds
Then, training+dataloading take 1.845503330230713 seconds
The mode is:  split
Start 19000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.33959412574768066
Time for copying to cuda: 0.009467840194702148
Time for forward pass: 0.04935097694396973
Time for backpropagation: 0.0026869773864746094
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48259735107421875 seconds
Index: 18
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.6930937767028809 seconds
Streaming imagenet data took 1.7068603038787842 seconds
Then, training+dataloading take 1.7093544006347656 seconds
The mode is:  split
Start 20000, end 21000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3404514789581299
Time for copying to cuda: 0.009441852569580078
Time for forward pass: 0.049431800842285156
Time for backpropagation: 0.002682924270629883
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4892916679382324 seconds
Index: 19
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7519159317016602 seconds
Streaming imagenet data took 1.8049037456512451 seconds
Then, training+dataloading take 1.8091490268707275 seconds
The mode is:  split
Start 21000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3367605209350586
Time for copying to cuda: 0.009592056274414062
Time for forward pass: 0.04941248893737793
Time for backpropagation: 0.0027320384979248047
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.48101019859313965 seconds
Index: 20
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7509779930114746 seconds
Streaming imagenet data took 1.7651240825653076 seconds
Then, training+dataloading take 1.7678227424621582 seconds
The mode is:  split
Start 22000, end 23000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34276652336120605
Time for copying to cuda: 0.009358406066894531
Time for forward pass: 0.04940485954284668
Time for backpropagation: 0.002721548080444336
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.487900972366333 seconds
Index: 21
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8214576244354248 seconds
Streaming imagenet data took 1.835730791091919 seconds
Then, training+dataloading take 1.8373570442199707 seconds
The mode is:  split
Start 23000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39188194274902344
Time for copying to cuda: 0.009397506713867188
Time for forward pass: 0.04929208755493164
Time for backpropagation: 0.002639293670654297
GPU memory for training: 1.1639018058776855                          

Memory occpied: (2290.0, 1578.0)
One training iteration takes: 0.5428588390350342 seconds
Index: 22
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7717864513397217 seconds
Streaming imagenet data took 1.7856924533843994 seconds
Then, training+dataloading take 1.788304090499878 seconds
The mode is:  split
Start 24000, end 25000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3495335578918457
Time for copying to cuda: 0.009557723999023438
Time for forward pass: 0.049490928649902344
Time for backpropagation: 0.0027489662170410156
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5101027488708496 seconds
Index: 23
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.704897165298462 seconds
Streaming imagenet data took 1.7188992500305176 seconds
Then, training+dataloading take 1.7214863300323486 seconds
The mode is:  split
Start 25000, end 26000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.34246301651000977
Time for copying to cuda: 0.009408712387084961
Time for forward pass: 0.04926276206970215
Time for backpropagation: 0.0025599002838134766
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5148522853851318 seconds
Index: 24
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.8223395347595215 seconds
Memory occpied: (2290.0, 1578.0)
Streaming imagenet data took 1.8363161087036133 seconds
Then, training+dataloading take 1.8386902809143066 seconds
The mode is:  split
Start 26000, end 27000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3410203456878662
Time for copying to cuda: 0.009410381317138672
Time for forward pass: 0.049307823181152344
Time for backpropagation: 0.0025670528411865234
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4907104969024658 seconds
Index: 25
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7591266632080078 seconds
Streaming imagenet data took 1.7732748985290527 seconds
Then, training+dataloading take 1.7758564949035645 seconds
The mode is:  split
Start 27000, end 28000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.35181212425231934
Time for copying to cuda: 0.009353160858154297
Time for forward pass: 0.04919266700744629
Time for backpropagation: 0.0025720596313476562
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5378427505493164 seconds
Index: 26
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7545802593231201 seconds
Streaming imagenet data took 1.8069772720336914 seconds
Then, training+dataloading take 1.8112616539001465 seconds
The mode is:  split
Start 28000, end 29000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3545827865600586
Time for copying to cuda: 0.009404182434082031
Time for forward pass: 0.04947352409362793
Time for backpropagation: 0.002756834030151367
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5055806636810303 seconds
Index: 27
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.753159761428833 seconds
Streaming imagenet data took 1.767258644104004 seconds
Then, training+dataloading take 1.770017147064209 seconds
The mode is:  split
Start 29000, end 30000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3392505645751953
Time for copying to cuda: 0.009559154510498047
Time for forward pass: 0.04935860633850098
Time for backpropagation: 0.0026237964630126953
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4898808002471924 seconds
Index: 28
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7414581775665283 seconds
Streaming imagenet data took 1.7552845478057861 seconds
Then, training+dataloading take 1.757939100265503 seconds
The mode is:  split
Start 30000, end 31000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38422369956970215
Time for copying to cuda: 0.009406328201293945
Time for forward pass: 0.04931306838989258
Time for backpropagation: 0.00290679931640625
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.5467934608459473 seconds
Index: 29
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.7257325649261475 seconds
Streaming imagenet data took 1.7785985469818115 seconds
Then, training+dataloading take 1.7828900814056396 seconds
The mode is:  split
Start 31000, end 32000, post_step 1000


Epoch: 0
Memory occpied: (2290.0, 1578.0)
Memory occpied: (2290.0, 1578.0)
Time of next(dataloader) is: 0.3523533344268799
Time for copying to cuda: 0.009430408477783203
Time for forward pass: 0.049288272857666016
Time for backpropagation: 0.0026438236236572266
GPU memory for training: 1.1639018058776855                          

One training iteration takes: 0.4885289669036865 seconds
Index: 30
Memory occpied: (2290.0, 1578.0)
Read 35.1968879699707 MBs for this batch
Executing all posts took 1.767618179321289 seconds
Streaming imagenet data took 1.7814304828643799 seconds
Then, training+dataloading take 1.784177541732788 seconds

Epoch: 0
Time of next(dataloader) is: 0.3398914337158203
Time for copying to cuda: 0.009496927261352539
Time for forward pass: 0.0492701530456543
Time for backpropagation: 0.002855062484741211
GPU memory for training: 1.1639018058776855                          

The whole process took 66.14269495010376 seconds
