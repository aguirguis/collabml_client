Namespace(batch_size=512, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='manual', split_idx=8, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.489625079916 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
1505280000.0 119077552.13847475 119077552.13847475
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 8 17
Intermediate:  0.24755859375
1.47705078125
Total layers size  4.189361572265625
Fixed, scale_with_bsz  0 2.05126953125
Mem usage  1514.0 3.0
Using split index: 8
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 512, post_step 128

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7686347961425781 seconds
Streaming imagenet data took 1.8163762092590332 seconds
The mode is:  split
Start 512, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32251572608947754
Time for copying to cuda: 0.03279447555541992
Memory occpied: (1642.0, 180.0)
Memory occpied: (1642.0, 550.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7906146049499512 seconds
Streaming imagenet data took 1.8397095203399658 seconds
Memory occpied: (1642.0, 1002.0)
Memory occpied: (2892.0, 2694.0)
Time for forward pass: 3.7404072284698486
Time for backpropagation: 0.05892634391784668
GPU memory for training: 2.850322723388672                          

One training iteration takes: 4.225736141204834 seconds
Index: 0
Then, training+dataloading take 4.22618556022644 seconds
The mode is:  split
Start 1024, end 1536, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32829976081848145
Time for copying to cuda: 0.03286910057067871
Time for forward pass: 0.05107903480529785
Time for backpropagation: 0.0026750564575195312
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5048806667327881 seconds
Index: 1
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.984997034072876 seconds
Streaming imagenet data took 2.071967601776123 seconds
Then, training+dataloading take 2.0760557651519775 seconds
The mode is:  split
Start 1536, end 2048, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3852572441101074
Time for copying to cuda: 0.03322768211364746
Time for forward pass: 0.07033276557922363
Time for backpropagation: 0.003195047378540039
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.5806260108947754 seconds
Index: 2
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.001617670059204 seconds
Streaming imagenet data took 2.0498805046081543 seconds
Then, training+dataloading take 2.052183151245117 seconds
The mode is:  split
Start 2048, end 2560, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3585236072540283
Time for copying to cuda: 0.03246116638183594
Time for forward pass: 0.07118439674377441
Time for backpropagation: 0.004281759262084961
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5646851062774658 seconds
Index: 3
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9866297245025635 seconds
Streaming imagenet data took 2.070590019226074 seconds
Then, training+dataloading take 2.076143741607666 seconds
The mode is:  split
Start 2560, end 3072, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.35340070724487305
Time for copying to cuda: 0.03263568878173828
Time for forward pass: 0.0703573226928711
Time for backpropagation: 0.0030260086059570312
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.8247933387756348 seconds
Streaming imagenet data took 1.8735103607177734 seconds
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
One training iteration takes: 5.531509637832642 seconds
Index: 4
Then, training+dataloading take 5.531646013259888 seconds
The mode is:  split
Start 3072, end 3584, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3441762924194336
Time for copying to cuda: 0.0639944076538086
Memory occpied: (2670.0, 2710.0)
Time for forward pass: 0.07047319412231445
Time for backpropagation: 0.003002643585205078
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5770535469055176 seconds
Index: 5
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0692901611328125 seconds
Streaming imagenet data took 2.1165990829467773 seconds
Then, training+dataloading take 2.120363473892212 seconds
The mode is:  split
Start 3584, end 4096, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36151552200317383
Time for copying to cuda: 0.03252744674682617
Time for forward pass: 0.07025408744812012
Time for backpropagation: 0.0029304027557373047
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5554680824279785 seconds
Index: 6
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.805647611618042 seconds
Streaming imagenet data took 1.890007734298706 seconds
Then, training+dataloading take 1.8958804607391357 seconds
The mode is:  split
Start 4096, end 4608, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.36503171920776367
Time for copying to cuda: 0.03316807746887207
Time for forward pass: 0.06986856460571289
Time for backpropagation: 0.0034825801849365234
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.561718225479126 seconds
Index: 7
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9217722415924072 seconds
Streaming imagenet data took 1.968984842300415 seconds
Then, training+dataloading take 1.9745416641235352 seconds
The mode is:  split
Start 4608, end 5120, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37104225158691406
Time for copying to cuda: 0.0676889419555664
Memory occpied: (2670.0, 2710.0)
Time for forward pass: 0.07045364379882812
Time for backpropagation: 0.0028934478759765625
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.602297306060791 seconds
Index: 8
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7475831508636475 seconds
Streaming imagenet data took 1.7958991527557373 seconds
Then, training+dataloading take 1.8018057346343994 seconds
The mode is:  split
Start 5120, end 5632, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3649411201477051
Time for copying to cuda: 0.032230377197265625
Time for forward pass: 0.07043218612670898
Time for backpropagation: 0.0034368038177490234
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5613517761230469 seconds
Index: 9
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.903219223022461 seconds
Streaming imagenet data took 1.9501354694366455 seconds
Then, training+dataloading take 1.9546444416046143 seconds
The mode is:  split
Start 5632, end 6144, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.40722131729125977
Time for copying to cuda: 0.032532453536987305
Time for forward pass: 0.07031512260437012
Time for backpropagation: 0.0032863616943359375
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6119213104248047 seconds
Index: 10
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7369835376739502 seconds
Streaming imagenet data took 1.8218753337860107 seconds
Then, training+dataloading take 1.826155424118042 seconds
The mode is:  split
Start 6144, end 6656, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.3690476417541504
Time for copying to cuda: 0.0329132080078125
Time for forward pass: 0.0742647647857666
Time for backpropagation: 0.009722709655761719
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5715687274932861 seconds
Index: 11
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9339520931243896 seconds
Streaming imagenet data took 1.981337547302246 seconds
Then, training+dataloading take 1.9872016906738281 seconds
The mode is:  split
Start 6656, end 7168, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37210965156555176
Time for copying to cuda: 0.03293347358703613
Time for forward pass: 0.0713644027709961
Time for backpropagation: 0.0035812854766845703
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.5688884258270264 seconds
Index: 12
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.049804210662842 seconds
Streaming imagenet data took 2.096688985824585 seconds
Then, training+dataloading take 2.102426290512085 seconds
The mode is:  split
Start 7168, end 7680, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36505627632141113
Time for copying to cuda: 0.03281879425048828
Time for forward pass: 0.07026147842407227
Time for backpropagation: 0.0033426284790039062
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5645120143890381 seconds
Index: 13
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0531201362609863 seconds
Streaming imagenet data took 2.1015820503234863 seconds
Then, training+dataloading take 2.1061761379241943 seconds
The mode is:  split
Start 7680, end 8192, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36941075325012207
Time for copying to cuda: 0.0328824520111084
Time for forward pass: 0.07013940811157227
Time for backpropagation: 0.009359598159790039
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5676329135894775 seconds
Index: 14
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.992659568786621 seconds
Streaming imagenet data took 2.0401816368103027 seconds
Then, training+dataloading take 2.0436627864837646 seconds
The mode is:  split
Start 8192, end 8704, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.40512871742248535
Time for copying to cuda: 0.0348820686340332
Time for forward pass: 0.0749199390411377
Time for backpropagation: 0.003926515579223633
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6309170722961426 seconds
Index: 15
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.6584196090698242 seconds
Streaming imagenet data took 1.7433671951293945 seconds
Then, training+dataloading take 1.7472996711730957 seconds
The mode is:  split
Start 8704, end 9216, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.41193222999572754
Time for copying to cuda: 0.03465747833251953
Time for forward pass: 0.0701901912689209
Time for backpropagation: 0.0035076141357421875
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.6148581504821777 seconds
Index: 16
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0274689197540283 seconds
Streaming imagenet data took 2.0750935077667236 seconds
Then, training+dataloading take 2.0811054706573486 seconds
The mode is:  split
Start 9216, end 9728, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36933135986328125
Time for copying to cuda: 0.032617807388305664
Time for forward pass: 0.07046246528625488
Time for backpropagation: 0.003293275833129883
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.574437141418457 seconds
Index: 17
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.020320177078247 seconds
Streaming imagenet data took 2.103970527648926 seconds
Then, training+dataloading take 2.110011339187622 seconds
The mode is:  split
Start 9728, end 10240, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.37163209915161133
Time for copying to cuda: 0.03255295753479004
Time for forward pass: 0.07024216651916504
Time for backpropagation: 0.0029935836791992188
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5737118721008301 seconds
Index: 18
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7484736442565918 seconds
Streaming imagenet data took 1.7957994937896729 seconds
Then, training+dataloading take 1.8007705211639404 seconds
The mode is:  split
Start 10240, end 10752, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38076233863830566
Time for copying to cuda: 0.03274250030517578
Time for forward pass: 0.07115674018859863
Time for backpropagation: 0.0041844844818115234
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5892999172210693 seconds
Index: 19
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0126495361328125 seconds
Streaming imagenet data took 2.0598301887512207 seconds
Then, training+dataloading take 2.063521146774292 seconds
The mode is:  split
Start 10752, end 11264, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3713362216949463
Time for copying to cuda: 0.03284025192260742
Time for forward pass: 0.07032108306884766
Time for backpropagation: 0.0028994083404541016
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5743165016174316 seconds
Index: 20
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7431914806365967 seconds
Streaming imagenet data took 1.7918486595153809 seconds
Then, training+dataloading take 1.7974987030029297 seconds
The mode is:  split
Start 11264, end 11776, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4079623222351074
Time for copying to cuda: 0.03549504280090332
Time for forward pass: 0.07018017768859863
Time for backpropagation: 0.003000497817993164
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6194067001342773 seconds
Index: 21
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.6890301704406738 seconds
Streaming imagenet data took 1.774332046508789 seconds
Then, training+dataloading take 1.7788443565368652 seconds
The mode is:  split
Start 11776, end 12288, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.41147661209106445
Time for copying to cuda: 0.03284907341003418
Time for forward pass: 0.07397794723510742
Time for backpropagation: 0.0037293434143066406
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.6207520961761475 seconds
Index: 22
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.773374080657959 seconds
Memory occpied: (2670.0, 2710.0)
Streaming imagenet data took 1.820812463760376 seconds
Then, training+dataloading take 1.8262860774993896 seconds
The mode is:  split
Start 12288, end 12800, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3685121536254883
Time for copying to cuda: 0.03302621841430664
Time for forward pass: 0.07010507583618164
Time for backpropagation: 0.003068208694458008
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5673000812530518 seconds
Index: 23
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.8362109661102295 seconds
Streaming imagenet data took 1.8841536045074463 seconds
Then, training+dataloading take 1.8891091346740723 seconds
The mode is:  split
Start 12800, end 13312, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3827810287475586
Time for copying to cuda: 0.07021427154541016
Memory occpied: (2670.0, 2710.0)
Time for forward pass: 0.07271289825439453
Time for backpropagation: 0.004281759262084961
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6278510093688965 seconds
Index: 24
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.112504005432129 seconds
Streaming imagenet data took 2.1602935791015625 seconds
Then, training+dataloading take 2.1652402877807617 seconds
The mode is:  split
Start 13312, end 13824, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3729984760284424
Time for copying to cuda: 0.03268146514892578
Time for forward pass: 0.07001733779907227
Time for backpropagation: 0.0030031204223632812
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5785818099975586 seconds
Index: 25
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0691754817962646 seconds
Streaming imagenet data took 2.116835355758667 seconds
Then, training+dataloading take 2.12188982963562 seconds
The mode is:  split
Start 13824, end 14336, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36884260177612305
Time for copying to cuda: 0.03305387496948242
Time for forward pass: 0.07594704627990723
Time for backpropagation: 0.003809213638305664
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5820193290710449 seconds
Index: 26
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.000579833984375 seconds
Streaming imagenet data took 2.0852601528167725 seconds
Then, training+dataloading take 2.0892629623413086 seconds
The mode is:  split
Start 14336, end 14848, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.40767908096313477
Time for copying to cuda: 0.03461503982543945
Time for forward pass: 0.07033133506774902
Time for backpropagation: 0.002976655960083008
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6032633781433105 seconds
Index: 27
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9959630966186523 seconds
Streaming imagenet data took 2.04351806640625 seconds
Then, training+dataloading take 2.0475220680236816 seconds
The mode is:  split
Start 14848, end 15360, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3789641857147217
Time for copying to cuda: 0.06824922561645508
Time for forward pass: 0.08458328247070312
Time for backpropagation: 0.004074573516845703
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.636188268661499 seconds
Index: 28
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0087716579437256 seconds
Streaming imagenet data took 2.0564775466918945 seconds
Then, training+dataloading take 2.0590453147888184 seconds
The mode is:  split
Start 15360, end 15872, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3746039867401123
Time for copying to cuda: 0.03405284881591797
Time for forward pass: 0.07153630256652832
Time for backpropagation: 0.00292205810546875
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5827176570892334 seconds
Index: 29
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.017609119415283 seconds
Streaming imagenet data took 2.0658352375030518 seconds
Then, training+dataloading take 2.067209005355835 seconds
The mode is:  split
Start 15872, end 16384, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4167349338531494
Time for copying to cuda: 0.032720327377319336
Time for forward pass: 0.0741422176361084
Time for backpropagation: 0.0038187503814697266
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.6241741180419922 seconds
Index: 30
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7860474586486816 seconds
Memory occpied: (2670.0, 2710.0)
Streaming imagenet data took 1.8338308334350586 seconds
Then, training+dataloading take 1.8379087448120117 seconds
The mode is:  split
Start 16384, end 16896, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37018442153930664
Time for copying to cuda: 0.032671451568603516
Time for forward pass: 0.07013964653015137
Time for backpropagation: 0.0033271312713623047
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5722403526306152 seconds
Index: 31
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.737145185470581 seconds
Streaming imagenet data took 1.7843120098114014 seconds
Then, training+dataloading take 1.785278558731079 seconds
The mode is:  split
Start 16896, end 17408, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4015815258026123
Time for copying to cuda: 0.03395676612854004
Time for forward pass: 0.07515931129455566
Time for backpropagation: 0.00956106185913086
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.6155669689178467 seconds
Index: 32
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0468900203704834 seconds
Streaming imagenet data took 2.094393491744995 seconds
Then, training+dataloading take 2.0966970920562744 seconds
The mode is:  split
Start 17408, end 17920, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37850308418273926
Time for copying to cuda: 0.032408952713012695
Time for forward pass: 0.07021522521972656
Time for backpropagation: 0.0031478404998779297
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5747077465057373 seconds
Index: 33
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.981898307800293 seconds
Streaming imagenet data took 2.067091226577759 seconds
Then, training+dataloading take 2.0686235427856445 seconds
The mode is:  split
Start 17920, end 18432, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.3753657341003418
Time for copying to cuda: 0.03367805480957031
Time for forward pass: 0.07026481628417969
Time for backpropagation: 0.0029973983764648438
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5750701427459717 seconds
Index: 34
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9409995079040527 seconds
Streaming imagenet data took 1.9879021644592285 seconds
Then, training+dataloading take 1.9904699325561523 seconds
The mode is:  split
Start 18432, end 18944, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4185967445373535
Time for copying to cuda: 0.03574872016906738
Time for forward pass: 0.07015633583068848
Time for backpropagation: 0.005167245864868164
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6466434001922607 seconds
Index: 35
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9936974048614502 seconds
Streaming imagenet data took 2.04160475730896 seconds
Then, training+dataloading take 2.0442404747009277 seconds
The mode is:  split
Start 18944, end 19456, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3716239929199219
Time for copying to cuda: 0.03264594078063965
Time for forward pass: 0.07004714012145996
Time for backpropagation: 0.0029001235961914062
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5714411735534668 seconds
Index: 36
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.709768295288086 seconds
Streaming imagenet data took 1.7568044662475586 seconds
Then, training+dataloading take 1.7594664096832275 seconds
The mode is:  split
Start 19456, end 19968, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3803887367248535
Time for copying to cuda: 0.0674595832824707
Memory occpied: (2670.0, 2710.0)
Time for forward pass: 0.0704505443572998
Time for backpropagation: 0.002972126007080078
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6108682155609131 seconds
Index: 37
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.8809711933135986 seconds
Streaming imagenet data took 1.9288873672485352 seconds
Then, training+dataloading take 1.9301018714904785 seconds
The mode is:  split
Start 19968, end 20480, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3745849132537842
Time for copying to cuda: 0.03266191482543945
Time for forward pass: 0.07032155990600586
Time for backpropagation: 0.0030519962310791016
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5734143257141113 seconds
Index: 38
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7353355884552002 seconds
Streaming imagenet data took 1.7824482917785645 seconds
Then, training+dataloading take 1.7834022045135498 seconds
The mode is:  split
Start 20480, end 20992, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4340791702270508
Memory occpied: (2670.0, 2710.0)
Time for copying to cuda: 0.03661799430847168
Time for forward pass: 0.071014404296875
Time for backpropagation: 0.003833770751953125
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.642827033996582 seconds
Index: 39
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9931833744049072 seconds
Streaming imagenet data took 2.0406289100646973 seconds
Then, training+dataloading take 2.043229341506958 seconds
The mode is:  split
Start 20992, end 21504, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37758421897888184
Time for copying to cuda: 0.03259134292602539
Time for forward pass: 0.07011175155639648
Time for backpropagation: 0.0029032230377197266
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.7069377899169922 seconds
Streaming imagenet data took 1.75411057472229 seconds
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
One training iteration takes: 5.526299953460693 seconds
Index: 40
Then, training+dataloading take 5.526479721069336 seconds
The mode is:  split
Start 21504, end 22016, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.3613412380218506
Time for copying to cuda: 0.033670663833618164
Time for forward pass: 0.07034754753112793
Time for backpropagation: 0.0030469894409179688
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5584356784820557 seconds
Index: 41
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.006640672683716 seconds
Streaming imagenet data took 2.0545055866241455 seconds
Then, training+dataloading take 2.060922384262085 seconds
The mode is:  split
Start 22016, end 22528, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.40885353088378906
Time for copying to cuda: 0.03662610054016113
Time for forward pass: 0.07030081748962402
Time for backpropagation: 0.003012418746948242
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.6362168788909912 seconds
Index: 42
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0271143913269043 seconds
Streaming imagenet data took 2.0749332904815674 seconds
Then, training+dataloading take 2.0760836601257324 seconds
The mode is:  split
Start 22528, end 23040, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.380352258682251
Time for copying to cuda: 0.0334019660949707
Time for forward pass: 0.0704348087310791
Time for backpropagation: 0.002995729446411133
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5850179195404053 seconds
Index: 43
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0225305557250977 seconds
Streaming imagenet data took 2.11299991607666 seconds
Then, training+dataloading take 2.1162872314453125 seconds
The mode is:  split
Start 23040, end 23552, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.42272472381591797
Time for copying to cuda: 0.034030914306640625
Time for forward pass: 0.07017993927001953
Time for backpropagation: 0.002943277359008789
GPU memory for training: 1.6621217727661133                          

Memory occpied: (2670.0, 2710.0)
One training iteration takes: 0.6291909217834473 seconds
Index: 44
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 2.0933518409729004 seconds
Streaming imagenet data took 2.1410584449768066 seconds
Then, training+dataloading take 2.1447949409484863 seconds
The mode is:  split
Start 23552, end 24064, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3783423900604248
Time for copying to cuda: 0.032912254333496094
Time for forward pass: 0.0704195499420166
Time for backpropagation: 0.0028836727142333984
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5637228488922119 seconds
Index: 45
Memory occpied: (2670.0, 2710.0)
Read 126.77341079711914 MBs for this batch
Executing all posts took 1.9555096626281738 seconds
Streaming imagenet data took 2.0406339168548584 seconds
Then, training+dataloading take 2.043362855911255 seconds
The mode is:  split
Start 24064, end 24320, post_step 128


Epoch: 0
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.37935924530029297
Time for copying to cuda: 0.03245258331298828
Time for forward pass: 0.07332706451416016
Time for backpropagation: 0.004052877426147461
GPU memory for training: 1.6621217727661133                          

One training iteration takes: 0.5913097858428955 seconds
Index: 46
Read 63.38670539855957 MBs for this batch
Executing all posts took 1.1325926780700684 seconds
Streaming imagenet data took 1.194258689880371 seconds
Then, training+dataloading take 1.1978864669799805 seconds

Epoch: 0
Memory occpied: (2670.0, 2710.0)
Memory occpied: (2670.0, 2710.0)
Time of next(dataloader) is: 0.340177059173584
Time for copying to cuda: 0.016585350036621094
Time for forward pass: 0.2602367401123047
Time for backpropagation: 0.01105809211730957
GPU memory for training: 2.2077198028564453                          

The whole process took 111.14560103416443 seconds
