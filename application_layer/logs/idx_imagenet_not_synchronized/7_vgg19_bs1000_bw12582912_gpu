Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=36, model='myvgg19', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=7, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 10051.072314915418 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 1.2845056e+07 1.2845056e+07 3.2112640e+06
 6.4225280e+06 6.4225280e+06 6.4225280e+06 6.4225280e+06 1.6056320e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.6056320e+06
 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 1.6056320e+06 1.6056320e+06 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 1.6384000e+04 4.0000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 1317414150.4605937 1317414150.4605937
All candidates indexes:  (array([36, 37, 38, 39, 40, 41, 42, 43, 44]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 7 36
Intermediate:  6.125
24.5
Total layers size  119.34365844726562
Server, client, server+client, vanilla  949.6103515625 19501.36474609375 20450.97509765625 38450.58349609375
Fixed, scale_with_bsz  0 25.07421875
Mem usage  1894.0 3.0
Using split index: 7
Freezing the lower layers of the model (myvgg19) till index 36
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 23.865817546844482 seconds
Memory occpied: (1894.0, 3.0)
Memory occpied: (1894.0, 3.0)
Streaming imagenet data took 26.579768657684326 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 4.152980089187622
Time for copying to cuda: 1.5366523265838623
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 23.84589409828186 seconds
Streaming imagenet data took 26.0914363861084 seconds
Time for forward pass: 23.985573768615723
Time for backpropagation: 0.04917764663696289
GPU memory for training: 21.65230655670166                          

One training iteration takes: 30.537628412246704 seconds
Index: 0
Then, training+dataloading take 30.55079984664917 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Memory occpied: (1894.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Time of next(dataloader) is: 4.091317415237427
Memory occpied: (9520.0, 10552.0)
Memory occpied: (9520.0, 10552.0)
Time for copying to cuda: 1.6987287998199463
Memory occpied: (13712.0, 10560.0)
Memory occpied: (13712.0, 10560.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/collabml_client/application_layer/models/myvgg.py", line 39, in forward
    x = m(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/pooling.py", line 162, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py", line 422, in fn
    return if_false(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 797, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 14.76 GiB total capacity; 11.18 GiB already allocated; 1.36 GiB free; 12.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 75.13543605804443 seconds
Length of received data: 6422574121
Read 6125.043984413147 MBs for this batch
Executing all posts took 23.349286317825317 seconds
Streaming imagenet data took 25.642967700958252 seconds
