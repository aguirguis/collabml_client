Cached  True
Transformed  True
All in COS  False
No adaptation  False
Namespace(all_in_cos=False, batch_size=1000, cached=True, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=25, model='myvgg11', no_adaptation=False, num_epochs=1, sequential=False, split_choice='manual', split_idx=6, start=0, testonly=False, transformed=True, use_intermediate=True)
Nb GPUS  2
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 10617.268119887442 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 3.2112640e+06 6.4225280e+06 6.4225280e+06
 1.6056320e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 8.0281600e+05 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 4.0000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
224483624004266.66 1391626567.0098867 1391626567.0098867
All candidates indexes:  (array([20, 21, 22, 23, 24, 25, 26, 27, 28]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  manual 6 25
Intermediate:  1.53125
24.5
Total layers size  62.687408447265625
Server, client, server+client, vanilla  908.396484375 8264.83837890625 9173.23486328125 31807.80712890625
Fixed, scale_with_bsz  0 25.07421875
Mem usage  1840.0 3.0
Using split index: 6
Freezing the lower layers of the model (myvgg11) till index 25
The mode is:  split
Start 0, end 1000, post_step 1000

Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Memory occpied: (1840.0, 3.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.551135778427124 seconds
Memory occpied: (1840.0, 3.0)
Streaming imagenet data took 8.217390060424805 seconds
The mode is:  split
Start 1000, end 2000, post_step 1000


Epoch: 0
Memory occpied: (1840.0, 3.0)
Time of next(dataloader) is: 1.1477646827697754
Time for copying to cuda: 0.3901965618133545
Memory occpied: (3372.0, 934.0)
Memory occpied: (3372.0, 1346.0)
Memory occpied: (3372.0, 1800.0)
Memory occpied: (12198.0, 10966.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.503968954086304 seconds
Memory occpied: (13452.0, 10966.0)
Streaming imagenet data took 8.19106149673462 seconds
Memory occpied: (13452.0, 10966.0)
Memory occpied: (13452.0, 10966.0)
Memory occpied: (11920.0, 10966.0)
Memory occpied: (11920.0, 10966.0)
Memory occpied: (11920.0, 10974.0)
Time for forward pass: 12.851943969726562
Time for backpropagation: 0.04766488075256348
GPU memory for training: 21.35338592529297                          

One training iteration takes: 14.656179428100586 seconds
Index: 0
Then, training+dataloading take 14.659504175186157 seconds
The mode is:  split
Start 2000, end 3000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 1.337691068649292
Time for copying to cuda: 0.3873279094696045
Time for forward pass: 2.7614479064941406
Time for backpropagation: 0.004976034164428711
GPU memory for training: 16.727325439453125                          

One training iteration takes: 4.830073595046997 seconds
Index: 1
Memory occpied: (11930.0, 4090.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.570581912994385 seconds
Memory occpied: (11936.0, 4090.0)
Streaming imagenet data took 8.207276821136475 seconds
Then, training+dataloading take 8.287848711013794 seconds
The mode is:  split
Start 3000, end 4000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 4090.0)
Time of next(dataloader) is: 1.289428472518921
Time for copying to cuda: 0.38378477096557617
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8708946704864502
Time for backpropagation: 0.0033125877380371094
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.797630548477173 seconds
Index: 2
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 6.963035345077515 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.6580445766448975 seconds
Then, training+dataloading take 7.748088121414185 seconds
The mode is:  split
Start 4000, end 5000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2162175178527832
Time for copying to cuda: 0.38567471504211426
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8952915668487549
Time for backpropagation: 0.0032126903533935547
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.7543346881866455 seconds
Index: 3
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.075059175491333 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.7011878490448 seconds
Then, training+dataloading take 7.789398431777954 seconds
The mode is:  split
Start 5000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.232050895690918
Time for copying to cuda: 0.38539791107177734
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8806488513946533
Time for backpropagation: 0.0032532215118408203
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.7493045330047607 seconds
Index: 4
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.078145980834961 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.698212623596191 seconds
Then, training+dataloading take 7.745047092437744 seconds
The mode is:  split
Start 6000, end 7000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.291257381439209
Time for copying to cuda: 0.3834853172302246
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8496901988983154
Time for backpropagation: 0.0032329559326171875
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.7666947841644287 seconds
Index: 5
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.120909929275513 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 7.748874664306641 seconds
Then, training+dataloading take 7.8324902057647705 seconds
The mode is:  split
Start 7000, end 8000, post_step 1000


Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2255098819732666
Time for copying to cuda: 0.38826918601989746
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.8699393272399902
Time for backpropagation: 0.0033571720123291016
GPU memory for training: 16.727325439453125                          

One training iteration takes: 2.730375051498413 seconds
Index: 6
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Memory occpied: (11936.0, 9388.0)
Length of received data: 1605678121
Read 1531.293984413147 MBs for this batch
Executing all posts took 7.506047010421753 seconds
Memory occpied: (11936.0, 9388.0)
Streaming imagenet data took 8.126054525375366 seconds
Then, training+dataloading take 8.210932970046997 seconds

Epoch: 0
Memory occpied: (11936.0, 9388.0)
Time of next(dataloader) is: 1.2529573440551758
Time for copying to cuda: 0.388019323348999
Memory occpied: (11936.0, 9388.0)
Time for forward pass: 0.866631269454956
Time for backpropagation: 0.0032224655151367188
GPU memory for training: 16.727325439453125                          

The whole process took 81.41432690620422 seconds
