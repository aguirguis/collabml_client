Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=25, model='myvgg11', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3138228720328 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 3.2112640e+06 6.4225280e+06 6.4225280e+06
 1.6056320e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 8.0281600e+05 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 8.8000000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119054509.39148308 119054509.39148308
All candidates indexes:  (array([20, 21, 22, 23, 24, 25, 26, 27, 28]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 25
Intermediate:  0.095703125
24.5
Total layers size  62.683677673339844
Server, client, server+client, vanilla  1118.40478515625 567.7547607421875 1686.1595458984375 5563.4578857421875
Candidate split  21
Server, client, server+client, vanilla  1118.40478515625 567.7547607421875 1686.1595458984375 5563.4578857421875
Model size  491.54931640625
Fixed, scale_with_bsz  491.54931640625 25.07421875
Mem usage  1824.0 3.0
Using split index: 21
Freezing the lower layers of the model (myvgg11) till index 25
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1824.0, 3.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9739983081817627 seconds
Streaming plantleave data took 0.9816575050354004 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3296635150909424
Time for copying to cuda: 0.005363941192626953
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.96700119972229 seconds
Streaming plantleave data took 0.9748618602752686 seconds
Time for forward pass: 3.007275342941284
Time for backpropagation: 0.05276322364807129
GPU memory for training: 1.9644956588745117                          

One training iteration takes: 3.4896905422210693 seconds
Index: 0
Then, training+dataloading take 3.4899346828460693 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Memory occpied: (1824.0, 1798.0)
Time of next(dataloader) is: 0.3678462505340576
Time for copying to cuda: 0.0054323673248291016
Time for forward pass: 0.06019902229309082
Time for backpropagation: 0.0031304359436035156
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5232772827148438 seconds
Index: 1
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8517522811889648 seconds
Streaming plantleave data took 0.8593714237213135 seconds
Then, training+dataloading take 0.8598392009735107 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4022409915924072
Time for copying to cuda: 0.005356311798095703
Time for forward pass: 0.06000924110412598
Time for backpropagation: 0.0031404495239257812
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5839190483093262 seconds
Index: 2
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8763444423675537 seconds
Streaming plantleave data took 0.884152889251709 seconds
Then, training+dataloading take 0.8844907283782959 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3494400978088379
Time for copying to cuda: 0.005270481109619141
Time for forward pass: 0.059963226318359375
Time for backpropagation: 0.003027677536010742
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5069460868835449 seconds
Index: 3
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9215984344482422 seconds
Streaming plantleave data took 0.93107008934021 seconds
Then, training+dataloading take 0.9318230152130127 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (3412.0, 1806.0)
Time of next(dataloader) is: 0.3364684581756592
Time for copying to cuda: 0.005270481109619141
Time for forward pass: 0.05986499786376953
Time for backpropagation: 0.002978086471557617
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.48702526092529297 seconds
Index: 4
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.7948541641235352 seconds
Streaming plantleave data took 0.7999706268310547 seconds
Then, training+dataloading take 0.8003959655761719 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3631458282470703
Time for copying to cuda: 0.005360126495361328
Time for forward pass: 0.0987234115600586
Time for backpropagation: 0.003570079803466797
GPU memory for training: 2.0885462760925293                          

Memory occpied: (3412.0, 1806.0)
One training iteration takes: 0.5597259998321533 seconds
Index: 5
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9434576034545898 seconds
Streaming plantleave data took 0.9479925632476807 seconds
Then, training+dataloading take 0.9483110904693604 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3388841152191162
Time for copying to cuda: 0.005285501480102539
Time for forward pass: 0.06002378463745117
Time for backpropagation: 0.00304412841796875
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.4991765022277832 seconds
Index: 6
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8610470294952393 seconds
Streaming plantleave data took 0.8656229972839355 seconds
Then, training+dataloading take 0.8659923076629639 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3410916328430176
Time for copying to cuda: 0.005297660827636719
Time for forward pass: 0.060029029846191406
Time for backpropagation: 0.0030770301818847656
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.4915585517883301 seconds
Index: 7
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.7631332874298096 seconds
Streaming plantleave data took 0.7682347297668457 seconds
Then, training+dataloading take 0.768641471862793 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3946208953857422
Time for copying to cuda: 0.0052373409271240234
Time for forward pass: 0.059882402420043945
Time for backpropagation: 0.0030057430267333984
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5670344829559326 seconds
Index: 8
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9595952033996582 seconds
Streaming plantleave data took 0.9642815589904785 seconds
Then, training+dataloading take 0.9646406173706055 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.340207576751709
Time for copying to cuda: 0.005265474319458008
Time for forward pass: 0.06001543998718262
Time for backpropagation: 0.0030667781829833984
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5032558441162109 seconds
Index: 9
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 1.1108129024505615 seconds
Streaming plantleave data took 1.1160531044006348 seconds
Then, training+dataloading take 1.1164531707763672 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34192776679992676
Time for copying to cuda: 0.005210399627685547
Time for forward pass: 0.05993485450744629
Time for backpropagation: 0.0030281543731689453
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.49468326568603516 seconds
Index: 10
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9264729022979736 seconds
Streaming plantleave data took 0.9358465671539307 seconds
Then, training+dataloading take 0.936436653137207 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Memory occpied: (3412.0, 1806.0)
Time of next(dataloader) is: 0.3376734256744385
Time for copying to cuda: 0.005283832550048828
Time for forward pass: 0.059969186782836914
Time for backpropagation: 0.003119230270385742
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.4988086223602295 seconds
Index: 11
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.937000036239624 seconds
Streaming plantleave data took 0.9421002864837646 seconds
Then, training+dataloading take 0.9425065517425537 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Memory occpied: (3412.0, 1806.0)
Time of next(dataloader) is: 0.43398284912109375
Time for copying to cuda: 0.00528264045715332
Time for forward pass: 0.05995774269104004
Time for backpropagation: 0.0031027793884277344
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5913479328155518 seconds
Index: 12
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8987598419189453 seconds
Streaming plantleave data took 0.9034247398376465 seconds
Then, training+dataloading take 0.9037590026855469 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34784579277038574
Time for copying to cuda: 0.00528717041015625
Time for forward pass: 0.059989213943481445
Time for backpropagation: 0.003106832504272461
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.502234697341919 seconds
Index: 13
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8493521213531494 seconds
Streaming plantleave data took 0.8544309139251709 seconds
Then, training+dataloading take 0.8548812866210938 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3364543914794922
Time for copying to cuda: 0.0052530765533447266
Time for forward pass: 0.059912919998168945
Time for backpropagation: 0.003014087677001953
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.48558592796325684 seconds
Index: 14
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8675432205200195 seconds
Streaming plantleave data took 0.9163417816162109 seconds
Then, training+dataloading take 0.9177091121673584 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39534735679626465
Time for copying to cuda: 0.005301237106323242
Time for forward pass: 0.05994558334350586
Time for backpropagation: 0.0030214786529541016
GPU memory for training: 2.0885462760925293                          

Memory occpied: (3412.0, 1806.0)
One training iteration takes: 0.5518143177032471 seconds
Index: 15
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8692905902862549 seconds
Streaming plantleave data took 0.8742868900299072 seconds
Then, training+dataloading take 0.8749113082885742 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3419466018676758
Time for copying to cuda: 0.00534510612487793
Time for forward pass: 0.059877872467041016
Time for backpropagation: 0.0029320716857910156
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.4917609691619873 seconds
Index: 16
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8743441104888916 seconds
Streaming plantleave data took 0.8790476322174072 seconds
Then, training+dataloading take 0.8795082569122314 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3410971164703369
Time for copying to cuda: 0.005295515060424805
Time for forward pass: 0.059891462326049805
Time for backpropagation: 0.0030829906463623047
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.49767255783081055 seconds
Index: 17
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8287746906280518 seconds
Streaming plantleave data took 0.8337206840515137 seconds
Then, training+dataloading take 0.8340694904327393 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3831138610839844
Time for copying to cuda: 0.005318641662597656
Time for forward pass: 0.06004810333251953
Time for backpropagation: 0.0031363964080810547
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.559546709060669 seconds
Index: 18
Memory occpied: (3412.0, 1806.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.890817403793335 seconds
Streaming plantleave data took 0.8955142498016357 seconds
Then, training+dataloading take 0.8958430290222168 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3347318172454834
Time for copying to cuda: 0.005265235900878906
Time for forward pass: 0.060003042221069336
Time for backpropagation: 0.0034399032592773438
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.5112524032592773 seconds
Index: 19
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.8933234214782715 seconds
Streaming plantleave data took 0.9033334255218506 seconds
Then, training+dataloading take 0.9043140411376953 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (3412.0, 1806.0)
Time of next(dataloader) is: 0.3395407199859619
Time for copying to cuda: 0.005209207534790039
Time for forward pass: 0.05995988845825195
Time for backpropagation: 0.0030221939086914062
GPU memory for training: 2.0885462760925293                          

One training iteration takes: 0.4965839385986328 seconds
Index: 20
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.9585423469543457 seconds
Streaming plantleave data took 0.9631500244140625 seconds
Then, training+dataloading take 0.9636731147766113 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38413357734680176
Time for copying to cuda: 0.0054552555084228516
Time for forward pass: 0.06002545356750488
Time for backpropagation: 0.0030455589294433594
GPU memory for training: 2.0885462760925293                          

Read 9.766636848449707 MBs for this batch
Executing all posts took 0.5462141036987305 seconds
One training iteration takes: 0.5896749496459961 seconds
Index: 21
Streaming plantleave data took 0.5948245525360107 seconds
Then, training+dataloading take 0.5955374240875244 seconds

Epoch: 0
Memory occpied: (3412.0, 1806.0)
Time of next(dataloader) is: 0.3360610008239746
Time for copying to cuda: 0.002886533737182617
Time for forward pass: 0.05379533767700195
Time for backpropagation: 0.0037233829498291016
GPU memory for training: 2.075857639312744                          

The whole process took 31.97371816635132 seconds
