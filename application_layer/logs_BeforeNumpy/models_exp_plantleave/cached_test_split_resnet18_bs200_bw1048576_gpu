Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=11, model='myresnet18', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.0782590611916 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.211264e+06 3.211264e+06 3.211264e+06 8.028160e+05 4.816896e+06
 4.816896e+06 2.408448e+06 2.408448e+06 1.204224e+06 1.204224e+06
 6.021120e+05 6.021120e+05 2.048000e+03 8.800000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119023633.5716685 119023633.5716685
All candidates indexes:  (array([12, 13]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 11
Intermediate:  0.095703125
6.125
Total layers size  27.181724548339844
Server, client, server+client, vanilla  210.21044921875 100.9666748046875 311.1771240234375 1421.6697998046875
Fixed, scale_with_bsz  0 6.69921875
Mem usage  1336.0 3.0
Using split index: 11
Freezing the lower layers of the model (myresnet18) till index 11
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1336.0, 3.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.6047217845916748 seconds
Streaming plantleave data took 0.6122522354125977 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3084137439727783
Time for copying to cuda: 0.005759000778198242
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.648310661315918 seconds
Streaming plantleave data took 0.6943042278289795 seconds
Memory occpied: (1356.0, 222.0)
Memory occpied: (1356.0, 644.0)
Memory occpied: (1356.0, 1118.0)
Time for forward pass: 3.414557695388794
Time for backpropagation: 0.24164915084838867
GPU memory for training: 3.1214780807495117                          

One training iteration takes: 4.025763988494873 seconds
Index: 0
Then, training+dataloading take 4.025827884674072 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.477489709854126
Time for copying to cuda: 0.005728721618652344
Memory occpied: (2888.0, 2952.0)
Time for forward pass: 0.016047239303588867
Time for backpropagation: 0.004511833190917969
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.5754837989807129 seconds
Index: 1
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.7301642894744873 seconds
Streaming plantleave data took 0.7377774715423584 seconds
Then, training+dataloading take 0.7380838394165039 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36491894721984863
Time for copying to cuda: 0.00562286376953125
Time for forward pass: 0.017104387283325195
Time for backpropagation: 0.0046541690826416016
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.4654057025909424 seconds
Index: 2
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5088768005371094 seconds
Streaming plantleave data took 0.5168614387512207 seconds
Then, training+dataloading take 0.5171692371368408 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4368722438812256
Time for copying to cuda: 0.005963802337646484
Time for forward pass: 0.017130136489868164
Time for backpropagation: 0.00497889518737793
GPU memory for training: 0.4096674919128418                          

Read 19.15005111694336 MBs for this batch
Executing all posts took 0.6092488765716553 seconds
Streaming plantleave data took 0.6187717914581299 seconds
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
One training iteration takes: 5.488526105880737 seconds
Index: 3
Then, training+dataloading take 5.488679647445679 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (2904.0, 2968.0)
Time of next(dataloader) is: 0.3555893898010254
Time for copying to cuda: 0.0060596466064453125
Time for forward pass: 0.01877903938293457
Time for backpropagation: 0.004175662994384766
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.474215030670166 seconds
Index: 4
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.519782304763794 seconds
Streaming plantleave data took 0.5274121761322021 seconds
Then, training+dataloading take 0.5278325080871582 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35860681533813477
Time for copying to cuda: 0.0054895877838134766
Time for forward pass: 0.02050495147705078
Time for backpropagation: 0.010709524154663086
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.498821496963501 seconds
Index: 5
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.507305383682251 seconds
Streaming plantleave data took 0.5152401924133301 seconds
Then, training+dataloading take 0.5155730247497559 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4187352657318115
Time for copying to cuda: 0.005730390548706055
Time for forward pass: 0.018352031707763672
Time for backpropagation: 0.00507354736328125
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.5673701763153076 seconds
Index: 6
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.6105649471282959 seconds
Streaming plantleave data took 0.6182401180267334 seconds
Then, training+dataloading take 0.6186385154724121 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Memory occpied: (2904.0, 2968.0)
Time of next(dataloader) is: 0.3782498836517334
Time for copying to cuda: 0.00571751594543457
Time for forward pass: 0.01954030990600586
Time for backpropagation: 0.006762504577636719
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.4960134029388428 seconds
Index: 7
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5098674297332764 seconds
Streaming plantleave data took 0.5150256156921387 seconds
Then, training+dataloading take 0.5154004096984863 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3620476722717285
Time for copying to cuda: 0.0058917999267578125
Time for forward pass: 0.016894102096557617
Time for backpropagation: 0.005326986312866211
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.48145222663879395 seconds
Index: 8
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.4987788200378418 seconds
Streaming plantleave data took 0.5034244060516357 seconds
Then, training+dataloading take 0.5037662982940674 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4432332515716553
Time for copying to cuda: 0.005629777908325195
Time for forward pass: 0.0193326473236084
Time for backpropagation: 0.0048558712005615234
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.5896027088165283 seconds
Index: 9
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.631359338760376 seconds
Streaming plantleave data took 0.641132116317749 seconds
Then, training+dataloading take 0.6415791511535645 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Memory occpied: (2904.0, 2968.0)
Time of next(dataloader) is: 0.4080781936645508
Time for copying to cuda: 0.0056726932525634766
Time for forward pass: 0.020648956298828125
Time for backpropagation: 0.005366086959838867
GPU memory for training: 0.4096674919128418                          

Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5457699298858643 seconds
Streaming plantleave data took 0.5549237728118896 seconds
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
One training iteration takes: 5.460109233856201 seconds
Index: 10
Then, training+dataloading take 5.460196256637573 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35393524169921875
Time for copying to cuda: 0.005322933197021484
Time for forward pass: 0.015663623809814453
Time for backpropagation: 0.004194021224975586
GPU memory for training: 0.4096674919128418                          

Memory occpied: (2904.0, 2968.0)
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.7158868312835693 seconds
Streaming plantleave data took 0.7235198020935059 seconds
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
Memory occpied: (2904.0, 2968.0)
One training iteration takes: 5.428918838500977 seconds
Index: 11
Then, training+dataloading take 5.429060697555542 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Memory occpied: (2904.0, 2968.0)
Time of next(dataloader) is: 0.40595006942749023
Time for copying to cuda: 0.005992889404296875
Time for forward pass: 0.020144224166870117
Time for backpropagation: 0.004976749420166016
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.539525032043457 seconds
Index: 12
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5483369827270508 seconds
Streaming plantleave data took 0.5561597347259521 seconds
Then, training+dataloading take 0.5565624237060547 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36403679847717285
Time for copying to cuda: 0.005853891372680664
Time for forward pass: 0.017443180084228516
Time for backpropagation: 0.010863065719604492
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.48170900344848633 seconds
Index: 13
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5169832706451416 seconds
Streaming plantleave data took 0.5250914096832275 seconds
Then, training+dataloading take 0.5254395008087158 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47084856033325195
Time for copying to cuda: 0.005498409271240234
Time for forward pass: 0.018564224243164062
Time for backpropagation: 0.005833625793457031
GPU memory for training: 0.4096674919128418                          

Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5779962539672852 seconds
Memory occpied: (2904.0, 2968.0)
Streaming plantleave data took 0.5844178199768066 seconds
One training iteration takes: 0.591052770614624 seconds
Index: 14
Then, training+dataloading take 0.5910899639129639 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.373610258102417
Time for copying to cuda: 0.007096529006958008
Time for forward pass: 0.02507328987121582
Time for backpropagation: 0.006742238998413086
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.4867434501647949 seconds
Index: 15
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5114667415618896 seconds
Streaming plantleave data took 0.5189275741577148 seconds
Then, training+dataloading take 0.5192303657531738 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38622450828552246
Time for copying to cuda: 0.005571842193603516
Time for forward pass: 0.016524314880371094
Time for backpropagation: 0.0050814151763916016
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.5256586074829102 seconds
Index: 16
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5655453205108643 seconds
Streaming plantleave data took 0.5738592147827148 seconds
Then, training+dataloading take 0.5742642879486084 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.43062543869018555
Time for copying to cuda: 0.0056836605072021484
Time for forward pass: 0.017373323440551758
Time for backpropagation: 0.005138874053955078
GPU memory for training: 0.4096674919128418                          

Memory occpied: (2904.0, 2968.0)
One training iteration takes: 0.5452094078063965 seconds
Index: 17
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5550844669342041 seconds
Streaming plantleave data took 0.5596976280212402 seconds
Then, training+dataloading take 0.5600600242614746 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.404940128326416
Time for copying to cuda: 0.005608558654785156
Time for forward pass: 0.017333269119262695
Time for backpropagation: 0.005308628082275391
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.525723934173584 seconds
Index: 18
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.545151948928833 seconds
Streaming plantleave data took 0.5503766536712646 seconds
Then, training+dataloading take 0.5507049560546875 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3667027950286865
Time for copying to cuda: 0.005353689193725586
Time for forward pass: 0.01699233055114746
Time for backpropagation: 0.0049648284912109375
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.5029482841491699 seconds
Index: 19
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.6201567649841309 seconds
Streaming plantleave data took 0.6296210289001465 seconds
Then, training+dataloading take 0.6302957534790039 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (2904.0, 2968.0)
Time of next(dataloader) is: 0.3688852787017822
Time for copying to cuda: 0.0055694580078125
Time for forward pass: 0.020163536071777344
Time for backpropagation: 0.005534172058105469
GPU memory for training: 0.4096674919128418                          

One training iteration takes: 0.49030566215515137 seconds
Index: 20
Read 19.15005111694336 MBs for this batch
Executing all posts took 0.5043807029724121 seconds
Streaming plantleave data took 0.5094881057739258 seconds
Then, training+dataloading take 0.5098729133605957 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3744215965270996
Time for copying to cuda: 0.006568431854248047
Time for forward pass: 0.017395734786987305
Time for backpropagation: 0.008464574813842773
GPU memory for training: 0.4096674919128418                          

Read 9.766636848449707 MBs for this batch
Executing all posts took 0.4189615249633789 seconds
Streaming plantleave data took 0.4279146194458008 seconds
One training iteration takes: 0.4846327304840088 seconds
Index: 21
Then, training+dataloading take 0.4846780300140381 seconds

Epoch: 0
Time of next(dataloader) is: 0.3970036506652832
Time for copying to cuda: 0.0029838085174560547
Time for forward pass: 0.09903526306152344
Time for backpropagation: 0.13673043251037598
GPU memory for training: 2.7057242393493652                          

Memory occpied: (2904.0, 2854.0)
The whole process took 39.09959959983826 seconds
