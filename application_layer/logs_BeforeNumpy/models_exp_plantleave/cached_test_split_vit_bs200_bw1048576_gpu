Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myvit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.2209277570348 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [6.02112e+05 0.00000e+00 0.00000e+00 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06 9.07776e+06
 9.07776e+06 9.07776e+06 9.07776e+06 3.07200e+03 3.07200e+03 3.07200e+03
 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119042333.44297007 119042333.44297007
All candidates indexes:  (array([15, 16, 17, 18]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.0029296875
17.314453125
Total layers size  104.46981048583984
Server, client, server+client, vanilla  774.57763671875 330.3240966796875 1104.9017333984375 3907.4725341796875
Candidate split  16
Server, client, server+client, vanilla  774.57763671875 330.3240966796875 1104.9017333984375 3907.4725341796875
Model size  327.36083984375
Fixed, scale_with_bsz  327.36083984375 17.888671875
Mem usage  1654.0 3.0
Using split index: 16
Freezing the lower layers of the model (myvit) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6711766719818115 seconds
Streaming plantleave data took 1.6717820167541504 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.30230712890625
Time for copying to cuda: 0.0004534721374511719
Memory occpied: (1654.0, 258.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5722179412841797 seconds
Streaming plantleave data took 1.5728991031646729 seconds
Memory occpied: (1654.0, 684.0)
Memory occpied: (1654.0, 1146.0)
Time for forward pass: 3.259122848510742
Time for backpropagation: 0.07581830024719238
GPU memory for training: 1.3172731399536133                          

One training iteration takes: 3.706498384475708 seconds
Index: 0
Then, training+dataloading take 3.706566095352173 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3467707633972168
Time for copying to cuda: 0.0004830360412597656
Time for forward pass: 0.03343796730041504
Time for backpropagation: 0.00882411003112793
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.46602416038513184 seconds
Index: 1
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6033272743225098 seconds
Streaming plantleave data took 1.6038970947265625 seconds
Then, training+dataloading take 1.6042819023132324 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38946008682250977
Time for copying to cuda: 0.0004622936248779297
Time for forward pass: 0.033333539962768555
Time for backpropagation: 0.008166790008544922
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.536085844039917 seconds
Index: 2
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6408493518829346 seconds
Streaming plantleave data took 1.6416282653808594 seconds
Then, training+dataloading take 1.6424269676208496 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.38730764389038086
Time for copying to cuda: 0.0004646778106689453
Time for forward pass: 0.033441781997680664
Time for backpropagation: 0.007946014404296875
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5206015110015869 seconds
Index: 3
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.564378261566162 seconds
Streaming plantleave data took 1.5649771690368652 seconds
Then, training+dataloading take 1.5655159950256348 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3312695026397705
Time for copying to cuda: 0.0004475116729736328
Time for forward pass: 0.03343653678894043
Time for backpropagation: 0.00784611701965332
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.4582326412200928 seconds
Index: 4
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.623126745223999 seconds
Streaming plantleave data took 1.6235995292663574 seconds
Then, training+dataloading take 1.6239676475524902 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.32924437522888184
Time for copying to cuda: 0.0004134178161621094
Time for forward pass: 0.03337359428405762
Time for backpropagation: 0.007922649383544922
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.4617347717285156 seconds
Index: 5
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5901474952697754 seconds
Streaming plantleave data took 1.590632438659668 seconds
Then, training+dataloading take 1.590991735458374 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38326096534729004
Time for copying to cuda: 0.00045418739318847656
Time for forward pass: 0.03378105163574219
Time for backpropagation: 0.008101463317871094
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.531829833984375 seconds
Index: 6
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6376843452453613 seconds
Streaming plantleave data took 1.6386477947235107 seconds
Then, training+dataloading take 1.6394391059875488 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.38216257095336914
Time for copying to cuda: 0.00043892860412597656
Time for forward pass: 0.03367137908935547
Time for backpropagation: 0.00812220573425293
GPU memory for training: 1.337578296661377                          

Memory occpied: (2422.0, 1660.0)
One training iteration takes: 0.5109825134277344 seconds
Index: 7
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6798183917999268 seconds
Streaming plantleave data took 1.680781602859497 seconds
Then, training+dataloading take 1.6813569068908691 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.3746321201324463
Time for copying to cuda: 0.00044608116149902344
Time for forward pass: 0.03382563591003418
Time for backpropagation: 0.008118629455566406
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5055570602416992 seconds
Index: 8
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5869669914245605 seconds
Streaming plantleave data took 1.5874526500701904 seconds
Then, training+dataloading take 1.5879123210906982 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.330413818359375
Time for copying to cuda: 0.0004291534423828125
Time for forward pass: 0.03328394889831543
Time for backpropagation: 0.007978677749633789
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.4671494960784912 seconds
Index: 9
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6155223846435547 seconds
Streaming plantleave data took 1.6159958839416504 seconds
Then, training+dataloading take 1.6163427829742432 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37482690811157227
Time for copying to cuda: 0.00043964385986328125
Time for forward pass: 0.033858299255371094
Time for backpropagation: 0.0081939697265625
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5082671642303467 seconds
Index: 10
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.602586030960083 seconds
Streaming plantleave data took 1.6035358905792236 seconds
Then, training+dataloading take 1.604311227798462 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.402559757232666
Time for copying to cuda: 0.0004277229309082031
Time for forward pass: 0.03367781639099121
Time for backpropagation: 0.008120059967041016
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5241320133209229 seconds
Index: 11
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6050746440887451 seconds
Streaming plantleave data took 1.605567216873169 seconds
Then, training+dataloading take 1.6060287952423096 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.33183789253234863
Time for copying to cuda: 0.0004513263702392578
Time for forward pass: 0.033679962158203125
Time for backpropagation: 0.008068084716796875
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.45312047004699707 seconds
Index: 12
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.620668649673462 seconds
Streaming plantleave data took 1.6211445331573486 seconds
Then, training+dataloading take 1.621513843536377 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34888195991516113
Time for copying to cuda: 0.0004527568817138672
Time for forward pass: 0.03336477279663086
Time for backpropagation: 0.007976293563842773
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.474825382232666 seconds
Index: 13
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6584420204162598 seconds
Streaming plantleave data took 1.658935546875 seconds
Then, training+dataloading take 1.6593241691589355 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.37045788764953613
Time for copying to cuda: 0.0004856586456298828
Time for forward pass: 0.03338217735290527
Time for backpropagation: 0.007860898971557617
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5353512763977051 seconds
Index: 14
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5995144844055176 seconds
Streaming plantleave data took 1.6393661499023438 seconds
Then, training+dataloading take 1.6405603885650635 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3701300621032715
Time for copying to cuda: 0.0004086494445800781
Time for forward pass: 0.05892443656921387
Time for backpropagation: 0.0076754093170166016
GPU memory for training: 1.337578296661377                          

Memory occpied: (2422.0, 1660.0)
One training iteration takes: 0.5282938480377197 seconds
Index: 15
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6696035861968994 seconds
Streaming plantleave data took 1.6705293655395508 seconds
Then, training+dataloading take 1.6711959838867188 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Memory occpied: (2422.0, 1660.0)
Time of next(dataloader) is: 0.32972288131713867
Time for copying to cuda: 0.0004677772521972656
Time for forward pass: 0.033551931381225586
Time for backpropagation: 0.00797891616821289
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.4577319622039795 seconds
Index: 16
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5946533679962158 seconds
Streaming plantleave data took 1.5951600074768066 seconds
Then, training+dataloading take 1.5956318378448486 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3297436237335205
Time for copying to cuda: 0.00042939186096191406
Time for forward pass: 0.03330421447753906
Time for backpropagation: 0.007804393768310547
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.46196627616882324 seconds
Index: 17
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6575829982757568 seconds
Streaming plantleave data took 1.6580431461334229 seconds
Then, training+dataloading take 1.6584086418151855 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3651394844055176
Time for copying to cuda: 0.0004277229309082031
Time for forward pass: 0.033188581466674805
Time for backpropagation: 0.00769495964050293
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.5133335590362549 seconds
Index: 18
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6520991325378418 seconds
Streaming plantleave data took 1.6530177593231201 seconds
Then, training+dataloading take 1.6536180973052979 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3680720329284668
Time for copying to cuda: 0.0004544258117675781
Time for forward pass: 0.03330373764038086
Time for backpropagation: 0.0077784061431884766
GPU memory for training: 1.337578296661377                          

Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.5409672260284424 seconds
Streaming plantleave data took 1.5419282913208008 seconds
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
Memory occpied: (2422.0, 1660.0)
One training iteration takes: 5.428187847137451 seconds
Index: 19
Then, training+dataloading take 5.4282546043396 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3269388675689697
Time for copying to cuda: 0.0004699230194091797
Time for forward pass: 0.03353595733642578
Time for backpropagation: 0.007920980453491211
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.45597171783447266 seconds
Index: 20
Memory occpied: (2422.0, 1660.0)
Read 0.5929527282714844 MBs for this batch
Executing all posts took 1.6412763595581055 seconds
Streaming plantleave data took 1.6418697834014893 seconds
Then, training+dataloading take 1.642226219177246 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34213829040527344
Time for copying to cuda: 0.0004363059997558594
Time for forward pass: 0.0335690975189209
Time for backpropagation: 0.007799386978149414
GPU memory for training: 1.337578296661377                          

One training iteration takes: 0.4836459159851074 seconds
Index: 21
Memory occpied: (2422.0, 1660.0)
Read 0.30251598358154297 MBs for this batch
Executing all posts took 0.8759744167327881 seconds
Streaming plantleave data took 0.8763821125030518 seconds
Then, training+dataloading take 0.8767194747924805 seconds

Epoch: 0
Time of next(dataloader) is: 0.32671499252319336
Time for copying to cuda: 0.00032711029052734375
Time for forward pass: 0.033623695373535156
Time for backpropagation: 0.007886409759521484
GPU memory for training: 1.3372888565063477                          

The whole process took 50.5779345035553 seconds
