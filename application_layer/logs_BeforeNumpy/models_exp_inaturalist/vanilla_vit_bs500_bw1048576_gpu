Namespace(batch_size=500, cpuonly=False, dataset='inaturalist', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='vit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Start 0, end 500, post_step 250

Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Decompress data took 0.04279470443725586 seconds
Memory occpied: (1654.0, 3.0)
Total decompress data took 1.7043609619140625 seconds
Decompress data took 0.043271780014038086 seconds
Memory occpied: (1654.0, 3.0)
Total decompress data took 1.7965316772460938 seconds
Read 131.31797695159912 MBs for this batch
Streaming inaturalist data took 4.901939153671265 seconds
The mode is:  vanilla
Start 500, end 1000, post_step 250


Epoch: 0
Memory occpied: (1654.0, 3.0)
Memory occpied: (1654.0, 3.0)
Decompress data took 0.04213452339172363 seconds
Time of next(dataloader) is: 2.3464853763580322
Time for copying to cuda: 0.11528682708740234
Memory occpied: (1942.0, 15.0)
Total decompress data took 1.7691946029663086 seconds
Decompress data took 0.045346975326538086 seconds
Memory occpied: (1942.0, 676.0)
Memory occpied: (1942.0, 1078.0)
Total decompress data took 1.9460008144378662 seconds
Read 134.46980094909668 MBs for this batch
Streaming inaturalist data took 5.302786350250244 seconds
Memory occpied: (14670.0, 13784.0)
Memory occpied: (14670.0, 14808.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 433, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 421, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 239, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/layers/mlp.py", line 27, in forward
    x = self.act(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/activation.py", line 670, in forward
    return F.gelu(input)
RuntimeError: CUDA out of memory. Tried to allocate 578.00 MiB (GPU 0; 14.76 GiB total capacity; 12.69 GiB already allocated; 149.75 MiB free; 13.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 19.204270601272583 seconds
