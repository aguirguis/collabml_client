Namespace(batch_size=512, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='vit', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Start 0, end 512, post_step 128

Memory occpied: (1630.0, 3.0)
Decompress data took 0.012145757675170898 seconds
Total decompress data took 0.41405510902404785 seconds
Decompress data took 0.00967097282409668 seconds
Memory occpied: (1630.0, 3.0)
Total decompress data took 0.47141528129577637 seconds
Decompress data took 0.01159214973449707 seconds
Total decompress data took 0.4187428951263428 seconds
Decompress data took 0.010384082794189453 seconds
Total decompress data took 0.5016248226165771 seconds
Read 63.78047180175781 MBs for this batch
Streaming imagenet data took 2.452946424484253 seconds
The mode is:  vanilla
Start 512, end 1024, post_step 128


Epoch: 0
Memory occpied: (1630.0, 3.0)
Decompress data took 0.018032073974609375 seconds
Memory occpied: (1630.0, 3.0)
Total decompress data took 0.6291570663452148 seconds
Decompress data took 0.011472463607788086 seconds
Time of next(dataloader) is: 1.86911940574646
Total decompress data took 0.48073911666870117 seconds
Decompress data took 0.010686159133911133 seconds
Time for copying to cuda: 0.07531404495239258
Memory occpied: (1924.0, 362.0)
Total decompress data took 0.5131993293762207 seconds
Decompress data took 0.011205196380615234 seconds
Total decompress data took 0.41985249519348145 seconds
Read 66.69892597198486 MBs for this batch
Streaming imagenet data took 2.853665351867676 seconds
Memory occpied: (1924.0, 806.0)
Memory occpied: (1924.0, 1256.0)
Memory occpied: (15106.0, 14466.0)
Memory occpied: (14650.0, 15058.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 549, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 538, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 269, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/layers/mlp.py", line 27, in forward
    x = self.fc1(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA out of memory. Tried to allocate 592.00 MiB (GPU 0; 14.76 GiB total capacity; 12.39 GiB already allocated; 459.75 MiB free; 13.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 16.597366094589233 seconds
