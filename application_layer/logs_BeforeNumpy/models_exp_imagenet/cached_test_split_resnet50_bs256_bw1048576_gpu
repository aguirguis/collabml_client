Namespace(batch_size=256, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=21, model='myresnet50', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.7852399527909 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.4450688e+07
 1.4450688e+07 1.4450688e+07 1.0838016e+07 7.2253440e+06 7.2253440e+06
 7.2253440e+06 5.4190080e+06 3.6126720e+06 3.6126720e+06 3.6126720e+06
 3.6126720e+06 3.6126720e+06 2.7095040e+06 1.8063360e+06 1.8063360e+06
 8.1920000e+03 4.0000000e+03]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119116298.97109221 119116298.97109221
All candidates indexes:  (array([20, 21]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 21
Intermediate:  0.0078125
6.125
Total layers size  110.74014282226562
Server, client, server+client, vanilla  265.20849609375 101.68115234375 366.8896484375 1814.68115234375
Candidate split  21
Server, client, server+client, vanilla  265.20849609375 101.68115234375 366.8896484375 1814.68115234375
Model size  97.72802734375
Fixed, scale_with_bsz  97.72802734375 6.69921875
Mem usage  1410.0 3.0
Using split index: 21
Freezing the lower layers of the model (myresnet50) till index 21
The mode is:  split
Start 0, end 256, post_step 128

Memory occpied: (1410.0, 3.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.8163073062896729 seconds
Streaming imagenet data took 0.8174779415130615 seconds
The mode is:  split
Start 256, end 512, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.27352380752563477
Time for copying to cuda: 0.0008606910705566406
Memory occpied: (1410.0, 132.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7182958126068115 seconds
Streaming imagenet data took 0.7198960781097412 seconds
Memory occpied: (1410.0, 594.0)
Memory occpied: (1410.0, 1018.0)
Time for forward pass: 3.1991095542907715
Time for backpropagation: 0.06411194801330566
GPU memory for training: 0.418027400970459                          

One training iteration takes: 3.5946521759033203 seconds
Index: 0
Then, training+dataloading take 3.5947201251983643 seconds
The mode is:  split
Start 512, end 768, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3448514938354492
Time for copying to cuda: 0.0009057521820068359
Time for forward pass: 0.015790224075317383
Time for backpropagation: 0.007579326629638672
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4646947383880615 seconds
Index: 1
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.789745569229126 seconds
Streaming imagenet data took 0.7911989688873291 seconds
Then, training+dataloading take 0.7914996147155762 seconds
The mode is:  split
Start 768, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31066465377807617
Time for copying to cuda: 0.0008759498596191406
Time for forward pass: 0.013261079788208008
Time for backpropagation: 0.0062749385833740234
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40289902687072754 seconds
Index: 2
Read 2.009765625 MBs for this batch
Executing all posts took 0.7785077095031738 seconds
Streaming imagenet data took 0.7801127433776855 seconds
Then, training+dataloading take 0.7805428504943848 seconds
The mode is:  split
Start 1024, end 1280, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3498232364654541
Time for copying to cuda: 0.0008683204650878906
Time for forward pass: 0.012839794158935547
Time for backpropagation: 0.0064127445220947266
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4493539333343506 seconds
Index: 3
Read 2.009765625 MBs for this batch
Executing all posts took 0.7906484603881836 seconds
Streaming imagenet data took 0.7918078899383545 seconds
Then, training+dataloading take 0.7922124862670898 seconds
The mode is:  split
Start 1280, end 1536, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3199276924133301
Time for copying to cuda: 0.0009191036224365234
Time for forward pass: 0.012933492660522461
Time for backpropagation: 0.006374359130859375
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41002678871154785 seconds
Index: 4
Read 2.009765625 MBs for this batch
Executing all posts took 0.739098072052002 seconds
Streaming imagenet data took 0.7403819561004639 seconds
Then, training+dataloading take 0.7407271862030029 seconds
The mode is:  split
Start 1536, end 1792, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.35235071182250977
Time for copying to cuda: 0.000873565673828125
Time for forward pass: 0.012886762619018555
Time for backpropagation: 0.006336688995361328
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.43454694747924805 seconds
Index: 5
Read 2.009765625 MBs for this batch
Executing all posts took 0.7077665328979492 seconds
Streaming imagenet data took 0.7092065811157227 seconds
Then, training+dataloading take 0.7095851898193359 seconds
The mode is:  split
Start 1792, end 2048, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3140747547149658
Time for copying to cuda: 0.0008809566497802734
Time for forward pass: 0.012934207916259766
Time for backpropagation: 0.0063953399658203125
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4021611213684082 seconds
Index: 6
Read 2.009765625 MBs for this batch
Executing all posts took 0.7060348987579346 seconds
Streaming imagenet data took 0.7073462009429932 seconds
Then, training+dataloading take 0.7077922821044922 seconds
The mode is:  split
Start 2048, end 2304, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.3202052116394043
Time for copying to cuda: 0.0008444786071777344
Time for forward pass: 0.012893438339233398
Time for backpropagation: 0.0062901973724365234
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.42945241928100586 seconds
Index: 7
Read 2.009765625 MBs for this batch
Executing all posts took 0.7430210113525391 seconds
Streaming imagenet data took 0.7441661357879639 seconds
Then, training+dataloading take 0.7445189952850342 seconds
The mode is:  split
Start 2304, end 2560, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3518495559692383
Time for copying to cuda: 0.0008788108825683594
Time for forward pass: 0.013175725936889648
Time for backpropagation: 0.0064449310302734375
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4679093360900879 seconds
Index: 8
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7280271053314209 seconds
Streaming imagenet data took 0.7292172908782959 seconds
Then, training+dataloading take 0.7295255661010742 seconds
The mode is:  split
Start 2560, end 2816, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3120448589324951
Time for copying to cuda: 0.0008671283721923828
Time for forward pass: 0.012932538986206055
Time for backpropagation: 0.006297588348388672
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.421842098236084 seconds
Index: 9
Read 2.009765625 MBs for this batch
Executing all posts took 0.7389669418334961 seconds
Streaming imagenet data took 0.7401103973388672 seconds
Then, training+dataloading take 0.7404069900512695 seconds
The mode is:  split
Start 2816, end 3072, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4014465808868408
Time for copying to cuda: 0.0009016990661621094
Time for forward pass: 0.013090848922729492
Time for backpropagation: 0.006579399108886719
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.488553524017334 seconds
Index: 10
Read 2.009765625 MBs for this batch
Executing all posts took 0.6950380802154541 seconds
Streaming imagenet data took 0.6961781978607178 seconds
Then, training+dataloading take 0.6964621543884277 seconds
The mode is:  split
Start 3072, end 3328, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.30912017822265625
Time for copying to cuda: 0.0008609294891357422
Time for forward pass: 0.012837886810302734
Time for backpropagation: 0.0063266754150390625
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41660451889038086 seconds
Index: 11
Read 2.009765625 MBs for this batch
Executing all posts took 0.7289917469024658 seconds
Streaming imagenet data took 0.7301516532897949 seconds
Then, training+dataloading take 0.7304327487945557 seconds
The mode is:  split
Start 3328, end 3584, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35960936546325684
Time for copying to cuda: 0.0008761882781982422
Time for forward pass: 0.012939453125
Time for backpropagation: 0.006259918212890625
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4896206855773926 seconds
Index: 12
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7431788444519043 seconds
Streaming imagenet data took 0.7443506717681885 seconds
Then, training+dataloading take 0.7446355819702148 seconds
The mode is:  split
Start 3584, end 3840, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3141002655029297
Time for copying to cuda: 0.0008571147918701172
Time for forward pass: 0.012933969497680664
Time for backpropagation: 0.00628352165222168
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4168586730957031 seconds
Index: 13
Read 2.009765625 MBs for this batch
Executing all posts took 0.6897854804992676 seconds
Streaming imagenet data took 0.6909027099609375 seconds
Then, training+dataloading take 0.6912224292755127 seconds
The mode is:  split
Start 3840, end 4096, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3503899574279785
Time for copying to cuda: 0.0008556842803955078
Time for forward pass: 0.01300048828125
Time for backpropagation: 0.006380319595336914
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.46712827682495117 seconds
Index: 14
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7405052185058594 seconds
Streaming imagenet data took 0.7416651248931885 seconds
Then, training+dataloading take 0.7419846057891846 seconds
The mode is:  split
Start 4096, end 4352, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3133385181427002
Time for copying to cuda: 0.0008637905120849609
Time for forward pass: 0.012875556945800781
Time for backpropagation: 0.0063517093658447266
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.419358491897583 seconds
Index: 15
Read 2.009765625 MBs for this batch
Executing all posts took 0.7341563701629639 seconds
Streaming imagenet data took 0.7353150844573975 seconds
Then, training+dataloading take 0.7356233596801758 seconds
The mode is:  split
Start 4352, end 4608, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.3918569087982178
Time for copying to cuda: 0.0008697509765625
Time for forward pass: 0.013020992279052734
Time for backpropagation: 0.0063593387603759766
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.48754167556762695 seconds
Index: 16
Read 2.009765625 MBs for this batch
Executing all posts took 0.8036758899688721 seconds
Streaming imagenet data took 0.8048050403594971 seconds
Then, training+dataloading take 0.8050796985626221 seconds
The mode is:  split
Start 4608, end 4864, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31400275230407715
Time for copying to cuda: 0.0008747577667236328
Time for forward pass: 0.012834787368774414
Time for backpropagation: 0.00632166862487793
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40313720703125 seconds
Index: 17
Read 2.009765625 MBs for this batch
Executing all posts took 0.7344458103179932 seconds
Streaming imagenet data took 0.7365379333496094 seconds
Then, training+dataloading take 0.7370119094848633 seconds
The mode is:  split
Start 4864, end 5120, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.32497191429138184
Time for copying to cuda: 0.0008747577667236328
Time for forward pass: 0.012966632843017578
Time for backpropagation: 0.006317853927612305
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41188573837280273 seconds
Index: 18
Read 2.009765625 MBs for this batch
Executing all posts took 0.6956522464752197 seconds
Streaming imagenet data took 0.6967833042144775 seconds
Then, training+dataloading take 0.6971466541290283 seconds
The mode is:  split
Start 5120, end 5376, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3125302791595459
Time for copying to cuda: 0.0008885860443115234
Time for forward pass: 0.0128936767578125
Time for backpropagation: 0.006306886672973633
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.43817853927612305 seconds
Index: 19
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7342073917388916 seconds
Streaming imagenet data took 0.7353706359863281 seconds
Then, training+dataloading take 0.7357058525085449 seconds
The mode is:  split
Start 5376, end 5632, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3251957893371582
Time for copying to cuda: 0.0008707046508789062
Time for forward pass: 0.012971162796020508
Time for backpropagation: 0.006381988525390625
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.42413806915283203 seconds
Index: 20
Read 2.009765625 MBs for this batch
Executing all posts took 0.7008979320526123 seconds
Streaming imagenet data took 0.7020504474639893 seconds
Then, training+dataloading take 0.7023816108703613 seconds
The mode is:  split
Start 5632, end 5888, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37073278427124023
Time for copying to cuda: 0.0008518695831298828
Time for forward pass: 0.01282644271850586
Time for backpropagation: 0.006325721740722656
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.5143241882324219 seconds
Index: 21
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7000207901000977 seconds
Streaming imagenet data took 0.7012114524841309 seconds
Then, training+dataloading take 0.7014999389648438 seconds
The mode is:  split
Start 5888, end 6144, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3099076747894287
Time for copying to cuda: 0.0008714199066162109
Time for forward pass: 0.01291036605834961
Time for backpropagation: 0.006369829177856445
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4068002700805664 seconds
Index: 22
Read 2.009765625 MBs for this batch
Executing all posts took 0.7367753982543945 seconds
Streaming imagenet data took 0.7379252910614014 seconds
Then, training+dataloading take 0.7382216453552246 seconds
The mode is:  split
Start 6144, end 6400, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38477563858032227
Time for copying to cuda: 0.0009114742279052734
Time for forward pass: 0.01324319839477539
Time for backpropagation: 0.0067136287689208984
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4756815433502197 seconds
Index: 23
Read 2.009765625 MBs for this batch
Executing all posts took 0.6927094459533691 seconds
Streaming imagenet data took 0.6938846111297607 seconds
Then, training+dataloading take 0.694180965423584 seconds
The mode is:  split
Start 6400, end 6656, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3255119323730469
Time for copying to cuda: 0.0008864402770996094
Time for forward pass: 0.013058900833129883
Time for backpropagation: 0.006305217742919922
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4072134494781494 seconds
Index: 24
Read 2.009765625 MBs for this batch
Executing all posts took 0.7501235008239746 seconds
Streaming imagenet data took 0.7512645721435547 seconds
Then, training+dataloading take 0.7515473365783691 seconds
The mode is:  split
Start 6656, end 6912, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35900163650512695
Time for copying to cuda: 0.0008780956268310547
Time for forward pass: 0.05835700035095215
Time for backpropagation: 0.006322383880615234
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.5370399951934814 seconds
Index: 25
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7038159370422363 seconds
Streaming imagenet data took 0.7049856185913086 seconds
Then, training+dataloading take 0.7052850723266602 seconds
The mode is:  split
Start 6912, end 7168, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3238213062286377
Time for copying to cuda: 0.0008780956268310547
Time for forward pass: 0.012927532196044922
Time for backpropagation: 0.006379842758178711
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4245719909667969 seconds
Index: 26
Read 2.009765625 MBs for this batch
Executing all posts took 0.7376811504364014 seconds
Streaming imagenet data took 0.7388365268707275 seconds
Then, training+dataloading take 0.7391266822814941 seconds
The mode is:  split
Start 7168, end 7424, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3560359477996826
Time for copying to cuda: 0.0008995532989501953
Time for forward pass: 0.013068437576293945
Time for backpropagation: 0.006525278091430664
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.47313356399536133 seconds
Index: 27
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.6979312896728516 seconds
Streaming imagenet data took 0.6991498470306396 seconds
Then, training+dataloading take 0.699446439743042 seconds
The mode is:  split
Start 7424, end 7680, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31549859046936035
Time for copying to cuda: 0.0009539127349853516
Time for forward pass: 0.013062000274658203
Time for backpropagation: 0.00625300407409668
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4108428955078125 seconds
Index: 28
Read 2.009765625 MBs for this batch
Executing all posts took 0.8068759441375732 seconds
Streaming imagenet data took 0.8080310821533203 seconds
Then, training+dataloading take 0.8083319664001465 seconds
The mode is:  split
Start 7680, end 7936, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3502521514892578
Time for copying to cuda: 0.0008878707885742188
Time for forward pass: 0.01299738883972168
Time for backpropagation: 0.006378173828125
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4649312496185303 seconds
Index: 29
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7019493579864502 seconds
Streaming imagenet data took 0.7031350135803223 seconds
Then, training+dataloading take 0.7034242153167725 seconds
The mode is:  split
Start 7936, end 8192, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3134939670562744
Time for copying to cuda: 0.0009179115295410156
Time for forward pass: 0.013010740280151367
Time for backpropagation: 0.006383657455444336
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4109048843383789 seconds
Index: 30
Read 2.009765625 MBs for this batch
Executing all posts took 0.8012170791625977 seconds
Streaming imagenet data took 0.8024065494537354 seconds
Then, training+dataloading take 0.8027009963989258 seconds
The mode is:  split
Start 8192, end 8448, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3614325523376465
Time for copying to cuda: 0.0009202957153320312
Time for forward pass: 0.012899160385131836
Time for backpropagation: 0.006428241729736328
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4898505210876465 seconds
Index: 31
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7341649532318115 seconds
Streaming imagenet data took 0.7353799343109131 seconds
Then, training+dataloading take 0.7356975078582764 seconds
The mode is:  split
Start 8448, end 8704, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.309478759765625
Time for copying to cuda: 0.0008928775787353516
Time for forward pass: 0.01298666000366211
Time for backpropagation: 0.006434202194213867
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.39120936393737793 seconds
Index: 32
Read 2.009765625 MBs for this batch
Executing all posts took 0.738684892654419 seconds
Streaming imagenet data took 0.7398605346679688 seconds
Then, training+dataloading take 0.7401576042175293 seconds
The mode is:  split
Start 8704, end 8960, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34844112396240234
Time for copying to cuda: 0.0008831024169921875
Time for forward pass: 0.01290130615234375
Time for backpropagation: 0.006354331970214844
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4648897647857666 seconds
Index: 33
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7407262325286865 seconds
Streaming imagenet data took 0.7419137954711914 seconds
Then, training+dataloading take 0.7421896457672119 seconds
The mode is:  split
Start 8960, end 9216, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3153238296508789
Time for copying to cuda: 0.0009071826934814453
Time for forward pass: 0.012934684753417969
Time for backpropagation: 0.006296634674072266
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4212770462036133 seconds
Index: 34
Read 2.009765625 MBs for this batch
Executing all posts took 0.6899120807647705 seconds
Streaming imagenet data took 0.6910495758056641 seconds
Then, training+dataloading take 0.6913633346557617 seconds
The mode is:  split
Start 9216, end 9472, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39726734161376953
Time for copying to cuda: 0.0008718967437744141
Time for forward pass: 0.013071060180664062
Time for backpropagation: 0.006585121154785156
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.49407100677490234 seconds
Index: 35
Read 2.009765625 MBs for this batch
Executing all posts took 0.6987016201019287 seconds
Streaming imagenet data took 0.6998236179351807 seconds
Then, training+dataloading take 0.7001004219055176 seconds
The mode is:  split
Start 9472, end 9728, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31137895584106445
Time for copying to cuda: 0.0009102821350097656
Time for forward pass: 0.013028383255004883
Time for backpropagation: 0.0064051151275634766
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4111459255218506 seconds
Index: 36
Read 2.009765625 MBs for this batch
Executing all posts took 0.7394571304321289 seconds
Streaming imagenet data took 0.7405872344970703 seconds
Then, training+dataloading take 0.7408602237701416 seconds
The mode is:  split
Start 9728, end 9984, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35243678092956543
Time for copying to cuda: 0.0008747577667236328
Time for forward pass: 0.013035297393798828
Time for backpropagation: 0.006451606750488281
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.46924901008605957 seconds
Index: 37
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7458765506744385 seconds
Streaming imagenet data took 0.7470204830169678 seconds
Then, training+dataloading take 0.7473125457763672 seconds
The mode is:  split
Start 9984, end 10240, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31222081184387207
Time for copying to cuda: 0.0009064674377441406
Time for forward pass: 0.013015508651733398
Time for backpropagation: 0.006354331970214844
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40853309631347656 seconds
Index: 38
Read 2.009765625 MBs for this batch
Executing all posts took 0.7420201301574707 seconds
Streaming imagenet data took 0.7431600093841553 seconds
Then, training+dataloading take 0.743459939956665 seconds
The mode is:  split
Start 10240, end 10496, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.42288804054260254
Time for copying to cuda: 0.0008778572082519531
Time for forward pass: 0.012954473495483398
Time for backpropagation: 0.006332874298095703
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.5164260864257812 seconds
Index: 39
Read 2.009765625 MBs for this batch
Executing all posts took 0.6888978481292725 seconds
Streaming imagenet data took 0.6900861263275146 seconds
Then, training+dataloading take 0.6903622150421143 seconds
The mode is:  split
Start 10496, end 10752, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3150901794433594
Time for copying to cuda: 0.0008776187896728516
Time for forward pass: 0.013082027435302734
Time for backpropagation: 0.0063953399658203125
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4087636470794678 seconds
Index: 40
Read 2.009765625 MBs for this batch
Executing all posts took 0.6950886249542236 seconds
Streaming imagenet data took 0.6962361335754395 seconds
Then, training+dataloading take 0.6965110301971436 seconds
The mode is:  split
Start 10752, end 11008, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35125064849853516
Time for copying to cuda: 0.0008821487426757812
Time for forward pass: 0.012938261032104492
Time for backpropagation: 0.006490945816040039
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.46893787384033203 seconds
Index: 41
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7418591976165771 seconds
Streaming imagenet data took 0.7430408000946045 seconds
Then, training+dataloading take 0.7433462142944336 seconds
The mode is:  split
Start 11008, end 11264, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.30963826179504395
Time for copying to cuda: 0.0009179115295410156
Time for forward pass: 0.012948036193847656
Time for backpropagation: 0.006296634674072266
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4101252555847168 seconds
Index: 42
Read 2.009765625 MBs for this batch
Executing all posts took 0.8399903774261475 seconds
Streaming imagenet data took 0.8420655727386475 seconds
Then, training+dataloading take 0.8425478935241699 seconds
The mode is:  split
Start 11264, end 11520, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3518064022064209
Time for copying to cuda: 0.0008630752563476562
Time for forward pass: 0.012882471084594727
Time for backpropagation: 0.0064084529876708984
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4388866424560547 seconds
Index: 43
Read 2.009765625 MBs for this batch
Executing all posts took 0.7422599792480469 seconds
Streaming imagenet data took 0.7434029579162598 seconds
Then, training+dataloading take 0.7438437938690186 seconds
The mode is:  split
Start 11520, end 11776, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3104684352874756
Time for copying to cuda: 0.0009281635284423828
Time for forward pass: 0.013012886047363281
Time for backpropagation: 0.006654977798461914
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.39883971214294434 seconds
Index: 44
Read 2.009765625 MBs for this batch
Executing all posts took 0.7342045307159424 seconds
Streaming imagenet data took 0.7363173961639404 seconds
Then, training+dataloading take 0.7371351718902588 seconds
The mode is:  split
Start 11776, end 12032, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.35386109352111816
Time for copying to cuda: 0.000896453857421875
Time for forward pass: 0.012884140014648438
Time for backpropagation: 0.0063440799713134766
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.44255638122558594 seconds
Index: 45
Read 2.009765625 MBs for this batch
Executing all posts took 0.7416436672210693 seconds
Streaming imagenet data took 0.7427811622619629 seconds
Then, training+dataloading take 0.7432239055633545 seconds
The mode is:  split
Start 12032, end 12288, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.311755895614624
Time for copying to cuda: 0.0009164810180664062
Time for forward pass: 0.013121366500854492
Time for backpropagation: 0.006468057632446289
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.42099952697753906 seconds
Index: 46
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7398881912231445 seconds
Streaming imagenet data took 0.7410843372344971 seconds
Then, training+dataloading take 0.7414460182189941 seconds
The mode is:  split
Start 12288, end 12544, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3145618438720703
Time for copying to cuda: 0.0008397102355957031
Time for forward pass: 0.012925863265991211
Time for backpropagation: 0.006371974945068359
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4253120422363281 seconds
Index: 47
Read 2.009765625 MBs for this batch
Executing all posts took 0.7404987812042236 seconds
Streaming imagenet data took 0.7416365146636963 seconds
Then, training+dataloading take 0.7419707775115967 seconds
The mode is:  split
Start 12544, end 12800, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35460710525512695
Time for copying to cuda: 0.0009188652038574219
Time for forward pass: 0.013421773910522461
Time for backpropagation: 0.00659489631652832
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.48630213737487793 seconds
Index: 48
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.695793628692627 seconds
Streaming imagenet data took 0.6970622539520264 seconds
Then, training+dataloading take 0.6974086761474609 seconds
The mode is:  split
Start 12800, end 13056, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31287240982055664
Time for copying to cuda: 0.0009024143218994141
Time for forward pass: 0.012962579727172852
Time for backpropagation: 0.0065310001373291016
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4123110771179199 seconds
Index: 49
Read 2.009765625 MBs for this batch
Executing all posts took 0.7465767860412598 seconds
Streaming imagenet data took 0.7477645874023438 seconds
Then, training+dataloading take 0.7480859756469727 seconds
The mode is:  split
Start 13056, end 13312, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35539913177490234
Time for copying to cuda: 0.0008656978607177734
Time for forward pass: 0.01297760009765625
Time for backpropagation: 0.006348848342895508
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4972701072692871 seconds
Index: 50
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7422127723693848 seconds
Streaming imagenet data took 0.7434213161468506 seconds
Then, training+dataloading take 0.7437548637390137 seconds
The mode is:  split
Start 13312, end 13568, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.32625865936279297
Time for copying to cuda: 0.0009343624114990234
Time for forward pass: 0.012946367263793945
Time for backpropagation: 0.006552457809448242
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4143187999725342 seconds
Index: 51
Read 2.009765625 MBs for this batch
Executing all posts took 0.6907138824462891 seconds
Streaming imagenet data took 0.6918928623199463 seconds
Then, training+dataloading take 0.6921999454498291 seconds
The mode is:  split
Start 13568, end 13824, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3592350482940674
Time for copying to cuda: 0.0009305477142333984
Time for forward pass: 0.013082027435302734
Time for backpropagation: 0.00643610954284668
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.48015832901000977 seconds
Index: 52
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.6920671463012695 seconds
Streaming imagenet data took 0.6933059692382812 seconds
Then, training+dataloading take 0.6936228275299072 seconds
The mode is:  split
Start 13824, end 14080, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3143291473388672
Time for copying to cuda: 0.0009527206420898438
Time for forward pass: 0.01303863525390625
Time for backpropagation: 0.0064275264739990234
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40767860412597656 seconds
Index: 53
Read 2.009765625 MBs for this batch
Executing all posts took 0.6961517333984375 seconds
Streaming imagenet data took 0.6973562240600586 seconds
Then, training+dataloading take 0.697669267654419 seconds
The mode is:  split
Start 14080, end 14336, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.406449556350708
Time for copying to cuda: 0.0009410381317138672
Time for forward pass: 0.013318300247192383
Time for backpropagation: 0.006600379943847656
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.5127747058868408 seconds
Index: 54
Read 2.009765625 MBs for this batch
Executing all posts took 0.7416725158691406 seconds
Streaming imagenet data took 0.7428219318389893 seconds
Then, training+dataloading take 0.7431259155273438 seconds
The mode is:  split
Start 14336, end 14592, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3157083988189697
Time for copying to cuda: 0.0009157657623291016
Time for forward pass: 0.01289820671081543
Time for backpropagation: 0.006506919860839844
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4273819923400879 seconds
Index: 55
Read 2.009765625 MBs for this batch
Executing all posts took 0.8058736324310303 seconds
Streaming imagenet data took 0.8080229759216309 seconds
Then, training+dataloading take 0.808459997177124 seconds
The mode is:  split
Start 14592, end 14848, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3531014919281006
Time for copying to cuda: 0.0008978843688964844
Time for forward pass: 0.013156414031982422
Time for backpropagation: 0.006437063217163086
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.451570987701416 seconds
Index: 56
Read 2.009765625 MBs for this batch
Executing all posts took 0.6917743682861328 seconds
Streaming imagenet data took 0.6929526329040527 seconds
Then, training+dataloading take 0.693396806716919 seconds
The mode is:  split
Start 14848, end 15104, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3078176975250244
Time for copying to cuda: 0.0008537769317626953
Time for forward pass: 0.01285552978515625
Time for backpropagation: 0.006441831588745117
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4105522632598877 seconds
Index: 57
Read 2.009765625 MBs for this batch
Executing all posts took 0.7859609127044678 seconds
Streaming imagenet data took 0.7881379127502441 seconds
Then, training+dataloading take 0.7889766693115234 seconds
The mode is:  split
Start 15104, end 15360, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3522148132324219
Time for copying to cuda: 0.0009100437164306641
Time for forward pass: 0.013059139251708984
Time for backpropagation: 0.006394624710083008
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4599764347076416 seconds
Index: 58
Read 2.009765625 MBs for this batch
Executing all posts took 0.7520160675048828 seconds
Streaming imagenet data took 0.7531366348266602 seconds
Then, training+dataloading take 0.7535765171051025 seconds
The mode is:  split
Start 15360, end 15616, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3155672550201416
Time for copying to cuda: 0.0009131431579589844
Time for forward pass: 0.012916088104248047
Time for backpropagation: 0.006391048431396484
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41147923469543457 seconds
Index: 59
Read 2.009765625 MBs for this batch
Executing all posts took 0.7284796237945557 seconds
Streaming imagenet data took 0.7305779457092285 seconds
Then, training+dataloading take 0.7313990592956543 seconds
The mode is:  split
Start 15616, end 15872, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3528885841369629
Time for copying to cuda: 0.0008707046508789062
Time for forward pass: 0.013087034225463867
Time for backpropagation: 0.00646209716796875
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4444575309753418 seconds
Index: 60
Read 2.009765625 MBs for this batch
Executing all posts took 0.6915407180786133 seconds
Streaming imagenet data took 0.6927030086517334 seconds
Then, training+dataloading take 0.6931195259094238 seconds
The mode is:  split
Start 15872, end 16128, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31069183349609375
Time for copying to cuda: 0.0009062290191650391
Time for forward pass: 0.012798309326171875
Time for backpropagation: 0.006339550018310547
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.39180827140808105 seconds
Index: 61
Read 2.009765625 MBs for this batch
Executing all posts took 0.7784264087677002 seconds
Streaming imagenet data took 0.7804172039031982 seconds
Then, training+dataloading take 0.7808651924133301 seconds
The mode is:  split
Start 16128, end 16384, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3523566722869873
Time for copying to cuda: 0.0009021759033203125
Time for forward pass: 0.013162612915039062
Time for backpropagation: 0.0064182281494140625
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4443929195404053 seconds
Index: 62
Read 2.009765625 MBs for this batch
Executing all posts took 0.6965656280517578 seconds
Streaming imagenet data took 0.6976985931396484 seconds
Then, training+dataloading take 0.6981074810028076 seconds
The mode is:  split
Start 16384, end 16640, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31188440322875977
Time for copying to cuda: 0.0008902549743652344
Time for forward pass: 0.012964487075805664
Time for backpropagation: 0.006456136703491211
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4012308120727539 seconds
Index: 63
Read 2.009765625 MBs for this batch
Executing all posts took 0.7896037101745605 seconds
Streaming imagenet data took 0.791712760925293 seconds
Then, training+dataloading take 0.7921855449676514 seconds
The mode is:  split
Start 16640, end 16896, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35205602645874023
Time for copying to cuda: 0.0008792877197265625
Time for forward pass: 0.013072729110717773
Time for backpropagation: 0.006371974945068359
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.44217801094055176 seconds
Index: 64
Read 2.009765625 MBs for this batch
Executing all posts took 0.7085943222045898 seconds
Streaming imagenet data took 0.7097294330596924 seconds
Then, training+dataloading take 0.7101600170135498 seconds
The mode is:  split
Start 16896, end 17152, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3117797374725342
Time for copying to cuda: 0.0008754730224609375
Time for forward pass: 0.012867212295532227
Time for backpropagation: 0.006307363510131836
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4168562889099121 seconds
Index: 65
Read 2.009765625 MBs for this batch
Executing all posts took 0.7097289562225342 seconds
Streaming imagenet data took 0.7108466625213623 seconds
Then, training+dataloading take 0.7111265659332275 seconds
The mode is:  split
Start 17152, end 17408, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35541510581970215
Time for copying to cuda: 0.00089263916015625
Time for forward pass: 0.01297140121459961
Time for backpropagation: 0.006418466567993164
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4734077453613281 seconds
Index: 66
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7234630584716797 seconds
Streaming imagenet data took 0.7246029376983643 seconds
Then, training+dataloading take 0.724919319152832 seconds
The mode is:  split
Start 17408, end 17664, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.320676326751709
Time for copying to cuda: 0.0008807182312011719
Time for forward pass: 0.013063192367553711
Time for backpropagation: 0.006544589996337891
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.42075181007385254 seconds
Index: 67
Read 2.009765625 MBs for this batch
Executing all posts took 0.694202184677124 seconds
Streaming imagenet data took 0.6953389644622803 seconds
Then, training+dataloading take 0.6956541538238525 seconds
The mode is:  split
Start 17664, end 17920, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4151756763458252
Time for copying to cuda: 0.0008680820465087891
Time for forward pass: 0.013319253921508789
Time for backpropagation: 0.006595611572265625
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.5141000747680664 seconds
Index: 68
Read 2.009765625 MBs for this batch
Executing all posts took 0.8091518878936768 seconds
Streaming imagenet data took 0.8102829456329346 seconds
Then, training+dataloading take 0.8105597496032715 seconds
The mode is:  split
Start 17920, end 18176, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3117794990539551
Time for copying to cuda: 0.0008721351623535156
Time for forward pass: 0.012865304946899414
Time for backpropagation: 0.0065076351165771484
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40955162048339844 seconds
Index: 69
Read 2.009765625 MBs for this batch
Executing all posts took 0.7586944103240967 seconds
Streaming imagenet data took 0.7606968879699707 seconds
Then, training+dataloading take 0.7611398696899414 seconds
The mode is:  split
Start 18176, end 18432, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.3530161380767822
Time for copying to cuda: 0.0008785724639892578
Time for forward pass: 0.013015508651733398
Time for backpropagation: 0.006395101547241211
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4529225826263428 seconds
Index: 70
Read 2.009765625 MBs for this batch
Executing all posts took 0.6998417377471924 seconds
Streaming imagenet data took 0.701040506362915 seconds
Then, training+dataloading take 0.7014784812927246 seconds
The mode is:  split
Start 18432, end 18688, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31522679328918457
Time for copying to cuda: 0.0009076595306396484
Time for forward pass: 0.012958288192749023
Time for backpropagation: 0.0064733028411865234
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40419936180114746 seconds
Index: 71
Read 2.009765625 MBs for this batch
Executing all posts took 0.7295498847961426 seconds
Streaming imagenet data took 0.7316856384277344 seconds
Then, training+dataloading take 0.7322003841400146 seconds
The mode is:  split
Start 18688, end 18944, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.31461596488952637
Time for copying to cuda: 0.0008833408355712891
Time for forward pass: 0.013089179992675781
Time for backpropagation: 0.006447553634643555
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4079422950744629 seconds
Index: 72
Read 2.009765625 MBs for this batch
Executing all posts took 0.6841311454772949 seconds
Streaming imagenet data took 0.6853208541870117 seconds
Then, training+dataloading take 0.6857969760894775 seconds
The mode is:  split
Start 18944, end 19200, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3147392272949219
Time for copying to cuda: 0.0009207725524902344
Time for forward pass: 0.012899160385131836
Time for backpropagation: 0.006391286849975586
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40439748764038086 seconds
Index: 73
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7406561374664307 seconds
Streaming imagenet data took 0.741858720779419 seconds
Then, training+dataloading take 0.7422094345092773 seconds
The mode is:  split
Start 19200, end 19456, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.30986690521240234
Time for copying to cuda: 0.0009174346923828125
Time for forward pass: 0.01302194595336914
Time for backpropagation: 0.006416797637939453
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41337013244628906 seconds
Index: 74
Read 2.009765625 MBs for this batch
Executing all posts took 0.7446718215942383 seconds
Streaming imagenet data took 0.7458245754241943 seconds
Then, training+dataloading take 0.7461719512939453 seconds
The mode is:  split
Start 19456, end 19712, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3599815368652344
Time for copying to cuda: 0.0008907318115234375
Time for forward pass: 0.01299738883972168
Time for backpropagation: 0.0065686702728271484
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4808464050292969 seconds
Index: 75
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7524957656860352 seconds
Streaming imagenet data took 0.7536745071411133 seconds
Then, training+dataloading take 0.7539780139923096 seconds
The mode is:  split
Start 19712, end 19968, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3139781951904297
Time for copying to cuda: 0.0008842945098876953
Time for forward pass: 0.013014078140258789
Time for backpropagation: 0.006436347961425781
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4021589756011963 seconds
Index: 76
Read 2.009765625 MBs for this batch
Executing all posts took 0.6991908550262451 seconds
Streaming imagenet data took 0.7003333568572998 seconds
Then, training+dataloading take 0.7006471157073975 seconds
The mode is:  split
Start 19968, end 20224, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3956594467163086
Time for copying to cuda: 0.0009028911590576172
Time for forward pass: 0.013020038604736328
Time for backpropagation: 0.006860971450805664
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4776437282562256 seconds
Index: 77
Read 2.009765625 MBs for this batch
Executing all posts took 0.7520945072174072 seconds
Streaming imagenet data took 0.7532479763031006 seconds
Then, training+dataloading take 0.7535316944122314 seconds
The mode is:  split
Start 20224, end 20480, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3111693859100342
Time for copying to cuda: 0.0008866786956787109
Time for forward pass: 0.013022422790527344
Time for backpropagation: 0.006437540054321289
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.41013669967651367 seconds
Index: 78
Read 2.009765625 MBs for this batch
Executing all posts took 0.6897287368774414 seconds
Streaming imagenet data took 0.6908845901489258 seconds
Then, training+dataloading take 0.6911561489105225 seconds
The mode is:  split
Start 20480, end 20736, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34585070610046387
Time for copying to cuda: 0.0008606910705566406
Time for forward pass: 0.012917518615722656
Time for backpropagation: 0.006590843200683594
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4625580310821533 seconds
Index: 79
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.7381985187530518 seconds
Streaming imagenet data took 0.7393805980682373 seconds
Then, training+dataloading take 0.7397167682647705 seconds
The mode is:  split
Start 20736, end 20992, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3278799057006836
Time for copying to cuda: 0.0009214878082275391
Time for forward pass: 0.013047218322753906
Time for backpropagation: 0.006417274475097656
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4245917797088623 seconds
Index: 80
Read 2.009765625 MBs for this batch
Executing all posts took 0.7147002220153809 seconds
Streaming imagenet data took 0.7158424854278564 seconds
Then, training+dataloading take 0.7161669731140137 seconds
The mode is:  split
Start 20992, end 21248, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35186338424682617
Time for copying to cuda: 0.0008897781372070312
Time for forward pass: 0.01295924186706543
Time for backpropagation: 0.006442070007324219
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.46857786178588867 seconds
Index: 81
Memory occpied: (1640.0, 1408.0)
Read 2.009765625 MBs for this batch
Executing all posts took 0.8135437965393066 seconds
Streaming imagenet data took 0.814702033996582 seconds
Then, training+dataloading take 0.8150386810302734 seconds
The mode is:  split
Start 21248, end 21504, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31920719146728516
Time for copying to cuda: 0.0009024143218994141
Time for forward pass: 0.012981653213500977
Time for backpropagation: 0.006555318832397461
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4076378345489502 seconds
Index: 82
Read 2.009765625 MBs for this batch
Executing all posts took 0.7696170806884766 seconds
Streaming imagenet data took 0.7716538906097412 seconds
Then, training+dataloading take 0.7721521854400635 seconds
The mode is:  split
Start 21504, end 21760, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35724520683288574
Time for copying to cuda: 0.0008800029754638672
Time for forward pass: 0.012934446334838867
Time for backpropagation: 0.0064258575439453125
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4410994052886963 seconds
Index: 83
Read 2.009765625 MBs for this batch
Executing all posts took 0.7487766742706299 seconds
Streaming imagenet data took 0.7499222755432129 seconds
Then, training+dataloading take 0.7503459453582764 seconds
The mode is:  split
Start 21760, end 22016, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3245542049407959
Time for copying to cuda: 0.0008783340454101562
Time for forward pass: 0.013004064559936523
Time for backpropagation: 0.006387233734130859
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4138920307159424 seconds
Index: 84
Read 2.009765625 MBs for this batch
Executing all posts took 0.742131233215332 seconds
Streaming imagenet data took 0.7442591190338135 seconds
Then, training+dataloading take 0.7447130680084229 seconds
The mode is:  split
Start 22016, end 22272, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3668034076690674
Time for copying to cuda: 0.0008895397186279297
Time for forward pass: 0.012992382049560547
Time for backpropagation: 0.006363868713378906
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.45804691314697266 seconds
Index: 85
Read 2.009765625 MBs for this batch
Executing all posts took 0.7509794235229492 seconds
Streaming imagenet data took 0.7521305084228516 seconds
Then, training+dataloading take 0.7525808811187744 seconds
The mode is:  split
Start 22272, end 22528, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3139774799346924
Time for copying to cuda: 0.0009195804595947266
Time for forward pass: 0.013192892074584961
Time for backpropagation: 0.006497621536254883
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.42386746406555176 seconds
Index: 86
Read 2.009765625 MBs for this batch
Executing all posts took 0.7649350166320801 seconds
Streaming imagenet data took 0.7669813632965088 seconds
Then, training+dataloading take 0.7674622535705566 seconds
The mode is:  split
Start 22528, end 22784, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3596363067626953
Time for copying to cuda: 0.0009052753448486328
Time for forward pass: 0.012958765029907227
Time for backpropagation: 0.0064885616302490234
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.46442747116088867 seconds
Index: 87
Read 2.009765625 MBs for this batch
Executing all posts took 0.7360150814056396 seconds
Streaming imagenet data took 0.7371532917022705 seconds
Then, training+dataloading take 0.7375702857971191 seconds
The mode is:  split
Start 22784, end 23040, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3106503486633301
Time for copying to cuda: 0.0008959770202636719
Time for forward pass: 0.01297450065612793
Time for backpropagation: 0.00644683837890625
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.40039587020874023 seconds
Index: 88
Read 2.009765625 MBs for this batch
Executing all posts took 0.6902649402618408 seconds
Streaming imagenet data took 0.6914141178131104 seconds
Then, training+dataloading take 0.6917088031768799 seconds
The mode is:  split
Start 23040, end 23296, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38797950744628906
Time for copying to cuda: 0.0008702278137207031
Time for forward pass: 0.012874364852905273
Time for backpropagation: 0.006386995315551758
GPU memory for training: 0.43349218368530273                          

Memory occpied: (1640.0, 1408.0)
One training iteration takes: 0.4998617172241211 seconds
Index: 89
Read 2.009765625 MBs for this batch
Executing all posts took 0.7434966564178467 seconds
Streaming imagenet data took 0.7445845603942871 seconds
Then, training+dataloading take 0.7448582649230957 seconds
The mode is:  split
Start 23296, end 23552, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31177353858947754
Time for copying to cuda: 0.0009102821350097656
Time for forward pass: 0.013065814971923828
Time for backpropagation: 0.006373882293701172
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4190795421600342 seconds
Index: 90
Read 2.009765625 MBs for this batch
Executing all posts took 0.6997463703155518 seconds
Streaming imagenet data took 0.7008953094482422 seconds
Then, training+dataloading take 0.7011959552764893 seconds
The mode is:  split
Start 23552, end 23808, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.394179105758667
Time for copying to cuda: 0.0008826255798339844
Time for forward pass: 0.012932062149047852
Time for backpropagation: 0.006591796875
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.4835968017578125 seconds
Index: 91
Read 2.009765625 MBs for this batch
Executing all posts took 0.6904878616333008 seconds
Streaming imagenet data took 0.6916449069976807 seconds
Then, training+dataloading take 0.6919300556182861 seconds
The mode is:  split
Start 23808, end 24064, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3187215328216553
Time for copying to cuda: 0.0009095668792724609
Time for forward pass: 0.013082504272460938
Time for backpropagation: 0.006474733352661133
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.409621000289917 seconds
Index: 92
Read 2.009765625 MBs for this batch
Executing all posts took 0.7517569065093994 seconds
Streaming imagenet data took 0.7537527084350586 seconds
Then, training+dataloading take 0.7542026042938232 seconds
The mode is:  split
Start 24064, end 24320, post_step 128


Epoch: 0
Memory occpied: (1640.0, 1408.0)
Time of next(dataloader) is: 0.3572256565093994
Time for copying to cuda: 0.0008862018585205078
Time for forward pass: 0.012999773025512695
Time for backpropagation: 0.006441593170166016
GPU memory for training: 0.43349218368530273                          

One training iteration takes: 0.45783519744873047 seconds
Index: 93
Read 2.009765625 MBs for this batch
Executing all posts took 0.6998345851898193 seconds
Streaming imagenet data took 0.701000452041626 seconds
Then, training+dataloading take 0.7014789581298828 seconds

Epoch: 0
Time of next(dataloader) is: 0.31053638458251953
Time for copying to cuda: 0.0009055137634277344
Time for forward pass: 0.013053655624389648
Time for backpropagation: 0.006393909454345703
GPU memory for training: 0.43349218368530273                          

The whole process took 79.72725677490234 seconds
