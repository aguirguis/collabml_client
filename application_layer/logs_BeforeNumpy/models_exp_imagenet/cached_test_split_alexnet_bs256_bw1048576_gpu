Namespace(batch_size=256, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.1472489173849 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119032676.21009947 119032676.21009947
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 417.84765625 702.58642578125 911.28515625
Candidate split  6
Server, client, server+client, vanilla  284.73876953125 417.84765625 702.58642578125 911.28515625
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 256, post_step 128

Memory occpied: (1514.0, 3.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5969364643096924 seconds
Streaming imagenet data took 0.6092216968536377 seconds
The mode is:  split
Start 256, end 512, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.31756114959716797
Time for copying to cuda: 0.010259151458740234
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.743725061416626 seconds
Memory occpied: (1546.0, 210.0)
Streaming imagenet data took 0.7563567161560059 seconds
Memory occpied: (1546.0, 672.0)
Memory occpied: (1546.0, 1062.0)
Time for forward pass: 3.635983943939209
Time for backpropagation: 0.05598711967468262
GPU memory for training: 2.067789077758789                          

One training iteration takes: 4.099058389663696 seconds
Index: 0
Then, training+dataloading take 4.099262714385986 seconds
The mode is:  split
Start 512, end 768, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3697085380554199
Time for copying to cuda: 0.008943319320678711
Time for forward pass: 0.037636756896972656
Time for backpropagation: 0.0029821395874023438
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5346832275390625 seconds
Index: 1
Memory occpied: (2036.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6604118347167969 seconds
Streaming imagenet data took 0.6729555130004883 seconds
Then, training+dataloading take 0.67348313331604 seconds
The mode is:  split
Start 768, end 1024, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36937761306762695
Time for copying to cuda: 0.009595870971679688
Time for forward pass: 0.03688764572143555
Time for backpropagation: 0.0031518936157226562
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5068178176879883 seconds
Index: 2
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6205143928527832 seconds
Streaming imagenet data took 0.6333904266357422 seconds
Then, training+dataloading take 0.633758544921875 seconds
The mode is:  split
Start 1024, end 1280, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3615453243255615
Time for copying to cuda: 0.009256124496459961
Time for forward pass: 0.04373621940612793
Time for backpropagation: 0.0031270980834960938
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5090103149414062 seconds
Index: 3
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6762115955352783 seconds
Streaming imagenet data took 0.6837422847747803 seconds
Then, training+dataloading take 0.6844034194946289 seconds
The mode is:  split
Start 1280, end 1536, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34243202209472656
Time for copying to cuda: 0.008884191513061523
Time for forward pass: 0.047078609466552734
Time for backpropagation: 0.010787010192871094
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5015926361083984 seconds
Index: 4
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5922980308532715 seconds
Streaming imagenet data took 0.6051332950592041 seconds
Then, training+dataloading take 0.6055119037628174 seconds
The mode is:  split
Start 1536, end 1792, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38269472122192383
Time for copying to cuda: 0.009472370147705078
Time for forward pass: 0.04841494560241699
Time for backpropagation: 0.0032422542572021484
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5622203350067139 seconds
Index: 5
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.666060209274292 seconds
Streaming imagenet data took 0.6736669540405273 seconds
Then, training+dataloading take 0.6740431785583496 seconds
The mode is:  split
Start 1792, end 2048, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3389885425567627
Time for copying to cuda: 0.009784221649169922
Time for forward pass: 0.048339128494262695
Time for backpropagation: 0.003177642822265625
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5003328323364258 seconds
Index: 6
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5948257446289062 seconds
Streaming imagenet data took 0.6076867580413818 seconds
Then, training+dataloading take 0.6080520153045654 seconds
The mode is:  split
Start 2048, end 2304, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3404276371002197
Time for copying to cuda: 0.047087907791137695
Time for forward pass: 0.04952239990234375
Time for backpropagation: 0.003065347671508789
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5637702941894531 seconds
Index: 7
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6721367835998535 seconds
Streaming imagenet data took 0.6796107292175293 seconds
Then, training+dataloading take 0.6802878379821777 seconds
The mode is:  split
Start 2304, end 2560, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3380725383758545
Time for copying to cuda: 0.009129047393798828
Time for forward pass: 0.0481419563293457
Time for backpropagation: 0.003027677536010742
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4847702980041504 seconds
Index: 8
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5953083038330078 seconds
Streaming imagenet data took 0.6080219745635986 seconds
Then, training+dataloading take 0.608389139175415 seconds
The mode is:  split
Start 2560, end 2816, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35798144340515137
Time for copying to cuda: 0.00936579704284668
Time for forward pass: 0.04822587966918945
Time for backpropagation: 0.003147602081298828
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5111269950866699 seconds
Index: 9
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6605331897735596 seconds
Streaming imagenet data took 0.6680004596710205 seconds
Then, training+dataloading take 0.6686949729919434 seconds
The mode is:  split
Start 2816, end 3072, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3378276824951172
Time for copying to cuda: 0.008880615234375
Time for forward pass: 0.050843000411987305
Time for backpropagation: 0.005921840667724609
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49459362030029297 seconds
Index: 10
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.603827953338623 seconds
Streaming imagenet data took 0.6166555881500244 seconds
Then, training+dataloading take 0.6169948577880859 seconds
The mode is:  split
Start 3072, end 3328, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39226746559143066
Time for copying to cuda: 0.009773015975952148
Time for forward pass: 0.06893777847290039
Time for backpropagation: 0.0047893524169921875
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5562660694122314 seconds
Index: 11
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.668628454208374 seconds
Streaming imagenet data took 0.6762175559997559 seconds
Then, training+dataloading take 0.6769030094146729 seconds
The mode is:  split
Start 3328, end 3584, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33908939361572266
Time for copying to cuda: 0.009099006652832031
Time for forward pass: 0.04819297790527344
Time for backpropagation: 0.003461122512817383
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4909045696258545 seconds
Index: 12
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5954012870788574 seconds
Streaming imagenet data took 0.6035184860229492 seconds
Then, training+dataloading take 0.6038849353790283 seconds
The mode is:  split
Start 3584, end 3840, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3812143802642822
Time for copying to cuda: 0.010181427001953125
Time for forward pass: 0.04818081855773926
Time for backpropagation: 0.0033740997314453125
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5487239360809326 seconds
Index: 13
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6600916385650635 seconds
Streaming imagenet data took 0.6676602363586426 seconds
Then, training+dataloading take 0.668022871017456 seconds
The mode is:  split
Start 3840, end 4096, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3349769115447998
Time for copying to cuda: 0.008892536163330078
Time for forward pass: 0.04823660850524902
Time for backpropagation: 0.011950016021728516
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49372386932373047 seconds
Index: 14
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6060419082641602 seconds
Streaming imagenet data took 0.6142728328704834 seconds
Then, training+dataloading take 0.6146419048309326 seconds
The mode is:  split
Start 4096, end 4352, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37053442001342773
Time for copying to cuda: 0.009140729904174805
Time for forward pass: 0.04834914207458496
Time for backpropagation: 0.044584035873413086
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5624845027923584 seconds
Index: 15
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.677013635635376 seconds
Streaming imagenet data took 0.6845769882202148 seconds
Then, training+dataloading take 0.6849582195281982 seconds
The mode is:  split
Start 4352, end 4608, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3611483573913574
Time for copying to cuda: 0.009479522705078125
Time for forward pass: 0.04834699630737305
Time for backpropagation: 0.0033452510833740234
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4973609447479248 seconds
Index: 16
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6081721782684326 seconds
Streaming imagenet data took 0.621213436126709 seconds
Then, training+dataloading take 0.6215789318084717 seconds
The mode is:  split
Start 4608, end 4864, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.41048455238342285
Time for copying to cuda: 0.009215593338012695
Time for forward pass: 0.04826831817626953
Time for backpropagation: 0.0032410621643066406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5811190605163574 seconds
Index: 17
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7047131061553955 seconds
Streaming imagenet data took 0.7123699188232422 seconds
Then, training+dataloading take 0.7130429744720459 seconds
The mode is:  split
Start 4864, end 5120, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34224915504455566
Time for copying to cuda: 0.009691238403320312
Time for forward pass: 0.04848432540893555
Time for backpropagation: 0.003217458724975586
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4824650287628174 seconds
Index: 18
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.603644847869873 seconds
Streaming imagenet data took 0.6168789863586426 seconds
Then, training+dataloading take 0.6172769069671631 seconds
The mode is:  split
Start 5120, end 5376, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36084604263305664
Time for copying to cuda: 0.00910186767578125
Time for forward pass: 0.04886150360107422
Time for backpropagation: 0.003744363784790039
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5064442157745361 seconds
Index: 19
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6792507171630859 seconds
Streaming imagenet data took 0.6867866516113281 seconds
Then, training+dataloading take 0.6874690055847168 seconds
The mode is:  split
Start 5376, end 5632, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34691429138183594
Time for copying to cuda: 0.009220361709594727
Time for forward pass: 0.05379486083984375
Time for backpropagation: 0.0034096240997314453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49734973907470703 seconds
Index: 20
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5938680171966553 seconds
Streaming imagenet data took 0.6071357727050781 seconds
Then, training+dataloading take 0.6075360774993896 seconds
The mode is:  split
Start 5632, end 5888, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3829512596130371
Time for copying to cuda: 0.008907556533813477
Time for forward pass: 0.06939029693603516
Time for backpropagation: 0.00432586669921875
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5603675842285156 seconds
Index: 21
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.651921272277832 seconds
Streaming imagenet data took 0.6595463752746582 seconds
Then, training+dataloading take 0.6602764129638672 seconds
The mode is:  split
Start 5888, end 6144, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33989739418029785
Time for copying to cuda: 0.008953094482421875
Time for forward pass: 0.04819750785827637
Time for backpropagation: 0.003413677215576172
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.498504638671875 seconds
Index: 22
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6051826477050781 seconds
Streaming imagenet data took 0.6183068752288818 seconds
Then, training+dataloading take 0.6186883449554443 seconds
The mode is:  split
Start 6144, end 6400, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3832278251647949
Time for copying to cuda: 0.00913381576538086
Time for forward pass: 0.04832339286804199
Time for backpropagation: 0.0033609867095947266
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5691397190093994 seconds
Index: 23
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6476759910583496 seconds
Streaming imagenet data took 0.6552526950836182 seconds
Then, training+dataloading take 0.6559782028198242 seconds
The mode is:  split
Start 6400, end 6656, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3385295867919922
Time for copying to cuda: 0.009244680404663086
Time for forward pass: 0.04824566841125488
Time for backpropagation: 0.003359079360961914
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.48241448402404785 seconds
Index: 24
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5898091793060303 seconds
Streaming imagenet data took 0.6025998592376709 seconds
Then, training+dataloading take 0.6029970645904541 seconds
The mode is:  split
Start 6656, end 6912, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35288429260253906
Time for copying to cuda: 0.013648271560668945
Time for forward pass: 0.09128689765930176
Time for backpropagation: 0.003679990768432617
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5544779300689697 seconds
Index: 25
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.684257984161377 seconds
Streaming imagenet data took 0.6918337345123291 seconds
Then, training+dataloading take 0.6925477981567383 seconds
The mode is:  split
Start 6912, end 7168, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.339644193649292
Time for copying to cuda: 0.009011268615722656
Time for forward pass: 0.04811859130859375
Time for backpropagation: 0.0030126571655273438
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4785127639770508 seconds
Index: 26
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5981056690216064 seconds
Streaming imagenet data took 0.6108970642089844 seconds
Then, training+dataloading take 0.6112470626831055 seconds
The mode is:  split
Start 7168, end 7424, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3559224605560303
Time for copying to cuda: 0.008968830108642578
Time for forward pass: 0.04822993278503418
Time for backpropagation: 0.0037965774536132812
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5316128730773926 seconds
Index: 27
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6729574203491211 seconds
Streaming imagenet data took 0.6805412769317627 seconds
Then, training+dataloading take 0.681255578994751 seconds
The mode is:  split
Start 7424, end 7680, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33712220191955566
Time for copying to cuda: 0.009016036987304688
Time for forward pass: 0.048177242279052734
Time for backpropagation: 0.003002643585205078
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4869883060455322 seconds
Index: 28
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5912294387817383 seconds
Streaming imagenet data took 0.5992982387542725 seconds
Then, training+dataloading take 0.5996570587158203 seconds
The mode is:  split
Start 7680, end 7936, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.38397860527038574
Time for copying to cuda: 0.01113581657409668
Time for forward pass: 0.04842114448547363
Time for backpropagation: 0.0029997825622558594
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5686745643615723 seconds
Index: 29
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6633787155151367 seconds
Streaming imagenet data took 0.6710803508758545 seconds
Then, training+dataloading take 0.6714832782745361 seconds
The mode is:  split
Start 7936, end 8192, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3570220470428467
Time for copying to cuda: 0.009225130081176758
Time for forward pass: 0.048171043395996094
Time for backpropagation: 0.0030956268310546875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.502910852432251 seconds
Index: 30
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6035957336425781 seconds
Streaming imagenet data took 0.6163606643676758 seconds
Then, training+dataloading take 0.6167526245117188 seconds
The mode is:  split
Start 8192, end 8448, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.39783716201782227
Time for copying to cuda: 0.009114265441894531
Time for forward pass: 0.04833078384399414
Time for backpropagation: 0.003199338912963867
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5478386878967285 seconds
Index: 31
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7031030654907227 seconds
Streaming imagenet data took 0.7106738090515137 seconds
Then, training+dataloading take 0.711338996887207 seconds
The mode is:  split
Start 8448, end 8704, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34090185165405273
Time for copying to cuda: 0.008980751037597656
Time for forward pass: 0.04925274848937988
Time for backpropagation: 0.004160642623901367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4977433681488037 seconds
Index: 32
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6152119636535645 seconds
Streaming imagenet data took 0.6280689239501953 seconds
Then, training+dataloading take 0.6284289360046387 seconds
The mode is:  split
Start 8704, end 8960, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4011220932006836
Time for copying to cuda: 0.009622335433959961
Time for forward pass: 0.04842567443847656
Time for backpropagation: 0.003195047378540039
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5932741165161133 seconds
Index: 33
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6809272766113281 seconds
Streaming imagenet data took 0.6885905265808105 seconds
Then, training+dataloading take 0.6893000602722168 seconds
The mode is:  split
Start 8960, end 9216, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34938907623291016
Time for copying to cuda: 0.010142087936401367
Time for forward pass: 0.04827427864074707
Time for backpropagation: 0.0033180713653564453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4885854721069336 seconds
Index: 34
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6078004837036133 seconds
Streaming imagenet data took 0.6209571361541748 seconds
Then, training+dataloading take 0.6213271617889404 seconds
The mode is:  split
Start 9216, end 9472, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3975334167480469
Time for copying to cuda: 0.009184122085571289
Time for forward pass: 0.04833221435546875
Time for backpropagation: 0.04575634002685547
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5869324207305908 seconds
Index: 35
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6853857040405273 seconds
Streaming imagenet data took 0.692986249923706 seconds
Then, training+dataloading take 0.693687915802002 seconds
The mode is:  split
Start 9472, end 9728, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3453965187072754
Time for copying to cuda: 0.009181976318359375
Time for forward pass: 0.048304080963134766
Time for backpropagation: 0.003324270248413086
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4856688976287842 seconds
Index: 36
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6015605926513672 seconds
Streaming imagenet data took 0.6148421764373779 seconds
Then, training+dataloading take 0.6152534484863281 seconds
The mode is:  split
Start 9728, end 9984, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.45188260078430176
Time for copying to cuda: 0.009610891342163086
Time for forward pass: 0.04858732223510742
Memory occpied: (2566.0, 2280.0)
Time for backpropagation: 0.0035495758056640625
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5899696350097656 seconds
Index: 37
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7018253803253174 seconds
Streaming imagenet data took 0.7095024585723877 seconds
Then, training+dataloading take 0.7102334499359131 seconds
The mode is:  split
Start 9984, end 10240, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3518974781036377
Time for copying to cuda: 0.009350061416625977
Time for forward pass: 0.048377037048339844
Time for backpropagation: 0.003143787384033203
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5005619525909424 seconds
Index: 38
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6053111553192139 seconds
Streaming imagenet data took 0.6135647296905518 seconds
Then, training+dataloading take 0.6139571666717529 seconds
The mode is:  split
Start 10240, end 10496, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4177701473236084
Time for copying to cuda: 0.008949756622314453
Time for forward pass: 0.04833269119262695
Time for backpropagation: 0.002973794937133789
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.6113913059234619 seconds
Index: 39
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7061638832092285 seconds
Streaming imagenet data took 0.7137093544006348 seconds
Then, training+dataloading take 0.7140970230102539 seconds
The mode is:  split
Start 10496, end 10752, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3394498825073242
Time for copying to cuda: 0.008491754531860352
Time for forward pass: 0.04797983169555664
Time for backpropagation: 0.0029883384704589844
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.48903775215148926 seconds
Index: 40
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6599221229553223 seconds
Streaming imagenet data took 0.6679971218109131 seconds
Then, training+dataloading take 0.6683707237243652 seconds
The mode is:  split
Start 10752, end 11008, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3748152256011963
Time for copying to cuda: 0.009432077407836914
Time for forward pass: 0.048505544662475586
Time for backpropagation: 0.04473567008972168
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5743298530578613 seconds
Index: 41
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6691083908081055 seconds
Streaming imagenet data took 0.6766481399536133 seconds
Then, training+dataloading take 0.6770415306091309 seconds
The mode is:  split
Start 11008, end 11264, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34044480323791504
Time for copying to cuda: 0.011198043823242188
Time for forward pass: 0.04816126823425293
Time for backpropagation: 0.0031480789184570312
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49301600456237793 seconds
Index: 42
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5957441329956055 seconds
Streaming imagenet data took 0.6085877418518066 seconds
Then, training+dataloading take 0.6089503765106201 seconds
The mode is:  split
Start 11264, end 11520, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3856372833251953
Time for copying to cuda: 0.009159088134765625
Time for forward pass: 0.06645083427429199
Time for backpropagation: 0.00429081916809082
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5525085926055908 seconds
Index: 43
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.667896032333374 seconds
Streaming imagenet data took 0.6755332946777344 seconds
Then, training+dataloading take 0.6762824058532715 seconds
The mode is:  split
Start 11520, end 11776, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34888243675231934
Time for copying to cuda: 0.00957036018371582
Time for forward pass: 0.048276424407958984
Time for backpropagation: 0.003093242645263672
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4870457649230957 seconds
Index: 44
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5985767841339111 seconds
Streaming imagenet data took 0.6113815307617188 seconds
Then, training+dataloading take 0.6117575168609619 seconds
The mode is:  split
Start 11776, end 12032, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3813779354095459
Time for copying to cuda: 0.009737253189086914
Time for forward pass: 0.04819440841674805
Time for backpropagation: 0.0030951499938964844
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5519654750823975 seconds
Index: 45
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.672562837600708 seconds
Streaming imagenet data took 0.6801803112030029 seconds
Then, training+dataloading take 0.6809108257293701 seconds
The mode is:  split
Start 12032, end 12288, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3446190357208252
Time for copying to cuda: 0.009051799774169922
Time for forward pass: 0.048246145248413086
Time for backpropagation: 0.003672361373901367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49954795837402344 seconds
Index: 46
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6017148494720459 seconds
Streaming imagenet data took 0.6147310733795166 seconds
Then, training+dataloading take 0.6151208877563477 seconds
The mode is:  split
Start 12288, end 12544, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3676180839538574
Time for copying to cuda: 0.009879350662231445
Time for forward pass: 0.04827880859375
Time for backpropagation: 0.003968477249145508
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5590207576751709 seconds
Index: 47
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.682244062423706 seconds
Streaming imagenet data took 0.6898055076599121 seconds
Then, training+dataloading take 0.6905303001403809 seconds
The mode is:  split
Start 12544, end 12800, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37445616722106934
Time for copying to cuda: 0.010529756546020508
Time for forward pass: 0.0483248233795166
Time for backpropagation: 0.003124713897705078
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5155255794525146 seconds
Index: 48
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6275954246520996 seconds
Streaming imagenet data took 0.6356766223907471 seconds
Then, training+dataloading take 0.636030912399292 seconds
The mode is:  split
Start 12800, end 13056, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3947765827178955
Time for copying to cuda: 0.009138107299804688
Time for forward pass: 0.04827880859375
Time for backpropagation: 0.0031027793884277344
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5490093231201172 seconds
Index: 49
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6758041381835938 seconds
Streaming imagenet data took 0.6834065914154053 seconds
Then, training+dataloading take 0.683882474899292 seconds
The mode is:  split
Start 13056, end 13312, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3399078845977783
Time for copying to cuda: 0.00917506217956543
Time for forward pass: 0.04818987846374512
Time for backpropagation: 0.0032606124877929688
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.484234094619751 seconds
Index: 50
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5964410305023193 seconds
Streaming imagenet data took 0.6045315265655518 seconds
Then, training+dataloading take 0.6048874855041504 seconds
The mode is:  split
Start 13312, end 13568, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33751368522644043
Time for copying to cuda: 0.008893013000488281
Time for forward pass: 0.07349562644958496
Time for backpropagation: 0.010405540466308594
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5402331352233887 seconds
Index: 51
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6765701770782471 seconds
Streaming imagenet data took 0.6841409206390381 seconds
Then, training+dataloading take 0.6845200061798096 seconds
The mode is:  split
Start 13568, end 13824, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34365391731262207
Time for copying to cuda: 0.009058713912963867
Time for forward pass: 0.04834127426147461
Time for backpropagation: 0.003123044967651367
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4922661781311035 seconds
Index: 52
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6046602725982666 seconds
Streaming imagenet data took 0.6178829669952393 seconds
Then, training+dataloading take 0.618257999420166 seconds
The mode is:  split
Start 13824, end 14080, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3743321895599365
Time for copying to cuda: 0.009214639663696289
Time for forward pass: 0.048307180404663086
Time for backpropagation: 0.0030219554901123047
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5468471050262451 seconds
Index: 53
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.670844316482544 seconds
Streaming imagenet data took 0.6785218715667725 seconds
Then, training+dataloading take 0.6792263984680176 seconds
The mode is:  split
Start 14080, end 14336, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35790252685546875
Time for copying to cuda: 0.008997678756713867
Time for forward pass: 0.04811453819274902
Time for backpropagation: 0.0029938220977783203
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5013422966003418 seconds
Index: 54
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5982801914215088 seconds
Streaming imagenet data took 0.6062784194946289 seconds
Then, training+dataloading take 0.606647253036499 seconds
The mode is:  split
Start 14336, end 14592, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.40209436416625977
Time for copying to cuda: 0.009174585342407227
Time for forward pass: 0.04826498031616211
Time for backpropagation: 0.003312826156616211
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5955159664154053 seconds
Index: 55
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6712181568145752 seconds
Streaming imagenet data took 0.6788468360900879 seconds
Then, training+dataloading take 0.679255485534668 seconds
The mode is:  split
Start 14592, end 14848, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3446927070617676
Time for copying to cuda: 0.009090423583984375
Time for forward pass: 0.050322532653808594
Time for backpropagation: 0.003187417984008789
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4809103012084961 seconds
Index: 56
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5947372913360596 seconds
Streaming imagenet data took 0.6076681613922119 seconds
Then, training+dataloading take 0.6080405712127686 seconds
The mode is:  split
Start 14848, end 15104, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33857178688049316
Time for copying to cuda: 0.009212017059326172
Time for forward pass: 0.07855606079101562
Time for backpropagation: 0.004843473434448242
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5370028018951416 seconds
Index: 57
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6765568256378174 seconds
Streaming imagenet data took 0.6841182708740234 seconds
Then, training+dataloading take 0.6848530769348145 seconds
The mode is:  split
Start 15104, end 15360, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3419809341430664
Time for copying to cuda: 0.008841276168823242
Time for forward pass: 0.0547642707824707
Time for backpropagation: 0.003504037857055664
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4944489002227783 seconds
Index: 58
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.587296724319458 seconds
Streaming imagenet data took 0.600255012512207 seconds
Then, training+dataloading take 0.6006288528442383 seconds
The mode is:  split
Start 15360, end 15616, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.36064958572387695
Time for copying to cuda: 0.009384393692016602
Time for forward pass: 0.04825615882873535
Time for backpropagation: 0.0031194686889648438
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5343544483184814 seconds
Index: 59
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6507129669189453 seconds
Streaming imagenet data took 0.6583549976348877 seconds
Then, training+dataloading take 0.6590480804443359 seconds
The mode is:  split
Start 15616, end 15872, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3601715564727783
Time for copying to cuda: 0.008917570114135742
Time for forward pass: 0.04810500144958496
Time for backpropagation: 0.003065824508666992
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49895644187927246 seconds
Index: 60
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6123254299163818 seconds
Streaming imagenet data took 0.6252751350402832 seconds
Then, training+dataloading take 0.6256437301635742 seconds
The mode is:  split
Start 15872, end 16128, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.4256570339202881
Time for copying to cuda: 0.009087800979614258
Time for forward pass: 0.04827880859375
Time for backpropagation: 0.002988100051879883
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.6325428485870361 seconds
Index: 61
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6866035461425781 seconds
Streaming imagenet data took 0.6942224502563477 seconds
Then, training+dataloading take 0.694892406463623 seconds
The mode is:  split
Start 16128, end 16384, post_step 128


Epoch: 0
Memory occpied: (2566.0, 2280.0)
Time of next(dataloader) is: 0.36010265350341797
Time for copying to cuda: 0.008881807327270508
Time for forward pass: 0.04814028739929199
Time for backpropagation: 0.0030345916748046875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5150859355926514 seconds
Index: 62
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6178267002105713 seconds
Streaming imagenet data took 0.6260039806365967 seconds
Then, training+dataloading take 0.6264464855194092 seconds
The mode is:  split
Start 16384, end 16640, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35795140266418457
Time for copying to cuda: 0.00899815559387207
Time for forward pass: 0.0490117073059082
Time for backpropagation: 0.0034401416778564453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5056686401367188 seconds
Index: 63
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6923556327819824 seconds
Streaming imagenet data took 0.7000012397766113 seconds
Then, training+dataloading take 0.7005946636199951 seconds
The mode is:  split
Start 16640, end 16896, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3430650234222412
Time for copying to cuda: 0.009066104888916016
Time for forward pass: 0.048348188400268555
Time for backpropagation: 0.002996206283569336
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49784398078918457 seconds
Index: 64
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6081323623657227 seconds
Streaming imagenet data took 0.6163277626037598 seconds
Then, training+dataloading take 0.6167275905609131 seconds
The mode is:  split
Start 16896, end 17152, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34075307846069336
Time for copying to cuda: 0.009441614151000977
Time for forward pass: 0.04896235466003418
Time for backpropagation: 0.0032265186309814453
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5263485908508301 seconds
Index: 65
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6942176818847656 seconds
Streaming imagenet data took 0.7019269466400146 seconds
Then, training+dataloading take 0.7023284435272217 seconds
The mode is:  split
Start 17152, end 17408, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34198474884033203
Time for copying to cuda: 0.010813713073730469
Time for forward pass: 0.04839015007019043
Time for backpropagation: 0.0031783580780029297
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.49428319931030273 seconds
Index: 66
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5875251293182373 seconds
Streaming imagenet data took 0.5955972671508789 seconds
Then, training+dataloading take 0.5959630012512207 seconds
The mode is:  split
Start 17408, end 17664, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37827515602111816
Time for copying to cuda: 0.00960397720336914
Time for forward pass: 0.048432111740112305
Time for backpropagation: 0.06207609176635742
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5956137180328369 seconds
Index: 67
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6694793701171875 seconds
Streaming imagenet data took 0.6770198345184326 seconds
Then, training+dataloading take 0.6774227619171143 seconds
The mode is:  split
Start 17664, end 17920, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3408064842224121
Time for copying to cuda: 0.009232282638549805
Time for forward pass: 0.04819774627685547
Time for backpropagation: 0.0031290054321289062
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.48335981369018555 seconds
Index: 68
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6210720539093018 seconds
Streaming imagenet data took 0.6291985511779785 seconds
Then, training+dataloading take 0.6295711994171143 seconds
The mode is:  split
Start 17920, end 18176, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3828766345977783
Time for copying to cuda: 0.009105205535888672
Time for forward pass: 0.04823732376098633
Time for backpropagation: 0.003113269805908203
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5768418312072754 seconds
Index: 69
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6768848896026611 seconds
Streaming imagenet data took 0.6845176219940186 seconds
Then, training+dataloading take 0.6849091053009033 seconds
The mode is:  split
Start 18176, end 18432, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3434634208679199
Time for copying to cuda: 0.009059906005859375
Time for forward pass: 0.04810810089111328
Time for backpropagation: 0.003036022186279297
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.48392343521118164 seconds
Index: 70
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.599414587020874 seconds
Streaming imagenet data took 0.6075577735900879 seconds
Then, training+dataloading take 0.6079311370849609 seconds
The mode is:  split
Start 18432, end 18688, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3388242721557617
Time for copying to cuda: 0.04655265808105469
Time for forward pass: 0.04849886894226074
Time for backpropagation: 0.0033016204833984375
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.519028902053833 seconds
Index: 71
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6769578456878662 seconds
Streaming imagenet data took 0.6845078468322754 seconds
Then, training+dataloading take 0.6849021911621094 seconds
The mode is:  split
Start 18688, end 18944, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33800196647644043
Time for copying to cuda: 0.009159088134765625
Time for forward pass: 0.04819536209106445
Time for backpropagation: 0.002988100051879883
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4726896286010742 seconds
Index: 72
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6094136238098145 seconds
Streaming imagenet data took 0.6174988746643066 seconds
Then, training+dataloading take 0.6178579330444336 seconds
The mode is:  split
Start 18944, end 19200, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3864903450012207
Time for copying to cuda: 0.00930929183959961
Time for forward pass: 0.048239707946777344
Time for backpropagation: 0.003065824508666992
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5161592960357666 seconds
Index: 73
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6818411350250244 seconds
Streaming imagenet data took 0.6894886493682861 seconds
Then, training+dataloading take 0.6899852752685547 seconds
The mode is:  split
Start 19200, end 19456, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34050512313842773
Time for copying to cuda: 0.008982658386230469
Time for forward pass: 0.048259735107421875
Time for backpropagation: 0.003154754638671875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4698905944824219 seconds
Index: 74
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6068787574768066 seconds
Streaming imagenet data took 0.6198923587799072 seconds
Then, training+dataloading take 0.620258092880249 seconds
The mode is:  split
Start 19456, end 19712, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3772423267364502
Time for copying to cuda: 0.009104490280151367
Time for forward pass: 0.04823923110961914
Time for backpropagation: 0.04387927055358887
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5626161098480225 seconds
Index: 75
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6760659217834473 seconds
Streaming imagenet data took 0.6836025714874268 seconds
Then, training+dataloading take 0.6843030452728271 seconds
The mode is:  split
Start 19712, end 19968, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34149932861328125
Time for copying to cuda: 0.009113311767578125
Time for forward pass: 0.05102181434631348
Time for backpropagation: 0.0031952857971191406
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5085115432739258 seconds
Index: 76
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6098132133483887 seconds
Streaming imagenet data took 0.6179089546203613 seconds
Then, training+dataloading take 0.6182987689971924 seconds
The mode is:  split
Start 19968, end 20224, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3673262596130371
Time for copying to cuda: 0.009265661239624023
Time for forward pass: 0.048421621322631836
Time for backpropagation: 0.06199789047241211
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5733613967895508 seconds
Index: 77
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.672405481338501 seconds
Streaming imagenet data took 0.6801106929779053 seconds
Then, training+dataloading take 0.6805157661437988 seconds
The mode is:  split
Start 20224, end 20480, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35036778450012207
Time for copying to cuda: 0.009140729904174805
Time for forward pass: 0.04843878746032715
Time for backpropagation: 0.003007173538208008
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4906630516052246 seconds
Index: 78
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6036434173583984 seconds
Streaming imagenet data took 0.6165778636932373 seconds
Then, training+dataloading take 0.6169314384460449 seconds
The mode is:  split
Start 20480, end 20736, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3790929317474365
Time for copying to cuda: 0.010746240615844727
Time for forward pass: 0.04832744598388672
Time for backpropagation: 0.0030875205993652344
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5788123607635498 seconds
Index: 79
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6625611782073975 seconds
Memory occpied: (2566.0, 2280.0)
Streaming imagenet data took 0.6702070236206055 seconds
Then, training+dataloading take 0.6708903312683105 seconds
The mode is:  split
Start 20736, end 20992, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.34414243698120117
Time for copying to cuda: 0.010580062866210938
Time for forward pass: 0.04828000068664551
Time for backpropagation: 0.010289669036865234
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5131466388702393 seconds
Index: 80
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5916652679443359 seconds
Streaming imagenet data took 0.6045541763305664 seconds
Then, training+dataloading take 0.6049339771270752 seconds
The mode is:  split
Start 20992, end 21248, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3389737606048584
Time for copying to cuda: 0.0090179443359375
Time for forward pass: 0.08956480026245117
Time for backpropagation: 0.0052220821380615234
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5493443012237549 seconds
Index: 81
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.7006106376647949 seconds
Streaming imagenet data took 0.7082171440124512 seconds
Then, training+dataloading take 0.7088916301727295 seconds
The mode is:  split
Start 21248, end 21504, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33666276931762695
Time for copying to cuda: 0.009034156799316406
Time for forward pass: 0.04832339286804199
Time for backpropagation: 0.003040790557861328
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.47847414016723633 seconds
Index: 82
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5966014862060547 seconds
Streaming imagenet data took 0.60469651222229 seconds
Then, training+dataloading take 0.6050779819488525 seconds
The mode is:  split
Start 21504, end 21760, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3981204032897949
Time for copying to cuda: 0.010370492935180664
Time for forward pass: 0.07429647445678711
Time for backpropagation: 0.004470348358154297
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5741097927093506 seconds
Index: 83
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6732680797576904 seconds
Streaming imagenet data took 0.6809015274047852 seconds
Then, training+dataloading take 0.6812829971313477 seconds
The mode is:  split
Start 21760, end 22016, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33771395683288574
Time for copying to cuda: 0.008966922760009766
Time for forward pass: 0.0481722354888916
Time for backpropagation: 0.0029783248901367188
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4883136749267578 seconds
Index: 84
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5888140201568604 seconds
Streaming imagenet data took 0.6017606258392334 seconds
Then, training+dataloading take 0.6021285057067871 seconds
The mode is:  split
Start 22016, end 22272, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3911306858062744
Time for copying to cuda: 0.009476423263549805
Time for forward pass: 0.08653521537780762
Time for backpropagation: 0.015227079391479492
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.598992109298706 seconds
Index: 85
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6839683055877686 seconds
Streaming imagenet data took 0.6915555000305176 seconds
Then, training+dataloading take 0.6922686100006104 seconds
The mode is:  split
Start 22272, end 22528, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.35707592964172363
Time for copying to cuda: 0.008966684341430664
Time for forward pass: 0.04823017120361328
Time for backpropagation: 0.0035359859466552734
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5048995018005371 seconds
Index: 86
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6114475727081299 seconds
Streaming imagenet data took 0.6246352195739746 seconds
Then, training+dataloading take 0.6250076293945312 seconds
The mode is:  split
Start 22528, end 22784, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.37787890434265137
Time for copying to cuda: 0.009105920791625977
Time for forward pass: 0.048270225524902344
Time for backpropagation: 0.0031070709228515625
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5577850341796875 seconds
Index: 87
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6587190628051758 seconds
Streaming imagenet data took 0.6662490367889404 seconds
Then, training+dataloading take 0.6669330596923828 seconds
The mode is:  split
Start 22784, end 23040, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3431892395019531
Time for copying to cuda: 0.008969783782958984
Time for forward pass: 0.048615217208862305
Time for backpropagation: 0.007753133773803711
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.48754334449768066 seconds
Index: 88
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5971624851226807 seconds
Streaming imagenet data took 0.6052193641662598 seconds
Then, training+dataloading take 0.6055877208709717 seconds
The mode is:  split
Start 23040, end 23296, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3367421627044678
Time for copying to cuda: 0.009486198425292969
Time for forward pass: 0.07223701477050781
Time for backpropagation: 0.0036787986755371094
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5152230262756348 seconds
Index: 89
Memory occpied: (2566.0, 2280.0)
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6644036769866943 seconds
Streaming imagenet data took 0.6719679832458496 seconds
Then, training+dataloading take 0.6723744869232178 seconds
The mode is:  split
Start 23296, end 23552, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.33791351318359375
Time for copying to cuda: 0.010022878646850586
Time for forward pass: 0.04819202423095703
Time for backpropagation: 0.0030956268310546875
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.4793374538421631 seconds
Index: 90
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.5999488830566406 seconds
Streaming imagenet data took 0.6082801818847656 seconds
Then, training+dataloading take 0.6086559295654297 seconds
The mode is:  split
Start 23552, end 23808, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3544337749481201
Time for copying to cuda: 0.009115934371948242
Time for forward pass: 0.04829287528991699
Time for backpropagation: 0.04361295700073242
GPU memory for training: 1.3573789596557617                          

Memory occpied: (2566.0, 2280.0)
One training iteration takes: 0.5463449954986572 seconds
Index: 91
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6681668758392334 seconds
Streaming imagenet data took 0.6757862567901611 seconds
Then, training+dataloading take 0.6761589050292969 seconds
The mode is:  split
Start 23808, end 24064, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.3408012390136719
Time for copying to cuda: 0.009064674377441406
Time for forward pass: 0.07875823974609375
Time for backpropagation: 0.0028874874114990234
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5180728435516357 seconds
Index: 92
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6373171806335449 seconds
Streaming imagenet data took 0.6502091884613037 seconds
Then, training+dataloading take 0.6505758762359619 seconds
The mode is:  split
Start 24064, end 24320, post_step 128


Epoch: 0
Time of next(dataloader) is: 0.44097375869750977
Time for copying to cuda: 0.009885311126708984
Memory occpied: (2566.0, 2280.0)
Time for forward pass: 0.0481722354888916
Time for backpropagation: 0.002958059310913086
GPU memory for training: 1.3573789596557617                          

One training iteration takes: 0.5772309303283691 seconds
Index: 93
Read 31.69896125793457 MBs for this batch
Executing all posts took 0.6851747035980225 seconds
Streaming imagenet data took 0.6927762031555176 seconds
Then, training+dataloading take 0.6935031414031982 seconds

Epoch: 0
Time of next(dataloader) is: 0.3344147205352783
Time for copying to cuda: 0.008809566497802734
Time for forward pass: 0.04800605773925781
Time for backpropagation: 0.002732992172241211
GPU memory for training: 1.3573789596557617                          

The whole process took 72.44485783576965 seconds
