Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.1123000041989 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119028095.38615036 119028095.38615036
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.082062005996704 seconds
Streaming imagenet data took 2.109739065170288 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39188623428344727
Time for copying to cuda: 0.019588232040405273
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0871284008026123 seconds
Streaming imagenet data took 2.1144511699676514 seconds
Time for forward pass: 3.041677236557007
Time for backpropagation: 0.05002021789550781
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.603105306625366 seconds
Index: 0
Then, training+dataloading take 3.603309154510498 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.3779456615447998
Time for copying to cuda: 0.018848896026611328
Time for forward pass: 0.07545685768127441
Time for backpropagation: 0.0036308765411376953
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5686509609222412 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.2371158599853516 seconds
Streaming imagenet data took 2.265024185180664 seconds
Then, training+dataloading take 2.269775152206421 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.47421956062316895
Time for copying to cuda: 0.018563508987426758
Time for forward pass: 0.07564139366149902
Time for backpropagation: 0.002881288528442383
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.690291166305542 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.328645706176758 seconds
Streaming imagenet data took 2.356462240219116 seconds
Then, training+dataloading take 2.361891746520996 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39986252784729004
Time for copying to cuda: 0.018495798110961914
Time for forward pass: 0.07565474510192871
Time for backpropagation: 0.0026807785034179688
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.589174747467041 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.8559107780456543 seconds
Streaming imagenet data took 2.883107900619507 seconds
Then, training+dataloading take 2.887261390686035 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4440639019012451
Time for copying to cuda: 0.01850104331970215
Time for forward pass: 0.07567095756530762
Time for backpropagation: 0.0028581619262695312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6961867809295654 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2757.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.729376792907715 seconds
Streaming imagenet data took 2.7567009925842285 seconds
Then, training+dataloading take 2.7603063583374023 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.46932482719421387
Time for copying to cuda: 0.018697261810302734
Time for forward pass: 0.08390951156616211
Time for backpropagation: 0.0028901100158691406
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.7128539085388184 seconds
Index: 5
Memory occpied: (3211.0, 1632.0)
Memory occpied: (3817.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.4491331577301025 seconds
Streaming imagenet data took 2.477372884750366 seconds
Then, training+dataloading take 2.481720209121704 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.40564751625061035
Time for copying to cuda: 0.018389225006103516
Time for forward pass: 0.0756843090057373
Time for backpropagation: 0.0028276443481445312
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5981056690216064 seconds
Index: 6
Memory occpied: (3837.0, 1632.0)
Memory occpied: (3837.0, 1632.0)
Memory occpied: (3837.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.511836290359497 seconds
Streaming imagenet data took 3.5397908687591553 seconds
Then, training+dataloading take 3.5447700023651123 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4346275329589844
Time for copying to cuda: 0.019179344177246094
Time for forward pass: 0.07567715644836426
Time for backpropagation: 0.002838611602783203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6212158203125 seconds
Index: 7
Memory occpied: (3909.0, 1793.0)
Memory occpied: (3909.0, 2305.0)
Memory occpied: (3909.0, 2763.0)
Memory occpied: (4423.0, 3253.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 4.7696533203125 seconds
Streaming imagenet data took 4.797199249267578 seconds
Then, training+dataloading take 4.801668167114258 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42088985443115234
Time for copying to cuda: 0.019894123077392578
Time for forward pass: 0.1422562599182129
Time for backpropagation: 0.0027954578399658203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6815588474273682 seconds
Index: 8
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 10.712546110153198 seconds
Streaming imagenet data took 10.783117055892944 seconds
Then, training+dataloading take 10.791121006011963 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Memory occpied: (4649.0, 3261.0)
Time of next(dataloader) is: 0.42433881759643555
Time for copying to cuda: 0.018700838088989258
Time for forward pass: 0.07540273666381836
Time for backpropagation: 0.0026624202728271484
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.59954833984375 seconds
Index: 9
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.178213119506836 seconds
Streaming imagenet data took 3.2063775062561035 seconds
Then, training+dataloading take 3.209447145462036 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.48868370056152344
Time for copying to cuda: 0.06429290771484375
Memory occpied: (4649.0, 3261.0)
Time for forward pass: 0.07573938369750977
Time for backpropagation: 0.0027801990509033203
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.7233376502990723 seconds
Index: 10
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 3.4949867725372314 seconds
Streaming imagenet data took 3.522030830383301 seconds
Then, training+dataloading take 3.526123285293579 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3973684310913086
Time for copying to cuda: 0.018537282943725586
Time for forward pass: 0.07560610771179199
Time for backpropagation: 0.0028297901153564453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6092720031738281 seconds
Index: 11
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Memory occpied: (4649.0, 3261.0)
Read 11.263076782226562 MBs for this batch
Executing all posts took 3.330517053604126 seconds
Streaming imagenet data took 3.335627794265747 seconds
Then, training+dataloading take 3.3365917205810547 seconds

Epoch: 0
Time of next(dataloader) is: 0.3695237636566162
Time for copying to cuda: 0.0032227039337158203
Time for forward pass: 0.0325009822845459
Time for backpropagation: 0.0025968551635742188
GPU memory for training: 1.0984325408935547                          

The whole process took 55.12625789642334 seconds
