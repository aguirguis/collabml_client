Namespace(batch_size=8000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.3669348004454 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119061470.87816398 119061470.87816398
All candidates indexes:  (array([20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 1419.4921875 1704.23095703125 17704.6484375
Fixed, scale_with_bsz  0 2.05126953125
Mem usage  1514.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 8000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 5.467315196990967 seconds
Streaming imagenet data took 5.51739239692688 seconds
The mode is:  split
Start 8000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.41556811332702637
Time for copying to cuda: 0.03254127502441406
Time for forward pass: 3.1354949474334717
Time for backpropagation: 0.07681894302368164
GPU memory for training: 1.263702392578125                          

One training iteration takes: 3.7561728954315186 seconds
Index: 0
Memory occpied: (1514.0, 1704.0)
Memory occpied: (2346.0, 1704.0)
Read 125.27742004394531 MBs for this batch
Executing all posts took 5.110310077667236 seconds
Streaming imagenet data took 5.160811424255371 seconds
Then, training+dataloading take 5.167795181274414 seconds
The mode is:  split
Start 16000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42125439643859863
Time for copying to cuda: 0.03220558166503906
Time for forward pass: 0.09113860130310059
Time for backpropagation: 0.002619504928588867
GPU memory for training: 1.4203567504882812                          

Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
Memory occpied: (2354.0, 1712.0)
One training iteration takes: 5.571000337600708 seconds
Index: 1
Read 125.27742004394531 MBs for this batch
Executing all posts took 5.60072922706604 seconds
Streaming imagenet data took 5.687952041625977 seconds
Then, training+dataloading take 5.696865081787109 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.42614054679870605
Time for copying to cuda: 0.03490471839904785
Read 5.01116943359375 MBs for this batch
Executing all posts took 0.4913487434387207 seconds
Streaming imagenet data took 0.4995155334472656 seconds
Time for forward pass: 0.09125518798828125
Time for backpropagation: 0.0026335716247558594
GPU memory for training: 1.4203567504882812                          

Memory occpied: (2354.0, 1712.0)
One training iteration takes: 0.6337053775787354 seconds
Index: 2
Then, training+dataloading take 0.6341476440429688 seconds

Epoch: 0
Time of next(dataloader) is: 0.2912726402282715
Time for copying to cuda: 0.0016546249389648438
Time for forward pass: 0.02512836456298828
Time for backpropagation: 0.002501964569091797
GPU memory for training: 1.083341121673584                          

The whole process took 24.545615196228027 seconds
