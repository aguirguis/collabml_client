Namespace(batch_size=2000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 908.4278375553523 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [774400. 774400. 186624. 559872. 559872. 129792. 259584. 259584. 173056.
 173056. 173056. 173056.  36864.  36864.  36864.  16384.  16384.  16384.
  16384.  16384.   4000.]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 119069453.52405514 119069453.52405514
All candidates indexes:  (array([12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.03515625
1.47705078125
Total layers size  4.189361572265625
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Candidate split  13
Server, client, server+client, vanilla  284.73876953125 647.1533203125 931.89208984375 4679.3798828125
Model size  233.45703125
Fixed, scale_with_bsz  233.45703125 2.05126953125
Mem usage  1514.0 3.0
Using split index: 13
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 2000, post_step 1000

Memory occpied: (1514.0, 3.0)
Memory occpied: (1514.0, 3.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.0532190799713135 seconds
Streaming imagenet data took 2.080439329147339 seconds
The mode is:  split
Start 2000, end 4000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3887522220611572
Time for copying to cuda: 0.019033193588256836
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.94913649559021 seconds
Streaming imagenet data took 1.9767117500305176 seconds
Time for forward pass: 3.017923355102539
Time for backpropagation: 0.050959110260009766
GPU memory for training: 1.102445125579834                          

One training iteration takes: 3.574758291244507 seconds
Index: 0
Then, training+dataloading take 3.57493257522583 seconds
The mode is:  split
Start 4000, end 6000, post_step 1000


Epoch: 0
Memory occpied: (1514.0, 1624.0)
Time of next(dataloader) is: 0.37351393699645996
Time for copying to cuda: 0.01853179931640625
Time for forward pass: 0.07541251182556152
Time for backpropagation: 0.0036690235137939453
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5624046325683594 seconds
Index: 1
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 2.1200404167175293 seconds
Streaming imagenet data took 2.1480109691619873 seconds
Then, training+dataloading take 2.151012659072876 seconds
The mode is:  split
Start 6000, end 8000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.430006742477417
Time for copying to cuda: 0.018346309661865234
Time for forward pass: 0.07554006576538086
Time for backpropagation: 0.0026607513427734375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.637549877166748 seconds
Index: 2
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.970931053161621 seconds
Streaming imagenet data took 1.998197317123413 seconds
Then, training+dataloading take 2.0034537315368652 seconds
The mode is:  split
Start 8000, end 10000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4005880355834961
Time for copying to cuda: 0.01848626136779785
Time for forward pass: 0.07555460929870605
Time for backpropagation: 0.002740144729614258
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5972886085510254 seconds
Index: 3
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.875586748123169 seconds
Streaming imagenet data took 1.9034411907196045 seconds
Then, training+dataloading take 1.9076447486877441 seconds
The mode is:  split
Start 10000, end 12000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4470949172973633
Time for copying to cuda: 0.01838207244873047
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07560157775878906
Time for backpropagation: 0.0027565956115722656
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6390135288238525 seconds
Index: 4
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.96925950050354 seconds
Streaming imagenet data took 1.9967808723449707 seconds
Then, training+dataloading take 2.001138925552368 seconds
The mode is:  split
Start 12000, end 14000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.3880279064178467
Time for copying to cuda: 0.018367528915405273
Time for forward pass: 0.07551217079162598
Time for backpropagation: 0.002752542495727539
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5848581790924072 seconds
Index: 5
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.814969778060913 seconds
Streaming imagenet data took 1.8423795700073242 seconds
Then, training+dataloading take 1.8451993465423584 seconds
The mode is:  split
Start 14000, end 16000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4303290843963623
Time for copying to cuda: 0.01841425895690918
Time for forward pass: 0.07535505294799805
Time for backpropagation: 0.0026323795318603516
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6787271499633789 seconds
Index: 6
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9672508239746094 seconds
Memory occpied: (2326.0, 1632.0)
Streaming imagenet data took 1.9951841831207275 seconds
Then, training+dataloading take 2.0001943111419678 seconds
The mode is:  split
Start 16000, end 18000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38921046257019043
Time for copying to cuda: 0.018399953842163086
Time for forward pass: 0.07551217079162598
Time for backpropagation: 0.0027048587799072266
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5840191841125488 seconds
Index: 7
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.8808245658874512 seconds
Streaming imagenet data took 1.9077990055084229 seconds
Then, training+dataloading take 1.9122629165649414 seconds
The mode is:  split
Start 18000, end 20000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4323101043701172
Time for copying to cuda: 0.018414735794067383
Time for forward pass: 0.07560014724731445
Time for backpropagation: 0.0026607513427734375
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.66609787940979 seconds
Index: 8
Memory occpied: (2326.0, 1632.0)
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.999633550643921 seconds
Streaming imagenet data took 2.0272555351257324 seconds
Then, training+dataloading take 2.0300893783569336 seconds
The mode is:  split
Start 20000, end 22000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.39072656631469727
Time for copying to cuda: 0.018529891967773438
Time for forward pass: 0.07553362846374512
Time for backpropagation: 0.002720355987548828
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.5835027694702148 seconds
Index: 9
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.882667064666748 seconds
Streaming imagenet data took 1.9098842144012451 seconds
Then, training+dataloading take 1.9142754077911377 seconds
The mode is:  split
Start 22000, end 24000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.4501056671142578
Time for copying to cuda: 0.018610715866088867
Memory occpied: (2326.0, 1632.0)
Time for forward pass: 0.07563972473144531
Time for backpropagation: 0.0027561187744140625
GPU memory for training: 1.2580008506774902                          

One training iteration takes: 0.6452064514160156 seconds
Index: 10
Memory occpied: (2326.0, 1632.0)
Read 70.3937759399414 MBs for this batch
Executing all posts took 1.9248578548431396 seconds
Streaming imagenet data took 1.9526095390319824 seconds
Then, training+dataloading take 1.9577131271362305 seconds
The mode is:  split
Start 24000, end 24320, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.38789916038513184
Time for copying to cuda: 0.018336772918701172
Time for forward pass: 0.0689537525177002
Time for backpropagation: 0.003021240234375
GPU memory for training: 1.2580008506774902                          

Read 11.263076782226562 MBs for this batch
Executing all posts took 0.54054856300354 seconds
Streaming imagenet data took 0.5495975017547607 seconds
One training iteration takes: 0.5719249248504639 seconds
Index: 11
Then, training+dataloading take 0.5722503662109375 seconds

Epoch: 0
Time of next(dataloader) is: 0.4226369857788086
Time for copying to cuda: 0.0033118724822998047
Time for forward pass: 0.03265023231506348
Time for backpropagation: 0.002857685089111328
GPU memory for training: 1.0984325408935547                          

Memory occpied: (2326.0, 1632.0)
The whole process took 33.92648530006409 seconds
