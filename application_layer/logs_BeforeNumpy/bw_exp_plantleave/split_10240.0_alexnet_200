Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 8795.219425436846 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 1152807000.5308583 1152807000.5308583
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3364748954772949 seconds
Streaming plantleave data took 0.34605860710144043 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3260211944580078
Time for copying to cuda: 0.02357625961303711
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3509798049926758 seconds
Streaming plantleave data took 0.36179208755493164 seconds
Memory occpied: (1526.0, 320.0)
Memory occpied: (1526.0, 786.0)
Memory occpied: (1526.0, 1200.0)
Time for forward pass: 3.5843749046325684
Time for backpropagation: 0.05432701110839844
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.06320858001709 seconds
Index: 0
Then, training+dataloading take 4.063270807266235 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4919862747192383
Time for copying to cuda: 0.012412071228027344
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5049207210540771 seconds
Streaming plantleave data took 0.5198113918304443 seconds
Time for forward pass: 0.07646393775939941
Time for backpropagation: 0.003442049026489258
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6767051219940186 seconds
Index: 1
Then, training+dataloading take 0.6767663955688477 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.42336273193359375 seconds
Time of next(dataloader) is: 0.42343950271606445
Time for copying to cuda: 0.007157802581787109
Streaming plantleave data took 0.4368479251861572 seconds
Time for forward pass: 0.03410959243774414
Time for backpropagation: 0.0026671886444091797
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5678050518035889 seconds
Index: 2
Then, training+dataloading take 0.5678503513336182 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5113742351531982
Time for copying to cuda: 0.015330791473388672
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5276939868927002 seconds
Streaming plantleave data took 0.5413846969604492 seconds
Time for forward pass: 0.035958290100097656
Time for backpropagation: 0.002659320831298828
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.7041194438934326 seconds
Index: 3
Then, training+dataloading take 0.7042009830474854 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Memory occpied: (2314.0, 2084.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4314272403717041 seconds
Time of next(dataloader) is: 0.43160247802734375
Time for copying to cuda: 0.011685848236083984
Streaming plantleave data took 0.44833850860595703 seconds
Time for forward pass: 0.04371023178100586
Time for backpropagation: 0.002663850784301758
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.575857400894165 seconds
Index: 4
Then, training+dataloading take 0.5759005546569824 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4647681713104248
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.46527957916259766 seconds
Time for copying to cuda: 0.05021071434020996
Streaming plantleave data took 0.5233566761016846 seconds
Time for forward pass: 0.04412102699279785
Time for backpropagation: 0.002712249755859375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.652977705001831 seconds
Index: 5
Then, training+dataloading take 0.653101921081543 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4638857841491699 seconds
Time of next(dataloader) is: 0.46448516845703125
Time for copying to cuda: 0.007356405258178711
Streaming plantleave data took 0.48105645179748535 seconds
Time for forward pass: 0.04366660118103027
Time for backpropagation: 0.0025000572204589844
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6038510799407959 seconds
Index: 6
Then, training+dataloading take 0.6038939952850342 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42902517318725586
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.44254040718078613 seconds
Time for copying to cuda: 0.013244152069091797
Streaming plantleave data took 0.4593949317932129 seconds
Time for forward pass: 0.04373598098754883
Time for backpropagation: 0.002530336380004883
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5792257785797119 seconds
Index: 7
Then, training+dataloading take 0.5793576240539551 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5078485012054443 seconds
Time of next(dataloader) is: 0.508326530456543
Time for copying to cuda: 0.0069158077239990234
Streaming plantleave data took 0.5212380886077881 seconds
Time for forward pass: 0.04346776008605957
Time for backpropagation: 0.0024709701538085938
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6604907512664795 seconds
Index: 8
Then, training+dataloading take 0.6605353355407715 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4414515495300293
Time for copying to cuda: 0.006951332092285156
Time for forward pass: 0.043411970138549805
Time for backpropagation: 0.0024652481079101562
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5915300846099854 seconds
Index: 9
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6187171936035156 seconds
Streaming plantleave data took 0.6249120235443115 seconds
Then, training+dataloading take 0.625237226486206 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5029644966125488
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5034613609313965 seconds
Time for copying to cuda: 0.008145809173583984
Streaming plantleave data took 0.5163564682006836 seconds
Time for forward pass: 0.07339191436767578
Time for backpropagation: 0.0032181739807128906
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6816689968109131 seconds
Index: 10
Then, training+dataloading take 0.6817281246185303 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42629361152648926
Time for copying to cuda: 0.017983675003051758
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.44496870040893555 seconds
Streaming plantleave data took 0.458712100982666 seconds
Time for forward pass: 0.0438082218170166
Time for backpropagation: 0.002630949020385742
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5856249332427979 seconds
Index: 11
Then, training+dataloading take 0.5858359336853027 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4767575263977051
Time for copying to cuda: 0.01097726821899414
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5149686336517334 seconds
Streaming plantleave data took 0.5273430347442627 seconds
Time for forward pass: 0.043741703033447266
Time for backpropagation: 0.0025794506072998047
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6412723064422607 seconds
Index: 12
Then, training+dataloading take 0.6414103507995605 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.4563124179840088
Time for copying to cuda: 0.014838695526123047
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.47181248664855957 seconds
Streaming plantleave data took 0.48882222175598145 seconds
Time for forward pass: 0.04376578330993652
Time for backpropagation: 0.0025920867919921875
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6013920307159424 seconds
Index: 13
Then, training+dataloading take 0.6014399528503418 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44191575050354004
Time for copying to cuda: 0.020737409591674805
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5076513290405273 seconds
Streaming plantleave data took 0.5226004123687744 seconds
Time for forward pass: 0.044109344482421875
Time for backpropagation: 0.002762317657470703
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.648712158203125 seconds
Index: 14
Then, training+dataloading take 0.6488325595855713 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.4357028007507324
Time for copying to cuda: 0.021873950958251953
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.46302318572998047 seconds
Streaming plantleave data took 0.4801902770996094 seconds
Time for forward pass: 0.04396414756774902
Time for backpropagation: 0.002646207809448242
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5958614349365234 seconds
Index: 15
Then, training+dataloading take 0.5959069728851318 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4378340244293213 seconds
Time of next(dataloader) is: 0.4390134811401367
Time for copying to cuda: 0.007259368896484375
Streaming plantleave data took 0.4556453227996826 seconds
Time for forward pass: 0.0437474250793457
Time for backpropagation: 0.002613067626953125
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5981566905975342 seconds
Index: 16
Then, training+dataloading take 0.5983099937438965 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5044751167297363
Time for copying to cuda: 0.010908842086791992
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5161418914794922 seconds
Streaming plantleave data took 0.5327322483062744 seconds
Time for forward pass: 0.043840646743774414
Time for backpropagation: 0.0025992393493652344
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6615850925445557 seconds
Index: 17
Then, training+dataloading take 0.6616275310516357 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4327220916748047 seconds
Time of next(dataloader) is: 0.4324972629547119
Time for copying to cuda: 0.007096052169799805
Streaming plantleave data took 0.4456334114074707 seconds
Time for forward pass: 0.043680667877197266
Time for backpropagation: 0.0027976036071777344
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5831122398376465 seconds
Index: 18
Then, training+dataloading take 0.5831563472747803 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47807741165161133
Time for copying to cuda: 0.009244680404663086
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4981856346130371 seconds
Streaming plantleave data took 0.5130612850189209 seconds
Time for forward pass: 0.08537745475769043
Time for backpropagation: 0.003271818161010742
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6809549331665039 seconds
Index: 19
Then, training+dataloading take 0.6810131072998047 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4688849449157715 seconds
Time of next(dataloader) is: 0.46886634826660156
Time for copying to cuda: 0.007368326187133789
Streaming plantleave data took 0.4859731197357178 seconds
Time for forward pass: 0.043677568435668945
Time for backpropagation: 0.002585887908935547
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.609175443649292 seconds
Index: 20
Then, training+dataloading take 0.6092197895050049 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44385504722595215
Time for copying to cuda: 0.013938665390014648
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.45833706855773926 seconds
Streaming plantleave data took 0.48150181770324707 seconds
Time for forward pass: 0.04397392272949219
Time for backpropagation: 0.0025682449340820312
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6419007778167725 seconds
Index: 21
Then, training+dataloading take 0.6419649124145508 seconds

Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.3996295928955078
Time for copying to cuda: 0.0037865638732910156
Time for forward pass: 0.21035194396972656
Time for backpropagation: 0.007938146591186523
GPU memory for training: 1.6737470626831055                          

The whole process took 25.095627069473267 seconds
