Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 44.420634807693844 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 5822301.4455140475 5822301.4455140475
All candidates indexes:  (array([15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.015625
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 245.9559326171875 515.0350341796875 653.0848388671875
Candidate split  16
Server, client, server+client, vanilla  269.0791015625 245.9559326171875 515.0350341796875 653.0848388671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 16
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Memory occpied: (1500.0, 3.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 7.216865062713623 seconds
Streaming plantleave data took 7.218837738037109 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.2960479259490967
Time for copying to cuda: 0.0011599063873291016
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8168082237243652 seconds
Streaming plantleave data took 0.8189370632171631 seconds
Memory occpied: (1500.0, 356.0)
Memory occpied: (1500.0, 826.0)
Time for forward pass: 3.2838804721832275
Memory occpied: (1500.0, 1500.0)
Time for backpropagation: 0.05365276336669922
GPU memory for training: 0.8652257919311523                          

One training iteration takes: 3.694312572479248 seconds
Index: 0
Then, training+dataloading take 3.6943724155426025 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3619835376739502
Time for copying to cuda: 0.0012133121490478516
Time for forward pass: 0.024645090103149414
Time for backpropagation: 0.0026636123657226562
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.481311559677124 seconds
Index: 1
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8350450992584229 seconds
Streaming plantleave data took 0.8370709419250488 seconds
Then, training+dataloading take 0.8373763561248779 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39167189598083496
Time for copying to cuda: 0.001173257827758789
Time for forward pass: 0.023471355438232422
Time for backpropagation: 0.0027899742126464844
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.529094934463501 seconds
Index: 2
Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8353080749511719 seconds
Streaming plantleave data took 0.8373153209686279 seconds
Then, training+dataloading take 0.8376336097717285 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36094164848327637
Time for copying to cuda: 0.0011925697326660156
Time for forward pass: 0.023479461669921875
Time for backpropagation: 0.0027763843536376953
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.473388671875 seconds
Index: 3
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8062093257904053 seconds
Streaming plantleave data took 0.809326171875 seconds
Then, training+dataloading take 0.8099415302276611 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.43582606315612793
Time for copying to cuda: 0.0011942386627197266
Time for forward pass: 0.023490428924560547
Time for backpropagation: 0.0027348995208740234
GPU memory for training: 0.9910669326782227                          

Memory occpied: (2112.0, 1508.0)
One training iteration takes: 0.5539064407348633 seconds
Index: 4
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8135919570922852 seconds
Streaming plantleave data took 0.8152375221252441 seconds
Then, training+dataloading take 0.8155896663665771 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3647756576538086
Time for copying to cuda: 0.0011715888977050781
Time for forward pass: 0.02343273162841797
Time for backpropagation: 0.002790689468383789
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.4854269027709961 seconds
Index: 5
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8680603504180908 seconds
Streaming plantleave data took 0.8712232112884521 seconds
Then, training+dataloading take 0.8721358776092529 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Memory occpied: (2112.0, 1508.0)
Time of next(dataloader) is: 0.3869330883026123
Time for copying to cuda: 0.0011937618255615234
Time for forward pass: 0.02347397804260254
Time for backpropagation: 0.0027425289154052734
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.49778294563293457 seconds
Index: 6
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8910484313964844 seconds
Streaming plantleave data took 0.8927075862884521 seconds
Then, training+dataloading take 0.893068790435791 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4108586311340332
Time for copying to cuda: 0.0012180805206298828
Time for forward pass: 0.06056928634643555
Time for backpropagation: 0.003688335418701172
GPU memory for training: 0.9910669326782227                          

Memory occpied: (2112.0, 1508.0)
One training iteration takes: 0.5648548603057861 seconds
Index: 7
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.7782583236694336 seconds
Streaming plantleave data took 0.7798948287963867 seconds
Then, training+dataloading take 0.7801969051361084 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3681671619415283
Time for copying to cuda: 0.0011706352233886719
Time for forward pass: 0.02348494529724121
Time for backpropagation: 0.002805948257446289
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.4678788185119629 seconds
Index: 8
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8060488700866699 seconds
Streaming plantleave data took 0.8089909553527832 seconds
Then, training+dataloading take 0.8098361492156982 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.43471765518188477
Time for copying to cuda: 0.0012428760528564453
Time for forward pass: 0.023622512817382812
Time for backpropagation: 0.002951383590698242
GPU memory for training: 0.9910669326782227                          

Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8605866432189941 seconds
Streaming plantleave data took 0.8634769916534424 seconds
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
One training iteration takes: 5.47389817237854 seconds
Index: 9
Then, training+dataloading take 5.473962783813477 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35950517654418945
Time for copying to cuda: 0.0011477470397949219
Time for forward pass: 0.023389816284179688
Time for backpropagation: 0.0028383731842041016
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.46212100982666016 seconds
Index: 10
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8726732730865479 seconds
Streaming plantleave data took 0.8746917247772217 seconds
Then, training+dataloading take 0.874974250793457 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39697265625
Time for copying to cuda: 0.0011649131774902344
Time for forward pass: 0.02338433265686035
Time for backpropagation: 0.0026760101318359375
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.5427663326263428 seconds
Index: 11
Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.780958890914917 seconds
Streaming plantleave data took 0.7829930782318115 seconds
Then, training+dataloading take 0.7833209037780762 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36646294593811035
Time for copying to cuda: 0.00119781494140625
Time for forward pass: 0.023301362991333008
Time for backpropagation: 0.002626657485961914
GPU memory for training: 0.9910669326782227                          

Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8722355365753174 seconds
Streaming plantleave data took 0.8752481937408447 seconds
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
One training iteration takes: 5.404652833938599 seconds
Index: 12
Then, training+dataloading take 5.404725790023804 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4168729782104492
Time for copying to cuda: 0.0011818408966064453
Time for forward pass: 0.023406267166137695
Time for backpropagation: 0.002694368362426758
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.5846784114837646 seconds
Index: 13
Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8338484764099121 seconds
Streaming plantleave data took 0.8355212211608887 seconds
Then, training+dataloading take 0.835871696472168 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3664238452911377
Time for copying to cuda: 0.0012264251708984375
Time for forward pass: 0.023585081100463867
Time for backpropagation: 0.0028815269470214844
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.47638916969299316 seconds
Index: 14
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.7875931262969971 seconds
Streaming plantleave data took 0.7892029285430908 seconds
Then, training+dataloading take 0.7895114421844482 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39702558517456055
Time for copying to cuda: 0.001161336898803711
Time for forward pass: 0.0233612060546875
Time for backpropagation: 0.0026884078979492188
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.5477585792541504 seconds
Index: 15
Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.7915914058685303 seconds
Streaming plantleave data took 0.793632984161377 seconds
Then, training+dataloading take 0.7939560413360596 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3526744842529297
Time for copying to cuda: 0.0011675357818603516
Time for forward pass: 0.023516416549682617
Time for backpropagation: 0.002932310104370117
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.45590853691101074 seconds
Index: 16
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8167529106140137 seconds
Streaming plantleave data took 0.818368673324585 seconds
Then, training+dataloading take 0.8186867237091064 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3942577838897705
Time for copying to cuda: 0.001163482666015625
Time for forward pass: 0.023276329040527344
Time for backpropagation: 0.002851247787475586
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.5478589534759521 seconds
Index: 17
Memory occpied: (2112.0, 1508.0)
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8431379795074463 seconds
Streaming plantleave data took 0.8448116779327393 seconds
Then, training+dataloading take 0.8451509475708008 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.35028791427612305
Time for copying to cuda: 0.0011456012725830078
Time for forward pass: 0.023388147354125977
Time for backpropagation: 0.0027358531951904297
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.45728468894958496 seconds
Index: 18
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8653960227966309 seconds
Streaming plantleave data took 0.8674778938293457 seconds
Then, training+dataloading take 0.8679070472717285 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3958437442779541
Time for copying to cuda: 0.001157522201538086
Time for forward pass: 0.023370981216430664
Time for backpropagation: 0.0027310848236083984
GPU memory for training: 0.9910669326782227                          

Memory occpied: (2112.0, 1508.0)
One training iteration takes: 0.5150089263916016 seconds
Index: 19
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8182110786437988 seconds
Streaming plantleave data took 0.8198063373565674 seconds
Then, training+dataloading take 0.8201420307159424 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.36273884773254395
Time for copying to cuda: 0.0011849403381347656
Time for forward pass: 0.023378372192382812
Time for backpropagation: 0.0027170181274414062
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.48993563652038574 seconds
Index: 20
Read 3.1323585510253906 MBs for this batch
Executing all posts took 0.8271346092224121 seconds
Streaming plantleave data took 0.8300869464874268 seconds
Then, training+dataloading take 0.8305976390838623 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Memory occpied: (2112.0, 1508.0)
Memory occpied: (2112.0, 1508.0)
Time of next(dataloader) is: 0.38532447814941406
Time for copying to cuda: 0.0011637210845947266
Time for forward pass: 0.023385047912597656
Time for backpropagation: 0.002789020538330078
GPU memory for training: 0.9910669326782227                          

One training iteration takes: 0.5003647804260254 seconds
Index: 21
Read 1.597609519958496 MBs for this batch
Executing all posts took 0.5746927261352539 seconds
Streaming plantleave data took 0.5755729675292969 seconds
Then, training+dataloading take 0.5759360790252686 seconds

Epoch: 0
Time of next(dataloader) is: 0.3422837257385254
Time for copying to cuda: 0.0007097721099853516
Time for forward pass: 0.022480487823486328
Time for backpropagation: 0.0032501220703125
GPU memory for training: 0.9889664649963379                          

The whole process took 44.242006063461304 seconds
