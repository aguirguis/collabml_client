Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 2714.996264363408 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 355859990.3626406 355859990.3626406
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3732643127441406 seconds
Streaming plantleave data took 0.38321661949157715 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.3362903594970703
Time for copying to cuda: 0.010332584381103516
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3920605182647705 seconds
Streaming plantleave data took 0.40228271484375 seconds
Memory occpied: (1526.0, 292.0)
Memory occpied: (1526.0, 724.0)
Memory occpied: (1526.0, 1186.0)
Time for forward pass: 3.572340726852417
Time for backpropagation: 0.06130266189575195
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.055922031402588 seconds
Index: 0
Then, training+dataloading take 4.055984258651733 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4046204090118408
Time for copying to cuda: 0.00804591178894043
Time for forward pass: 0.038553476333618164
Time for backpropagation: 0.003766298294067383
GPU memory for training: 1.2210283279418945                          

Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4725046157836914 seconds
Streaming plantleave data took 0.48328089714050293 seconds
One training iteration takes: 0.5442116260528564 seconds
Index: 1
Then, training+dataloading take 0.5443305969238281 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.42667222023010254
Time for copying to cuda: 0.010073423385620117
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.46166348457336426 seconds
Time for forward pass: 0.03361010551452637
Streaming plantleave data took 0.47229743003845215 seconds
Time for backpropagation: 0.0031163692474365234
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5618374347686768 seconds
Index: 2
Then, training+dataloading take 0.5618801116943359 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41167116165161133
Time for copying to cuda: 0.007003068923950195
Time for forward pass: 0.03346085548400879
Time for backpropagation: 0.0027201175689697266
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5402810573577881 seconds
Index: 3
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.562514066696167 seconds
Streaming plantleave data took 0.6165354251861572 seconds
Then, training+dataloading take 0.6178033351898193 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4696159362792969
Time for copying to cuda: 0.008633852005004883
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5276095867156982 seconds
Time for forward pass: 0.04851484298706055
Time for backpropagation: 0.003076314926147461
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5407233238220215 seconds
Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.638343334197998 seconds
Index: 4
Then, training+dataloading take 0.6383867263793945 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4092826843261719
Time for copying to cuda: 0.012304306030273438
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4430530071258545 seconds
Streaming plantleave data took 0.45525193214416504 seconds
Time for forward pass: 0.04350543022155762
Time for backpropagation: 0.0025348663330078125
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5642144680023193 seconds
Index: 5
Then, training+dataloading take 0.5644128322601318 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42378830909729004
Time for copying to cuda: 0.008713483810424805
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5215659141540527 seconds
Time for forward pass: 0.05498957633972168
Streaming plantleave data took 0.5371387004852295 seconds
Time for backpropagation: 0.004254579544067383
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6387569904327393 seconds
Index: 6
Then, training+dataloading take 0.6388759613037109 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.42684483528137207
Time for copying to cuda: 0.017401456832885742
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4600863456726074 seconds
Streaming plantleave data took 0.4702732563018799 seconds
Time for forward pass: 0.04363727569580078
Time for backpropagation: 0.0027513504028320312
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5716109275817871 seconds
Index: 7
Then, training+dataloading take 0.5716552734375 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4022531509399414
Time for copying to cuda: 0.008608102798461914
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.44596147537231445 seconds
Streaming plantleave data took 0.4604802131652832 seconds
Time for forward pass: 0.05121493339538574
Time for backpropagation: 0.0026977062225341797
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6031816005706787 seconds
Index: 8
Then, training+dataloading take 0.60325026512146 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4981563091278076
Time for copying to cuda: 0.009929418563842773
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5528948307037354 seconds
Time for forward pass: 0.044538021087646484
Time for backpropagation: 0.0031630992889404297
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5661435127258301 seconds
Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6409518718719482 seconds
Index: 9
Then, training+dataloading take 0.6409945487976074 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.41149258613586426
Time for copying to cuda: 0.010319709777832031
Time for forward pass: 0.04433798789978027
Time for backpropagation: 0.002658843994140625
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5538308620452881 seconds
Index: 10
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.6160123348236084 seconds
Streaming plantleave data took 0.6259908676147461 seconds
Then, training+dataloading take 0.6263124942779541 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47431015968322754
Time for copying to cuda: 0.008326530456542969
Time for forward pass: 0.04483914375305176
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5844309329986572 seconds
Time for backpropagation: 0.05868816375732422
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5986254215240479 seconds
Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6985502243041992 seconds
Index: 11
Then, training+dataloading take 0.6985957622528076 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4388139247894287
Time for copying to cuda: 0.009097814559936523
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5012118816375732 seconds
Time for forward pass: 0.052605628967285156
Time for backpropagation: 0.003206014633178711
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5157639980316162 seconds
One training iteration takes: 0.5904419422149658 seconds
Index: 12
Then, training+dataloading take 0.5906550884246826 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4343709945678711
Time for copying to cuda: 0.012151956558227539
Time for forward pass: 0.04714155197143555
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5071759223937988 seconds
Time for backpropagation: 0.06054258346557617
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5685577392578125 seconds
Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.656937837600708 seconds
Index: 13
Then, training+dataloading take 0.6570074558258057 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.44797515869140625
Time for copying to cuda: 0.015818357467651367
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.48306870460510254 seconds
Streaming plantleave data took 0.49776792526245117 seconds
Time for forward pass: 0.04385519027709961
Time for backpropagation: 0.002818584442138672
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6147150993347168 seconds
Index: 14
Then, training+dataloading take 0.6147561073303223 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4374275207519531
Time for copying to cuda: 0.008719205856323242
Time for forward pass: 0.05001068115234375
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5565013885498047 seconds
Time for backpropagation: 0.0640101432800293
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5747244358062744 seconds
Memory occpied: (2314.0, 2084.0)
One training iteration takes: 0.6506142616271973 seconds
Index: 15
Then, training+dataloading take 0.6506578922271729 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4101066589355469
Time for copying to cuda: 0.013725996017456055
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4730343818664551 seconds
Time for forward pass: 0.04864168167114258
Time for backpropagation: 0.0033597946166992188
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.49047279357910156 seconds
One training iteration takes: 0.5520467758178711 seconds
Index: 16
Then, training+dataloading take 0.5520892143249512 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.48707151412963867
Time for copying to cuda: 0.009220600128173828
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5477762222290039 seconds
Time for forward pass: 0.04692506790161133
Time for backpropagation: 0.0036287307739257812
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.5666122436523438 seconds
One training iteration takes: 0.6365823745727539 seconds
Index: 17
Then, training+dataloading take 0.6367156505584717 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.4145681858062744
Time for copying to cuda: 0.008658170700073242
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.46278977394104004 seconds
Time for forward pass: 0.04390764236450195
Time for backpropagation: 0.002998828887939453
GPU memory for training: 1.2210283279418945                          

Streaming plantleave data took 0.4753398895263672 seconds
One training iteration takes: 0.5487239360809326 seconds
Index: 18
Then, training+dataloading take 0.5487840175628662 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.45937585830688477
Time for copying to cuda: 0.011944770812988281
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.49839138984680176 seconds
Streaming plantleave data took 0.5130774974822998 seconds
Time for forward pass: 0.04403996467590332
Time for backpropagation: 0.002541780471801758
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6349496841430664 seconds
Index: 19
Then, training+dataloading take 0.6350846290588379 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (2314.0, 2084.0)
Time of next(dataloader) is: 0.47617030143737793
Time for copying to cuda: 0.007954835891723633
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.517256498336792 seconds
Streaming plantleave data took 0.5329861640930176 seconds
Time for forward pass: 0.04949069023132324
Time for backpropagation: 0.002588033676147461
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.629805326461792 seconds
Index: 20
Then, training+dataloading take 0.6298470497131348 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4037055969238281
Time for copying to cuda: 0.010514259338378906
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.42002296447753906 seconds
Streaming plantleave data took 0.4426708221435547 seconds
Time for forward pass: 0.043801307678222656
Time for backpropagation: 0.002567291259765625
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5510349273681641 seconds
Index: 21
Then, training+dataloading take 0.5510919094085693 seconds

Epoch: 0
Time of next(dataloader) is: 0.44971489906311035
Time for copying to cuda: 0.003821849822998047
Memory occpied: (2314.0, 2084.0)
Time for forward pass: 0.1994168758392334
Time for backpropagation: 0.008250951766967773
GPU memory for training: 1.6732282638549805                          

The whole process took 25.148125410079956 seconds
