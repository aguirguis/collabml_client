Namespace(batch_size=200, cpuonly=False, dataset='plantleave', downloadall=False, end=10000, freeze=True, freeze_idx=17, model='myalexnet', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
IN SPLITTING ALGO
Recorded bandwidth: 9843.922884779495 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [7.74400e+05 7.74400e+05 1.86624e+05 5.59872e+05 5.59872e+05 1.29792e+05
 2.59584e+05 2.59584e+05 1.73056e+05 1.73056e+05 1.73056e+05 1.73056e+05
 3.68640e+04 3.68640e+04 3.68640e+04 1.63840e+04 1.63840e+04 1.63840e+04
 1.63840e+04 1.63840e+04 8.80000e+01]
Input_size  0.57421875
TESTING *****************************
Input size, BW, MIN:
350755662506666.6 1290262660.353818 1290262660.353818
All candidates indexes:  (array([ 5, 12, 13, 14, 15, 16, 17, 18, 19, 20]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 17
Intermediate:  0.123779296875
1.47705078125
Total layers size  4.185630798339844
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Candidate split  6
Server, client, server+client, vanilla  269.0791015625 360.3602294921875 629.4393310546875 745.8582763671875
Model size  217.79736328125
Fixed, scale_with_bsz  217.79736328125 2.05126953125
Mem usage  1500.0 3.0
Using split index: 6
Freezing the lower layers of the model (myalexnet) till index 17
The mode is:  split
Start 0, end 200, post_step 50

Memory occpied: (1500.0, 3.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.34036946296691895 seconds
Streaming plantleave data took 0.35025501251220703 seconds
The mode is:  split
Start 200, end 400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.34088778495788574
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.3490159511566162 seconds
Time for copying to cuda: 0.008059978485107422
Streaming plantleave data took 0.36044907569885254 seconds
Memory occpied: (1526.0, 326.0)
Memory occpied: (1526.0, 742.0)
Memory occpied: (1526.0, 1204.0)
Time for forward pass: 3.587139129638672
Time for backpropagation: 0.05231428146362305
GPU memory for training: 1.8592071533203125                          

One training iteration takes: 4.0501182079315186 seconds
Index: 0
Then, training+dataloading take 4.0501868724823 seconds
The mode is:  split
Start 400, end 600, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.45848608016967773 seconds
Time of next(dataloader) is: 0.45880603790283203
Time for copying to cuda: 0.007103681564331055
Streaming plantleave data took 0.47183752059936523 seconds
Time for forward pass: 0.03371405601501465
Time for backpropagation: 0.002828836441040039
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5754978656768799 seconds
Index: 1
Then, training+dataloading take 0.5756731033325195 seconds
The mode is:  split
Start 600, end 800, post_step 50


Epoch: 0
Memory occpied: (2222.0, 2084.0)
Time of next(dataloader) is: 0.4025113582611084
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.41070079803466797 seconds
Time for copying to cuda: 0.0075337886810302734
Streaming plantleave data took 0.4239025115966797 seconds
Time for forward pass: 0.03334856033325195
Time for backpropagation: 0.002627134323120117
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5195181369781494 seconds
Index: 2
Then, training+dataloading take 0.519559383392334 seconds
The mode is:  split
Start 800, end 1000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4212768077850342
Time for copying to cuda: 0.007985353469848633
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4298121929168701 seconds
Streaming plantleave data took 0.44286251068115234 seconds
Time for forward pass: 0.03330039978027344
Time for backpropagation: 0.0026743412017822266
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5424880981445312 seconds
Index: 3
Then, training+dataloading take 0.5425362586975098 seconds
The mode is:  split
Start 1000, end 1200, post_step 50


Epoch: 0
Memory occpied: (2222.0, 2084.0)
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.515007495880127 seconds
Time of next(dataloader) is: 0.5156798362731934
Time for copying to cuda: 0.007009983062744141
Streaming plantleave data took 0.528350830078125 seconds
Time for forward pass: 0.03994417190551758
Time for backpropagation: 0.0025687217712402344
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6652593612670898 seconds
Index: 4
Then, training+dataloading take 0.6653056144714355 seconds
The mode is:  split
Start 1200, end 1400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.416806697845459
Time for copying to cuda: 0.015019655227661133
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4441702365875244 seconds
Streaming plantleave data took 0.4572322368621826 seconds
Time for forward pass: 0.04354524612426758
Time for backpropagation: 0.0026106834411621094
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5808355808258057 seconds
Index: 5
Then, training+dataloading take 0.5810306072235107 seconds
The mode is:  split
Start 1400, end 1600, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5086443424224854 seconds
Time of next(dataloader) is: 0.5086343288421631
Time for copying to cuda: 0.007097005844116211
Streaming plantleave data took 0.5217990875244141 seconds
Time for forward pass: 0.043535709381103516
Time for backpropagation: 0.002645254135131836
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6786646842956543 seconds
Index: 6
Then, training+dataloading take 0.6787903308868408 seconds
The mode is:  split
Start 1600, end 1800, post_step 50


Epoch: 0
Memory occpied: (2222.0, 2084.0)
Time of next(dataloader) is: 0.4239010810852051
Time for copying to cuda: 0.012559175491333008
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.44948649406433105 seconds
Streaming plantleave data took 0.45989990234375 seconds
Time for forward pass: 0.043686866760253906
Time for backpropagation: 0.002776622772216797
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2222.0, 2084.0)
Memory occpied: (2222.0, 2084.0)
Memory occpied: (2222.0, 2084.0)
Memory occpied: (2222.0, 2084.0)
One training iteration takes: 5.510690212249756 seconds
Index: 7
Then, training+dataloading take 5.510763883590698 seconds
The mode is:  split
Start 1800, end 2000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4265580177307129 seconds
Time of next(dataloader) is: 0.4273834228515625
Time for copying to cuda: 0.007294654846191406
Streaming plantleave data took 0.4436764717102051 seconds
Time for forward pass: 0.043668270111083984
Time for backpropagation: 0.0026841163635253906
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.594512939453125 seconds
Index: 8
Then, training+dataloading take 0.5946385860443115 seconds
The mode is:  split
Start 2000, end 2200, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.48795199394226074
Time for copying to cuda: 0.017828702926635742
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.506558895111084 seconds
Streaming plantleave data took 0.5231385231018066 seconds
Time for forward pass: 0.04386162757873535
Time for backpropagation: 0.002776622772216797
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2222.0, 2084.0)
One training iteration takes: 0.648789644241333 seconds
Index: 9
Then, training+dataloading take 0.6488358974456787 seconds
The mode is:  split
Start 2200, end 2400, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.42058610916137695
Time for copying to cuda: 0.017290115356445312
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4384148120880127 seconds
Streaming plantleave data took 0.4513540267944336 seconds
Time for forward pass: 0.043643951416015625
Time for backpropagation: 0.0026586055755615234
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5835573673248291 seconds
Index: 10
Then, training+dataloading take 0.5836062431335449 seconds
The mode is:  split
Start 2400, end 2600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4843738079071045
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4849891662597656 seconds
Time for copying to cuda: 0.0074846744537353516
Streaming plantleave data took 0.5019176006317139 seconds
Time for forward pass: 0.06698775291442871
Time for backpropagation: 0.003160238265991211
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2222.0, 2084.0)
One training iteration takes: 0.6645078659057617 seconds
Index: 11
Then, training+dataloading take 0.6645638942718506 seconds
The mode is:  split
Start 2600, end 2800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4528646469116211
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.45357608795166016 seconds
Time for copying to cuda: 0.007132291793823242
Streaming plantleave data took 0.46630001068115234 seconds
Time for forward pass: 0.04373669624328613
Time for backpropagation: 0.00258636474609375
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5806803703308105 seconds
Index: 12
Then, training+dataloading take 0.5807242393493652 seconds
The mode is:  split
Start 2800, end 3000, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4900186061859131 seconds
Time of next(dataloader) is: 0.4911673069000244
Time for copying to cuda: 0.007292032241821289
Streaming plantleave data took 0.5076718330383301 seconds
Time for forward pass: 0.0690450668334961
Time for backpropagation: 0.003171682357788086
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2222.0, 2084.0)
One training iteration takes: 0.6741862297058105 seconds
Index: 13
Then, training+dataloading take 0.6742420196533203 seconds
The mode is:  split
Start 3000, end 3200, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.43409204483032227 seconds
Time of next(dataloader) is: 0.4352400302886963
Time for copying to cuda: 0.007220029830932617
Streaming plantleave data took 0.4514811038970947 seconds
Time for forward pass: 0.04359030723571777
Time for backpropagation: 0.002563953399658203
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5765104293823242 seconds
Index: 14
Then, training+dataloading take 0.5765552520751953 seconds
The mode is:  split
Start 3200, end 3400, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.5054609775543213 seconds
Time of next(dataloader) is: 0.5057692527770996
Time for copying to cuda: 0.007439613342285156
Streaming plantleave data took 0.5231161117553711 seconds
Time for forward pass: 0.06827282905578613
Time for backpropagation: 0.003145933151245117
GPU memory for training: 1.2210283279418945                          

Memory occpied: (2222.0, 2084.0)
One training iteration takes: 0.6881334781646729 seconds
Index: 15
Then, training+dataloading take 0.6881897449493408 seconds
The mode is:  split
Start 3400, end 3600, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.47313690185546875
Time for copying to cuda: 0.009500503540039062
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.48323583602905273 seconds
Streaming plantleave data took 0.5000624656677246 seconds
Time for forward pass: 0.04375314712524414
Time for backpropagation: 0.002557039260864258
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6159300804138184 seconds
Index: 16
Then, training+dataloading take 0.6159751415252686 seconds
The mode is:  split
Start 3600, end 3800, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.5806188583374023
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.594578742980957 seconds
Time for copying to cuda: 0.013697147369384766
Streaming plantleave data took 0.6117057800292969 seconds
Memory occpied: (2222.0, 2084.0)
Time for forward pass: 0.043892621994018555
Time for backpropagation: 0.002572298049926758
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.7340786457061768 seconds
Index: 17
Then, training+dataloading take 0.7341275215148926 seconds
The mode is:  split
Start 3800, end 4000, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.4351804256439209
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.4356508255004883 seconds
Time for copying to cuda: 0.0076062679290771484
Streaming plantleave data took 0.45265650749206543 seconds
Time for forward pass: 0.043683528900146484
Time for backpropagation: 0.0027091503143310547
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.584923505783081 seconds
Index: 18
Then, training+dataloading take 0.5849673748016357 seconds
The mode is:  split
Start 4000, end 4200, post_step 50


Epoch: 0
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.48514389991760254 seconds
Time of next(dataloader) is: 0.4861299991607666
Time for copying to cuda: 0.007255077362060547
Streaming plantleave data took 0.5027670860290527 seconds
Time for forward pass: 0.04364633560180664
Time for backpropagation: 0.0025675296783447266
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6565930843353271 seconds
Index: 19
Then, training+dataloading take 0.656714916229248 seconds
The mode is:  split
Start 4200, end 4400, post_step 50


Epoch: 0
Memory occpied: (2222.0, 2084.0)
Time of next(dataloader) is: 0.46851348876953125
Time for copying to cuda: 0.022662639617919922
Read 24.765094757080078 MBs for this batch
Executing all posts took 0.49215078353881836 seconds
Streaming plantleave data took 0.5094325542449951 seconds
Time for forward pass: 0.043845176696777344
Time for backpropagation: 0.002674102783203125
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.6279404163360596 seconds
Index: 20
Then, training+dataloading take 0.6279830932617188 seconds
The mode is:  split
Start 4400, end 4502, post_step 50


Epoch: 0
Time of next(dataloader) is: 0.39541196823120117
Time for copying to cuda: 0.015137195587158203
Read 12.630309104919434 MBs for this batch
Executing all posts took 0.41103243827819824 seconds
Streaming plantleave data took 0.43363499641418457 seconds
Time for forward pass: 0.0437777042388916
Time for backpropagation: 0.0025713443756103516
GPU memory for training: 1.2210283279418945                          

One training iteration takes: 0.5698192119598389 seconds
Index: 21
Then, training+dataloading take 0.569953203201294 seconds

Epoch: 0
Time of next(dataloader) is: 0.4375767707824707
Time for copying to cuda: 0.0036919116973876953
Time for forward pass: 0.20343923568725586
Time for backpropagation: 0.0036013126373291016
GPU memory for training: 1.673959732055664                          

Memory occpied: (2222.0, 2084.0)
The whole process took 30.428064584732056 seconds
