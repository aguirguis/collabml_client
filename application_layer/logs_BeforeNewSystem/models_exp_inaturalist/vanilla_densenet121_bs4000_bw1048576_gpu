Namespace(batch_size=4000, cpuonly=False, dataset='inaturalist', downloadall=False, end=10000, freeze=True, freeze_idx=20, model='densenet121', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (densenet121) till index 20
The mode is:  vanilla
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Memory occpied: (1326.0, 3.0)
Read 1056.3339109420776 MBs for this batch
Streaming inaturalist data took 22.174756050109863 seconds
The mode is:  vanilla

Epoch: 0
Time of next(dataloader) is: 18.479098796844482
Time for copying to cuda: 0.5948596000671387
Read 1077.8234357833862 MBs for this batch
Streaming inaturalist data took 20.73434042930603 seconds
Memory occpied: (1326.0, 3.0)
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torchvision/models/densenet.py", line 215, in forward
    features = self.features(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2421, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 5.98 GiB (GPU 0; 14.76 GiB total capacity; 8.28 GiB already allocated; 5.22 GiB free; 8.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The whole process took 55.91126298904419 seconds
