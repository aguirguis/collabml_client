Namespace(batch_size=1000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=36, model='myvgg19', num_epochs=1, sequential=False, split_choice='automatic', split_idx=100, start=0, testonly=False, use_intermediate=True)
==> Preparing data..
==> Building model..
INIT  1333.0 3.0
Error of iperf: the server is busy running a test. try again later
Recorded bandwidth: 908.2855256674147 Mbps
In _get_intermediate_outputs_and_time
Done intermediate outputs and time
Sizes  [1.2845056e+07 1.2845056e+07 1.2845056e+07 1.2845056e+07 3.2112640e+06
 6.4225280e+06 6.4225280e+06 6.4225280e+06 6.4225280e+06 1.6056320e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06 3.2112640e+06
 3.2112640e+06 3.2112640e+06 3.2112640e+06 8.0281600e+05 1.6056320e+06
 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06 1.6056320e+06
 1.6056320e+06 1.6056320e+06 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05 4.0140800e+05
 4.0140800e+05 1.0035200e+05 1.0035200e+05 1.6384000e+04 1.6384000e+04
 1.6384000e+04 1.6384000e+04 1.6384000e+04 1.6384000e+04 4.0000000e+03]
Input_size  133802.66666666666
TESTING *****************************
Input size, BW, MIN:
334506666.6666666 119050800.42027938 119050800.42027938
All candidates indexes:  (array([38, 39, 40, 41, 42, 43, 44]),)
SPLIT IDX CHOICE, split idx manual, freeze_idx:  automatic 100 36
Intermediate:  382.8125
115.9921875
Total layers size  119.34365844726562
Fixed, scale_with_bsz  548.0470275878906 116.56640625
Mem usage  8383.0 3.0
Using split index: 28
Freezing the lower layers of the model (myvgg19) till index 36
The mode is:  split
1
Start 0, end 1000, post_step 1000

Memory occpied: (9035.0, 3.0)
Memory occpied: (9035.0, 3.0)
Memory occpied: (9035.0, 3.0)
Memory occpied: (9035.0, 3.0)
Memory occpied: (9035.0, 3.0)
Memory occpied: (9035.0, 3.0)
Memory occpied: (9071.0, 348.0)
Memory occpied: (9167.0, 1110.0)
Memory occpied: (9263.0, 2511.0)
Memory occpied: (9779.0, 4135.0)
Memory occpied: (10035.0, 5343.0)
Memory occpied: (13319.0, 12087.0)
Memory occpied: (12109.0, 11071.0)
Memory occpied: (12185.0, 11095.0)
Memory occpied: (12897.0, 11111.0)
Memory occpied: (12897.0, 11111.0)
Memory occpied: (12925.0, 11119.0)
Memory occpied: (12941.0, 11534.0)
Memory occpied: (12941.0, 11958.0)
Memory occpied: (12941.0, 12336.0)
Memory occpied: (14167.0, 12932.0)
Memory occpied: (14167.0, 12932.0)
Memory occpied: (14167.0, 12948.0)
Memory occpied: (14183.0, 12948.0)
Read 382.8574380874634 MBs for this batch
Executing all posts took 26.90750026702881 seconds
Streaming imagenet data took 27.050231456756592 seconds
The mode is:  split
1
Start 1000, end 2000, post_step 1000


Epoch: 0
Time of next(dataloader) is: 0.47153234481811523
Memory occpied: (14567.0, 12948.0)
Time for copying to cuda: 0.1255784034729004
Memory occpied: (14567.0, 13585.0)
Memory occpied: (14567.0, 13991.0)
Memory occpied: (14567.0, 14385.0)
Exception: Caught RuntimeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/collabml_client/application_layer/models/myvgg.py", line 39, in forward
    x = m(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 1; 14.76 GiB total capacity; 742.03 MiB already allocated; 164.75 MiB free; 752.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Memory occpied: (15015.0, 14945.0)
The whole process took 41.763123750686646 seconds
Read 382.8574380874634 MBs for this batch
Executing all posts took 18.61547350883484 seconds
Streaming imagenet data took 18.770905256271362 seconds
Control connection MSS 1448
