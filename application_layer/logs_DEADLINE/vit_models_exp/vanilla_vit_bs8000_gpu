Namespace(batch_size=8000, cpuonly=False, dataset='imagenet', downloadall=False, end=10000, freeze=True, freeze_idx=17, manual_split=False, model='vit', num_epochs=1, sequential=False, split_idx=100, start=0, testonly=False, use_intermediate=False)
==> Preparing data..
==> Building model..
Using split index: 100
Freezing the lower layers of the model (vit) till index 17
The mode is:  vanilla
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Memory occpied: (1630.0, 3.0)
Read 988.8015155792236 MBs for this batch
Streaming imagenet data took 18.674309492111206 seconds
The mode is:  vanilla

Epoch: 0
Read 1024.4528188705444 MBs for this batch
Streaming imagenet data took 18.66845965385437 seconds
Time of next(dataloader) is: 26.14222812652588
Time for copying to cuda: 1.1737470626831055
Exception: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 433, in forward
    x = self.forward_features(x)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 421, in forward_features
    x = self.blocks(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 238, in forward
    x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/timm/models/vision_transformer.py", line 196, in forward
    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA out of memory. Tried to allocate 6.76 GiB (GPU 0; 14.76 GiB total capacity; 9.32 GiB already allocated; 4.15 GiB free; 9.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Memory occpied: (1630.0, 10822.0)
The whole process took 59.456438302993774 seconds
